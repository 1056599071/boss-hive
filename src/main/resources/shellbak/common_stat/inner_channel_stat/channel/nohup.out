开始执行20170818日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.368 seconds
Query ID = boss_20180102225648_d901414f-c344-454d-8d96-608745580d51
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158581, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158581/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158581
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-02 22:56:58,598 Stage-1 map = 0%,  reduce = 0%
2018-01-02 22:57:08,956 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 13.15 sec
2018-01-02 22:57:09,989 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 25.33 sec
2018-01-02 22:57:12,073 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 28.9 sec
2018-01-02 22:57:13,105 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 41.13 sec
2018-01-02 22:57:15,171 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 44.66 sec
2018-01-02 22:57:16,204 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 48.44 sec
2018-01-02 22:57:18,267 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 51.97 sec
2018-01-02 22:57:19,299 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 55.39 sec
2018-01-02 22:57:21,364 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 59.91 sec
2018-01-02 22:57:24,460 Stage-1 map = 53%,  reduce = 7%, Cumulative CPU 67.42 sec
2018-01-02 22:57:27,563 Stage-1 map = 56%,  reduce = 7%, Cumulative CPU 72.98 sec
2018-01-02 22:57:30,666 Stage-1 map = 59%,  reduce = 7%, Cumulative CPU 79.27 sec
2018-01-02 22:57:31,696 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 79.93 sec
2018-01-02 22:57:33,830 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 87.02 sec
2018-01-02 22:57:36,923 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 94.89 sec
2018-01-02 22:57:40,015 Stage-1 map = 69%,  reduce = 11%, Cumulative CPU 101.98 sec
2018-01-02 22:57:42,072 Stage-1 map = 71%,  reduce = 11%, Cumulative CPU 105.36 sec
2018-01-02 22:57:43,102 Stage-1 map = 74%,  reduce = 11%, Cumulative CPU 108.87 sec
2018-01-02 22:57:44,132 Stage-1 map = 86%,  reduce = 11%, Cumulative CPU 111.25 sec
2018-01-02 22:57:46,190 Stage-1 map = 87%,  reduce = 19%, Cumulative CPU 114.64 sec
2018-01-02 22:57:47,218 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 114.73 sec
2018-01-02 22:57:48,248 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 117.98 sec
2018-01-02 22:57:49,280 Stage-1 map = 100%,  reduce = 37%, Cumulative CPU 118.59 sec
2018-01-02 22:57:50,309 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 133.26 sec
MapReduce Total cumulative CPU time: 2 minutes 13 seconds 260 msec
Ended Job = job_1513599404024_158581
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158583, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158583/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158583
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 22:57:57,087 Stage-2 map = 0%,  reduce = 0%
2018-01-02 22:58:04,303 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.25 sec
2018-01-02 22:58:05,334 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.69 sec
2018-01-02 22:58:10,486 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.54 sec
MapReduce Total cumulative CPU time: 19 seconds 540 msec
Ended Job = job_1513599404024_158583
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158584, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158584/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158584
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 22:58:15,358 Stage-3 map = 0%,  reduce = 0%
2018-01-02 22:58:26,668 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.98 sec
2018-01-02 22:58:32,834 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.58 sec
MapReduce Total cumulative CPU time: 5 seconds 580 msec
Ended Job = job_1513599404024_158584
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 133.26 sec   HDFS Read: 371801693 HDFS Write: 2441478 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.54 sec   HDFS Read: 51005508 HDFS Write: 120424 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.58 sec   HDFS Read: 128099 HDFS Write: 3822 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 38 seconds 380 msec
OK
Time taken: 105.541 seconds, Fetched: 527 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.396 seconds
Query ID = boss_20180102225840_1bd78356-a172-4e99-bb6d-34318aee065c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 18
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158590, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158590/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158590
Hadoop job information for Stage-1: number of mappers: 23; number of reducers: 18
2018-01-02 22:58:57,763 Stage-1 map = 0%,  reduce = 0%
2018-01-02 22:59:08,190 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 113.25 sec
2018-01-02 22:59:09,226 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 191.64 sec
2018-01-02 22:59:10,260 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 207.34 sec
2018-01-02 22:59:11,297 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 232.75 sec
2018-01-02 22:59:12,328 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 282.21 sec
2018-01-02 22:59:14,418 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 335.02 sec
2018-01-02 22:59:15,460 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 377.86 sec
2018-01-02 22:59:16,490 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 398.35 sec
2018-01-02 22:59:17,520 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 421.02 sec
2018-01-02 22:59:18,549 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 461.41 sec
2018-01-02 22:59:19,578 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 469.15 sec
2018-01-02 22:59:20,611 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 493.78 sec
2018-01-02 22:59:21,639 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 513.37 sec
2018-01-02 22:59:22,674 Stage-1 map = 68%,  reduce = 2%, Cumulative CPU 531.96 sec
2018-01-02 22:59:23,704 Stage-1 map = 73%,  reduce = 6%, Cumulative CPU 565.78 sec
2018-01-02 22:59:24,735 Stage-1 map = 76%,  reduce = 6%, Cumulative CPU 573.15 sec
2018-01-02 22:59:25,764 Stage-1 map = 79%,  reduce = 8%, Cumulative CPU 579.67 sec
2018-01-02 22:59:26,794 Stage-1 map = 84%,  reduce = 10%, Cumulative CPU 592.67 sec
2018-01-02 22:59:27,822 Stage-1 map = 85%,  reduce = 12%, Cumulative CPU 596.91 sec
2018-01-02 22:59:28,850 Stage-1 map = 89%,  reduce = 12%, Cumulative CPU 603.1 sec
2018-01-02 22:59:29,882 Stage-1 map = 91%,  reduce = 13%, Cumulative CPU 606.2 sec
2018-01-02 22:59:30,911 Stage-1 map = 96%,  reduce = 20%, Cumulative CPU 620.81 sec
2018-01-02 22:59:31,939 Stage-1 map = 96%,  reduce = 24%, Cumulative CPU 623.75 sec
2018-01-02 22:59:32,968 Stage-1 map = 96%,  reduce = 25%, Cumulative CPU 625.21 sec
2018-01-02 22:59:33,998 Stage-1 map = 96%,  reduce = 26%, Cumulative CPU 625.92 sec
2018-01-02 22:59:36,055 Stage-1 map = 97%,  reduce = 27%, Cumulative CPU 639.84 sec
2018-01-02 22:59:37,085 Stage-1 map = 100%,  reduce = 29%, Cumulative CPU 643.19 sec
2018-01-02 22:59:38,114 Stage-1 map = 100%,  reduce = 85%, Cumulative CPU 693.84 sec
2018-01-02 22:59:39,147 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 706.0 sec
2018-01-02 22:59:46,343 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 710.14 sec
MapReduce Total cumulative CPU time: 11 minutes 50 seconds 140 msec
Ended Job = job_1513599404024_158590
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158592, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158592/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158592
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:00:00,187 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:00:07,405 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.41 sec
2018-01-02 23:00:17,705 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.91 sec
2018-01-02 23:00:21,824 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.27 sec
2018-01-02 23:00:24,911 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 13.01 sec
2018-01-02 23:00:25,938 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.29 sec
MapReduce Total cumulative CPU time: 17 seconds 290 msec
Ended Job = job_1513599404024_158592
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158595, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158595/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158595
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:00:33,710 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:00:38,889 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.76 sec
2018-01-02 23:00:45,064 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.84 sec
MapReduce Total cumulative CPU time: 5 seconds 840 msec
Ended Job = job_1513599404024_158595
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 23  Reduce: 18   Cumulative CPU: 710.14 sec   HDFS Read: 1638613118 HDFS Write: 584468 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.29 sec   HDFS Read: 49152428 HDFS Write: 27681 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.84 sec   HDFS Read: 35357 HDFS Write: 3239 SUCCESS
Total MapReduce CPU Time Spent: 12 minutes 13 seconds 270 msec
OK
Time taken: 125.537 seconds, Fetched: 427 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180102230100_a1ad2a63-403a-4302-beb1-d3cf906cc870
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158598, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158598/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158598
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:01:19,013 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:01:43,826 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 10.36 sec
2018-01-02 23:01:46,920 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.51 sec
2018-01-02 23:01:50,018 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 15.87 sec
2018-01-02 23:01:53,111 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 16.64 sec
2018-01-02 23:01:56,203 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 17.6 sec
2018-01-02 23:01:59,297 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 18.23 sec
2018-01-02 23:02:02,390 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 18.92 sec
2018-01-02 23:02:05,484 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 19.99 sec
2018-01-02 23:02:08,576 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 20.68 sec
2018-01-02 23:02:11,667 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 21.81 sec
2018-01-02 23:02:13,729 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 21.81 sec
2018-01-02 23:02:16,980 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 23.0 sec
2018-01-02 23:02:20,068 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 23.94 sec
2018-01-02 23:02:23,154 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 35.85 sec
2018-01-02 23:02:26,239 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 36.65 sec
2018-01-02 23:02:29,326 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 37.21 sec
2018-01-02 23:02:32,410 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 37.68 sec
2018-01-02 23:02:35,492 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 38.01 sec
2018-01-02 23:02:38,579 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 38.63 sec
2018-01-02 23:02:41,660 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 44.62 sec
2018-01-02 23:02:44,741 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 45.53 sec
2018-01-02 23:02:47,824 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 45.92 sec
2018-01-02 23:02:50,905 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 46.41 sec
2018-01-02 23:02:53,986 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 47.04 sec
2018-01-02 23:02:57,070 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 47.51 sec
2018-01-02 23:03:00,149 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 48.61 sec
2018-01-02 23:03:03,228 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 50.41 sec
2018-01-02 23:03:06,310 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 50.84 sec
2018-01-02 23:03:09,389 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 52.73 sec
2018-01-02 23:03:22,748 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 58.84 sec
MapReduce Total cumulative CPU time: 58 seconds 840 msec
Ended Job = job_1513599404024_158598
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158609, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158609/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158609
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:03:37,218 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:03:42,378 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.25 sec
2018-01-02 23:03:48,567 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.97 sec
2018-01-02 23:03:50,639 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.7 sec
MapReduce Total cumulative CPU time: 17 seconds 700 msec
Ended Job = job_1513599404024_158609
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158613, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158613/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158613
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:04:04,413 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:04:13,668 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.9 sec
2018-01-02 23:04:32,178 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 12.42 sec
MapReduce Total cumulative CPU time: 12 seconds 420 msec
Ended Job = job_1513599404024_158613
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 58.84 sec   HDFS Read: 114332981 HDFS Write: 725728 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.7 sec   HDFS Read: 49289178 HDFS Write: 236114 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 12.42 sec   HDFS Read: 243751 HDFS Write: 7578 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 28 seconds 960 msec
OK
Time taken: 212.404 seconds, Fetched: 936 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180102230439_f6efefb8-69d6-472f-b03f-d80afd930762
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158617, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158617/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158617
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:04:52,240 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:05:02,609 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 8.99 sec
2018-01-02 23:05:05,709 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 12.61 sec
2018-01-02 23:05:08,802 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 13.86 sec
2018-01-02 23:05:11,892 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.25 sec
2018-01-02 23:05:14,985 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 16.35 sec
2018-01-02 23:05:18,074 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 16.91 sec
2018-01-02 23:05:21,160 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 17.48 sec
2018-01-02 23:05:24,250 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 18.49 sec
2018-01-02 23:05:27,336 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 19.61 sec
2018-01-02 23:05:30,422 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 20.43 sec
2018-01-02 23:05:32,482 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 20.56 sec
2018-01-02 23:05:35,567 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 22.45 sec
2018-01-02 23:05:38,652 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 23.82 sec
2018-01-02 23:05:41,739 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 24.56 sec
2018-01-02 23:05:44,823 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 25.63 sec
2018-01-02 23:05:47,911 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 27.61 sec
2018-01-02 23:05:49,972 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 29.29 sec
2018-01-02 23:06:04,399 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.37 sec
MapReduce Total cumulative CPU time: 35 seconds 370 msec
Ended Job = job_1513599404024_158617
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158625, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158625/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158625
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:06:26,245 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:06:42,758 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 12.3 sec
2018-01-02 23:06:43,789 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 24.16 sec
2018-01-02 23:07:01,276 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 32.38 sec
MapReduce Total cumulative CPU time: 32 seconds 380 msec
Ended Job = job_1513599404024_158625
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158629, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158629/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158629
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:07:29,147 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:07:34,298 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.99 sec
2018-01-02 23:07:43,948 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.41 sec
MapReduce Total cumulative CPU time: 9 seconds 410 msec
Ended Job = job_1513599404024_158629
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.37 sec   HDFS Read: 114332971 HDFS Write: 2065090 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 32.38 sec   HDFS Read: 50628540 HDFS Write: 150011 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.41 sec   HDFS Read: 157649 HDFS Write: 2942 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 17 seconds 160 msec
OK
Time taken: 185.08 seconds, Fetched: 435 row(s)
开始执行20170819日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.366 seconds
Query ID = boss_20180102230752_1207646b-08f2-4595-b541-a10adfd87a7c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158632, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158632/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158632
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-02 23:08:03,231 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:08:10,506 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 8.04 sec
2018-01-02 23:08:15,675 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 20.96 sec
2018-01-02 23:08:18,771 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 24.96 sec
2018-01-02 23:08:19,803 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 36.02 sec
2018-01-02 23:08:21,872 Stage-1 map = 39%,  reduce = 4%, Cumulative CPU 36.62 sec
2018-01-02 23:08:22,907 Stage-1 map = 40%,  reduce = 7%, Cumulative CPU 43.57 sec
2018-01-02 23:08:24,971 Stage-1 map = 41%,  reduce = 7%, Cumulative CPU 46.42 sec
2018-01-02 23:08:28,063 Stage-1 map = 42%,  reduce = 7%, Cumulative CPU 62.69 sec
2018-01-02 23:08:29,094 Stage-1 map = 44%,  reduce = 7%, Cumulative CPU 66.39 sec
2018-01-02 23:08:30,123 Stage-1 map = 44%,  reduce = 11%, Cumulative CPU 66.95 sec
2018-01-02 23:08:31,153 Stage-1 map = 45%,  reduce = 11%, Cumulative CPU 68.7 sec
2018-01-02 23:08:32,211 Stage-1 map = 46%,  reduce = 11%, Cumulative CPU 83.71 sec
2018-01-02 23:08:34,274 Stage-1 map = 47%,  reduce = 11%, Cumulative CPU 86.46 sec
2018-01-02 23:08:35,306 Stage-1 map = 48%,  reduce = 11%, Cumulative CPU 89.83 sec
2018-01-02 23:08:37,365 Stage-1 map = 50%,  reduce = 11%, Cumulative CPU 92.84 sec
2018-01-02 23:08:38,396 Stage-1 map = 52%,  reduce = 11%, Cumulative CPU 96.57 sec
2018-01-02 23:08:40,454 Stage-1 map = 53%,  reduce = 11%, Cumulative CPU 99.01 sec
2018-01-02 23:08:41,484 Stage-1 map = 55%,  reduce = 11%, Cumulative CPU 102.27 sec
2018-01-02 23:08:43,546 Stage-1 map = 56%,  reduce = 11%, Cumulative CPU 104.13 sec
2018-01-02 23:08:44,577 Stage-1 map = 57%,  reduce = 11%, Cumulative CPU 107.29 sec
2018-01-02 23:08:46,637 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 110.29 sec
2018-01-02 23:08:47,666 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 119.6 sec
2018-01-02 23:08:49,723 Stage-1 map = 62%,  reduce = 11%, Cumulative CPU 122.72 sec
2018-01-02 23:08:51,779 Stage-1 map = 63%,  reduce = 11%, Cumulative CPU 138.91 sec
2018-01-02 23:08:52,811 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 141.28 sec
2018-01-02 23:08:54,868 Stage-1 map = 67%,  reduce = 11%, Cumulative CPU 144.18 sec
2018-01-02 23:08:55,897 Stage-1 map = 68%,  reduce = 11%, Cumulative CPU 146.94 sec
2018-01-02 23:08:57,953 Stage-1 map = 70%,  reduce = 11%, Cumulative CPU 149.89 sec
2018-01-02 23:08:58,981 Stage-1 map = 71%,  reduce = 11%, Cumulative CPU 153.36 sec
2018-01-02 23:09:01,037 Stage-1 map = 84%,  reduce = 15%, Cumulative CPU 156.61 sec
2018-01-02 23:09:02,065 Stage-1 map = 86%,  reduce = 15%, Cumulative CPU 159.05 sec
2018-01-02 23:09:03,096 Stage-1 map = 86%,  reduce = 19%, Cumulative CPU 159.19 sec
2018-01-02 23:09:04,126 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 159.27 sec
2018-01-02 23:09:05,155 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 162.06 sec
2018-01-02 23:09:08,239 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 164.74 sec
2018-01-02 23:09:09,270 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 166.31 sec
2018-01-02 23:09:10,298 Stage-1 map = 100%,  reduce = 41%, Cumulative CPU 167.08 sec
2018-01-02 23:09:11,326 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 174.9 sec
2018-01-02 23:09:12,358 Stage-1 map = 100%,  reduce = 89%, Cumulative CPU 176.69 sec
2018-01-02 23:09:14,413 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 181.54 sec
MapReduce Total cumulative CPU time: 3 minutes 1 seconds 540 msec
Ended Job = job_1513599404024_158632
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158637, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158637/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158637
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:09:27,250 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:09:39,624 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 7.79 sec
2018-01-02 23:09:47,855 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 16.94 sec
2018-01-02 23:09:49,911 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.98 sec
MapReduce Total cumulative CPU time: 23 seconds 980 msec
Ended Job = job_1513599404024_158637
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158641, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158641/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158641
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:09:55,631 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:10:05,929 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.71 sec
2018-01-02 23:10:15,191 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.6 sec
MapReduce Total cumulative CPU time: 7 seconds 600 msec
Ended Job = job_1513599404024_158641
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 181.54 sec   HDFS Read: 364205388 HDFS Write: 2465775 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.98 sec   HDFS Read: 50277511 HDFS Write: 123118 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.6 sec   HDFS Read: 130793 HDFS Write: 3861 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 33 seconds 120 msec
OK
Time taken: 145.211 seconds, Fetched: 533 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.382 seconds
Query ID = boss_20180102231024_a0c50050-1b3f-4fd7-83d8-e9d18f84a002
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 18
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158644, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158644/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158644
Hadoop job information for Stage-1: number of mappers: 24; number of reducers: 18
2018-01-02 23:10:34,807 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:10:46,223 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 81.12 sec
2018-01-02 23:10:47,257 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 178.5 sec
2018-01-02 23:10:49,332 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 237.57 sec
2018-01-02 23:10:50,366 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 327.28 sec
2018-01-02 23:10:52,432 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 409.81 sec
2018-01-02 23:10:53,464 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 468.64 sec
2018-01-02 23:10:54,616 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 499.13 sec
2018-01-02 23:10:55,669 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 540.39 sec
2018-01-02 23:10:56,701 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 587.28 sec
2018-01-02 23:10:57,735 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 647.18 sec
2018-01-02 23:10:58,767 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 661.81 sec
2018-01-02 23:11:00,828 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 738.38 sec
2018-01-02 23:11:02,895 Stage-1 map = 85%,  reduce = 3%, Cumulative CPU 751.16 sec
2018-01-02 23:11:03,936 Stage-1 map = 87%,  reduce = 10%, Cumulative CPU 765.53 sec
2018-01-02 23:11:04,969 Stage-1 map = 89%,  reduce = 13%, Cumulative CPU 773.25 sec
2018-01-02 23:11:06,001 Stage-1 map = 89%,  reduce = 22%, Cumulative CPU 779.25 sec
2018-01-02 23:11:07,037 Stage-1 map = 93%,  reduce = 24%, Cumulative CPU 819.67 sec
2018-01-02 23:11:08,068 Stage-1 map = 95%,  reduce = 25%, Cumulative CPU 822.28 sec
2018-01-02 23:11:09,100 Stage-1 map = 95%,  reduce = 27%, Cumulative CPU 824.19 sec
2018-01-02 23:11:10,131 Stage-1 map = 95%,  reduce = 29%, Cumulative CPU 830.06 sec
2018-01-02 23:11:11,161 Stage-1 map = 98%,  reduce = 31%, Cumulative CPU 833.41 sec
2018-01-02 23:11:13,224 Stage-1 map = 100%,  reduce = 32%, Cumulative CPU 839.01 sec
2018-01-02 23:11:14,255 Stage-1 map = 100%,  reduce = 43%, Cumulative CPU 849.66 sec
2018-01-02 23:11:15,286 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 867.75 sec
2018-01-02 23:11:16,316 Stage-1 map = 100%,  reduce = 87%, Cumulative CPU 893.6 sec
2018-01-02 23:11:17,348 Stage-1 map = 100%,  reduce = 89%, Cumulative CPU 897.42 sec
2018-01-02 23:11:18,377 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 917.24 sec
2018-01-02 23:11:19,407 Stage-1 map = 100%,  reduce = 99%, Cumulative CPU 920.89 sec
2018-01-02 23:11:20,436 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 925.23 sec
MapReduce Total cumulative CPU time: 15 minutes 25 seconds 230 msec
Ended Job = job_1513599404024_158644
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158653, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158653/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158653
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:11:26,458 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:11:32,662 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.16 sec
2018-01-02 23:11:47,096 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.28 sec
MapReduce Total cumulative CPU time: 18 seconds 280 msec
Ended Job = job_1513599404024_158653
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158666, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158666/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158666
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:12:12,867 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:12:30,513 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.86 sec
2018-01-02 23:12:58,998 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 12.13 sec
2018-01-02 23:13:01,058 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 15.09 sec
MapReduce Total cumulative CPU time: 15 seconds 90 msec
Ended Job = job_1513599404024_158666
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 24  Reduce: 18   Cumulative CPU: 925.23 sec   HDFS Read: 1636541179 HDFS Write: 624673 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.28 sec   HDFS Read: 48440339 HDFS Write: 28242 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 15.09 sec   HDFS Read: 35918 HDFS Write: 3120 SUCCESS
Total MapReduce CPU Time Spent: 15 minutes 58 seconds 600 msec
OK
Time taken: 158.105 seconds, Fetched: 433 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180102231308_6760954a-d856-4b2b-aec8-90137437a7a8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158691, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158691/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158691
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:13:27,984 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:13:38,353 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 9.2 sec
2018-01-02 23:13:41,455 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 11.68 sec
2018-01-02 23:13:44,556 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 12.65 sec
2018-01-02 23:13:47,659 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 13.75 sec
2018-01-02 23:13:50,768 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 14.87 sec
2018-01-02 23:13:52,998 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 15.52 sec
2018-01-02 23:13:56,089 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 15.91 sec
2018-01-02 23:13:59,195 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 16.49 sec
2018-01-02 23:14:02,288 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 17.02 sec
2018-01-02 23:14:05,379 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 17.72 sec
2018-01-02 23:14:08,475 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 18.54 sec
2018-01-02 23:14:11,569 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 19.01 sec
2018-01-02 23:14:14,671 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 19.91 sec
2018-01-02 23:14:17,765 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 20.59 sec
2018-01-02 23:14:20,901 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 20.81 sec
2018-01-02 23:14:23,987 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 21.3 sec
2018-01-02 23:14:27,079 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 22.46 sec
2018-01-02 23:14:29,138 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 23.34 sec
2018-01-02 23:14:32,222 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 23.79 sec
2018-01-02 23:14:35,308 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 24.36 sec
2018-01-02 23:14:38,391 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 27.7 sec
2018-01-02 23:14:41,491 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 28.29 sec
2018-01-02 23:14:44,580 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 28.7 sec
2018-01-02 23:14:45,609 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 29.78 sec
2018-01-02 23:14:50,755 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 33.95 sec
MapReduce Total cumulative CPU time: 33 seconds 950 msec
Ended Job = job_1513599404024_158691
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158720, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158720/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158720
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:15:11,388 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:15:19,642 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.27 sec
2018-01-02 23:15:28,916 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.17 sec
2018-01-02 23:15:32,005 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.2 sec
MapReduce Total cumulative CPU time: 19 seconds 200 msec
Ended Job = job_1513599404024_158720
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158740, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158740/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158740
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:15:45,110 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:15:59,542 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.9 sec
2018-01-02 23:16:04,879 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.03 sec
MapReduce Total cumulative CPU time: 8 seconds 30 msec
Ended Job = job_1513599404024_158740
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 33.95 sec   HDFS Read: 110763400 HDFS Write: 661241 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.2 sec   HDFS Read: 48472397 HDFS Write: 236907 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.03 sec   HDFS Read: 244544 HDFS Write: 7447 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 180 msec
OK
Time taken: 178.15 seconds, Fetched: 928 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.375 seconds
Query ID = boss_20180102231614_4f06e1b2-cdf0-4edf-beb6-721d4701e497
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158759, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158759/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158759
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:16:37,547 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:16:51,025 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 12.14 sec
2018-01-02 23:16:55,160 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 19.87 sec
2018-01-02 23:16:58,277 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 23.12 sec
2018-01-02 23:17:02,407 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 25.21 sec
2018-01-02 23:17:05,500 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 27.07 sec
2018-01-02 23:17:08,606 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 27.9 sec
2018-01-02 23:17:11,702 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 36.83 sec
2018-01-02 23:17:14,792 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 37.99 sec
2018-01-02 23:17:17,885 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 39.6 sec
2018-01-02 23:17:20,974 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 41.29 sec
2018-01-02 23:17:24,061 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 42.94 sec
2018-01-02 23:17:27,153 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 53.63 sec
2018-01-02 23:17:30,238 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 54.72 sec
2018-01-02 23:17:33,323 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 57.48 sec
2018-01-02 23:17:36,412 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 60.22 sec
2018-01-02 23:17:38,469 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 62.16 sec
2018-01-02 23:17:42,583 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 64.13 sec
2018-01-02 23:17:45,671 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 70.1 sec
2018-01-02 23:17:48,756 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 71.02 sec
2018-01-02 23:17:49,784 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 72.43 sec
2018-01-02 23:17:55,961 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 78.71 sec
MapReduce Total cumulative CPU time: 1 minutes 18 seconds 710 msec
Ended Job = job_1513599404024_158759
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158780, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158780/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158780
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:18:02,831 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:18:10,044 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.57 sec
2018-01-02 23:18:15,194 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.6 sec
2018-01-02 23:18:20,338 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.88 sec
MapReduce Total cumulative CPU time: 19 seconds 880 msec
Ended Job = job_1513599404024_158780
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158785, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158785/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158785
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:18:26,985 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:18:34,194 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.98 sec
2018-01-02 23:18:41,390 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.05 sec
MapReduce Total cumulative CPU time: 7 seconds 50 msec
Ended Job = job_1513599404024_158785
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 78.71 sec   HDFS Read: 110763390 HDFS Write: 2026941 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.88 sec   HDFS Read: 49838097 HDFS Write: 134018 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.05 sec   HDFS Read: 141656 HDFS Write: 2929 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 45 seconds 640 msec
OK
Time taken: 148.403 seconds, Fetched: 431 row(s)
开始执行20170820日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.366 seconds
Query ID = boss_20180102231849_cd41089d-21a9-47bd-a9a1-7ff072d0d606
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158797, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158797/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158797
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-02 23:19:01,401 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:19:07,654 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 7.39 sec
2018-01-02 23:19:11,786 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 18.94 sec
2018-01-02 23:19:12,819 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 30.9 sec
2018-01-02 23:19:14,887 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 34.45 sec
2018-01-02 23:19:15,919 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 37.94 sec
2018-01-02 23:19:17,993 Stage-1 map = 44%,  reduce = 4%, Cumulative CPU 41.59 sec
2018-01-02 23:19:19,026 Stage-1 map = 46%,  reduce = 7%, Cumulative CPU 45.41 sec
2018-01-02 23:19:20,062 Stage-1 map = 49%,  reduce = 7%, Cumulative CPU 48.79 sec
2018-01-02 23:19:21,095 Stage-1 map = 51%,  reduce = 7%, Cumulative CPU 52.15 sec
2018-01-02 23:19:23,160 Stage-1 map = 53%,  reduce = 11%, Cumulative CPU 55.63 sec
2018-01-02 23:19:24,191 Stage-1 map = 54%,  reduce = 11%, Cumulative CPU 58.77 sec
2018-01-02 23:19:26,251 Stage-1 map = 55%,  reduce = 11%, Cumulative CPU 66.16 sec
2018-01-02 23:19:27,282 Stage-1 map = 57%,  reduce = 11%, Cumulative CPU 69.33 sec
2018-01-02 23:19:29,342 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 74.55 sec
2018-01-02 23:19:30,373 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 77.51 sec
2018-01-02 23:19:32,434 Stage-1 map = 63%,  reduce = 11%, Cumulative CPU 81.4 sec
2018-01-02 23:19:33,467 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 84.38 sec
2018-01-02 23:19:35,525 Stage-1 map = 66%,  reduce = 11%, Cumulative CPU 89.23 sec
2018-01-02 23:19:36,555 Stage-1 map = 68%,  reduce = 11%, Cumulative CPU 91.51 sec
2018-01-02 23:19:38,613 Stage-1 map = 81%,  reduce = 11%, Cumulative CPU 95.47 sec
2018-01-02 23:19:39,642 Stage-1 map = 82%,  reduce = 15%, Cumulative CPU 98.84 sec
2018-01-02 23:19:40,672 Stage-1 map = 82%,  reduce = 19%, Cumulative CPU 98.84 sec
2018-01-02 23:19:41,700 Stage-1 map = 82%,  reduce = 22%, Cumulative CPU 98.93 sec
2018-01-02 23:19:42,734 Stage-1 map = 84%,  reduce = 22%, Cumulative CPU 102.4 sec
2018-01-02 23:19:45,820 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 106.08 sec
2018-01-02 23:19:48,908 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 109.26 sec
2018-01-02 23:19:51,996 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 113.17 sec
2018-01-02 23:19:53,025 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 120.0 sec
2018-01-02 23:19:54,052 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 129.58 sec
MapReduce Total cumulative CPU time: 2 minutes 9 seconds 580 msec
Ended Job = job_1513599404024_158797
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158818, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158818/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158818
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:19:59,749 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:20:05,927 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.92 sec
2018-01-02 23:20:07,986 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.3 sec
2018-01-02 23:20:11,076 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.07 sec
MapReduce Total cumulative CPU time: 18 seconds 70 msec
Ended Job = job_1513599404024_158818
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158829, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158829/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158829
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:20:18,738 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:20:23,965 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.68 sec
2018-01-02 23:20:30,135 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.98 sec
MapReduce Total cumulative CPU time: 5 seconds 980 msec
Ended Job = job_1513599404024_158829
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 129.58 sec   HDFS Read: 365792053 HDFS Write: 2462262 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.07 sec   HDFS Read: 51917533 HDFS Write: 123484 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.98 sec   HDFS Read: 131159 HDFS Write: 3848 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 33 seconds 630 msec
OK
Time taken: 101.81 seconds, Fetched: 520 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.386 seconds
Query ID = boss_20180102232045_d25fb550-1ce7-4f3f-ac6e-91ede83925c5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 18
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158848, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158848/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158848
Hadoop job information for Stage-1: number of mappers: 25; number of reducers: 18
2018-01-02 23:20:54,802 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:21:04,206 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 68.01 sec
2018-01-02 23:21:05,240 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 181.89 sec
2018-01-02 23:21:06,272 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 212.65 sec
2018-01-02 23:21:07,331 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 219.08 sec
2018-01-02 23:21:08,369 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 245.62 sec
2018-01-02 23:21:09,400 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 255.23 sec
2018-01-02 23:21:10,433 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 322.0 sec
2018-01-02 23:21:11,466 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 345.36 sec
2018-01-02 23:21:12,498 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 364.73 sec
2018-01-02 23:21:13,532 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 382.66 sec
2018-01-02 23:21:14,565 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 389.58 sec
2018-01-02 23:21:15,603 Stage-1 map = 71%,  reduce = 6%, Cumulative CPU 401.57 sec
2018-01-02 23:21:16,637 Stage-1 map = 72%,  reduce = 11%, Cumulative CPU 423.93 sec
2018-01-02 23:21:17,672 Stage-1 map = 74%,  reduce = 16%, Cumulative CPU 430.56 sec
2018-01-02 23:21:18,702 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 434.32 sec
2018-01-02 23:21:19,736 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 447.8 sec
2018-01-02 23:21:20,771 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 450.82 sec
2018-01-02 23:21:21,801 Stage-1 map = 78%,  reduce = 19%, Cumulative CPU 470.52 sec
2018-01-02 23:21:22,918 Stage-1 map = 78%,  reduce = 21%, Cumulative CPU 495.52 sec
2018-01-02 23:21:23,951 Stage-1 map = 78%,  reduce = 24%, Cumulative CPU 497.61 sec
2018-01-02 23:21:24,981 Stage-1 map = 79%,  reduce = 25%, Cumulative CPU 502.28 sec
2018-01-02 23:21:26,013 Stage-1 map = 80%,  reduce = 25%, Cumulative CPU 515.03 sec
2018-01-02 23:21:28,085 Stage-1 map = 82%,  reduce = 25%, Cumulative CPU 521.82 sec
2018-01-02 23:21:29,246 Stage-1 map = 85%,  reduce = 25%, Cumulative CPU 528.13 sec
2018-01-02 23:21:30,287 Stage-1 map = 85%,  reduce = 26%, Cumulative CPU 529.65 sec
2018-01-02 23:21:31,320 Stage-1 map = 85%,  reduce = 28%, Cumulative CPU 531.66 sec
2018-01-02 23:21:38,604 Stage-1 map = 86%,  reduce = 28%, Cumulative CPU 622.41 sec
2018-01-02 23:21:39,744 Stage-1 map = 88%,  reduce = 28%, Cumulative CPU 628.01 sec
2018-01-02 23:21:42,839 Stage-1 map = 90%,  reduce = 28%, Cumulative CPU 655.55 sec
2018-01-02 23:21:43,868 Stage-1 map = 92%,  reduce = 29%, Cumulative CPU 659.95 sec
2018-01-02 23:21:44,897 Stage-1 map = 92%,  reduce = 30%, Cumulative CPU 668.66 sec
2018-01-02 23:21:46,958 Stage-1 map = 92%,  reduce = 31%, Cumulative CPU 671.16 sec
2018-01-02 23:21:47,986 Stage-1 map = 93%,  reduce = 31%, Cumulative CPU 675.93 sec
2018-01-02 23:21:49,017 Stage-1 map = 94%,  reduce = 31%, Cumulative CPU 691.9 sec
2018-01-02 23:21:52,101 Stage-1 map = 95%,  reduce = 31%, Cumulative CPU 697.8 sec
2018-01-02 23:21:55,183 Stage-1 map = 97%,  reduce = 31%, Cumulative CPU 717.01 sec
2018-01-02 23:21:56,214 Stage-1 map = 98%,  reduce = 31%, Cumulative CPU 720.88 sec
2018-01-02 23:21:57,241 Stage-1 map = 98%,  reduce = 32%, Cumulative CPU 721.53 sec
2018-01-02 23:21:58,269 Stage-1 map = 100%,  reduce = 36%, Cumulative CPU 725.29 sec
2018-01-02 23:21:59,297 Stage-1 map = 100%,  reduce = 76%, Cumulative CPU 763.57 sec
2018-01-02 23:22:00,326 Stage-1 map = 100%,  reduce = 85%, Cumulative CPU 774.94 sec
2018-01-02 23:22:01,358 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 788.89 sec
2018-01-02 23:22:02,386 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 801.08 sec
MapReduce Total cumulative CPU time: 13 minutes 21 seconds 80 msec
Ended Job = job_1513599404024_158848
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158868, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158868/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158868
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:22:19,588 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:22:28,865 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.78 sec
2018-01-02 23:22:29,895 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.68 sec
2018-01-02 23:22:36,071 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.21 sec
MapReduce Total cumulative CPU time: 18 seconds 210 msec
Ended Job = job_1513599404024_158868
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158876, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158876/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158876
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:22:58,759 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:23:10,106 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.0 sec
2018-01-02 23:23:18,339 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.37 sec
MapReduce Total cumulative CPU time: 6 seconds 370 msec
Ended Job = job_1513599404024_158876
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 25  Reduce: 18   Cumulative CPU: 801.08 sec   HDFS Read: 1654485969 HDFS Write: 651461 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.21 sec   HDFS Read: 50110641 HDFS Write: 27949 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.37 sec   HDFS Read: 35621 HDFS Write: 2969 SUCCESS
Total MapReduce CPU Time Spent: 13 minutes 45 seconds 660 msec
OK
Time taken: 153.51 seconds, Fetched: 421 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.35 seconds
Query ID = boss_20180102232334_0ac46838-272a-44c9-8b4e-5a1f1a537773
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158890, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158890/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158890
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:23:44,115 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:23:53,435 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 8.42 sec
2018-01-02 23:23:56,536 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 9.83 sec
2018-01-02 23:24:01,689 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.9 sec
2018-01-02 23:24:07,868 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 32.25 sec
2018-01-02 23:24:10,953 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 32.89 sec
2018-01-02 23:24:14,045 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 33.28 sec
2018-01-02 23:24:17,137 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 33.81 sec
2018-01-02 23:24:20,219 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 34.5 sec
2018-01-02 23:24:23,301 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 35.19 sec
2018-01-02 23:24:26,389 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 35.57 sec
2018-01-02 23:24:29,472 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 35.93 sec
2018-01-02 23:24:32,559 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 36.37 sec
2018-01-02 23:24:35,642 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 36.84 sec
2018-01-02 23:24:38,722 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 38.82 sec
2018-01-02 23:24:41,804 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 39.98 sec
2018-01-02 23:24:44,885 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 40.24 sec
2018-01-02 23:24:47,965 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 40.49 sec
2018-01-02 23:24:51,050 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 41.08 sec
2018-01-02 23:24:54,129 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 41.33 sec
2018-01-02 23:24:57,209 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 41.69 sec
2018-01-02 23:25:00,288 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 42.17 sec
2018-01-02 23:25:03,369 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 42.41 sec
2018-01-02 23:25:06,446 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 43.54 sec
2018-01-02 23:25:09,524 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 44.02 sec
2018-01-02 23:25:12,608 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 44.47 sec
2018-01-02 23:25:13,636 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 46.02 sec
2018-01-02 23:25:19,806 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 52.76 sec
MapReduce Total cumulative CPU time: 52 seconds 760 msec
Ended Job = job_1513599404024_158890
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158911, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158911/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158911
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:25:39,627 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:25:44,797 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.9 sec
2018-01-02 23:25:46,860 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.47 sec
2018-01-02 23:25:52,013 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.52 sec
MapReduce Total cumulative CPU time: 14 seconds 520 msec
Ended Job = job_1513599404024_158911
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158919, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158919/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158919
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:25:57,646 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:26:08,974 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.67 sec
2018-01-02 23:26:15,145 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.51 sec
MapReduce Total cumulative CPU time: 7 seconds 510 msec
Ended Job = job_1513599404024_158919
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 52.76 sec   HDFS Read: 109472849 HDFS Write: 657669 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.52 sec   HDFS Read: 50112360 HDFS Write: 239164 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.51 sec   HDFS Read: 246801 HDFS Write: 7637 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 14 seconds 790 msec
OK
Time taken: 163.133 seconds, Fetched: 936 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180102232623_1d357a83-e251-4908-9e68-f9ea45658c23
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158933, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158933/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158933
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:26:35,289 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:26:46,686 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 7.94 sec
2018-01-02 23:26:49,786 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 8.8 sec
2018-01-02 23:26:52,879 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 10.57 sec
2018-01-02 23:26:55,973 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 13.17 sec
2018-01-02 23:26:59,063 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 13.86 sec
2018-01-02 23:27:02,151 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 15.09 sec
2018-01-02 23:27:05,242 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 17.3 sec
2018-01-02 23:27:08,330 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 17.97 sec
2018-01-02 23:27:11,415 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 18.57 sec
2018-01-02 23:27:14,506 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 20.13 sec
2018-01-02 23:27:17,594 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 21.02 sec
2018-01-02 23:27:19,654 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 21.97 sec
2018-01-02 23:27:22,740 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 23.02 sec
2018-01-02 23:27:25,828 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 23.67 sec
2018-01-02 23:27:28,912 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 24.27 sec
2018-01-02 23:27:31,994 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 26.46 sec
2018-01-02 23:27:35,087 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 27.48 sec
2018-01-02 23:27:38,169 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 28.57 sec
2018-01-02 23:27:41,250 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 31.52 sec
2018-01-02 23:27:44,334 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 32.87 sec
2018-01-02 23:27:45,361 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 33.58 sec
2018-01-02 23:27:54,609 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 41.08 sec
MapReduce Total cumulative CPU time: 41 seconds 80 msec
Ended Job = job_1513599404024_158933
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158953, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158953/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158953
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:28:03,436 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:28:10,710 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.7 sec
2018-01-02 23:28:11,739 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.63 sec
2018-01-02 23:28:28,187 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.42 sec
MapReduce Total cumulative CPU time: 23 seconds 420 msec
Ended Job = job_1513599404024_158953
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158962, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158962/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158962
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:28:37,870 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:28:59,464 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.04 sec
2018-01-02 23:29:06,651 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.08 sec
MapReduce Total cumulative CPU time: 8 seconds 80 msec
Ended Job = job_1513599404024_158962
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 41.08 sec   HDFS Read: 109472839 HDFS Write: 1941763 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.42 sec   HDFS Read: 51396454 HDFS Write: 135772 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.08 sec   HDFS Read: 143410 HDFS Write: 3058 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 12 seconds 580 msec
OK
Time taken: 163.884 seconds, Fetched: 430 row(s)
开始执行20170821日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.372 seconds
Query ID = boss_20180102232914_ef4a7f0d-ac78-4abd-8fc4-39ff90eee4f1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158973, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158973/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158973
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-02 23:29:26,728 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:29:37,099 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 23.76 sec
2018-01-02 23:29:40,226 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 32.04 sec
2018-01-02 23:29:43,325 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 38.75 sec
2018-01-02 23:29:46,418 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 65.03 sec
2018-01-02 23:29:49,521 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 68.08 sec
2018-01-02 23:29:50,555 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 82.07 sec
2018-01-02 23:29:52,615 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 85.17 sec
2018-01-02 23:29:53,645 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 88.39 sec
2018-01-02 23:29:55,706 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 94.78 sec
2018-01-02 23:29:58,800 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 101.02 sec
2018-01-02 23:30:01,892 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 107.89 sec
2018-01-02 23:30:04,984 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 114.42 sec
2018-01-02 23:30:08,077 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 121.15 sec
2018-01-02 23:30:10,134 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 123.53 sec
2018-01-02 23:30:11,164 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 126.48 sec
2018-01-02 23:30:12,195 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 128.47 sec
2018-01-02 23:30:18,376 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 145.96 sec
MapReduce Total cumulative CPU time: 2 minutes 25 seconds 960 msec
Ended Job = job_1513599404024_158973
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158979, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158979/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158979
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:30:26,267 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:30:31,446 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.2 sec
2018-01-02 23:30:40,737 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 17.35 sec
2018-01-02 23:30:42,801 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 19.79 sec
2018-01-02 23:30:44,862 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 24.39 sec
MapReduce Total cumulative CPU time: 24 seconds 390 msec
Ended Job = job_1513599404024_158979
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158987, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158987/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158987
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:30:54,714 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:31:00,897 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.72 sec
2018-01-02 23:31:23,503 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.35 sec
MapReduce Total cumulative CPU time: 7 seconds 350 msec
Ended Job = job_1513599404024_158987
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 145.96 sec   HDFS Read: 356223790 HDFS Write: 2189787 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 24.39 sec   HDFS Read: 48283007 HDFS Write: 98443 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.35 sec   HDFS Read: 106118 HDFS Write: 3734 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 57 seconds 700 msec
OK
Time taken: 129.741 seconds, Fetched: 508 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.394 seconds
Query ID = boss_20180102233131_b672222c-67d0-4b0e-9b02-47b25303ee9b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 16
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_158996, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_158996/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_158996
Hadoop job information for Stage-1: number of mappers: 20; number of reducers: 16
2018-01-02 23:31:48,545 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:31:58,919 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 34.98 sec
2018-01-02 23:31:59,963 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 100.11 sec
2018-01-02 23:32:01,003 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 157.29 sec
2018-01-02 23:32:02,040 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 206.83 sec
2018-01-02 23:32:03,074 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 242.2 sec
2018-01-02 23:32:04,110 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 296.36 sec
2018-01-02 23:32:05,144 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 341.14 sec
2018-01-02 23:32:06,177 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 383.87 sec
2018-01-02 23:32:07,337 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 413.26 sec
2018-01-02 23:32:08,370 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 456.55 sec
2018-01-02 23:32:09,402 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 478.6 sec
2018-01-02 23:32:10,435 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 544.65 sec
2018-01-02 23:32:11,471 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 579.3 sec
2018-01-02 23:32:12,502 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 606.35 sec
2018-01-02 23:32:13,533 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 646.24 sec
2018-01-02 23:32:14,563 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 652.64 sec
2018-01-02 23:32:15,599 Stage-1 map = 86%,  reduce = 3%, Cumulative CPU 672.63 sec
2018-01-02 23:32:16,630 Stage-1 map = 95%,  reduce = 8%, Cumulative CPU 700.19 sec
2018-01-02 23:32:17,661 Stage-1 map = 95%,  reduce = 15%, Cumulative CPU 703.71 sec
2018-01-02 23:32:18,694 Stage-1 map = 95%,  reduce = 16%, Cumulative CPU 703.98 sec
2018-01-02 23:32:19,729 Stage-1 map = 95%,  reduce = 20%, Cumulative CPU 705.3 sec
2018-01-02 23:32:22,821 Stage-1 map = 95%,  reduce = 22%, Cumulative CPU 718.14 sec
2018-01-02 23:32:23,851 Stage-1 map = 95%,  reduce = 28%, Cumulative CPU 736.72 sec
2018-01-02 23:32:25,912 Stage-1 map = 96%,  reduce = 28%, Cumulative CPU 741.23 sec
2018-01-02 23:32:29,005 Stage-1 map = 97%,  reduce = 28%, Cumulative CPU 746.27 sec
2018-01-02 23:32:30,037 Stage-1 map = 100%,  reduce = 32%, Cumulative CPU 749.63 sec
2018-01-02 23:32:31,068 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 773.88 sec
2018-01-02 23:32:32,101 Stage-1 map = 100%,  reduce = 85%, Cumulative CPU 796.88 sec
2018-01-02 23:32:33,131 Stage-1 map = 100%,  reduce = 90%, Cumulative CPU 801.76 sec
2018-01-02 23:32:34,163 Stage-1 map = 100%,  reduce = 96%, Cumulative CPU 806.7 sec
2018-01-02 23:32:35,192 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 811.61 sec
MapReduce Total cumulative CPU time: 13 minutes 31 seconds 610 msec
Ended Job = job_1513599404024_158996
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159007, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159007/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159007
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:32:42,202 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:32:49,422 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.5 sec
2018-01-02 23:32:54,568 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.91 sec
2018-01-02 23:33:04,854 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.01 sec
MapReduce Total cumulative CPU time: 19 seconds 10 msec
Ended Job = job_1513599404024_159007
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159012, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159012/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159012
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:33:29,701 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:33:35,980 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.13 sec
2018-01-02 23:33:53,803 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 12.06 sec
MapReduce Total cumulative CPU time: 12 seconds 60 msec
Ended Job = job_1513599404024_159012
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 20  Reduce: 16   Cumulative CPU: 811.61 sec   HDFS Read: 1481503400 HDFS Write: 563605 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.01 sec   HDFS Read: 46660231 HDFS Write: 26090 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 12.54 sec   HDFS Read: 33766 HDFS Write: 2976 SUCCESS
Total MapReduce CPU Time Spent: 14 minutes 3 seconds 160 msec
OK
Time taken: 144.646 seconds, Fetched: 420 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180102233402_693fae5a-22a3-40a1-8e58-94efd4842728
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159022, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159022/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159022
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:34:16,095 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:34:34,683 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 9.14 sec
2018-01-02 23:34:37,778 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 14.59 sec
2018-01-02 23:34:40,869 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 16.71 sec
2018-01-02 23:34:43,957 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 17.89 sec
2018-01-02 23:34:47,049 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 19.21 sec
2018-01-02 23:34:50,137 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 19.85 sec
2018-01-02 23:34:53,223 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 20.46 sec
2018-01-02 23:34:56,313 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 21.71 sec
2018-01-02 23:34:58,371 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 22.25 sec
2018-01-02 23:35:01,457 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 23.14 sec
2018-01-02 23:35:04,544 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 23.59 sec
2018-01-02 23:35:07,628 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 24.07 sec
2018-01-02 23:35:10,711 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 25.01 sec
2018-01-02 23:35:13,795 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 25.36 sec
2018-01-02 23:35:16,876 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 25.75 sec
2018-01-02 23:35:19,957 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 26.57 sec
2018-01-02 23:35:23,041 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 27.34 sec
2018-01-02 23:35:26,121 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 27.97 sec
2018-01-02 23:35:30,228 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 35.7 sec
2018-01-02 23:35:33,311 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 36.29 sec
2018-01-02 23:35:36,390 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 36.71 sec
2018-01-02 23:35:38,449 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 37.23 sec
2018-01-02 23:35:41,531 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 40.98 sec
2018-01-02 23:35:44,610 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 41.23 sec
2018-01-02 23:35:46,663 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 42.47 sec
2018-01-02 23:35:55,909 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 47.0 sec
MapReduce Total cumulative CPU time: 47 seconds 0 msec
Ended Job = job_1513599404024_159022
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159037, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159037/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159037
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:36:15,824 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:36:20,990 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.73 sec
2018-01-02 23:36:28,201 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.42 sec
2018-01-02 23:36:30,261 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.87 sec
MapReduce Total cumulative CPU time: 16 seconds 870 msec
Ended Job = job_1513599404024_159037
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159045, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159045/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159045
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:36:37,023 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:36:42,180 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.04 sec
2018-01-02 23:36:55,535 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.98 sec
MapReduce Total cumulative CPU time: 5 seconds 980 msec
Ended Job = job_1513599404024_159045
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 47.0 sec   HDFS Read: 103395495 HDFS Write: 661562 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.87 sec   HDFS Read: 46754202 HDFS Write: 214326 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.98 sec   HDFS Read: 221963 HDFS Write: 7325 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 9 seconds 850 msec
OK
Time taken: 173.985 seconds, Fetched: 878 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180102233711_e566d15a-d57f-4f58-8ce6-1a190f13bc26
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159053, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159053/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159053
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:37:21,677 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:37:32,033 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.98 sec
2018-01-02 23:37:35,131 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 12.37 sec
2018-01-02 23:37:38,225 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 14.07 sec
2018-01-02 23:37:40,285 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 16.01 sec
2018-01-02 23:37:43,377 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 16.98 sec
2018-01-02 23:37:46,467 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 18.62 sec
2018-01-02 23:37:49,554 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 19.33 sec
2018-01-02 23:37:52,667 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 20.37 sec
2018-01-02 23:37:55,759 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 21.45 sec
2018-01-02 23:37:58,848 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 22.64 sec
2018-01-02 23:38:01,937 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 24.68 sec
2018-01-02 23:38:05,022 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 26.48 sec
2018-01-02 23:38:08,112 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 27.54 sec
2018-01-02 23:38:11,198 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 28.45 sec
2018-01-02 23:38:14,281 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 31.46 sec
2018-01-02 23:38:21,478 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 37.84 sec
MapReduce Total cumulative CPU time: 37 seconds 840 msec
Ended Job = job_1513599404024_159053
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159066, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159066/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159066
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:38:45,248 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:38:50,412 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.83 sec
2018-01-02 23:38:57,642 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.28 sec
MapReduce Total cumulative CPU time: 16 seconds 280 msec
Ended Job = job_1513599404024_159066
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159070, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159070/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159070
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:39:04,263 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:39:08,395 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.71 sec
2018-01-02 23:39:14,571 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.07 sec
MapReduce Total cumulative CPU time: 5 seconds 70 msec
Ended Job = job_1513599404024_159070
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 37.84 sec   HDFS Read: 103395485 HDFS Write: 1739888 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.28 sec   HDFS Read: 47832528 HDFS Write: 116922 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.07 sec   HDFS Read: 124560 HDFS Write: 2929 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 190 msec
OK
Time taken: 124.327 seconds, Fetched: 415 row(s)
开始执行20170822日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.386 seconds
Query ID = boss_20180102233922_3f547962-63f1-4e40-8fec-4f86d72ef740
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159077, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159077/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159077
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-02 23:39:41,088 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:39:55,699 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 24.67 sec
2018-01-02 23:39:57,766 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 26.73 sec
2018-01-02 23:39:58,801 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 31.76 sec
2018-01-02 23:40:00,870 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 34.63 sec
2018-01-02 23:40:01,905 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 37.34 sec
2018-01-02 23:40:03,974 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 39.91 sec
2018-01-02 23:40:05,006 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 42.36 sec
2018-01-02 23:40:07,069 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 46.17 sec
2018-01-02 23:40:08,100 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 49.55 sec
2018-01-02 23:40:10,163 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 52.68 sec
2018-01-02 23:40:11,197 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 55.0 sec
2018-01-02 23:40:13,265 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 60.92 sec
2018-01-02 23:40:16,358 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 66.94 sec
2018-01-02 23:40:19,447 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 72.69 sec
2018-01-02 23:40:22,544 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 77.84 sec
2018-01-02 23:40:25,634 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 82.88 sec
2018-01-02 23:40:28,725 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 89.49 sec
2018-01-02 23:40:31,816 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 95.45 sec
2018-01-02 23:40:34,903 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 102.38 sec
2018-01-02 23:40:36,962 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 104.8 sec
2018-01-02 23:40:37,994 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 107.82 sec
2018-01-02 23:40:41,102 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 111.19 sec
2018-01-02 23:40:56,012 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 120.81 sec
2018-01-02 23:40:58,516 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 123.61 sec
2018-01-02 23:41:04,145 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 131.08 sec
2018-01-02 23:41:06,211 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 134.47 sec
2018-01-02 23:41:28,823 Stage-1 map = 100%,  reduce = 89%, Cumulative CPU 137.79 sec
2018-01-02 23:41:40,375 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 145.14 sec
MapReduce Total cumulative CPU time: 2 minutes 25 seconds 140 msec
Ended Job = job_1513599404024_159077
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159093, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159093/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159093
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:42:41,101 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:42:48,346 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.1 sec
2018-01-02 23:43:12,056 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.76 sec
MapReduce Total cumulative CPU time: 20 seconds 760 msec
Ended Job = job_1513599404024_159093
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159097, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159097/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159097
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:43:27,705 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:43:32,881 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-02 23:43:39,140 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.43 sec
MapReduce Total cumulative CPU time: 6 seconds 430 msec
Ended Job = job_1513599404024_159097
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 146.07 sec   HDFS Read: 356177209 HDFS Write: 2226888 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.76 sec   HDFS Read: 48599064 HDFS Write: 99689 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.43 sec   HDFS Read: 107364 HDFS Write: 3887 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 53 seconds 260 msec
OK
Time taken: 257.374 seconds, Fetched: 553 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.388 seconds
Query ID = boss_20180102234346_331be95b-b1cf-414d-b11e-8dac93c5146e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 15
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159100, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159100/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159100
Hadoop job information for Stage-1: number of mappers: 18; number of reducers: 15
2018-01-02 23:43:55,881 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:44:05,266 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 47.52 sec
2018-01-02 23:44:06,299 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 136.91 sec
2018-01-02 23:44:07,331 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 138.93 sec
2018-01-02 23:44:08,362 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 150.4 sec
2018-01-02 23:44:09,395 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 172.89 sec
2018-01-02 23:44:10,426 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 187.37 sec
2018-01-02 23:44:11,457 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 189.92 sec
2018-01-02 23:44:12,487 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 200.11 sec
2018-01-02 23:44:13,517 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 231.3 sec
2018-01-02 23:44:14,546 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 245.04 sec
2018-01-02 23:44:15,576 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 255.38 sec
2018-01-02 23:44:16,610 Stage-1 map = 66%,  reduce = 5%, Cumulative CPU 274.09 sec
2018-01-02 23:44:17,639 Stage-1 map = 70%,  reduce = 10%, Cumulative CPU 282.76 sec
2018-01-02 23:44:18,673 Stage-1 map = 81%,  reduce = 10%, Cumulative CPU 298.44 sec
2018-01-02 23:44:19,704 Stage-1 map = 81%,  reduce = 13%, Cumulative CPU 299.0 sec
2018-01-02 23:44:20,733 Stage-1 map = 81%,  reduce = 15%, Cumulative CPU 299.75 sec
2018-01-02 23:44:22,790 Stage-1 map = 81%,  reduce = 16%, Cumulative CPU 303.11 sec
2018-01-02 23:44:23,819 Stage-1 map = 85%,  reduce = 16%, Cumulative CPU 317.53 sec
2018-01-02 23:44:24,848 Stage-1 map = 85%,  reduce = 21%, Cumulative CPU 319.68 sec
2018-01-02 23:44:25,877 Stage-1 map = 90%,  reduce = 24%, Cumulative CPU 335.62 sec
2018-01-02 23:44:26,905 Stage-1 map = 90%,  reduce = 25%, Cumulative CPU 335.97 sec
2018-01-02 23:44:28,965 Stage-1 map = 91%,  reduce = 26%, Cumulative CPU 340.85 sec
2018-01-02 23:44:32,050 Stage-1 map = 92%,  reduce = 28%, Cumulative CPU 362.18 sec
2018-01-02 23:44:35,138 Stage-1 map = 92%,  reduce = 30%, Cumulative CPU 372.0 sec
2018-01-02 23:44:36,166 Stage-1 map = 95%,  reduce = 30%, Cumulative CPU 373.95 sec
2018-01-02 23:44:37,199 Stage-1 map = 96%,  reduce = 30%, Cumulative CPU 380.77 sec
2018-01-02 23:44:38,227 Stage-1 map = 96%,  reduce = 31%, Cumulative CPU 381.71 sec
2018-01-02 23:44:44,397 Stage-1 map = 97%,  reduce = 31%, Cumulative CPU 411.61 sec
2018-01-02 23:44:46,455 Stage-1 map = 100%,  reduce = 31%, Cumulative CPU 415.67 sec
2018-01-02 23:44:47,485 Stage-1 map = 100%,  reduce = 38%, Cumulative CPU 418.27 sec
2018-01-02 23:44:48,513 Stage-1 map = 100%,  reduce = 81%, Cumulative CPU 453.59 sec
2018-01-02 23:44:49,541 Stage-1 map = 100%,  reduce = 96%, Cumulative CPU 478.65 sec
2018-01-02 23:44:50,569 Stage-1 map = 100%,  reduce = 98%, Cumulative CPU 481.54 sec
2018-01-02 23:44:53,652 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 489.45 sec
MapReduce Total cumulative CPU time: 8 minutes 9 seconds 450 msec
Ended Job = job_1513599404024_159100
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159109, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159109/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159109
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:44:59,451 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:45:05,662 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.45 sec
2018-01-02 23:45:08,762 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 16.6 sec
2018-01-02 23:45:13,931 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 22.1 sec
MapReduce Total cumulative CPU time: 22 seconds 100 msec
Ended Job = job_1513599404024_159109
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159113, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159113/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159113
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:45:19,581 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:45:25,777 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.66 sec
2018-01-02 23:45:35,053 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.86 sec
MapReduce Total cumulative CPU time: 5 seconds 860 msec
Ended Job = job_1513599404024_159113
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 18  Reduce: 15   Cumulative CPU: 489.45 sec   HDFS Read: 1332638900 HDFS Write: 537350 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 22.1 sec   HDFS Read: 46912670 HDFS Write: 26017 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.86 sec   HDFS Read: 33693 HDFS Write: 3233 SUCCESS
Total MapReduce CPU Time Spent: 8 minutes 37 seconds 410 msec
OK
Time taken: 110.196 seconds, Fetched: 420 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.425 seconds
Query ID = boss_20180102234543_0403c97b-581b-41db-b631-5124f289da47
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159116, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159116/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159116
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:45:53,928 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:46:03,244 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 8.05 sec
2018-01-02 23:46:06,340 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 10.72 sec
2018-01-02 23:46:09,431 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 11.58 sec
2018-01-02 23:46:12,519 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 12.11 sec
2018-01-02 23:46:15,609 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 12.58 sec
2018-01-02 23:46:18,697 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 13.62 sec
2018-01-02 23:46:21,783 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 14.04 sec
2018-01-02 23:46:24,872 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 14.8 sec
2018-01-02 23:46:27,957 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 15.68 sec
2018-01-02 23:46:31,042 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 16.57 sec
2018-01-02 23:46:33,101 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 16.69 sec
2018-01-02 23:46:36,185 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 17.22 sec
2018-01-02 23:46:39,268 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 17.54 sec
2018-01-02 23:46:42,354 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 18.44 sec
2018-01-02 23:46:45,448 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 19.29 sec
2018-01-02 23:46:48,530 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 19.71 sec
2018-01-02 23:46:51,612 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 20.0 sec
2018-01-02 23:46:54,692 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 21.47 sec
2018-01-02 23:46:57,772 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 22.12 sec
2018-01-02 23:46:59,826 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 23.33 sec
2018-01-02 23:47:08,051 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 28.73 sec
MapReduce Total cumulative CPU time: 28 seconds 730 msec
Ended Job = job_1513599404024_159116
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159125, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159125/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159125
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:47:13,747 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:47:18,898 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.13 sec
2018-01-02 23:47:27,142 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.8 sec
2018-01-02 23:47:29,196 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.59 sec
MapReduce Total cumulative CPU time: 16 seconds 590 msec
Ended Job = job_1513599404024_159125
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159130, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159130/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159130
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:47:35,902 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:47:41,304 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec
2018-01-02 23:47:50,571 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 10.51 sec
MapReduce Total cumulative CPU time: 10 seconds 510 msec
Ended Job = job_1513599404024_159130
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 28.73 sec   HDFS Read: 104203414 HDFS Write: 629322 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.59 sec   HDFS Read: 47000918 HDFS Write: 206586 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 10.51 sec   HDFS Read: 214223 HDFS Write: 7558 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 830 msec
OK
Time taken: 127.734 seconds, Fetched: 893 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180102234806_1c79815e-fdd1-4dae-9da6-3fb9c9d86b34
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159135, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159135/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159135
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:48:22,432 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:48:33,846 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.45 sec
2018-01-02 23:48:36,952 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 13.53 sec
2018-01-02 23:48:40,050 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.38 sec
2018-01-02 23:48:43,147 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 16.47 sec
2018-01-02 23:48:46,244 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 17.65 sec
2018-01-02 23:48:49,339 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 19.03 sec
2018-01-02 23:48:52,431 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 20.59 sec
2018-01-02 23:48:55,529 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 21.68 sec
2018-01-02 23:48:57,591 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 24.04 sec
2018-01-02 23:49:00,683 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 25.28 sec
2018-01-02 23:49:03,778 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 26.38 sec
2018-01-02 23:49:06,868 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 29.91 sec
2018-01-02 23:49:07,899 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 30.77 sec
2018-01-02 23:49:12,029 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.36 sec
MapReduce Total cumulative CPU time: 35 seconds 360 msec
Ended Job = job_1513599404024_159135
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159144, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159144/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159144
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:49:18,789 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:49:26,019 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.71 sec
2018-01-02 23:49:37,366 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.42 sec
2018-01-02 23:49:41,487 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.44 sec
2018-01-02 23:49:43,548 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.03 sec
MapReduce Total cumulative CPU time: 18 seconds 30 msec
Ended Job = job_1513599404024_159144
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159151, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159151/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159151
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:49:49,305 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:50:01,645 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.72 sec
2018-01-02 23:50:08,835 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.83 sec
MapReduce Total cumulative CPU time: 5 seconds 830 msec
Ended Job = job_1513599404024_159151
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.36 sec   HDFS Read: 104203404 HDFS Write: 1699117 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.03 sec   HDFS Read: 48070713 HDFS Write: 107284 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.83 sec   HDFS Read: 114922 HDFS Write: 2684 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 220 msec
OK
Time taken: 123.547 seconds, Fetched: 401 row(s)
开始执行20170823日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180102235016_3d5d8cfa-5302-4b35-8b23-a0352c392f2e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159155, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159155/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159155
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-02 23:50:25,822 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:50:35,193 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 23.72 sec
2018-01-02 23:50:38,288 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 27.37 sec
2018-01-02 23:50:41,384 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 30.85 sec
2018-01-02 23:50:43,444 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 44.13 sec
2018-01-02 23:50:44,474 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 47.76 sec
2018-01-02 23:50:46,539 Stage-1 map = 50%,  reduce = 7%, Cumulative CPU 52.62 sec
2018-01-02 23:50:47,570 Stage-1 map = 53%,  reduce = 11%, Cumulative CPU 56.69 sec
2018-01-02 23:50:49,632 Stage-1 map = 54%,  reduce = 11%, Cumulative CPU 60.99 sec
2018-01-02 23:50:50,662 Stage-1 map = 57%,  reduce = 11%, Cumulative CPU 65.07 sec
2018-01-02 23:50:52,719 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 68.78 sec
2018-01-02 23:50:53,748 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 72.29 sec
2018-01-02 23:50:55,806 Stage-1 map = 77%,  reduce = 11%, Cumulative CPU 79.26 sec
2018-01-02 23:50:57,866 Stage-1 map = 77%,  reduce = 15%, Cumulative CPU 79.36 sec
2018-01-02 23:50:58,894 Stage-1 map = 80%,  reduce = 22%, Cumulative CPU 83.05 sec
2018-01-02 23:51:01,979 Stage-1 map = 81%,  reduce = 22%, Cumulative CPU 86.61 sec
2018-01-02 23:51:05,064 Stage-1 map = 83%,  reduce = 22%, Cumulative CPU 91.36 sec
2018-01-02 23:51:08,151 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 95.11 sec
2018-01-02 23:51:11,236 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 98.75 sec
2018-01-02 23:51:14,318 Stage-1 map = 100%,  reduce = 32%, Cumulative CPU 102.69 sec
2018-01-02 23:51:15,347 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 107.55 sec
2018-01-02 23:51:16,378 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 115.99 sec
MapReduce Total cumulative CPU time: 1 minutes 55 seconds 990 msec
Ended Job = job_1513599404024_159155
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159163, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159163/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159163
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:51:22,097 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:51:27,269 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.88 sec
2018-01-02 23:51:28,302 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.89 sec
2018-01-02 23:51:34,489 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.13 sec
MapReduce Total cumulative CPU time: 19 seconds 130 msec
Ended Job = job_1513599404024_159163
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159168, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159168/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159168
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:51:40,169 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:51:45,324 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.31 sec
2018-01-02 23:51:51,496 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.66 sec
MapReduce Total cumulative CPU time: 6 seconds 660 msec
Ended Job = job_1513599404024_159168
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 115.99 sec   HDFS Read: 383467879 HDFS Write: 2538341 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.13 sec   HDFS Read: 49837362 HDFS Write: 117602 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.66 sec   HDFS Read: 125277 HDFS Write: 3969 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 21 seconds 780 msec
OK
Time taken: 95.68 seconds, Fetched: 546 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.417 seconds
Query ID = boss_20180102235159_53e93bea-7ffd-466b-853c-c7f3cdb254b4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 14
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159171, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159171/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159171
Hadoop job information for Stage-1: number of mappers: 18; number of reducers: 14
2018-01-02 23:52:11,270 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:52:22,690 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 130.82 sec
2018-01-02 23:52:23,727 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 191.89 sec
2018-01-02 23:52:24,765 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 200.19 sec
2018-01-02 23:52:25,796 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 225.47 sec
2018-01-02 23:52:26,828 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 247.84 sec
2018-01-02 23:52:27,860 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 254.09 sec
2018-01-02 23:52:28,891 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 269.41 sec
2018-01-02 23:52:29,922 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 300.96 sec
2018-01-02 23:52:30,954 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 314.41 sec
2018-01-02 23:52:31,984 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 326.75 sec
2018-01-02 23:52:33,017 Stage-1 map = 93%,  reduce = 0%, Cumulative CPU 337.35 sec
2018-01-02 23:52:34,053 Stage-1 map = 93%,  reduce = 6%, Cumulative CPU 339.31 sec
2018-01-02 23:52:35,086 Stage-1 map = 94%,  reduce = 17%, Cumulative CPU 346.45 sec
2018-01-02 23:52:36,117 Stage-1 map = 94%,  reduce = 21%, Cumulative CPU 350.94 sec
2018-01-02 23:52:37,148 Stage-1 map = 97%,  reduce = 23%, Cumulative CPU 354.92 sec
2018-01-02 23:52:39,206 Stage-1 map = 97%,  reduce = 24%, Cumulative CPU 358.32 sec
2018-01-02 23:52:40,236 Stage-1 map = 100%,  reduce = 24%, Cumulative CPU 361.22 sec
2018-01-02 23:52:41,266 Stage-1 map = 100%,  reduce = 44%, Cumulative CPU 371.5 sec
2018-01-02 23:52:42,299 Stage-1 map = 100%,  reduce = 98%, Cumulative CPU 410.5 sec
2018-01-02 23:52:43,328 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 413.16 sec
MapReduce Total cumulative CPU time: 6 minutes 53 seconds 160 msec
Ended Job = job_1513599404024_159171
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159174, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159174/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159174
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-02 23:53:17,101 Stage-2 map = 0%,  reduce = 0%
2018-01-02 23:53:22,264 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.84 sec
2018-01-02 23:53:30,499 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.34 sec
2018-01-02 23:53:35,643 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.52 sec
MapReduce Total cumulative CPU time: 18 seconds 520 msec
Ended Job = job_1513599404024_159174
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159180, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159180/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159180
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-02 23:54:10,405 Stage-3 map = 0%,  reduce = 0%
2018-01-02 23:54:29,965 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.13 sec
2018-01-02 23:54:36,149 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.26 sec
MapReduce Total cumulative CPU time: 6 seconds 260 msec
Ended Job = job_1513599404024_159180
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 18  Reduce: 14   Cumulative CPU: 413.16 sec   HDFS Read: 1305439547 HDFS Write: 556839 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.52 sec   HDFS Read: 47858742 HDFS Write: 26025 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.26 sec   HDFS Read: 33701 HDFS Write: 3074 SUCCESS
Total MapReduce CPU Time Spent: 7 minutes 17 seconds 940 msec
OK
Time taken: 158.924 seconds, Fetched: 423 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180102235444_3c4b7708-6f3d-4cdd-956b-b1c3d09b4417
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159184, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159184/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159184
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-02 23:55:00,927 Stage-1 map = 0%,  reduce = 0%
2018-01-02 23:56:00,932 Stage-1 map = 0%,  reduce = 0%, Cumulative CPU 7.76 sec
2018-01-02 23:56:10,199 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 16.57 sec
2018-01-02 23:56:13,300 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 19.99 sec
2018-01-02 23:56:17,460 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 21.49 sec
2018-01-02 23:56:27,780 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 24.76 sec
2018-01-02 23:56:30,861 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 25.46 sec
2018-01-02 23:56:44,150 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 32.63 sec
2018-01-02 23:56:52,392 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 35.33 sec
2018-01-02 23:57:01,643 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 40.97 sec
2018-01-02 23:57:05,750 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 42.91 sec
2018-01-02 23:57:09,853 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 44.69 sec
2018-01-02 23:57:12,937 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 45.27 sec
2018-01-02 23:57:20,128 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 47.21 sec
2018-01-02 23:57:23,212 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 47.87 sec
2018-01-02 23:57:27,310 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 48.83 sec
2018-01-02 23:57:31,411 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 50.63 sec
2018-01-02 23:57:34,484 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 51.19 sec
2018-01-02 23:57:37,565 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 52.34 sec
2018-01-02 23:57:40,641 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 52.62 sec
2018-01-02 23:57:52,955 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 54.94 sec
2018-01-02 23:57:56,032 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 55.22 sec
2018-01-02 23:58:06,294 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 57.24 sec
2018-01-02 23:58:13,490 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 58.63 sec
2018-01-02 23:58:16,576 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 58.83 sec
2018-01-02 23:58:23,754 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 60.95 sec
2018-01-02 23:58:29,906 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 62.83 sec
2018-01-02 23:58:32,980 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 63.93 sec
2018-01-02 23:58:42,217 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 65.58 sec
2018-01-02 23:58:45,299 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 66.08 sec
2018-01-02 23:58:49,401 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 67.57 sec
2018-01-02 23:58:52,483 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 68.81 sec
2018-01-02 23:58:55,570 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 69.34 sec
2018-01-02 23:59:04,832 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 70.72 sec
2018-01-02 23:59:12,028 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 71.93 sec
2018-01-02 23:59:21,256 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 78.52 sec
2018-01-02 23:59:24,329 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 78.9 sec
2018-01-02 23:59:30,481 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 79.57 sec
2018-01-02 23:59:33,556 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 79.71 sec
2018-01-02 23:59:36,633 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 80.81 sec
2018-01-02 23:59:39,707 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 81.07 sec
2018-01-02 23:59:42,781 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 81.53 sec
2018-01-02 23:59:45,855 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 81.95 sec
2018-01-02 23:59:48,932 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 82.69 sec
2018-01-02 23:59:52,006 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 82.95 sec
2018-01-02 23:59:55,081 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 83.44 sec
2018-01-02 23:59:58,156 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 84.13 sec
2018-01-03 00:00:01,229 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 85.65 sec
2018-01-03 00:00:04,314 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 86.15 sec
2018-01-03 00:00:07,387 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 88.08 sec
2018-01-03 00:00:14,567 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 92.73 sec
MapReduce Total cumulative CPU time: 1 minutes 32 seconds 730 msec
Ended Job = job_1513599404024_159184
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159191, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159191/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159191
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:00:23,362 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:00:37,761 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.26 sec
2018-01-03 00:00:50,082 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.79 sec
2018-01-03 00:00:51,110 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.21 sec
2018-01-03 00:00:53,160 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.64 sec
MapReduce Total cumulative CPU time: 16 seconds 640 msec
Ended Job = job_1513599404024_159191
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159198, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159198/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159198
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:01:07,810 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:01:13,994 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.64 sec
2018-01-03 00:01:20,173 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.28 sec
MapReduce Total cumulative CPU time: 7 seconds 280 msec
Ended Job = job_1513599404024_159198
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 92.73 sec   HDFS Read: 107845111 HDFS Write: 695724 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.64 sec   HDFS Read: 47994165 HDFS Write: 219452 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.28 sec   HDFS Read: 227089 HDFS Write: 7637 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 56 seconds 650 msec
OK
Time taken: 396.312 seconds, Fetched: 919 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.365 seconds
Query ID = boss_20180103000128_a592a8c4-5285-4813-837b-05020b610cde
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159203, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159203/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159203
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:01:38,836 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:01:56,393 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 10.84 sec
2018-01-03 00:01:59,483 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 12.9 sec
2018-01-03 00:02:02,577 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 13.7 sec
2018-01-03 00:02:05,665 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 14.82 sec
2018-01-03 00:02:08,751 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 15.92 sec
2018-01-03 00:02:11,842 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 17.13 sec
2018-01-03 00:02:14,928 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 18.2 sec
2018-01-03 00:02:18,014 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 19.06 sec
2018-01-03 00:02:21,100 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 20.21 sec
2018-01-03 00:02:24,183 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 23.66 sec
2018-01-03 00:02:27,269 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 24.83 sec
2018-01-03 00:02:30,351 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 26.47 sec
2018-01-03 00:02:37,552 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.22 sec
MapReduce Total cumulative CPU time: 32 seconds 220 msec
Ended Job = job_1513599404024_159203
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159210, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159210/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159210
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:02:45,252 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:02:52,468 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.12 sec
2018-01-03 00:02:53,576 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.1 sec
2018-01-03 00:02:59,320 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.67 sec
MapReduce Total cumulative CPU time: 19 seconds 670 msec
Ended Job = job_1513599404024_159210
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159213, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159213/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159213
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:03:04,947 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:03:18,314 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.24 sec
2018-01-03 00:03:25,517 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.36 sec
MapReduce Total cumulative CPU time: 6 seconds 360 msec
Ended Job = job_1513599404024_159213
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 32.22 sec   HDFS Read: 107845101 HDFS Write: 1762312 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.67 sec   HDFS Read: 49060753 HDFS Write: 115965 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.36 sec   HDFS Read: 123603 HDFS Write: 2804 SUCCESS
Total MapReduce CPU Time Spent: 58 seconds 250 msec
OK
Time taken: 119.339 seconds, Fetched: 407 row(s)
开始执行20170824日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.375 seconds
Query ID = boss_20180103000342_af555236-8944-446a-b56e-8b786a7be191
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159218, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159218/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159218
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 00:03:58,865 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:04:10,702 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 11.61 sec
2018-01-03 00:04:13,816 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 14.94 sec
2018-01-03 00:04:16,911 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 17.91 sec
2018-01-03 00:04:20,002 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 21.46 sec
2018-01-03 00:04:23,094 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 24.72 sec
2018-01-03 00:04:26,186 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 27.72 sec
2018-01-03 00:04:29,276 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 31.01 sec
2018-01-03 00:04:31,394 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 34.09 sec
2018-01-03 00:04:32,427 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 48.64 sec
2018-01-03 00:04:34,487 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 51.8 sec
2018-01-03 00:04:35,520 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 55.31 sec
2018-01-03 00:04:37,576 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 58.53 sec
2018-01-03 00:04:38,605 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 62.41 sec
2018-01-03 00:04:40,661 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 66.2 sec
2018-01-03 00:04:41,692 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 69.48 sec
2018-01-03 00:04:43,747 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 72.88 sec
2018-01-03 00:04:44,777 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 76.24 sec
2018-01-03 00:04:46,832 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 79.27 sec
2018-01-03 00:04:47,861 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 84.32 sec
2018-01-03 00:04:50,943 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 87.88 sec
2018-01-03 00:04:54,030 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 92.84 sec
2018-01-03 00:04:57,111 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 102.78 sec
2018-01-03 00:04:59,171 Stage-1 map = 79%,  reduce = 6%, Cumulative CPU 108.96 sec
2018-01-03 00:05:00,200 Stage-1 map = 79%,  reduce = 11%, Cumulative CPU 109.55 sec
2018-01-03 00:05:02,259 Stage-1 map = 81%,  reduce = 11%, Cumulative CPU 116.05 sec
2018-01-03 00:05:04,315 Stage-1 map = 100%,  reduce = 11%, Cumulative CPU 118.03 sec
2018-01-03 00:05:05,344 Stage-1 map = 100%,  reduce = 72%, Cumulative CPU 127.45 sec
2018-01-03 00:05:06,371 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 131.67 sec
MapReduce Total cumulative CPU time: 2 minutes 11 seconds 670 msec
Ended Job = job_1513599404024_159218
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159227, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159227/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159227
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:05:14,114 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:05:22,374 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.65 sec
2018-01-03 00:05:27,530 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.22 sec
2018-01-03 00:05:31,657 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.68 sec
MapReduce Total cumulative CPU time: 20 seconds 680 msec
Ended Job = job_1513599404024_159227
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159230, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159230/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159230
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:05:45,335 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:05:50,504 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.79 sec
2018-01-03 00:05:56,690 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.12 sec
MapReduce Total cumulative CPU time: 6 seconds 120 msec
Ended Job = job_1513599404024_159230
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 131.67 sec   HDFS Read: 349703154 HDFS Write: 2215883 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.68 sec   HDFS Read: 47952840 HDFS Write: 101114 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.12 sec   HDFS Read: 108789 HDFS Write: 4269 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 38 seconds 470 msec
OK
Time taken: 135.216 seconds, Fetched: 526 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.397 seconds
Query ID = boss_20180103000604_0f3c83f1-2518-487a-b067-a77d28560082
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 13
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159236, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159236/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159236
Hadoop job information for Stage-1: number of mappers: 17; number of reducers: 13
2018-01-03 00:06:41,462 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:06:50,851 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 105.5 sec
2018-01-03 00:06:51,883 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 163.74 sec
2018-01-03 00:06:52,916 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 171.47 sec
2018-01-03 00:06:53,950 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 186.01 sec
2018-01-03 00:06:54,981 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 193.33 sec
2018-01-03 00:06:56,011 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 229.08 sec
2018-01-03 00:06:57,043 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 235.94 sec
2018-01-03 00:06:58,073 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 239.76 sec
2018-01-03 00:06:59,103 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 285.86 sec
2018-01-03 00:07:00,133 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 291.9 sec
2018-01-03 00:07:02,197 Stage-1 map = 88%,  reduce = 17%, Cumulative CPU 308.91 sec
2018-01-03 00:07:03,231 Stage-1 map = 88%,  reduce = 23%, Cumulative CPU 311.18 sec
2018-01-03 00:07:05,290 Stage-1 map = 96%,  reduce = 24%, Cumulative CPU 322.9 sec
2018-01-03 00:07:07,348 Stage-1 map = 96%,  reduce = 27%, Cumulative CPU 323.78 sec
2018-01-03 00:07:08,376 Stage-1 map = 97%,  reduce = 29%, Cumulative CPU 327.86 sec
2018-01-03 00:07:10,433 Stage-1 map = 97%,  reduce = 31%, Cumulative CPU 329.9 sec
2018-01-03 00:07:13,522 Stage-1 map = 100%,  reduce = 34%, Cumulative CPU 336.95 sec
2018-01-03 00:07:14,549 Stage-1 map = 100%,  reduce = 82%, Cumulative CPU 371.61 sec
2018-01-03 00:07:15,576 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 382.44 sec
2018-01-03 00:07:17,631 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 385.28 sec
MapReduce Total cumulative CPU time: 6 minutes 25 seconds 280 msec
Ended Job = job_1513599404024_159236
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159247, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159247/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159247
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:07:35,443 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:07:49,852 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.77 sec
2018-01-03 00:07:55,079 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.2 sec
MapReduce Total cumulative CPU time: 17 seconds 200 msec
Ended Job = job_1513599404024_159247
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159252, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159252/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159252
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:08:15,876 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:08:21,046 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.56 sec
2018-01-03 00:08:30,332 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.75 sec
MapReduce Total cumulative CPU time: 7 seconds 750 msec
Ended Job = job_1513599404024_159252
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 17  Reduce: 13   Cumulative CPU: 385.28 sec   HDFS Read: 1218115542 HDFS Write: 509381 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.2 sec   HDFS Read: 46248958 HDFS Write: 25036 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.75 sec   HDFS Read: 32712 HDFS Write: 2891 SUCCESS
Total MapReduce CPU Time Spent: 6 minutes 50 seconds 230 msec
OK
Time taken: 146.926 seconds, Fetched: 417 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103000838_4f152e26-3c9a-4f2c-ae5f-a8a005e24add
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159258, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159258/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159258
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:08:48,193 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:09:01,643 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 8.5 sec
2018-01-03 00:09:04,736 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 10.25 sec
2018-01-03 00:09:07,826 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.9 sec
2018-01-03 00:09:10,920 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 14.81 sec
2018-01-03 00:09:14,008 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 15.48 sec
2018-01-03 00:09:17,094 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 30.92 sec
2018-01-03 00:09:20,185 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 31.51 sec
2018-01-03 00:09:23,270 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 31.95 sec
2018-01-03 00:09:26,357 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 32.66 sec
2018-01-03 00:09:29,445 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 32.99 sec
2018-01-03 00:09:32,529 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 34.72 sec
2018-01-03 00:09:35,618 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 35.04 sec
2018-01-03 00:09:38,702 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 35.47 sec
2018-01-03 00:09:41,785 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 35.81 sec
2018-01-03 00:09:43,838 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 36.27 sec
2018-01-03 00:09:46,921 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 36.72 sec
2018-01-03 00:09:50,002 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 37.12 sec
2018-01-03 00:09:53,083 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 37.36 sec
2018-01-03 00:09:56,165 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 37.78 sec
2018-01-03 00:09:59,244 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 38.19 sec
2018-01-03 00:10:02,324 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 38.49 sec
2018-01-03 00:10:05,405 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 38.85 sec
2018-01-03 00:10:08,483 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 39.06 sec
2018-01-03 00:10:11,563 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 39.48 sec
2018-01-03 00:10:14,640 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 41.06 sec
2018-01-03 00:10:17,718 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 41.45 sec
2018-01-03 00:10:19,768 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 42.38 sec
2018-01-03 00:10:25,929 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 47.54 sec
MapReduce Total cumulative CPU time: 47 seconds 540 msec
Ended Job = job_1513599404024_159258
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159270, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159270/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159270
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:10:31,574 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:10:36,722 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.17 sec
2018-01-03 00:10:43,915 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.57 sec
2018-01-03 00:10:45,973 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.93 sec
MapReduce Total cumulative CPU time: 17 seconds 930 msec
Ended Job = job_1513599404024_159270
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159272, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159272/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159272
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:10:53,675 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:11:14,248 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.51 sec
2018-01-03 00:11:24,528 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.01 sec
MapReduce Total cumulative CPU time: 8 seconds 10 msec
Ended Job = job_1513599404024_159272
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 47.54 sec   HDFS Read: 106195993 HDFS Write: 630123 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.93 sec   HDFS Read: 46366500 HDFS Write: 207992 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.01 sec   HDFS Read: 215629 HDFS Write: 7442 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 13 seconds 480 msec
OK
Time taken: 167.437 seconds, Fetched: 898 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103001132_22226e07-7452-4ac4-badd-48b566cf369f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159280, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159280/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159280
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:11:51,776 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:12:11,408 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.17 sec
2018-01-03 00:12:14,506 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 14.13 sec
2018-01-03 00:12:17,598 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.54 sec
2018-01-03 00:12:20,689 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 17.5 sec
2018-01-03 00:12:23,782 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 18.42 sec
2018-01-03 00:12:26,870 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 19.83 sec
2018-01-03 00:12:29,960 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 20.99 sec
2018-01-03 00:12:33,053 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 22.79 sec
2018-01-03 00:12:36,140 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 24.47 sec
2018-01-03 00:12:39,228 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 26.1 sec
2018-01-03 00:12:42,317 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 27.37 sec
2018-01-03 00:12:45,403 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 28.4 sec
2018-01-03 00:12:48,489 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 31.51 sec
2018-01-03 00:12:54,668 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 37.84 sec
MapReduce Total cumulative CPU time: 37 seconds 840 msec
Ended Job = job_1513599404024_159280
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159289, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159289/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159289
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:13:02,402 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:13:07,562 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.04 sec
2018-01-03 00:13:17,871 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.08 sec
MapReduce Total cumulative CPU time: 18 seconds 80 msec
Ended Job = job_1513599404024_159289
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159295, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159295/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159295
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:13:27,725 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:13:32,887 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.83 sec
2018-01-03 00:13:39,068 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.74 sec
MapReduce Total cumulative CPU time: 6 seconds 740 msec
Ended Job = job_1513599404024_159295
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 37.84 sec   HDFS Read: 106195983 HDFS Write: 1710530 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.08 sec   HDFS Read: 47446907 HDFS Write: 115511 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.74 sec   HDFS Read: 123149 HDFS Write: 2803 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 2 seconds 660 msec
OK
Time taken: 127.478 seconds, Fetched: 413 row(s)
开始执行20170825日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103001347_d694a278-4d16-4f80-9825-b821b2627438
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159300, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159300/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159300
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 00:14:03,124 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:14:13,638 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 32.58 sec
2018-01-03 00:14:16,745 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 56.21 sec
2018-01-03 00:14:19,843 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 59.74 sec
2018-01-03 00:14:20,876 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 97.34 sec
2018-01-03 00:14:21,908 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 100.72 sec
2018-01-03 00:14:23,972 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 102.53 sec
2018-01-03 00:14:25,004 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 105.48 sec
2018-01-03 00:14:28,100 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 109.32 sec
2018-01-03 00:14:29,130 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 111.57 sec
2018-01-03 00:14:31,190 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 114.96 sec
2018-01-03 00:14:32,222 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 118.07 sec
2018-01-03 00:14:34,284 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 121.34 sec
2018-01-03 00:14:35,318 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 124.73 sec
2018-01-03 00:14:37,378 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 127.83 sec
2018-01-03 00:14:38,408 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 130.42 sec
2018-01-03 00:14:40,468 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 133.28 sec
2018-01-03 00:14:41,500 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 136.57 sec
2018-01-03 00:14:43,561 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 140.74 sec
2018-01-03 00:14:44,594 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 144.6 sec
2018-01-03 00:14:46,652 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 147.61 sec
2018-01-03 00:14:47,682 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 150.85 sec
2018-01-03 00:14:49,743 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 156.65 sec
2018-01-03 00:14:51,801 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 158.8 sec
2018-01-03 00:14:55,926 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 164.13 sec
2018-01-03 00:14:59,016 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 170.18 sec
2018-01-03 00:15:02,104 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 177.14 sec
MapReduce Total cumulative CPU time: 2 minutes 57 seconds 140 msec
Ended Job = job_1513599404024_159300
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159308, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159308/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159308
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:15:11,930 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:15:18,121 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.32 sec
2018-01-03 00:15:31,504 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.15 sec
MapReduce Total cumulative CPU time: 19 seconds 150 msec
Ended Job = job_1513599404024_159308
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159312, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159312/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159312
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:15:37,242 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:15:42,412 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec
2018-01-03 00:15:47,565 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.16 sec
MapReduce Total cumulative CPU time: 6 seconds 160 msec
Ended Job = job_1513599404024_159312
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 177.14 sec   HDFS Read: 371269791 HDFS Write: 2262342 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.15 sec   HDFS Read: 47987622 HDFS Write: 100682 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.16 sec   HDFS Read: 108357 HDFS Write: 3907 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 22 seconds 450 msec
OK
Time taken: 122.567 seconds, Fetched: 530 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.407 seconds
Query ID = boss_20180103001556_eced24ba-9392-44ea-a02b-c2b3e41626b0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 13
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159319, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159319/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159319
Hadoop job information for Stage-1: number of mappers: 15; number of reducers: 13
2018-01-03 00:16:14,623 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:16:20,884 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 7.56 sec
2018-01-03 00:16:25,069 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 80.81 sec
2018-01-03 00:16:26,101 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 115.75 sec
2018-01-03 00:16:28,169 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 158.08 sec
2018-01-03 00:16:29,200 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 167.38 sec
2018-01-03 00:16:30,232 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 176.98 sec
2018-01-03 00:16:31,263 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 187.34 sec
2018-01-03 00:16:32,301 Stage-1 map = 50%,  reduce = 7%, Cumulative CPU 205.32 sec
2018-01-03 00:16:33,333 Stage-1 map = 56%,  reduce = 8%, Cumulative CPU 232.63 sec
2018-01-03 00:16:34,364 Stage-1 map = 57%,  reduce = 9%, Cumulative CPU 236.46 sec
2018-01-03 00:16:35,395 Stage-1 map = 63%,  reduce = 12%, Cumulative CPU 268.57 sec
2018-01-03 00:16:36,431 Stage-1 map = 69%,  reduce = 12%, Cumulative CPU 289.04 sec
2018-01-03 00:16:38,505 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 310.91 sec
2018-01-03 00:16:39,537 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 318.21 sec
2018-01-03 00:16:40,569 Stage-1 map = 74%,  reduce = 18%, Cumulative CPU 319.13 sec
2018-01-03 00:16:41,600 Stage-1 map = 80%,  reduce = 19%, Cumulative CPU 331.52 sec
2018-01-03 00:16:42,630 Stage-1 map = 90%,  reduce = 19%, Cumulative CPU 345.42 sec
2018-01-03 00:16:44,693 Stage-1 map = 91%,  reduce = 26%, Cumulative CPU 349.98 sec
2018-01-03 00:16:46,758 Stage-1 map = 95%,  reduce = 29%, Cumulative CPU 384.91 sec
2018-01-03 00:16:47,788 Stage-1 map = 95%,  reduce = 31%, Cumulative CPU 385.65 sec
2018-01-03 00:16:51,908 Stage-1 map = 96%,  reduce = 31%, Cumulative CPU 414.93 sec
2018-01-03 00:16:54,998 Stage-1 map = 97%,  reduce = 31%, Cumulative CPU 420.09 sec
2018-01-03 00:16:57,061 Stage-1 map = 100%,  reduce = 31%, Cumulative CPU 424.26 sec
2018-01-03 00:16:58,091 Stage-1 map = 100%,  reduce = 44%, Cumulative CPU 430.81 sec
2018-01-03 00:16:59,121 Stage-1 map = 100%,  reduce = 95%, Cumulative CPU 470.58 sec
2018-01-03 00:17:01,184 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 482.26 sec
MapReduce Total cumulative CPU time: 8 minutes 2 seconds 260 msec
Ended Job = job_1513599404024_159319
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159329, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159329/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159329
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:17:11,674 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:17:17,864 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.16 sec
2018-01-03 00:17:24,058 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.16 sec
MapReduce Total cumulative CPU time: 16 seconds 160 msec
Ended Job = job_1513599404024_159329
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159335, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159335/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159335
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:17:33,667 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:17:39,858 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.61 sec
2018-01-03 00:17:48,096 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.94 sec
MapReduce Total cumulative CPU time: 5 seconds 940 msec
Ended Job = job_1513599404024_159335
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 15  Reduce: 13   Cumulative CPU: 482.26 sec   HDFS Read: 1199130502 HDFS Write: 520908 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.16 sec   HDFS Read: 46248808 HDFS Write: 25069 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.94 sec   HDFS Read: 32745 HDFS Write: 2907 SUCCESS
Total MapReduce CPU Time Spent: 8 minutes 24 seconds 360 msec
OK
Time taken: 112.766 seconds, Fetched: 415 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103001803_81885eb8-934f-48d9-832a-1f9848c455d0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159340, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159340/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159340
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:18:13,802 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:18:32,386 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 8.27 sec
2018-01-03 00:18:35,481 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 9.68 sec
2018-01-03 00:18:38,572 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 10.96 sec
2018-01-03 00:18:41,658 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 11.58 sec
2018-01-03 00:18:44,747 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.11 sec
2018-01-03 00:18:46,806 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 12.11 sec
2018-01-03 00:18:49,889 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 13.19 sec
2018-01-03 00:18:52,978 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 13.54 sec
2018-01-03 00:18:56,062 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 15.22 sec
2018-01-03 00:18:59,145 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 15.94 sec
2018-01-03 00:19:02,232 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 16.69 sec
2018-01-03 00:19:05,314 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 17.0 sec
2018-01-03 00:19:08,397 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 17.57 sec
2018-01-03 00:19:11,480 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 18.01 sec
2018-01-03 00:19:14,558 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 18.36 sec
2018-01-03 00:19:17,638 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 18.64 sec
2018-01-03 00:19:20,723 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 19.07 sec
2018-01-03 00:19:23,802 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 19.75 sec
2018-01-03 00:19:26,880 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 20.09 sec
2018-01-03 00:19:29,960 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 20.38 sec
2018-01-03 00:19:33,037 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 20.67 sec
2018-01-03 00:19:36,114 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 21.09 sec
2018-01-03 00:19:39,194 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 22.01 sec
2018-01-03 00:19:42,270 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 22.39 sec
2018-01-03 00:19:45,351 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 23.61 sec
2018-01-03 00:19:58,687 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 27.82 sec
MapReduce Total cumulative CPU time: 27 seconds 820 msec
Ended Job = job_1513599404024_159340
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159349, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159349/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159349
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:20:05,416 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:20:10,574 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.73 sec
2018-01-03 00:20:18,798 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.44 sec
2018-01-03 00:20:24,957 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.79 sec
MapReduce Total cumulative CPU time: 15 seconds 790 msec
Ended Job = job_1513599404024_159349
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159352, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159352/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159352
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:20:30,563 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:20:35,711 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec
2018-01-03 00:20:41,875 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.46 sec
MapReduce Total cumulative CPU time: 6 seconds 460 msec
Ended Job = job_1513599404024_159352
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 27.82 sec   HDFS Read: 103187634 HDFS Write: 625508 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.79 sec   HDFS Read: 46350204 HDFS Write: 214751 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.46 sec   HDFS Read: 222384 HDFS Write: 7631 SUCCESS
Total MapReduce CPU Time Spent: 50 seconds 70 msec
OK
Time taken: 159.115 seconds, Fetched: 910 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103002057_f0e61a7a-efda-40e3-ace4-9d286fcce838
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159358, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159358/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159358
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:21:15,791 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:21:26,160 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 8.87 sec
2018-01-03 00:21:29,266 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 11.67 sec
2018-01-03 00:21:32,364 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 13.2 sec
2018-01-03 00:21:35,459 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 14.15 sec
2018-01-03 00:21:38,556 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 15.38 sec
2018-01-03 00:21:41,650 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 16.68 sec
2018-01-03 00:21:44,742 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 18.0 sec
2018-01-03 00:21:47,838 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 18.89 sec
2018-01-03 00:21:50,929 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 20.27 sec
2018-01-03 00:21:54,022 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 21.13 sec
2018-01-03 00:21:57,115 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 23.08 sec
2018-01-03 00:22:00,203 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 24.31 sec
2018-01-03 00:22:02,269 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 26.42 sec
2018-01-03 00:22:10,512 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 31.41 sec
MapReduce Total cumulative CPU time: 31 seconds 410 msec
Ended Job = job_1513599404024_159358
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159365, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159365/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159365
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:22:16,191 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:22:23,398 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.26 sec
2018-01-03 00:22:28,537 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.77 sec
2018-01-03 00:22:36,756 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.17 sec
MapReduce Total cumulative CPU time: 16 seconds 170 msec
Ended Job = job_1513599404024_159365
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159366, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159366/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159366
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:22:42,366 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:22:54,701 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec
2018-01-03 00:23:09,082 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.32 sec
MapReduce Total cumulative CPU time: 6 seconds 320 msec
Ended Job = job_1513599404024_159366
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 31.41 sec   HDFS Read: 103187625 HDFS Write: 1441167 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.17 sec   HDFS Read: 47165867 HDFS Write: 126262 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.32 sec   HDFS Read: 133900 HDFS Write: 2911 SUCCESS
Total MapReduce CPU Time Spent: 53 seconds 900 msec
OK
Time taken: 132.501 seconds, Fetched: 405 row(s)
开始执行20170826日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103002325_f4245496-2e8f-43f7-ac4f-bd4e63d39482
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159370, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159370/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159370
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 00:23:37,119 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:23:46,448 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 12.23 sec
2018-01-03 00:23:47,480 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 23.7 sec
2018-01-03 00:23:49,544 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 27.5 sec
2018-01-03 00:23:50,579 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 30.84 sec
2018-01-03 00:23:52,641 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 34.01 sec
2018-01-03 00:23:53,672 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 37.44 sec
2018-01-03 00:23:55,734 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 40.88 sec
2018-01-03 00:23:56,765 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 43.97 sec
2018-01-03 00:23:58,827 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 47.23 sec
2018-01-03 00:23:59,863 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 49.81 sec
2018-01-03 00:24:01,924 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 53.03 sec
2018-01-03 00:24:02,955 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 55.9 sec
2018-01-03 00:24:05,022 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 59.86 sec
2018-01-03 00:24:06,053 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 62.81 sec
2018-01-03 00:24:08,125 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 66.16 sec
2018-01-03 00:24:09,161 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 70.29 sec
2018-01-03 00:24:12,252 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 72.6 sec
2018-01-03 00:24:14,312 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 75.17 sec
2018-01-03 00:24:17,399 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 78.75 sec
2018-01-03 00:24:19,469 Stage-1 map = 76%,  reduce = 11%, Cumulative CPU 80.01 sec
2018-01-03 00:24:20,501 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 83.73 sec
2018-01-03 00:24:23,591 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 87.2 sec
2018-01-03 00:24:25,648 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 89.28 sec
2018-01-03 00:24:26,676 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 102.42 sec
MapReduce Total cumulative CPU time: 1 minutes 42 seconds 420 msec
Ended Job = job_1513599404024_159370
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159377, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159377/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159377
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:24:32,385 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:24:37,556 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.58 sec
2018-01-03 00:24:46,831 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.7 sec
2018-01-03 00:24:48,892 Stage-2 map = 100%,  reduce = 91%, Cumulative CPU 16.65 sec
2018-01-03 00:24:49,922 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.24 sec
MapReduce Total cumulative CPU time: 18 seconds 240 msec
Ended Job = job_1513599404024_159377
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159379, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159379/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159379
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:25:23,199 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:25:29,594 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.03 sec
2018-01-03 00:25:34,847 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.39 sec
MapReduce Total cumulative CPU time: 5 seconds 390 msec
Ended Job = job_1513599404024_159379
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 102.42 sec   HDFS Read: 349387270 HDFS Write: 2251911 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.24 sec   HDFS Read: 49514217 HDFS Write: 96047 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.39 sec   HDFS Read: 103722 HDFS Write: 3774 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 6 seconds 50 msec
OK
Time taken: 131.942 seconds, Fetched: 502 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.386 seconds
Query ID = boss_20180103002543_0c0064fb-7e2f-4e02-bf80-5222e3af5b8b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 13
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159389, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159389/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159389
Hadoop job information for Stage-1: number of mappers: 15; number of reducers: 13
2018-01-03 00:25:55,559 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:26:06,054 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 122.63 sec
2018-01-03 00:26:07,089 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 178.89 sec
2018-01-03 00:26:08,123 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 182.5 sec
2018-01-03 00:26:09,159 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 212.02 sec
2018-01-03 00:26:10,191 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 236.18 sec
2018-01-03 00:26:11,226 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 239.45 sec
2018-01-03 00:26:12,257 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 259.76 sec
2018-01-03 00:26:13,288 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 275.3 sec
2018-01-03 00:26:14,319 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 280.5 sec
2018-01-03 00:26:15,351 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 293.41 sec
2018-01-03 00:26:16,384 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 304.0 sec
2018-01-03 00:26:17,421 Stage-1 map = 88%,  reduce = 8%, Cumulative CPU 316.66 sec
2018-01-03 00:26:18,458 Stage-1 map = 91%,  reduce = 15%, Cumulative CPU 321.56 sec
2018-01-03 00:26:19,490 Stage-1 map = 92%,  reduce = 21%, Cumulative CPU 330.78 sec
2018-01-03 00:26:20,521 Stage-1 map = 96%,  reduce = 25%, Cumulative CPU 333.07 sec
2018-01-03 00:26:21,553 Stage-1 map = 96%,  reduce = 27%, Cumulative CPU 333.49 sec
2018-01-03 00:26:22,584 Stage-1 map = 97%,  reduce = 28%, Cumulative CPU 336.68 sec
2018-01-03 00:26:23,613 Stage-1 map = 97%,  reduce = 29%, Cumulative CPU 337.22 sec
2018-01-03 00:26:26,699 Stage-1 map = 100%,  reduce = 35%, Cumulative CPU 335.1 sec
2018-01-03 00:26:27,731 Stage-1 map = 100%,  reduce = 73%, Cumulative CPU 361.91 sec
2018-01-03 00:26:28,760 Stage-1 map = 100%,  reduce = 87%, Cumulative CPU 372.58 sec
2018-01-03 00:26:29,787 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 383.62 sec
MapReduce Total cumulative CPU time: 6 minutes 23 seconds 620 msec
Ended Job = job_1513599404024_159389
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159396, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159396/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159396
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:26:36,782 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:26:46,066 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.6 sec
2018-01-03 00:26:50,191 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.2 sec
2018-01-03 00:26:54,309 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.65 sec
MapReduce Total cumulative CPU time: 14 seconds 650 msec
Ended Job = job_1513599404024_159396
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159398, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159398/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159398
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:26:59,974 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:27:04,099 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.48 sec
2018-01-03 00:27:10,265 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.34 sec
MapReduce Total cumulative CPU time: 5 seconds 340 msec
Ended Job = job_1513599404024_159398
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 15  Reduce: 13   Cumulative CPU: 383.62 sec   HDFS Read: 1235415455 HDFS Write: 567888 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.65 sec   HDFS Read: 47832814 HDFS Write: 27501 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.34 sec   HDFS Read: 35177 HDFS Write: 2988 SUCCESS
Total MapReduce CPU Time Spent: 6 minutes 43 seconds 610 msec
OK
Time taken: 87.505 seconds, Fetched: 423 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.365 seconds
Query ID = boss_20180103002717_e866e8ed-62e8-4c54-bdb1-6c163b207e4b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159402, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159402/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159402
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:27:28,297 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:27:46,908 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 9.63 sec
2018-01-03 00:27:50,008 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.08 sec
2018-01-03 00:27:53,103 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 15.52 sec
2018-01-03 00:27:56,197 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 16.4 sec
2018-01-03 00:27:59,292 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 17.4 sec
2018-01-03 00:28:02,387 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 18.02 sec
2018-01-03 00:28:05,477 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 18.98 sec
2018-01-03 00:28:08,571 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 19.87 sec
2018-01-03 00:28:11,661 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 20.64 sec
2018-01-03 00:28:14,753 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 21.14 sec
2018-01-03 00:28:17,844 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 21.79 sec
2018-01-03 00:28:19,901 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 22.75 sec
2018-01-03 00:28:22,986 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 23.65 sec
2018-01-03 00:28:26,078 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 24.1 sec
2018-01-03 00:28:29,162 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 24.59 sec
2018-01-03 00:28:32,248 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 25.17 sec
2018-01-03 00:28:35,337 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 25.56 sec
2018-01-03 00:28:38,421 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 26.19 sec
2018-01-03 00:28:41,507 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 27.24 sec
2018-01-03 00:28:44,590 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 27.8 sec
2018-01-03 00:28:47,672 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 28.34 sec
2018-01-03 00:28:50,757 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 28.73 sec
2018-01-03 00:28:53,838 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 29.49 sec
2018-01-03 00:28:56,917 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 31.16 sec
2018-01-03 00:29:00,001 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 31.92 sec
2018-01-03 00:29:03,081 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 32.3 sec
2018-01-03 00:29:04,112 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 33.72 sec
2018-01-03 00:29:23,636 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 37.85 sec
MapReduce Total cumulative CPU time: 37 seconds 850 msec
Ended Job = job_1513599404024_159402
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159410, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159410/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159410
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:29:37,369 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:29:42,515 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.09 sec
2018-01-03 00:29:49,705 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.22 sec
MapReduce Total cumulative CPU time: 15 seconds 220 msec
Ended Job = job_1513599404024_159410
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159415, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159415/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159415
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:29:55,324 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:30:05,632 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.87 sec
2018-01-03 00:30:19,011 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.13 sec
MapReduce Total cumulative CPU time: 6 seconds 130 msec
Ended Job = job_1513599404024_159415
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 37.85 sec   HDFS Read: 100844683 HDFS Write: 566025 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.22 sec   HDFS Read: 47827751 HDFS Write: 205580 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.13 sec   HDFS Read: 213217 HDFS Write: 7109 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 200 msec
OK
Time taken: 182.079 seconds, Fetched: 848 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.35 seconds
Query ID = boss_20180103003026_bffeb81e-8bb8-435e-8119-3d19ff08eea6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159418, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159418/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159418
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:31:19,761 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:32:07,700 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 15.21 sec
2018-01-03 00:32:10,805 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 19.67 sec
2018-01-03 00:32:13,913 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 23.05 sec
2018-01-03 00:32:17,002 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 26.13 sec
2018-01-03 00:32:22,157 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 29.16 sec
2018-01-03 00:32:25,246 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 31.16 sec
2018-01-03 00:32:28,334 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 32.55 sec
2018-01-03 00:32:32,455 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 33.98 sec
2018-01-03 00:32:35,541 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 35.7 sec
2018-01-03 00:32:38,730 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 42.56 sec
2018-01-03 00:32:40,916 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 43.66 sec
2018-01-03 00:32:44,028 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 44.94 sec
2018-01-03 00:32:47,124 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 46.73 sec
2018-01-03 00:32:50,210 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 47.71 sec
2018-01-03 00:32:53,294 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 48.5 sec
2018-01-03 00:32:57,414 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 59.06 sec
2018-01-03 00:33:00,518 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 60.48 sec
2018-01-03 00:33:03,613 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 61.46 sec
2018-01-03 00:33:06,706 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 61.93 sec
2018-01-03 00:33:09,792 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 64.18 sec
2018-01-03 00:33:12,881 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 65.86 sec
2018-01-03 00:33:15,969 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 68.05 sec
2018-01-03 00:33:19,049 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 69.53 sec
2018-01-03 00:33:22,131 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 71.02 sec
2018-01-03 00:33:31,430 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 76.58 sec
MapReduce Total cumulative CPU time: 1 minutes 16 seconds 580 msec
Ended Job = job_1513599404024_159418
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159436, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159436/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159436
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:33:50,136 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:33:56,336 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.11 sec
2018-01-03 00:34:00,469 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 17.88 sec
2018-01-03 00:34:04,592 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 26.89 sec
MapReduce Total cumulative CPU time: 26 seconds 890 msec
Ended Job = job_1513599404024_159436
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159439, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159439/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159439
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:34:16,454 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:34:22,724 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.93 sec
2018-01-03 00:34:42,344 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.92 sec
MapReduce Total cumulative CPU time: 9 seconds 920 msec
Ended Job = job_1513599404024_159439
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 76.58 sec   HDFS Read: 100844673 HDFS Write: 1275010 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 26.89 sec   HDFS Read: 48536736 HDFS Write: 132432 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.92 sec   HDFS Read: 140070 HDFS Write: 2776 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 53 seconds 390 msec
OK
Time taken: 256.678 seconds, Fetched: 402 row(s)
开始执行20170827日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103003450_62f74519-8e3d-42fb-b814-17c2bfb2d767
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159441, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159441/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159441
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 00:35:06,697 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:35:15,033 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 11.67 sec
2018-01-03 00:35:17,110 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 36.03 sec
2018-01-03 00:35:20,612 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 43.43 sec
2018-01-03 00:35:22,684 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 47.13 sec
2018-01-03 00:35:23,718 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 50.77 sec
2018-01-03 00:35:25,792 Stage-1 map = 44%,  reduce = 11%, Cumulative CPU 56.27 sec
2018-01-03 00:35:26,827 Stage-1 map = 46%,  reduce = 11%, Cumulative CPU 59.62 sec
2018-01-03 00:35:28,896 Stage-1 map = 48%,  reduce = 11%, Cumulative CPU 63.58 sec
2018-01-03 00:35:29,933 Stage-1 map = 51%,  reduce = 11%, Cumulative CPU 67.42 sec
2018-01-03 00:35:32,424 Stage-1 map = 53%,  reduce = 11%, Cumulative CPU 71.59 sec
2018-01-03 00:35:34,893 Stage-1 map = 56%,  reduce = 11%, Cumulative CPU 78.88 sec
2018-01-03 00:35:35,925 Stage-1 map = 57%,  reduce = 11%, Cumulative CPU 81.98 sec
2018-01-03 00:35:37,989 Stage-1 map = 58%,  reduce = 11%, Cumulative CPU 85.66 sec
2018-01-03 00:35:39,021 Stage-1 map = 60%,  reduce = 11%, Cumulative CPU 88.66 sec
2018-01-03 00:35:41,093 Stage-1 map = 62%,  reduce = 11%, Cumulative CPU 93.11 sec
2018-01-03 00:35:42,133 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 96.21 sec
2018-01-03 00:35:44,200 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 100.41 sec
2018-01-03 00:35:45,234 Stage-1 map = 67%,  reduce = 11%, Cumulative CPU 103.59 sec
2018-01-03 00:35:47,308 Stage-1 map = 72%,  reduce = 11%, Cumulative CPU 111.32 sec
2018-01-03 00:35:48,340 Stage-1 map = 84%,  reduce = 11%, Cumulative CPU 112.44 sec
2018-01-03 00:35:50,408 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 116.0 sec
2018-01-03 00:35:53,510 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 119.71 sec
2018-01-03 00:35:56,608 Stage-1 map = 89%,  reduce = 22%, Cumulative CPU 122.98 sec
2018-01-03 00:35:57,640 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 123.64 sec
2018-01-03 00:35:58,676 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 139.35 sec
MapReduce Total cumulative CPU time: 2 minutes 19 seconds 350 msec
Ended Job = job_1513599404024_159441
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159449, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159449/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159449
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:36:05,444 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:36:10,635 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.91 sec
2018-01-03 00:36:18,923 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.3 sec
2018-01-03 00:36:22,019 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.7 sec
MapReduce Total cumulative CPU time: 18 seconds 700 msec
Ended Job = job_1513599404024_159449
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159453, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159453/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159453
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:36:28,679 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:36:33,836 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.37 sec
2018-01-03 00:36:42,067 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.5 sec
MapReduce Total cumulative CPU time: 6 seconds 500 msec
Ended Job = job_1513599404024_159453
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 139.35 sec   HDFS Read: 376398287 HDFS Write: 2406473 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.7 sec   HDFS Read: 49782727 HDFS Write: 109231 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.5 sec   HDFS Read: 116906 HDFS Write: 3864 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 44 seconds 550 msec
OK
Time taken: 112.765 seconds, Fetched: 522 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.388 seconds
Query ID = boss_20180103003649_1ceee2ea-4bb1-4ebd-8b18-68b900390716
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 13
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159460, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159460/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159460
Hadoop job information for Stage-1: number of mappers: 16; number of reducers: 13
2018-01-03 00:37:01,725 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:37:11,095 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 98.93 sec
2018-01-03 00:37:12,132 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 158.28 sec
2018-01-03 00:37:13,167 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 179.01 sec
2018-01-03 00:37:14,202 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 199.48 sec
2018-01-03 00:37:15,238 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 211.88 sec
2018-01-03 00:37:16,270 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 224.18 sec
2018-01-03 00:37:17,305 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 248.49 sec
2018-01-03 00:37:18,337 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 260.65 sec
2018-01-03 00:37:19,368 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 264.69 sec
2018-01-03 00:37:20,401 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 293.11 sec
2018-01-03 00:37:21,440 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 305.02 sec
2018-01-03 00:37:22,472 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 314.96 sec
2018-01-03 00:37:23,514 Stage-1 map = 88%,  reduce = 14%, Cumulative CPU 322.82 sec
2018-01-03 00:37:24,547 Stage-1 map = 90%,  reduce = 18%, Cumulative CPU 330.87 sec
2018-01-03 00:37:25,578 Stage-1 map = 91%,  reduce = 20%, Cumulative CPU 334.76 sec
2018-01-03 00:37:26,611 Stage-1 map = 91%,  reduce = 23%, Cumulative CPU 335.41 sec
2018-01-03 00:37:27,642 Stage-1 map = 100%,  reduce = 23%, Cumulative CPU 345.5 sec
2018-01-03 00:37:28,673 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 375.96 sec
2018-01-03 00:37:29,704 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 393.0 sec
2018-01-03 00:37:30,735 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 397.36 sec
MapReduce Total cumulative CPU time: 6 minutes 37 seconds 360 msec
Ended Job = job_1513599404024_159460
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159469, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159469/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159469
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:37:38,464 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:37:43,632 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.8 sec
2018-01-03 00:37:44,666 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.51 sec
2018-01-03 00:37:57,033 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.14 sec
MapReduce Total cumulative CPU time: 15 seconds 140 msec
Ended Job = job_1513599404024_159469
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159475, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159475/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159475
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:38:04,735 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:38:11,027 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.03 sec
2018-01-03 00:38:16,180 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.17 sec
MapReduce Total cumulative CPU time: 6 seconds 170 msec
Ended Job = job_1513599404024_159475
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 16  Reduce: 13   Cumulative CPU: 397.36 sec   HDFS Read: 1273999596 HDFS Write: 636797 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.14 sec   HDFS Read: 48015671 HDFS Write: 29427 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.17 sec   HDFS Read: 37103 HDFS Write: 3065 SUCCESS
Total MapReduce CPU Time Spent: 6 minutes 58 seconds 670 msec
OK
Time taken: 88.409 seconds, Fetched: 433 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.348 seconds
Query ID = boss_20180103003824_d4c29565-a73e-4ad4-85f8-d472b0262b7e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159484, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159484/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159484
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:38:36,042 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:38:46,451 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 7.72 sec
2018-01-03 00:38:49,549 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 8.69 sec
2018-01-03 00:38:52,643 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.27 sec
2018-01-03 00:38:55,732 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 18.41 sec
2018-01-03 00:38:58,825 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 18.97 sec
2018-01-03 00:39:01,914 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 19.4 sec
2018-01-03 00:39:05,017 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 19.97 sec
2018-01-03 00:39:08,108 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 22.73 sec
2018-01-03 00:39:11,195 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 27.1 sec
2018-01-03 00:39:14,281 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 27.41 sec
2018-01-03 00:39:17,370 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 29.02 sec
2018-01-03 00:39:20,454 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 29.32 sec
2018-01-03 00:39:23,539 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 29.75 sec
2018-01-03 00:39:26,626 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 30.2 sec
2018-01-03 00:39:29,709 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 36.52 sec
2018-01-03 00:39:32,791 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 36.91 sec
2018-01-03 00:39:35,874 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 37.2 sec
2018-01-03 00:39:38,954 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 37.31 sec
2018-01-03 00:39:42,034 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 37.56 sec
2018-01-03 00:39:45,117 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 38.15 sec
2018-01-03 00:39:48,198 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 42.49 sec
2018-01-03 00:39:51,278 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 42.96 sec
2018-01-03 00:39:54,361 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 43.2 sec
2018-01-03 00:39:57,440 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 43.5 sec
2018-01-03 00:40:00,519 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 45.01 sec
2018-01-03 00:40:03,602 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 45.35 sec
2018-01-03 00:40:05,658 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 49.92 sec
2018-01-03 00:40:07,720 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 50.96 sec
2018-01-03 00:40:12,861 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 56.83 sec
MapReduce Total cumulative CPU time: 56 seconds 830 msec
Ended Job = job_1513599404024_159484
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159518, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159518/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159518
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:40:20,844 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:40:26,359 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.09 sec
2018-01-03 00:40:28,436 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.13 sec
2018-01-03 00:40:42,832 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.66 sec
MapReduce Total cumulative CPU time: 18 seconds 660 msec
Ended Job = job_1513599404024_159518
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159525, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159525/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159525
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:41:13,528 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:41:56,968 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec
2018-01-03 00:42:03,145 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.92 sec
MapReduce Total cumulative CPU time: 6 seconds 920 msec
Ended Job = job_1513599404024_159525
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 56.83 sec   HDFS Read: 108079464 HDFS Write: 610683 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.66 sec   HDFS Read: 47986357 HDFS Write: 222803 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.92 sec   HDFS Read: 230440 HDFS Write: 7296 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 22 seconds 410 msec
OK
Time taken: 219.286 seconds, Fetched: 863 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103004210_bacb76e8-de02-49f5-8147-21df7afe28ad
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159541, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159541/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159541
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:42:21,015 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:42:32,421 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 9.6 sec
2018-01-03 00:42:35,521 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 12.87 sec
2018-01-03 00:42:37,585 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 14.72 sec
2018-01-03 00:42:40,677 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 16.02 sec
2018-01-03 00:42:43,771 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 17.06 sec
2018-01-03 00:42:46,863 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 18.13 sec
2018-01-03 00:42:49,953 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 19.33 sec
2018-01-03 00:42:53,048 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 20.73 sec
2018-01-03 00:42:56,138 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 21.43 sec
2018-01-03 00:42:59,228 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 22.79 sec
2018-01-03 00:43:02,321 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 24.28 sec
2018-01-03 00:43:05,408 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 25.76 sec
2018-01-03 00:43:08,497 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 27.43 sec
2018-01-03 00:43:11,590 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 29.17 sec
2018-01-03 00:43:17,768 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 34.11 sec
MapReduce Total cumulative CPU time: 34 seconds 110 msec
Ended Job = job_1513599404024_159541
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159557, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159557/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159557
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:43:56,575 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:44:01,740 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.46 sec
2018-01-03 00:44:02,771 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.1 sec
2018-01-03 00:44:16,157 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.04 sec
MapReduce Total cumulative CPU time: 15 seconds 40 msec
Ended Job = job_1513599404024_159557
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159571, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159571/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159571
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:44:23,826 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:44:31,045 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec
2018-01-03 00:44:37,220 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.68 sec
MapReduce Total cumulative CPU time: 6 seconds 680 msec
Ended Job = job_1513599404024_159571
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 34.11 sec   HDFS Read: 108079454 HDFS Write: 1334589 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.04 sec   HDFS Read: 48710263 HDFS Write: 147403 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.68 sec   HDFS Read: 155041 HDFS Write: 2800 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 830 msec
OK
Time taken: 147.346 seconds, Fetched: 400 row(s)
开始执行20170828日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.365 seconds
Query ID = boss_20180103004445_d621c00e-55d2-4093-ae0f-c68a42b3088b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159577, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159577/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159577
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:44:54,472 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:45:04,846 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 11.93 sec
2018-01-03 00:45:06,916 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 15.75 sec
2018-01-03 00:45:10,020 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 18.94 sec
2018-01-03 00:45:12,083 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 21.45 sec
2018-01-03 00:45:17,251 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 26.48 sec
MapReduce Total cumulative CPU time: 26 seconds 480 msec
Ended Job = job_1513599404024_159577
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159584, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159584/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159584
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:45:22,957 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:45:31,221 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.47 sec
2018-01-03 00:45:36,379 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.07 sec
2018-01-03 00:45:37,410 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.19 sec
MapReduce Total cumulative CPU time: 16 seconds 190 msec
Ended Job = job_1513599404024_159584
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159592, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159592/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159592
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:45:44,084 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:46:03,639 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.77 sec
2018-01-03 00:46:08,781 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.25 sec
MapReduce Total cumulative CPU time: 5 seconds 250 msec
Ended Job = job_1513599404024_159592
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 26.48 sec   HDFS Read: 76760777 HDFS Write: 511265 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.19 sec   HDFS Read: 45091643 HDFS Write: 25394 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.25 sec   HDFS Read: 33069 HDFS Write: 2335 SUCCESS
Total MapReduce CPU Time Spent: 47 seconds 920 msec
OK
Time taken: 85.64 seconds, Fetched: 330 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.392 seconds
Query ID = boss_20180103004625_a3c83594-6d95-4364-8252-915bb5bc3166
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159601, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159601/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159601
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 00:46:42,810 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:46:53,152 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 23.59 sec
2018-01-03 00:46:56,250 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 31.12 sec
2018-01-03 00:46:59,342 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 37.64 sec
2018-01-03 00:47:02,432 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 44.28 sec
2018-01-03 00:47:03,462 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 46.77 sec
2018-01-03 00:47:05,523 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 49.77 sec
2018-01-03 00:47:06,556 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 51.78 sec
2018-01-03 00:47:07,586 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 65.01 sec
2018-01-03 00:47:10,671 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 69.21 sec
2018-01-03 00:47:12,732 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 71.97 sec
2018-01-03 00:47:13,766 Stage-1 map = 100%,  reduce = 31%, Cumulative CPU 74.97 sec
2018-01-03 00:47:14,798 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 83.14 sec
MapReduce Total cumulative CPU time: 1 minutes 23 seconds 140 msec
Ended Job = job_1513599404024_159601
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159619, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159619/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159619
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:47:29,532 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:47:34,696 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.21 sec
2018-01-03 00:47:35,727 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.66 sec
2018-01-03 00:47:48,083 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.51 sec
MapReduce Total cumulative CPU time: 14 seconds 510 msec
Ended Job = job_1513599404024_159619
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159625, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159625/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159625
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:47:53,731 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:48:01,965 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.61 sec
2018-01-03 00:48:07,106 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.75 sec
MapReduce Total cumulative CPU time: 5 seconds 750 msec
Ended Job = job_1513599404024_159625
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 83.14 sec   HDFS Read: 270770367 HDFS Write: 135897 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.51 sec   HDFS Read: 44716799 HDFS Write: 12369 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.75 sec   HDFS Read: 20045 HDFS Write: 1856 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 43 seconds 400 msec
OK
Time taken: 102.57 seconds, Fetched: 266 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103004814_3254cfe0-4598-4fa4-86d9-f5c486d95c53
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159631, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159631/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159631
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:48:32,923 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:48:43,305 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 8.98 sec
2018-01-03 00:48:46,407 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 10.16 sec
2018-01-03 00:48:49,500 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 11.69 sec
2018-01-03 00:48:51,560 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 12.42 sec
2018-01-03 00:48:54,651 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 13.15 sec
2018-01-03 00:48:57,740 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 13.51 sec
2018-01-03 00:49:00,825 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 13.86 sec
2018-01-03 00:49:03,919 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 14.45 sec
2018-01-03 00:49:07,007 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 15.96 sec
2018-01-03 00:49:10,091 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 16.59 sec
2018-01-03 00:49:13,181 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 16.91 sec
2018-01-03 00:49:16,264 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 17.32 sec
2018-01-03 00:49:19,350 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 17.71 sec
2018-01-03 00:49:22,436 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 18.14 sec
2018-01-03 00:49:25,517 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 18.35 sec
2018-01-03 00:49:31,681 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 18.71 sec
2018-01-03 00:49:34,762 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 19.03 sec
2018-01-03 00:49:37,848 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 19.24 sec
2018-01-03 00:49:40,930 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 19.38 sec
2018-01-03 00:49:44,008 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 20.1 sec
2018-01-03 00:49:47,084 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 20.32 sec
2018-01-03 00:49:50,164 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 20.52 sec
2018-01-03 00:49:52,216 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 20.87 sec
2018-01-03 00:49:55,292 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 21.08 sec
2018-01-03 00:49:58,372 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 21.34 sec
2018-01-03 00:50:01,448 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 21.54 sec
2018-01-03 00:50:04,526 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 22.75 sec
2018-01-03 00:50:07,606 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 23.13 sec
2018-01-03 00:50:09,657 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 24.36 sec
2018-01-03 00:50:16,847 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 29.73 sec
MapReduce Total cumulative CPU time: 29 seconds 730 msec
Ended Job = job_1513599404024_159631
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159661, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159661/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159661
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:50:31,644 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:50:37,955 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.82 sec
2018-01-03 00:50:44,507 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.12 sec
2018-01-03 00:50:46,568 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.3 sec
MapReduce Total cumulative CPU time: 15 seconds 300 msec
Ended Job = job_1513599404024_159661
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159667, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159667/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159667
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:50:52,294 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:50:56,412 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.88 sec
2018-01-03 00:51:01,558 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.53 sec
MapReduce Total cumulative CPU time: 5 seconds 530 msec
Ended Job = job_1513599404024_159667
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 29.73 sec   HDFS Read: 94664101 HDFS Write: 614252 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.3 sec   HDFS Read: 45194574 HDFS Write: 198405 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.53 sec   HDFS Read: 206042 HDFS Write: 7560 SUCCESS
Total MapReduce CPU Time Spent: 50 seconds 560 msec
OK
Time taken: 167.79 seconds, Fetched: 895 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103005117_68e32992-0bc5-4c34-b4fa-7942b846d81d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159672, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159672/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159672
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:51:27,373 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:51:37,742 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.6 sec
2018-01-03 00:51:40,849 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 14.4 sec
2018-01-03 00:51:43,948 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 16.48 sec
2018-01-03 00:51:47,046 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 17.62 sec
2018-01-03 00:51:50,147 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 19.19 sec
2018-01-03 00:51:53,241 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 20.04 sec
2018-01-03 00:51:56,330 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 21.19 sec
2018-01-03 00:51:59,425 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 22.83 sec
2018-01-03 00:52:02,514 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 23.83 sec
2018-01-03 00:52:05,601 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 25.56 sec
2018-01-03 00:52:08,692 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 27.0 sec
2018-01-03 00:52:11,778 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 27.76 sec
2018-01-03 00:52:14,863 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 28.39 sec
2018-01-03 00:52:17,951 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 29.48 sec
2018-01-03 00:52:21,035 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 30.19 sec
2018-01-03 00:52:24,119 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 31.32 sec
2018-01-03 00:52:27,205 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 33.77 sec
2018-01-03 00:52:29,262 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 35.31 sec
2018-01-03 00:52:34,407 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.59 sec
MapReduce Total cumulative CPU time: 39 seconds 590 msec
Ended Job = job_1513599404024_159672
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159680, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159680/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159680
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:52:40,120 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:52:45,277 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.58 sec
2018-01-03 00:52:48,367 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.61 sec
2018-01-03 00:52:52,473 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.36 sec
MapReduce Total cumulative CPU time: 16 seconds 360 msec
Ended Job = job_1513599404024_159680
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159684, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159684/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159684
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:52:58,107 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:53:11,509 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.1 sec
2018-01-03 00:53:17,671 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.35 sec
MapReduce Total cumulative CPU time: 6 seconds 350 msec
Ended Job = job_1513599404024_159684
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 39.59 sec   HDFS Read: 94664091 HDFS Write: 1070741 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.36 sec   HDFS Read: 45651063 HDFS Write: 122119 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.35 sec   HDFS Read: 129757 HDFS Write: 2793 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 2 seconds 300 msec
OK
Time taken: 121.386 seconds, Fetched: 408 row(s)
开始执行20170829日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.365 seconds
Query ID = boss_20180103005325_9ccdf12e-b1c5-4cfe-be00-8f4616c9c993
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159690, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159690/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159690
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 00:53:34,804 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:53:44,127 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 12.14 sec
2018-01-03 00:53:45,159 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 23.61 sec
2018-01-03 00:53:47,221 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 27.37 sec
2018-01-03 00:53:48,255 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 30.99 sec
2018-01-03 00:53:50,318 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 34.25 sec
2018-01-03 00:53:51,350 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 39.27 sec
2018-01-03 00:53:54,441 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 42.57 sec
2018-01-03 00:53:57,536 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 45.73 sec
2018-01-03 00:53:59,595 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 48.89 sec
2018-01-03 00:54:01,658 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 49.88 sec
2018-01-03 00:54:02,690 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 53.03 sec
2018-01-03 00:54:05,779 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 56.25 sec
2018-01-03 00:54:08,871 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 59.5 sec
2018-01-03 00:54:11,960 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 63.53 sec
2018-01-03 00:54:15,046 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 66.95 sec
2018-01-03 00:54:18,134 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 70.11 sec
2018-01-03 00:54:19,162 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 71.62 sec
2018-01-03 00:54:20,192 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 71.74 sec
2018-01-03 00:54:21,220 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 79.93 sec
MapReduce Total cumulative CPU time: 1 minutes 19 seconds 930 msec
Ended Job = job_1513599404024_159690
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159706, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159706/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159706
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:54:26,991 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:54:33,200 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.67 sec
2018-01-03 00:54:34,232 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.49 sec
2018-01-03 00:54:40,418 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.08 sec
MapReduce Total cumulative CPU time: 18 seconds 80 msec
Ended Job = job_1513599404024_159706
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159712, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159712/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159712
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:54:46,068 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:54:50,213 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.7 sec
2018-01-03 00:54:57,444 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.34 sec
MapReduce Total cumulative CPU time: 5 seconds 340 msec
Ended Job = job_1513599404024_159712
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 79.93 sec   HDFS Read: 258618550 HDFS Write: 1623652 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.08 sec   HDFS Read: 47001875 HDFS Write: 76347 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.34 sec   HDFS Read: 84018 HDFS Write: 3526 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 43 seconds 350 msec
OK
Time taken: 92.85 seconds, Fetched: 469 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.401 seconds
Query ID = boss_20180103005505_0a639548-a8d7-4b97-93fb-72989b84f35a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159717, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159717/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159717
Hadoop job information for Stage-1: number of mappers: 11; number of reducers: 9
2018-01-03 00:55:15,416 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:55:25,797 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 116.52 sec
2018-01-03 00:55:26,830 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 120.27 sec
2018-01-03 00:55:28,898 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 149.41 sec
2018-01-03 00:55:29,929 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 154.8 sec
2018-01-03 00:55:30,961 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 158.35 sec
2018-01-03 00:55:31,992 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 175.93 sec
2018-01-03 00:55:33,023 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 192.91 sec
2018-01-03 00:55:34,054 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 212.12 sec
2018-01-03 00:55:35,085 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 215.38 sec
2018-01-03 00:55:36,115 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 224.32 sec
2018-01-03 00:55:37,145 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 227.56 sec
2018-01-03 00:55:38,185 Stage-1 map = 88%,  reduce = 12%, Cumulative CPU 229.93 sec
2018-01-03 00:55:39,216 Stage-1 map = 90%,  reduce = 21%, Cumulative CPU 235.14 sec
2018-01-03 00:55:40,247 Stage-1 map = 91%,  reduce = 21%, Cumulative CPU 238.05 sec
2018-01-03 00:55:41,277 Stage-1 map = 94%,  reduce = 21%, Cumulative CPU 239.44 sec
2018-01-03 00:55:42,307 Stage-1 map = 96%,  reduce = 21%, Cumulative CPU 242.55 sec
2018-01-03 00:55:44,368 Stage-1 map = 100%,  reduce = 24%, Cumulative CPU 245.18 sec
2018-01-03 00:55:45,398 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 259.14 sec
2018-01-03 00:55:46,426 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 274.6 sec
MapReduce Total cumulative CPU time: 4 minutes 34 seconds 600 msec
Ended Job = job_1513599404024_159717
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159730, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159730/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159730
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:55:52,115 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:55:56,244 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.33 sec
2018-01-03 00:55:57,275 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.44 sec
2018-01-03 00:56:01,394 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.22 sec
MapReduce Total cumulative CPU time: 13 seconds 220 msec
Ended Job = job_1513599404024_159730
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159732, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159732/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159732
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:56:15,155 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:56:20,323 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.4 sec
2018-01-03 00:56:33,732 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.48 sec
MapReduce Total cumulative CPU time: 4 seconds 480 msec
Ended Job = job_1513599404024_159732
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 11  Reduce: 9   Cumulative CPU: 274.6 sec   HDFS Read: 842429191 HDFS Write: 375586 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.22 sec   HDFS Read: 45755648 HDFS Write: 21952 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.48 sec   HDFS Read: 29628 HDFS Write: 2523 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 52 seconds 300 msec
OK
Time taken: 89.548 seconds, Fetched: 370 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.351 seconds
Query ID = boss_20180103005641_bba66d1a-d948-414b-aac5-e23a8549284c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159740, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159740/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159740
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:56:52,563 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:57:10,143 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 8.23 sec
2018-01-03 00:57:13,238 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 10.88 sec
2018-01-03 00:57:16,330 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.58 sec
2018-01-03 00:57:19,418 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 12.2 sec
2018-01-03 00:57:22,508 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 12.72 sec
2018-01-03 00:57:25,595 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 13.05 sec
2018-01-03 00:57:28,682 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 13.46 sec
2018-01-03 00:57:31,771 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 13.94 sec
2018-01-03 00:57:34,855 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 14.05 sec
2018-01-03 00:57:37,940 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 14.74 sec
2018-01-03 00:57:41,025 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 15.02 sec
2018-01-03 00:57:44,108 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 15.42 sec
2018-01-03 00:57:47,190 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 15.76 sec
2018-01-03 00:57:49,244 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 16.34 sec
2018-01-03 00:57:52,329 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 16.76 sec
2018-01-03 00:57:55,410 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 17.19 sec
2018-01-03 00:57:58,509 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 17.39 sec
2018-01-03 00:58:01,594 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 17.87 sec
2018-01-03 00:58:04,677 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 18.12 sec
2018-01-03 00:58:07,758 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 18.6 sec
2018-01-03 00:58:10,839 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 18.8 sec
2018-01-03 00:58:13,917 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 19.13 sec
2018-01-03 00:58:16,998 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 19.37 sec
2018-01-03 00:58:20,075 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 20.24 sec
2018-01-03 00:58:23,152 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 21.16 sec
2018-01-03 00:58:26,231 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 21.36 sec
2018-01-03 00:58:29,309 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 22.57 sec
2018-01-03 00:58:35,471 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 27.82 sec
MapReduce Total cumulative CPU time: 27 seconds 820 msec
Ended Job = job_1513599404024_159740
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159758, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159758/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159758
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 00:58:41,156 Stage-2 map = 0%,  reduce = 0%
2018-01-03 00:58:46,326 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.85 sec
2018-01-03 00:59:00,736 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.58 sec
2018-01-03 00:59:02,793 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.11 sec
MapReduce Total cumulative CPU time: 16 seconds 110 msec
Ended Job = job_1513599404024_159758
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159765, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159765/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159765
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 00:59:08,538 Stage-3 map = 0%,  reduce = 0%
2018-01-03 00:59:13,678 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.41 sec
2018-01-03 00:59:18,816 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.0 sec
MapReduce Total cumulative CPU time: 6 seconds 0 msec
Ended Job = job_1513599404024_159765
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 27.82 sec   HDFS Read: 98582949 HDFS Write: 623064 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.11 sec   HDFS Read: 46000974 HDFS Write: 203164 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.0 sec   HDFS Read: 210801 HDFS Write: 7261 SUCCESS
Total MapReduce CPU Time Spent: 49 seconds 930 msec
OK
Time taken: 158.374 seconds, Fetched: 898 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103005934_24ab7fd6-600c-4ba2-b150-07e77095791c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159767, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159767/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159767
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 00:59:44,688 Stage-1 map = 0%,  reduce = 0%
2018-01-03 00:59:55,060 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.21 sec
2018-01-03 00:59:58,167 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 10.31 sec
2018-01-03 01:00:01,265 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 11.59 sec
2018-01-03 01:00:03,329 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 12.62 sec
2018-01-03 01:00:06,426 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 13.34 sec
2018-01-03 01:00:09,519 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 14.6 sec
2018-01-03 01:00:12,609 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 15.37 sec
2018-01-03 01:00:15,704 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 15.89 sec
2018-01-03 01:00:18,799 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 17.26 sec
2018-01-03 01:00:21,888 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 18.07 sec
2018-01-03 01:00:24,981 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 19.04 sec
2018-01-03 01:00:28,071 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 22.49 sec
2018-01-03 01:00:29,101 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 23.05 sec
2018-01-03 01:00:42,491 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 27.53 sec
MapReduce Total cumulative CPU time: 27 seconds 530 msec
Ended Job = job_1513599404024_159767
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159778, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159778/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159778
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:00:49,219 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:00:54,382 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.38 sec
2018-01-03 01:00:59,528 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.48 sec
MapReduce Total cumulative CPU time: 13 seconds 480 msec
Ended Job = job_1513599404024_159778
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159784, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159784/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159784
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:01:05,159 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:01:11,364 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.36 sec
2018-01-03 01:01:17,555 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.78 sec
MapReduce Total cumulative CPU time: 7 seconds 780 msec
Ended Job = job_1513599404024_159784
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 27.53 sec   HDFS Read: 98582939 HDFS Write: 1159131 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.48 sec   HDFS Read: 46537041 HDFS Write: 126432 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.78 sec   HDFS Read: 134070 HDFS Write: 2770 SUCCESS
Total MapReduce CPU Time Spent: 48 seconds 790 msec
OK
Time taken: 105.037 seconds, Fetched: 403 row(s)
开始执行20170830日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.371 seconds
Query ID = boss_20180103010126_f50e3d3d-896d-485a-b3b5-6a15312ffa51
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159789, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159789/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159789
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 01:01:37,160 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:01:47,579 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 13.35 sec
2018-01-03 01:01:50,679 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 16.73 sec
2018-01-03 01:01:52,743 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 19.83 sec
2018-01-03 01:01:53,775 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 29.54 sec
2018-01-03 01:01:55,839 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 32.92 sec
2018-01-03 01:01:56,871 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 37.12 sec
2018-01-03 01:01:58,930 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 40.16 sec
2018-01-03 01:01:59,963 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 44.91 sec
2018-01-03 01:02:02,021 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 48.31 sec
2018-01-03 01:02:03,051 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 51.57 sec
2018-01-03 01:02:05,113 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 54.91 sec
2018-01-03 01:02:06,143 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 58.52 sec
2018-01-03 01:02:08,203 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 62.21 sec
2018-01-03 01:02:09,237 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 65.39 sec
2018-01-03 01:02:11,294 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 69.48 sec
2018-01-03 01:02:12,324 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 72.9 sec
2018-01-03 01:02:14,384 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 76.27 sec
2018-01-03 01:02:15,415 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 79.6 sec
2018-01-03 01:02:18,511 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 83.01 sec
2018-01-03 01:02:21,598 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 86.6 sec
2018-01-03 01:02:23,657 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 90.66 sec
2018-01-03 01:02:24,691 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 91.37 sec
2018-01-03 01:02:26,751 Stage-1 map = 78%,  reduce = 8%, Cumulative CPU 94.51 sec
2018-01-03 01:02:29,841 Stage-1 map = 82%,  reduce = 8%, Cumulative CPU 97.74 sec
2018-01-03 01:02:31,899 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 100.81 sec
2018-01-03 01:02:33,957 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 111.4 sec
MapReduce Total cumulative CPU time: 1 minutes 51 seconds 400 msec
Ended Job = job_1513599404024_159789
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159799, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159799/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159799
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:02:40,766 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:02:46,960 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.82 sec
2018-01-03 01:02:58,292 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.38 sec
2018-01-03 01:03:01,384 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.4 sec
2018-01-03 01:03:07,568 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 17.56 sec
2018-01-03 01:03:09,628 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.97 sec
MapReduce Total cumulative CPU time: 23 seconds 970 msec
Ended Job = job_1513599404024_159799
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159804, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159804/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159804
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:03:25,414 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:03:29,552 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.7 sec
2018-01-03 01:03:38,811 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.18 sec
MapReduce Total cumulative CPU time: 6 seconds 180 msec
Ended Job = job_1513599404024_159804
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 111.4 sec   HDFS Read: 328531504 HDFS Write: 2093257 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.97 sec   HDFS Read: 46536331 HDFS Write: 86827 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.18 sec   HDFS Read: 94502 HDFS Write: 3672 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 21 seconds 550 msec
OK
Time taken: 133.259 seconds, Fetched: 485 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.401 seconds
Query ID = boss_20180103010346_c0ea8dc7-fac9-4c6d-a396-8a2d8a190ff7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 12
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159812, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159812/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159812
Hadoop job information for Stage-1: number of mappers: 14; number of reducers: 12
2018-01-03 01:04:07,223 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:04:15,545 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 10.26 sec
2018-01-03 01:04:17,617 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 133.72 sec
2018-01-03 01:04:18,651 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 168.3 sec
2018-01-03 01:04:19,687 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 172.3 sec
2018-01-03 01:04:20,719 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 204.31 sec
2018-01-03 01:04:21,754 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 218.72 sec
2018-01-03 01:04:22,787 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 221.59 sec
2018-01-03 01:04:23,818 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 243.2 sec
2018-01-03 01:04:24,851 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 245.89 sec
2018-01-03 01:04:25,888 Stage-1 map = 83%,  reduce = 7%, Cumulative CPU 249.42 sec
2018-01-03 01:04:26,922 Stage-1 map = 86%,  reduce = 18%, Cumulative CPU 263.74 sec
2018-01-03 01:04:27,954 Stage-1 map = 92%,  reduce = 18%, Cumulative CPU 269.67 sec
2018-01-03 01:04:28,989 Stage-1 map = 92%,  reduce = 20%, Cumulative CPU 269.99 sec
2018-01-03 01:04:30,021 Stage-1 map = 97%,  reduce = 23%, Cumulative CPU 276.15 sec
2018-01-03 01:04:32,114 Stage-1 map = 97%,  reduce = 26%, Cumulative CPU 276.9 sec
2018-01-03 01:04:33,144 Stage-1 map = 100%,  reduce = 26%, Cumulative CPU 280.6 sec
2018-01-03 01:04:34,172 Stage-1 map = 100%,  reduce = 64%, Cumulative CPU 298.91 sec
2018-01-03 01:04:35,202 Stage-1 map = 100%,  reduce = 86%, Cumulative CPU 311.75 sec
2018-01-03 01:04:36,234 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 316.42 sec
2018-01-03 01:04:37,268 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 321.14 sec
MapReduce Total cumulative CPU time: 5 minutes 21 seconds 140 msec
Ended Job = job_1513599404024_159812
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159825, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159825/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159825
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:04:58,102 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:05:03,257 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.73 sec
2018-01-03 01:05:11,493 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.62 sec
2018-01-03 01:05:13,552 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.74 sec
MapReduce Total cumulative CPU time: 14 seconds 740 msec
Ended Job = job_1513599404024_159825
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159837, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159837/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159837
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:05:21,265 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:05:26,519 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.03 sec
2018-01-03 01:05:33,728 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.46 sec
MapReduce Total cumulative CPU time: 5 seconds 460 msec
Ended Job = job_1513599404024_159837
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 14  Reduce: 12   Cumulative CPU: 321.14 sec   HDFS Read: 1077283316 HDFS Write: 480271 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.74 sec   HDFS Read: 44925965 HDFS Write: 26425 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.46 sec   HDFS Read: 34101 HDFS Write: 2880 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 41 seconds 340 msec
OK
Time taken: 108.126 seconds, Fetched: 398 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103010541_2d6c7b68-a456-4de9-9dfd-f4262039529d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159843, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159843/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159843
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 01:05:59,515 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:06:09,883 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 8.34 sec
2018-01-03 01:06:12,986 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.13 sec
2018-01-03 01:06:16,080 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 13.4 sec
2018-01-03 01:06:19,172 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 13.96 sec
2018-01-03 01:06:22,266 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 14.64 sec
2018-01-03 01:06:25,355 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.25 sec
2018-01-03 01:06:28,442 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.88 sec
2018-01-03 01:06:31,532 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 16.55 sec
2018-01-03 01:06:34,619 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 16.93 sec
2018-01-03 01:06:37,707 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 17.34 sec
2018-01-03 01:06:40,797 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 17.85 sec
2018-01-03 01:06:43,882 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 18.39 sec
2018-01-03 01:06:46,968 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 18.94 sec
2018-01-03 01:06:49,025 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 19.65 sec
2018-01-03 01:06:52,112 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 20.18 sec
2018-01-03 01:06:55,193 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 20.55 sec
2018-01-03 01:06:58,275 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 20.69 sec
2018-01-03 01:07:01,363 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 20.97 sec
2018-01-03 01:07:04,447 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 23.68 sec
2018-01-03 01:07:07,528 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 23.98 sec
2018-01-03 01:07:10,611 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 24.92 sec
2018-01-03 01:07:13,694 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 25.18 sec
2018-01-03 01:07:16,774 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 25.71 sec
2018-01-03 01:07:19,861 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 26.15 sec
2018-01-03 01:07:22,942 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 28.73 sec
2018-01-03 01:07:26,020 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 30.0 sec
2018-01-03 01:07:29,104 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.28 sec
2018-01-03 01:07:35,270 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 38.55 sec
MapReduce Total cumulative CPU time: 38 seconds 550 msec
Ended Job = job_1513599404024_159843
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159875, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159875/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159875
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:07:42,543 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:07:47,705 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.37 sec
2018-01-03 01:07:55,951 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.28 sec
2018-01-03 01:07:59,044 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.88 sec
MapReduce Total cumulative CPU time: 16 seconds 880 msec
Ended Job = job_1513599404024_159875
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159882, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159882/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159882
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:08:05,666 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:08:10,833 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.58 sec
2018-01-03 01:08:18,050 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.77 sec
MapReduce Total cumulative CPU time: 7 seconds 770 msec
Ended Job = job_1513599404024_159882
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 38.55 sec   HDFS Read: 99101079 HDFS Write: 614900 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.88 sec   HDFS Read: 45057656 HDFS Write: 198689 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.77 sec   HDFS Read: 206326 HDFS Write: 7309 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 3 seconds 200 msec
OK
Time taken: 157.626 seconds, Fetched: 896 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103010825_8685f325-fd87-4bb7-ac2b-717cd2a00cef
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159892, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159892/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159892
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 01:08:44,117 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:08:54,458 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.44 sec
2018-01-03 01:08:57,555 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 13.32 sec
2018-01-03 01:09:00,673 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 14.67 sec
2018-01-03 01:09:03,766 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 15.61 sec
2018-01-03 01:09:06,859 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 16.53 sec
2018-01-03 01:09:09,951 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 17.62 sec
2018-01-03 01:09:13,038 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 18.3 sec
2018-01-03 01:09:16,130 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 19.13 sec
2018-01-03 01:09:18,191 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 20.03 sec
2018-01-03 01:09:21,285 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 20.89 sec
2018-01-03 01:09:24,388 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 21.69 sec
2018-01-03 01:09:27,476 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 22.9 sec
2018-01-03 01:09:31,054 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 23.54 sec
2018-01-03 01:09:34,145 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 24.74 sec
2018-01-03 01:09:37,230 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 28.81 sec
2018-01-03 01:09:39,287 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 30.24 sec
2018-01-03 01:09:47,523 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 36.41 sec
MapReduce Total cumulative CPU time: 36 seconds 410 msec
Ended Job = job_1513599404024_159892
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159908, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159908/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159908
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:09:53,355 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:09:59,541 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.84 sec
2018-01-03 01:10:07,772 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.85 sec
2018-01-03 01:10:10,866 Stage-2 map = 100%,  reduce = 68%, Cumulative CPU 15.28 sec
2018-01-03 01:10:11,901 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.74 sec
MapReduce Total cumulative CPU time: 18 seconds 740 msec
Ended Job = job_1513599404024_159908
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159912, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159912/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159912
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:10:24,841 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:10:29,999 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.9 sec
2018-01-03 01:10:36,177 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.47 sec
MapReduce Total cumulative CPU time: 5 seconds 470 msec
Ended Job = job_1513599404024_159912
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 36.41 sec   HDFS Read: 99101069 HDFS Write: 1106881 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.74 sec   HDFS Read: 45549637 HDFS Write: 137882 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.47 sec   HDFS Read: 145520 HDFS Write: 2851 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 0 seconds 620 msec
OK
Time taken: 131.413 seconds, Fetched: 411 row(s)
开始执行20170831日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103011044_0a34a95e-95ed-4171-b8b3-c75629a16322
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159918, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159918/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159918
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 01:11:02,133 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:11:11,487 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.42 sec
2018-01-03 01:11:12,523 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 24.94 sec
2018-01-03 01:11:14,596 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 28.52 sec
2018-01-03 01:11:15,631 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 33.0 sec
2018-01-03 01:11:17,697 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 36.19 sec
2018-01-03 01:11:18,731 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 39.96 sec
2018-01-03 01:11:20,796 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 43.48 sec
2018-01-03 01:11:21,828 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 46.92 sec
2018-01-03 01:11:23,895 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 50.45 sec
2018-01-03 01:11:24,928 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 53.51 sec
2018-01-03 01:11:25,959 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 56.96 sec
2018-01-03 01:11:26,991 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 60.02 sec
2018-01-03 01:11:30,085 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 62.92 sec
2018-01-03 01:11:33,177 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 66.1 sec
2018-01-03 01:11:36,272 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 69.29 sec
2018-01-03 01:11:37,309 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 70.49 sec
2018-01-03 01:11:39,372 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 74.68 sec
2018-01-03 01:11:42,467 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 77.84 sec
2018-01-03 01:11:45,561 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 81.01 sec
2018-01-03 01:11:47,624 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 83.52 sec
2018-01-03 01:11:49,687 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 89.28 sec
2018-01-03 01:11:50,717 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 92.76 sec
MapReduce Total cumulative CPU time: 1 minutes 32 seconds 760 msec
Ended Job = job_1513599404024_159918
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159929, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159929/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159929
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:11:56,404 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:12:03,633 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 15.35 sec
2018-01-03 01:12:17,267 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.71 sec
MapReduce Total cumulative CPU time: 23 seconds 710 msec
Ended Job = job_1513599404024_159929
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159933, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159933/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159933
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:12:22,905 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:12:42,451 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.39 sec
2018-01-03 01:12:48,621 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.9 sec
MapReduce Total cumulative CPU time: 6 seconds 900 msec
Ended Job = job_1513599404024_159933
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 92.76 sec   HDFS Read: 306900675 HDFS Write: 2044482 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.71 sec   HDFS Read: 45369356 HDFS Write: 85072 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.9 sec   HDFS Read: 92747 HDFS Write: 3441 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 3 seconds 370 msec
OK
Time taken: 125.521 seconds, Fetched: 466 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.397 seconds
Query ID = boss_20180103011304_d2a88cae-bc51-4812-b65c-1b9c07ceefbb
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 11
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159938, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159938/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159938
Hadoop job information for Stage-1: number of mappers: 13; number of reducers: 11
2018-01-03 01:13:16,322 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:13:25,706 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 23.97 sec
2018-01-03 01:13:26,739 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 90.45 sec
2018-01-03 01:13:28,805 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 101.85 sec
2018-01-03 01:13:29,840 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 127.38 sec
2018-01-03 01:13:31,903 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 138.09 sec
2018-01-03 01:13:32,934 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 149.2 sec
2018-01-03 01:13:34,186 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 185.22 sec
2018-01-03 01:13:35,220 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 211.83 sec
2018-01-03 01:13:36,252 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 233.58 sec
2018-01-03 01:13:37,292 Stage-1 map = 62%,  reduce = 8%, Cumulative CPU 244.66 sec
2018-01-03 01:13:38,324 Stage-1 map = 67%,  reduce = 10%, Cumulative CPU 255.35 sec
2018-01-03 01:13:40,392 Stage-1 map = 75%,  reduce = 13%, Cumulative CPU 290.11 sec
2018-01-03 01:13:41,423 Stage-1 map = 76%,  reduce = 13%, Cumulative CPU 293.23 sec
2018-01-03 01:13:42,456 Stage-1 map = 82%,  reduce = 14%, Cumulative CPU 308.53 sec
2018-01-03 01:13:43,487 Stage-1 map = 85%,  reduce = 18%, Cumulative CPU 313.81 sec
2018-01-03 01:13:44,518 Stage-1 map = 85%,  reduce = 21%, Cumulative CPU 314.58 sec
2018-01-03 01:13:45,549 Stage-1 map = 90%,  reduce = 23%, Cumulative CPU 323.1 sec
2018-01-03 01:13:46,578 Stage-1 map = 92%,  reduce = 24%, Cumulative CPU 342.62 sec
2018-01-03 01:13:47,606 Stage-1 map = 97%,  reduce = 25%, Cumulative CPU 347.36 sec
2018-01-03 01:13:48,639 Stage-1 map = 97%,  reduce = 29%, Cumulative CPU 348.37 sec
2018-01-03 01:13:49,667 Stage-1 map = 100%,  reduce = 34%, Cumulative CPU 351.46 sec
2018-01-03 01:13:50,695 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 386.31 sec
2018-01-03 01:13:52,750 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 391.52 sec
MapReduce Total cumulative CPU time: 6 minutes 31 seconds 520 msec
Ended Job = job_1513599404024_159938
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159944, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159944/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159944
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:13:59,452 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:14:04,614 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.23 sec
2018-01-03 01:14:13,884 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.12 sec
2018-01-03 01:14:15,945 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 13.29 sec
2018-01-03 01:14:20,064 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.63 sec
MapReduce Total cumulative CPU time: 21 seconds 630 msec
Ended Job = job_1513599404024_159944
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159947, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159947/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159947
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:14:28,104 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:14:37,373 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.91 sec
2018-01-03 01:14:43,544 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.44 sec
MapReduce Total cumulative CPU time: 8 seconds 440 msec
Ended Job = job_1513599404024_159947
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 13  Reduce: 11   Cumulative CPU: 391.52 sec   HDFS Read: 1012682743 HDFS Write: 447310 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.35 sec   HDFS Read: 43774542 HDFS Write: 25253 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.44 sec   HDFS Read: 32929 HDFS Write: 2718 SUCCESS
Total MapReduce CPU Time Spent: 7 minutes 3 seconds 310 msec
OK
Time taken: 100.2 seconds, Fetched: 384 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103011451_2fe66e86-6639-4902-bfb3-1116125d8c62
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159949, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159949/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159949
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 2
2018-01-03 01:15:13,051 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:15:48,327 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 12.78 sec
2018-01-03 01:15:52,973 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 15.77 sec
2018-01-03 01:15:55,087 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 17.42 sec
2018-01-03 01:15:58,195 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 18.26 sec
2018-01-03 01:16:02,797 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 21.11 sec
2018-01-03 01:16:05,969 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 22.19 sec
2018-01-03 01:16:09,056 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 23.9 sec
2018-01-03 01:16:12,138 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 25.49 sec
2018-01-03 01:16:15,222 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 28.34 sec
2018-01-03 01:16:18,302 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 29.28 sec
2018-01-03 01:16:21,384 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 29.72 sec
2018-01-03 01:16:24,478 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 29.99 sec
2018-01-03 01:16:27,563 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 30.56 sec
2018-01-03 01:16:30,648 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 30.95 sec
2018-01-03 01:16:33,338 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 31.58 sec
2018-01-03 01:16:36,431 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 32.12 sec
2018-01-03 01:16:42,678 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 32.76 sec
2018-01-03 01:16:45,935 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 33.09 sec
2018-01-03 01:16:49,015 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 33.7 sec
2018-01-03 01:16:52,114 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 34.48 sec
2018-01-03 01:16:55,268 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 35.1 sec
2018-01-03 01:16:58,364 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 35.61 sec
2018-01-03 01:17:01,444 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 36.3 sec
2018-01-03 01:17:04,710 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 36.82 sec
2018-01-03 01:17:06,765 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 37.28 sec
2018-01-03 01:17:13,148 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 37.8 sec
2018-01-03 01:17:17,518 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 38.99 sec
2018-01-03 01:17:24,819 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 40.61 sec
2018-01-03 01:17:33,382 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 42.26 sec
2018-01-03 01:17:40,988 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 44.83 sec
2018-01-03 01:17:48,462 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 47.75 sec
2018-01-03 01:17:52,727 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 47.75 sec
2018-01-03 01:18:00,018 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 48.47 sec
2018-01-03 01:18:07,821 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 48.98 sec
2018-01-03 01:18:11,421 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 49.18 sec
2018-01-03 01:18:22,697 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 50.3 sec
2018-01-03 01:18:29,151 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 52.39 sec
2018-01-03 01:18:48,529 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 60.36 sec
2018-01-03 01:18:53,862 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 60.98 sec
2018-01-03 01:19:15,031 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 62.62 sec
2018-01-03 01:19:30,675 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 62.94 sec
2018-01-03 01:19:46,898 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 65.1 sec
2018-01-03 01:19:52,157 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 70.98 sec
2018-01-03 01:19:59,350 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 77.32 sec
MapReduce Total cumulative CPU time: 1 minutes 17 seconds 320 msec
Ended Job = job_1513599404024_159949
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159983, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159983/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159983
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:20:18,965 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:20:26,185 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 7.35 sec
2018-01-03 01:20:37,495 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 7.92 sec
2018-01-03 01:20:45,713 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 18.39 sec
2018-01-03 01:20:48,793 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.09 sec
MapReduce Total cumulative CPU time: 23 seconds 90 msec
Ended Job = job_1513599404024_159983
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159989, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159989/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159989
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:20:55,591 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:21:00,742 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.48 sec
2018-01-03 01:21:12,089 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.19 sec
MapReduce Total cumulative CPU time: 8 seconds 190 msec
Ended Job = job_1513599404024_159989
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 2   Cumulative CPU: 77.32 sec   HDFS Read: 102492824 HDFS Write: 581853 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.09 sec   HDFS Read: 43906671 HDFS Write: 184224 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.19 sec   HDFS Read: 191861 HDFS Write: 6733 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 48 seconds 600 msec
OK
Time taken: 381.923 seconds, Fetched: 824 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.346 seconds
Query ID = boss_20180103012119_90623874-704e-42e5-956a-145b76c8c1c2
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_159993, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_159993/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_159993
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 2
2018-01-03 01:21:32,246 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:21:53,961 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 12.03 sec
2018-01-03 01:21:57,050 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 13.68 sec
2018-01-03 01:22:01,166 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 17.24 sec
2018-01-03 01:22:04,258 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 31.35 sec
2018-01-03 01:22:07,344 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 32.14 sec
2018-01-03 01:22:10,431 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 32.86 sec
2018-01-03 01:22:13,521 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 45.44 sec
2018-01-03 01:22:16,605 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 45.91 sec
2018-01-03 01:22:20,722 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 46.88 sec
2018-01-03 01:22:23,806 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 48.03 sec
2018-01-03 01:22:26,888 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 49.01 sec
2018-01-03 01:22:28,942 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 49.58 sec
2018-01-03 01:22:33,052 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 50.95 sec
2018-01-03 01:22:36,131 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 52.44 sec
2018-01-03 01:22:39,214 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 52.77 sec
2018-01-03 01:22:42,294 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 53.15 sec
2018-01-03 01:22:44,347 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 53.52 sec
2018-01-03 01:22:47,426 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 54.07 sec
2018-01-03 01:22:50,508 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 54.55 sec
2018-01-03 01:22:53,585 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 55.54 sec
2018-01-03 01:22:56,663 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 55.84 sec
2018-01-03 01:22:59,746 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 56.04 sec
2018-01-03 01:23:02,844 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 56.95 sec
2018-01-03 01:23:05,922 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 57.18 sec
2018-01-03 01:23:12,085 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 57.9 sec
2018-01-03 01:23:15,163 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 60.27 sec
2018-01-03 01:23:18,244 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 64.73 sec
2018-01-03 01:23:21,322 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 65.85 sec
2018-01-03 01:23:24,401 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 67.27 sec
2018-01-03 01:23:30,563 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 72.6 sec
2018-01-03 01:23:31,590 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 79.04 sec
MapReduce Total cumulative CPU time: 1 minutes 19 seconds 40 msec
Ended Job = job_1513599404024_159993
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160005, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160005/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160005
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:24:33,160 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:24:42,958 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.56 sec
2018-01-03 01:24:50,186 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.91 sec
MapReduce Total cumulative CPU time: 19 seconds 910 msec
Ended Job = job_1513599404024_160005
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160010, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160010/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160010
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:24:56,198 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:25:01,359 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.16 sec
2018-01-03 01:25:07,539 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.58 sec
MapReduce Total cumulative CPU time: 5 seconds 580 msec
Ended Job = job_1513599404024_160010
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 2   Cumulative CPU: 79.04 sec   HDFS Read: 102492809 HDFS Write: 1063166 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.91 sec   HDFS Read: 44387984 HDFS Write: 132233 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.58 sec   HDFS Read: 139871 HDFS Write: 2737 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 44 seconds 530 msec
OK
Time taken: 228.709 seconds, Fetched: 398 row(s)
开始执行20170901日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103012523_1ea0bd1c-91e0-48e3-823b-189dc5d01a2d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160013, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160013/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160013
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 01:25:35,501 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:25:45,920 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 10.96 sec
2018-01-03 01:25:46,954 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 22.74 sec
2018-01-03 01:25:49,022 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 26.76 sec
2018-01-03 01:25:50,054 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 30.07 sec
2018-01-03 01:25:52,118 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 34.01 sec
2018-01-03 01:25:53,149 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 37.2 sec
2018-01-03 01:25:55,210 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 40.34 sec
2018-01-03 01:25:56,240 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 43.89 sec
2018-01-03 01:25:58,304 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 47.31 sec
2018-01-03 01:25:59,336 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 50.35 sec
2018-01-03 01:26:01,396 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 53.34 sec
2018-01-03 01:26:02,425 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 56.36 sec
2018-01-03 01:26:03,455 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 59.33 sec
2018-01-03 01:26:04,485 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 62.45 sec
2018-01-03 01:26:06,546 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 65.46 sec
2018-01-03 01:26:09,638 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 68.45 sec
2018-01-03 01:26:12,728 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 72.3 sec
2018-01-03 01:26:15,826 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 76.92 sec
2018-01-03 01:26:18,933 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 79.96 sec
2018-01-03 01:26:22,025 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 83.35 sec
2018-01-03 01:26:23,223 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 85.27 sec
2018-01-03 01:26:25,283 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 91.09 sec
2018-01-03 01:26:26,579 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 96.79 sec
MapReduce Total cumulative CPU time: 1 minutes 36 seconds 790 msec
Ended Job = job_1513599404024_160013
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160023, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160023/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160023
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:26:41,343 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:26:46,520 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.76 sec
2018-01-03 01:26:50,649 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.13 sec
2018-01-03 01:26:54,779 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.5 sec
MapReduce Total cumulative CPU time: 18 seconds 500 msec
Ended Job = job_1513599404024_160023
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160029, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160029/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160029
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:27:09,550 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:27:15,787 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.26 sec
2018-01-03 01:27:29,161 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.92 sec
MapReduce Total cumulative CPU time: 5 seconds 920 msec
Ended Job = job_1513599404024_160029
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 96.79 sec   HDFS Read: 269728973 HDFS Write: 2120845 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.5 sec   HDFS Read: 46934575 HDFS Write: 87103 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.92 sec   HDFS Read: 94778 HDFS Write: 3701 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 1 seconds 210 msec
OK
Time taken: 126.654 seconds, Fetched: 481 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.394 seconds
Query ID = boss_20180103012736_ee9d0ae1-4362-454f-87fa-e9a9b3deba69
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 10
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160034, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160034/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160034
Hadoop job information for Stage-1: number of mappers: 12; number of reducers: 10
2018-01-03 01:27:48,722 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:28:05,551 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 48.67 sec
2018-01-03 01:28:08,645 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 57.96 sec
2018-01-03 01:28:09,676 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 70.44 sec
2018-01-03 01:28:11,741 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 77.11 sec
2018-01-03 01:28:12,771 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 93.02 sec
2018-01-03 01:28:14,872 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 97.22 sec
2018-01-03 01:28:15,964 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 103.48 sec
2018-01-03 01:28:19,185 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 121.53 sec
2018-01-03 01:28:21,246 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 135.82 sec
2018-01-03 01:28:22,276 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 139.24 sec
2018-01-03 01:28:24,389 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 145.08 sec
2018-01-03 01:28:26,446 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 153.49 sec
2018-01-03 01:28:27,475 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 155.68 sec
2018-01-03 01:28:28,504 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 174.19 sec
2018-01-03 01:28:33,658 Stage-1 map = 36%,  reduce = 1%, Cumulative CPU 186.68 sec
2018-01-03 01:28:35,718 Stage-1 map = 36%,  reduce = 2%, Cumulative CPU 190.57 sec
2018-01-03 01:28:36,753 Stage-1 map = 37%,  reduce = 2%, Cumulative CPU 195.79 sec
2018-01-03 01:28:37,785 Stage-1 map = 38%,  reduce = 2%, Cumulative CPU 197.3 sec
2018-01-03 01:28:38,815 Stage-1 map = 39%,  reduce = 3%, Cumulative CPU 200.15 sec
2018-01-03 01:28:39,847 Stage-1 map = 41%,  reduce = 3%, Cumulative CPU 210.81 sec
2018-01-03 01:28:40,876 Stage-1 map = 46%,  reduce = 3%, Cumulative CPU 213.77 sec
2018-01-03 01:28:41,905 Stage-1 map = 46%,  reduce = 4%, Cumulative CPU 220.27 sec
2018-01-03 01:28:47,044 Stage-1 map = 52%,  reduce = 4%, Cumulative CPU 240.05 sec
2018-01-03 01:28:48,072 Stage-1 map = 52%,  reduce = 5%, Cumulative CPU 246.74 sec
2018-01-03 01:28:51,159 Stage-1 map = 52%,  reduce = 6%, Cumulative CPU 265.79 sec
2018-01-03 01:28:52,187 Stage-1 map = 52%,  reduce = 7%, Cumulative CPU 267.6 sec
2018-01-03 01:28:54,244 Stage-1 map = 53%,  reduce = 7%, Cumulative CPU 275.75 sec
2018-01-03 01:28:58,357 Stage-1 map = 54%,  reduce = 7%, Cumulative CPU 285.46 sec
2018-01-03 01:28:59,385 Stage-1 map = 54%,  reduce = 8%, Cumulative CPU 297.08 sec
2018-01-03 01:29:00,412 Stage-1 map = 55%,  reduce = 10%, Cumulative CPU 305.73 sec
2018-01-03 01:29:01,439 Stage-1 map = 57%,  reduce = 10%, Cumulative CPU 301.48 sec
2018-01-03 01:29:02,466 Stage-1 map = 57%,  reduce = 13%, Cumulative CPU 306.04 sec
2018-01-03 01:29:04,522 Stage-1 map = 58%,  reduce = 13%, Cumulative CPU 327.79 sec
2018-01-03 01:29:07,608 Stage-1 map = 63%,  reduce = 13%, Cumulative CPU 338.07 sec
2018-01-03 01:29:09,667 Stage-1 map = 63%,  reduce = 14%, Cumulative CPU 345.04 sec
2018-01-03 01:29:10,693 Stage-1 map = 64%,  reduce = 14%, Cumulative CPU 350.64 sec
2018-01-03 01:29:11,720 Stage-1 map = 64%,  reduce = 16%, Cumulative CPU 356.5 sec
2018-01-03 01:29:12,746 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 357.69 sec
2018-01-03 01:29:16,850 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 375.61 sec
2018-01-03 01:29:17,880 Stage-1 map = 69%,  reduce = 18%, Cumulative CPU 381.29 sec
2018-01-03 01:29:18,907 Stage-1 map = 69%,  reduce = 19%, Cumulative CPU 385.59 sec
2018-01-03 01:29:20,961 Stage-1 map = 71%,  reduce = 19%, Cumulative CPU 391.55 sec
2018-01-03 01:29:24,040 Stage-1 map = 73%,  reduce = 19%, Cumulative CPU 401.42 sec
2018-01-03 01:29:26,091 Stage-1 map = 76%,  reduce = 19%, Cumulative CPU 405.91 sec
2018-01-03 01:29:27,122 Stage-1 map = 76%,  reduce = 20%, Cumulative CPU 408.46 sec
2018-01-03 01:29:28,148 Stage-1 map = 76%,  reduce = 21%, Cumulative CPU 412.31 sec
2018-01-03 01:29:29,175 Stage-1 map = 76%,  reduce = 22%, Cumulative CPU 414.66 sec
2018-01-03 01:29:32,252 Stage-1 map = 77%,  reduce = 22%, Cumulative CPU 420.77 sec
2018-01-03 01:29:38,409 Stage-1 map = 78%,  reduce = 22%, Cumulative CPU 435.73 sec
2018-01-03 01:29:40,461 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 422.33 sec
2018-01-03 01:29:41,486 Stage-1 map = 93%,  reduce = 23%, Cumulative CPU 413.32 sec
2018-01-03 01:29:42,512 Stage-1 map = 93%,  reduce = 26%, Cumulative CPU 413.61 sec
2018-01-03 01:29:43,538 Stage-1 map = 93%,  reduce = 27%, Cumulative CPU 413.66 sec
2018-01-03 01:29:45,592 Stage-1 map = 93%,  reduce = 28%, Cumulative CPU 418.79 sec
2018-01-03 01:29:46,618 Stage-1 map = 93%,  reduce = 29%, Cumulative CPU 421.23 sec
2018-01-03 01:29:47,643 Stage-1 map = 93%,  reduce = 30%, Cumulative CPU 422.18 sec
2018-01-03 01:29:49,694 Stage-1 map = 93%,  reduce = 31%, Cumulative CPU 428.76 sec
2018-01-03 01:29:54,825 Stage-1 map = 94%,  reduce = 31%, Cumulative CPU 442.47 sec
2018-01-03 01:30:29,806 Stage-1 map = 95%,  reduce = 31%, Cumulative CPU 482.98 sec
2018-01-03 01:30:39,032 Stage-1 map = 96%,  reduce = 31%, Cumulative CPU 489.86 sec
2018-01-03 01:30:47,231 Stage-1 map = 97%,  reduce = 31%, Cumulative CPU 479.12 sec
2018-01-03 01:30:48,256 Stage-1 map = 100%,  reduce = 31%, Cumulative CPU 481.03 sec
2018-01-03 01:30:49,281 Stage-1 map = 100%,  reduce = 59%, Cumulative CPU 493.73 sec
2018-01-03 01:30:50,306 Stage-1 map = 100%,  reduce = 93%, Cumulative CPU 515.84 sec
2018-01-03 01:30:51,332 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 519.63 sec
2018-01-03 01:30:55,465 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 526.44 sec
MapReduce Total cumulative CPU time: 8 minutes 46 seconds 440 msec
Ended Job = job_1513599404024_160034
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160042, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160042/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160042
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:31:07,020 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:31:13,206 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.6 sec
2018-01-03 01:31:28,639 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.16 sec
2018-01-03 01:31:30,700 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 13.47 sec
2018-01-03 01:31:34,808 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.92 sec
MapReduce Total cumulative CPU time: 21 seconds 920 msec
Ended Job = job_1513599404024_160042
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160070, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160070/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160070
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:32:40,451 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:32:46,552 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.48 sec
2018-01-03 01:32:53,947 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.56 sec
MapReduce Total cumulative CPU time: 4 seconds 560 msec
Ended Job = job_1513599404024_160070
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 12  Reduce: 10   Cumulative CPU: 526.75 sec   HDFS Read: 906941364 HDFS Write: 458228 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 21.92 sec   HDFS Read: 45274054 HDFS Write: 25404 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.56 sec   HDFS Read: 33080 HDFS Write: 2915 SUCCESS
Total MapReduce CPU Time Spent: 9 minutes 13 seconds 230 msec
OK
Time taken: 320.122 seconds, Fetched: 405 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103013303_a406982f-5caa-488e-8bbe-3d9466797d89
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160092, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160092/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160092
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 01:33:15,232 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:33:25,629 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 8.46 sec
2018-01-03 01:33:28,731 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 10.35 sec
2018-01-03 01:33:31,825 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 12.18 sec
2018-01-03 01:33:34,916 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 13.04 sec
2018-01-03 01:33:38,010 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 13.77 sec
2018-01-03 01:33:41,110 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 14.24 sec
2018-01-03 01:33:44,199 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 14.93 sec
2018-01-03 01:33:47,307 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 15.57 sec
2018-01-03 01:33:50,391 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 16.21 sec
2018-01-03 01:33:53,477 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 16.7 sec
2018-01-03 01:33:56,565 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 17.19 sec
2018-01-03 01:33:58,621 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 17.73 sec
2018-01-03 01:34:01,706 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 18.38 sec
2018-01-03 01:34:04,795 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 18.85 sec
2018-01-03 01:34:07,881 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 19.32 sec
2018-01-03 01:34:10,963 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 19.61 sec
2018-01-03 01:34:14,049 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 19.92 sec
2018-01-03 01:34:17,130 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 20.42 sec
2018-01-03 01:34:20,211 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 21.49 sec
2018-01-03 01:34:23,295 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 22.06 sec
2018-01-03 01:34:26,375 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 22.47 sec
2018-01-03 01:34:29,455 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 22.76 sec
2018-01-03 01:34:32,539 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 23.05 sec
2018-01-03 01:34:35,617 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 25.67 sec
2018-01-03 01:34:38,696 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 26.47 sec
2018-01-03 01:34:41,777 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 27.67 sec
2018-01-03 01:35:09,491 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.65 sec
MapReduce Total cumulative CPU time: 32 seconds 650 msec
Ended Job = job_1513599404024_160092
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160146, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160146/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160146
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:35:16,189 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:35:21,342 Stage-2 map = 50%,  reduce = 0%
2018-01-03 01:35:22,371 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.41 sec
2018-01-03 01:35:28,543 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.29 sec
MapReduce Total cumulative CPU time: 15 seconds 290 msec
Ended Job = job_1513599404024_160146
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160158, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160158/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160158
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:35:35,203 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:35:40,356 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.38 sec
2018-01-03 01:35:58,854 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.54 sec
MapReduce Total cumulative CPU time: 7 seconds 540 msec
Ended Job = job_1513599404024_160158
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 32.65 sec   HDFS Read: 94154499 HDFS Write: 564638 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.29 sec   HDFS Read: 45378050 HDFS Write: 193142 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.54 sec   HDFS Read: 200779 HDFS Write: 7056 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 480 msec
OK
Time taken: 176.139 seconds, Fetched: 842 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103013606_b4348b4c-1c3b-4c81-8964-997337910f44
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160178, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160178/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160178
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 01:36:16,964 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:36:34,634 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 10.12 sec
2018-01-03 01:36:37,726 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 11.43 sec
2018-01-03 01:36:40,814 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 12.13 sec
2018-01-03 01:36:42,872 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 13.05 sec
2018-01-03 01:36:45,957 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 14.08 sec
2018-01-03 01:36:49,044 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 15.06 sec
2018-01-03 01:36:52,126 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 15.99 sec
2018-01-03 01:36:55,208 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 16.53 sec
2018-01-03 01:36:58,295 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 17.5 sec
2018-01-03 01:37:01,377 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 18.49 sec
2018-01-03 01:37:04,459 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 19.82 sec
2018-01-03 01:37:07,544 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 21.19 sec
2018-01-03 01:37:08,571 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 23.33 sec
2018-01-03 01:37:14,739 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 28.88 sec
MapReduce Total cumulative CPU time: 28 seconds 880 msec
Ended Job = job_1513599404024_160178
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160212, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160212/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160212
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:37:27,473 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:37:32,738 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.46 sec
2018-01-03 01:37:34,804 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.42 sec
2018-01-03 01:37:41,018 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.39 sec
MapReduce Total cumulative CPU time: 16 seconds 390 msec
Ended Job = job_1513599404024_160212
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160225, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160225/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160225
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:37:59,788 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:38:06,010 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.91 sec
2018-01-03 01:38:11,178 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.33 sec
MapReduce Total cumulative CPU time: 5 seconds 330 msec
Ended Job = job_1513599404024_160225
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 28.88 sec   HDFS Read: 94154489 HDFS Write: 958532 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.39 sec   HDFS Read: 45771944 HDFS Write: 133556 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.33 sec   HDFS Read: 141194 HDFS Write: 2894 SUCCESS
Total MapReduce CPU Time Spent: 50 seconds 600 msec
OK
Time taken: 125.601 seconds, Fetched: 431 row(s)
开始执行20170902日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103013819_1d4eb816-c10b-4005-b75d-8dd79f7db193
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160240, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160240/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160240
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 01:38:30,541 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:38:39,879 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 12.0 sec
2018-01-03 01:38:40,913 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 23.89 sec
2018-01-03 01:38:42,985 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 27.84 sec
2018-01-03 01:38:44,021 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 31.35 sec
2018-01-03 01:38:46,085 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 34.73 sec
2018-01-03 01:38:47,119 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 38.41 sec
2018-01-03 01:38:49,181 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 41.99 sec
2018-01-03 01:38:50,212 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 45.13 sec
2018-01-03 01:38:52,273 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 48.66 sec
2018-01-03 01:38:53,307 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 51.79 sec
2018-01-03 01:38:55,368 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 55.81 sec
2018-01-03 01:38:56,399 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 58.71 sec
2018-01-03 01:38:58,459 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 61.63 sec
2018-01-03 01:38:59,490 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 64.51 sec
2018-01-03 01:39:01,552 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 67.81 sec
2018-01-03 01:39:02,585 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 70.95 sec
2018-01-03 01:39:05,674 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 74.63 sec
2018-01-03 01:39:08,772 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 78.78 sec
2018-01-03 01:39:09,805 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 83.26 sec
2018-01-03 01:39:10,834 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 92.05 sec
MapReduce Total cumulative CPU time: 1 minutes 32 seconds 50 msec
Ended Job = job_1513599404024_160240
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160263, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160263/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160263
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:39:24,587 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:39:29,749 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.77 sec
2018-01-03 01:39:32,841 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.06 sec
2018-01-03 01:39:35,929 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.65 sec
MapReduce Total cumulative CPU time: 16 seconds 650 msec
Ended Job = job_1513599404024_160263
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160275, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160275/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160275
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:39:42,587 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:39:47,770 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.91 sec
2018-01-03 01:40:00,169 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.39 sec
MapReduce Total cumulative CPU time: 5 seconds 390 msec
Ended Job = job_1513599404024_160275
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 92.05 sec   HDFS Read: 323291921 HDFS Write: 2380019 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.65 sec   HDFS Read: 49846360 HDFS Write: 98673 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.39 sec   HDFS Read: 106348 HDFS Write: 3538 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 54 seconds 90 msec
OK
Time taken: 103.056 seconds, Fetched: 475 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103014009_f052c581-753d-4aba-8fd2-bb0bd2ed188b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 11
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160290, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160290/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160290
Hadoop job information for Stage-1: number of mappers: 15; number of reducers: 11
2018-01-03 01:40:56,570 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:41:02,842 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 7.58 sec
2018-01-03 01:41:06,986 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 98.55 sec
2018-01-03 01:41:08,028 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 139.8 sec
2018-01-03 01:41:09,062 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 142.93 sec
2018-01-03 01:41:10,097 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 185.27 sec
2018-01-03 01:41:11,129 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 192.24 sec
2018-01-03 01:41:12,164 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 199.54 sec
2018-01-03 01:41:13,203 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 218.27 sec
2018-01-03 01:41:14,240 Stage-1 map = 68%,  reduce = 7%, Cumulative CPU 222.2 sec
2018-01-03 01:41:15,272 Stage-1 map = 70%,  reduce = 15%, Cumulative CPU 250.4 sec
2018-01-03 01:41:16,302 Stage-1 map = 73%,  reduce = 15%, Cumulative CPU 261.29 sec
2018-01-03 01:41:17,333 Stage-1 map = 73%,  reduce = 16%, Cumulative CPU 261.65 sec
2018-01-03 01:41:18,364 Stage-1 map = 76%,  reduce = 18%, Cumulative CPU 269.73 sec
2018-01-03 01:41:19,398 Stage-1 map = 86%,  reduce = 18%, Cumulative CPU 284.61 sec
2018-01-03 01:41:20,429 Stage-1 map = 86%,  reduce = 20%, Cumulative CPU 285.22 sec
2018-01-03 01:41:21,463 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 289.13 sec
2018-01-03 01:41:22,493 Stage-1 map = 90%,  reduce = 24%, Cumulative CPU 297.5 sec
2018-01-03 01:41:23,522 Stage-1 map = 100%,  reduce = 27%, Cumulative CPU 304.51 sec
2018-01-03 01:41:24,553 Stage-1 map = 100%,  reduce = 52%, Cumulative CPU 315.18 sec
2018-01-03 01:41:25,584 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 343.5 sec
2018-01-03 01:41:27,644 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 346.36 sec
MapReduce Total cumulative CPU time: 5 minutes 46 seconds 360 msec
Ended Job = job_1513599404024_160290
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160326, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160326/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160326
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:41:34,739 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:41:40,946 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.59 sec
2018-01-03 01:41:46,112 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.37 sec
MapReduce Total cumulative CPU time: 14 seconds 370 msec
Ended Job = job_1513599404024_160326
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160334, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160334/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160334
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:41:52,858 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:41:58,030 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.56 sec
2018-01-03 01:42:04,227 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.72 sec
MapReduce Total cumulative CPU time: 5 seconds 720 msec
Ended Job = job_1513599404024_160334
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 15  Reduce: 11   Cumulative CPU: 346.36 sec   HDFS Read: 1066222703 HDFS Write: 529743 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.37 sec   HDFS Read: 47998180 HDFS Write: 26619 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.72 sec   HDFS Read: 34295 HDFS Write: 2847 SUCCESS
Total MapReduce CPU Time Spent: 6 minutes 6 seconds 450 msec
OK
Time taken: 116.289 seconds, Fetched: 410 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103014212_b268bc8c-61de-4443-9a25-6bbb46067507
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160347, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160347/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160347
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 01:42:22,458 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:42:32,822 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 9.01 sec
2018-01-03 01:42:35,923 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 13.11 sec
2018-01-03 01:42:39,018 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 14.1 sec
2018-01-03 01:42:42,109 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 15.06 sec
2018-01-03 01:42:44,173 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.79 sec
2018-01-03 01:42:47,264 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 16.38 sec
2018-01-03 01:42:50,352 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 16.89 sec
2018-01-03 01:42:53,445 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 17.52 sec
2018-01-03 01:42:56,532 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 18.06 sec
2018-01-03 01:42:59,618 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 18.79 sec
2018-01-03 01:43:02,706 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 19.52 sec
2018-01-03 01:43:05,790 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 20.19 sec
2018-01-03 01:43:08,875 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 20.54 sec
2018-01-03 01:43:11,960 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 21.51 sec
2018-01-03 01:43:15,043 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 22.0 sec
2018-01-03 01:43:18,126 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 22.51 sec
2018-01-03 01:43:21,209 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 23.06 sec
2018-01-03 01:43:24,289 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 23.69 sec
2018-01-03 01:43:27,369 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 26.09 sec
2018-01-03 01:43:28,396 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 27.2 sec
2018-01-03 01:43:37,647 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 31.34 sec
MapReduce Total cumulative CPU time: 31 seconds 340 msec
Ended Job = job_1513599404024_160347
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160375, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160375/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160375
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:43:53,391 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:43:59,577 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.37 sec
2018-01-03 01:44:06,809 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.41 sec
MapReduce Total cumulative CPU time: 20 seconds 410 msec
Ended Job = job_1513599404024_160375
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160385, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160385/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160385
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:44:18,799 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:44:34,264 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.58 sec
2018-01-03 01:44:46,647 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.53 sec
MapReduce Total cumulative CPU time: 9 seconds 530 msec
Ended Job = job_1513599404024_160385
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 31.34 sec   HDFS Read: 97418328 HDFS Write: 576429 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.41 sec   HDFS Read: 48042190 HDFS Write: 204876 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.53 sec   HDFS Read: 212513 HDFS Write: 6860 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 280 msec
OK
Time taken: 155.644 seconds, Fetched: 833 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.379 seconds
Query ID = boss_20180103014454_d6a41689-b4d1-4ad0-99c7-1cc21ecdab95
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160399, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160399/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160399
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 01:45:18,290 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:45:28,666 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 12.36 sec
2018-01-03 01:45:31,774 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 15.1 sec
2018-01-03 01:45:34,874 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 17.4 sec
2018-01-03 01:45:37,971 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 18.71 sec
2018-01-03 01:45:41,070 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 20.59 sec
2018-01-03 01:45:44,164 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 21.9 sec
2018-01-03 01:45:47,257 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 23.58 sec
2018-01-03 01:45:50,357 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 25.47 sec
2018-01-03 01:45:53,449 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 27.01 sec
2018-01-03 01:45:56,541 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 27.82 sec
2018-01-03 01:45:59,652 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 29.69 sec
2018-01-03 01:46:02,744 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 31.11 sec
2018-01-03 01:46:05,834 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 33.5 sec
2018-01-03 01:46:08,925 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 35.77 sec
2018-01-03 01:46:10,983 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 37.37 sec
2018-01-03 01:46:17,166 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 43.34 sec
MapReduce Total cumulative CPU time: 43 seconds 340 msec
Ended Job = job_1513599404024_160399
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160422, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160422/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160422
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:46:32,092 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:46:37,258 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.42 sec
2018-01-03 01:46:40,354 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.6 sec
2018-01-03 01:46:43,443 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.8 sec
MapReduce Total cumulative CPU time: 16 seconds 800 msec
Ended Job = job_1513599404024_160422
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160437, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160437/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160437
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:46:50,080 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:46:56,266 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.96 sec
2018-01-03 01:47:04,502 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.94 sec
MapReduce Total cumulative CPU time: 6 seconds 940 msec
Ended Job = job_1513599404024_160437
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 43.34 sec   HDFS Read: 97418318 HDFS Write: 1376314 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.8 sec   HDFS Read: 48842075 HDFS Write: 155589 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.94 sec   HDFS Read: 163227 HDFS Write: 2814 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 7 seconds 80 msec
OK
Time taken: 131.015 seconds, Fetched: 410 row(s)
开始执行20170903日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103014713_b0a4bebd-739d-4ef1-a998-5c02ff3bca49
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160456, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160456/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160456
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 01:47:22,035 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:47:31,416 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 12.87 sec
2018-01-03 01:47:32,449 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 25.75 sec
2018-01-03 01:47:34,520 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 31.99 sec
2018-01-03 01:47:37,626 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 38.32 sec
2018-01-03 01:47:40,720 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 45.77 sec
2018-01-03 01:47:43,811 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 52.31 sec
2018-01-03 01:47:46,903 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 58.95 sec
2018-01-03 01:47:49,989 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 66.44 sec
2018-01-03 01:47:53,076 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 74.19 sec
2018-01-03 01:47:56,164 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 81.27 sec
2018-01-03 01:47:59,249 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 88.25 sec
2018-01-03 01:48:02,334 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 91.23 sec
2018-01-03 01:48:05,424 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 94.5 sec
2018-01-03 01:48:06,456 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 95.43 sec
2018-01-03 01:48:07,488 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 112.39 sec
MapReduce Total cumulative CPU time: 1 minutes 52 seconds 390 msec
Ended Job = job_1513599404024_160456
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160480, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160480/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160480
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:48:14,222 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:48:19,383 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.79 sec
2018-01-03 01:48:21,447 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.24 sec
2018-01-03 01:48:25,570 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.08 sec
MapReduce Total cumulative CPU time: 18 seconds 80 msec
Ended Job = job_1513599404024_160480
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160500, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160500/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160500
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:48:40,263 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:48:45,436 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.86 sec
2018-01-03 01:48:50,597 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.22 sec
MapReduce Total cumulative CPU time: 6 seconds 220 msec
Ended Job = job_1513599404024_160500
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 112.39 sec   HDFS Read: 320085451 HDFS Write: 2299763 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.08 sec   HDFS Read: 70687353 HDFS Write: 97485 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.22 sec   HDFS Read: 105160 HDFS Write: 3521 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 16 seconds 690 msec
OK
Time taken: 98.543 seconds, Fetched: 489 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.421 seconds
Query ID = boss_20180103014858_f5c137a6-93ec-4807-9552-f65e8454de43
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 11
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160520, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160520/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160520
Hadoop job information for Stage-1: number of mappers: 14; number of reducers: 11
2018-01-03 01:49:12,797 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:49:22,146 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 24.51 sec
2018-01-03 01:49:23,183 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 156.74 sec
2018-01-03 01:49:25,254 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 171.52 sec
2018-01-03 01:49:26,291 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 209.06 sec
2018-01-03 01:49:27,351 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 211.3 sec
2018-01-03 01:49:28,385 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 217.91 sec
2018-01-03 01:49:29,418 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 228.69 sec
2018-01-03 01:49:30,450 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 252.72 sec
2018-01-03 01:49:32,515 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 265.65 sec
2018-01-03 01:49:33,548 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 268.97 sec
2018-01-03 01:49:34,579 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 275.1 sec
2018-01-03 01:49:35,620 Stage-1 map = 93%,  reduce = 10%, Cumulative CPU 282.53 sec
2018-01-03 01:49:36,654 Stage-1 map = 97%,  reduce = 24%, Cumulative CPU 292.81 sec
2018-01-03 01:49:37,685 Stage-1 map = 100%,  reduce = 24%, Cumulative CPU 295.09 sec
2018-01-03 01:49:38,716 Stage-1 map = 100%,  reduce = 41%, Cumulative CPU 303.69 sec
2018-01-03 01:49:39,746 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 330.58 sec
MapReduce Total cumulative CPU time: 5 minutes 30 seconds 580 msec
Ended Job = job_1513599404024_160520
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160538, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160538/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160538
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:49:59,591 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:50:05,784 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.41 sec
2018-01-03 01:50:10,937 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.03 sec
MapReduce Total cumulative CPU time: 15 seconds 30 msec
Ended Job = job_1513599404024_160538
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160559, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160559/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160559
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:50:16,800 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:50:37,414 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.98 sec
2018-01-03 01:50:43,604 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.17 sec
MapReduce Total cumulative CPU time: 6 seconds 170 msec
Ended Job = job_1513599404024_160559
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 14  Reduce: 11   Cumulative CPU: 330.58 sec   HDFS Read: 1049641128 HDFS Write: 540751 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.03 sec   HDFS Read: 68930437 HDFS Write: 26895 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.17 sec   HDFS Read: 34571 HDFS Write: 2833 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 51 seconds 780 msec
OK
Time taken: 105.947 seconds, Fetched: 405 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.425 seconds
Query ID = boss_20180103015051_bb681b0e-1a23-43db-b737-6bec004fe5d7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160574, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160574/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160574
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 01:51:01,919 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:51:12,296 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 10.02 sec
2018-01-03 01:51:15,395 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 10.82 sec
2018-01-03 01:51:18,491 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 12.63 sec
2018-01-03 01:51:21,583 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 13.53 sec
2018-01-03 01:51:24,677 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 14.53 sec
2018-01-03 01:51:27,767 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 15.21 sec
2018-01-03 01:51:30,936 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 15.68 sec
2018-01-03 01:51:34,028 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 15.87 sec
2018-01-03 01:51:37,112 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 16.36 sec
2018-01-03 01:51:40,198 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 16.84 sec
2018-01-03 01:51:43,287 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 17.32 sec
2018-01-03 01:51:46,372 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 18.02 sec
2018-01-03 01:51:49,459 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 18.48 sec
2018-01-03 01:51:52,546 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 19.15 sec
2018-01-03 01:51:54,603 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 19.55 sec
2018-01-03 01:52:03,856 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 20.02 sec
2018-01-03 01:52:06,942 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 20.36 sec
2018-01-03 01:52:13,107 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 21.66 sec
2018-01-03 01:52:16,188 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 22.4 sec
2018-01-03 01:52:19,267 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 22.78 sec
2018-01-03 01:52:22,353 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 23.49 sec
2018-01-03 01:52:25,441 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 23.89 sec
2018-01-03 01:52:28,524 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 24.31 sec
2018-01-03 01:52:31,604 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 24.66 sec
2018-01-03 01:52:34,684 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 26.0 sec
2018-01-03 01:52:37,767 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 26.63 sec
2018-01-03 01:52:39,821 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 27.93 sec
2018-01-03 01:52:50,105 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.66 sec
MapReduce Total cumulative CPU time: 32 seconds 660 msec
Ended Job = job_1513599404024_160574
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160612, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160612/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160612
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:53:01,925 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:53:07,085 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.83 sec
2018-01-03 01:53:14,296 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.72 sec
MapReduce Total cumulative CPU time: 18 seconds 720 msec
Ended Job = job_1513599404024_160612
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160621, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160621/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160621
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:53:37,012 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:53:42,181 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.89 sec
2018-01-03 01:53:51,437 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.78 sec
MapReduce Total cumulative CPU time: 7 seconds 780 msec
Ended Job = job_1513599404024_160621
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 32.66 sec   HDFS Read: 96225542 HDFS Write: 575478 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.72 sec   HDFS Read: 68962488 HDFS Write: 208230 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.78 sec   HDFS Read: 215867 HDFS Write: 7095 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 160 msec
OK
Time taken: 180.97 seconds, Fetched: 825 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.382 seconds
Query ID = boss_20180103015407_2f80cb52-2525-464e-804c-5bff328fa8b6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160638, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160638/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160638
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 01:54:42,145 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:54:52,519 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 10.71 sec
2018-01-03 01:54:55,625 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.52 sec
2018-01-03 01:54:58,723 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 13.63 sec
2018-01-03 01:55:01,817 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 15.83 sec
2018-01-03 01:55:04,915 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 16.61 sec
2018-01-03 01:55:08,008 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 17.9 sec
2018-01-03 01:55:11,098 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 19.04 sec
2018-01-03 01:55:14,193 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 19.84 sec
2018-01-03 01:55:17,283 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 20.73 sec
2018-01-03 01:55:20,372 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 22.11 sec
2018-01-03 01:55:23,463 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 23.27 sec
2018-01-03 01:55:25,522 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 25.34 sec
2018-01-03 01:55:26,551 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 26.21 sec
2018-01-03 01:55:32,734 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 31.36 sec
MapReduce Total cumulative CPU time: 31 seconds 360 msec
Ended Job = job_1513599404024_160638
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160661, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160661/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160661
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:55:38,560 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:55:43,738 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.21 sec
2018-01-03 01:55:44,772 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.37 sec
2018-01-03 01:55:49,931 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.29 sec
MapReduce Total cumulative CPU time: 15 seconds 290 msec
Ended Job = job_1513599404024_160661
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160664, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160664/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160664
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:56:04,742 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:56:09,920 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.46 sec
2018-01-03 01:56:17,131 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.31 sec
MapReduce Total cumulative CPU time: 6 seconds 310 msec
Ended Job = job_1513599404024_160664
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 31.36 sec   HDFS Read: 96225532 HDFS Write: 1199375 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.29 sec   HDFS Read: 69586385 HDFS Write: 150216 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.31 sec   HDFS Read: 157854 HDFS Write: 2857 SUCCESS
Total MapReduce CPU Time Spent: 52 seconds 960 msec
OK
Time taken: 130.962 seconds, Fetched: 402 row(s)
开始执行20170904日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103015625_74e10e10-2549-4138-90d6-4af40d7f9d6c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160675, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160675/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160675
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 01:56:40,423 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:56:51,833 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 13.59 sec
2018-01-03 01:56:54,945 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 16.82 sec
2018-01-03 01:56:57,008 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 26.69 sec
2018-01-03 01:56:58,039 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 28.46 sec
2018-01-03 01:57:00,100 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 30.56 sec
2018-01-03 01:57:03,202 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 35.67 sec
2018-01-03 01:57:06,292 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 40.04 sec
2018-01-03 01:57:09,383 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 47.51 sec
2018-01-03 01:57:12,479 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 54.74 sec
2018-01-03 01:57:13,508 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 56.69 sec
2018-01-03 01:57:15,566 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 59.62 sec
2018-01-03 01:57:18,652 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 62.54 sec
2018-01-03 01:57:20,708 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 65.53 sec
2018-01-03 01:57:23,795 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 68.83 sec
2018-01-03 01:57:24,829 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 69.36 sec
2018-01-03 01:57:26,886 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 73.05 sec
2018-01-03 01:57:29,970 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 76.16 sec
2018-01-03 01:57:33,059 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 79.27 sec
2018-01-03 01:57:34,090 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 80.9 sec
2018-01-03 01:57:36,146 Stage-1 map = 100%,  reduce = 86%, Cumulative CPU 89.09 sec
2018-01-03 01:57:37,174 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 90.89 sec
MapReduce Total cumulative CPU time: 1 minutes 30 seconds 890 msec
Ended Job = job_1513599404024_160675
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160692, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160692/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160692
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:57:44,981 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:57:53,221 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 7.41 sec
2018-01-03 01:57:59,397 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.06 sec
2018-01-03 01:58:01,453 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.0 sec
MapReduce Total cumulative CPU time: 21 seconds 0 msec
Ended Job = job_1513599404024_160692
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160698, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160698/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160698
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:58:07,312 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:58:12,464 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.74 sec
2018-01-03 01:58:17,610 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.11 sec
MapReduce Total cumulative CPU time: 6 seconds 110 msec
Ended Job = job_1513599404024_160698
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 90.89 sec   HDFS Read: 251331517 HDFS Write: 1964621 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 21.0 sec   HDFS Read: 45788435 HDFS Write: 84304 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.11 sec   HDFS Read: 91979 HDFS Write: 3536 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 58 seconds 0 msec
OK
Time taken: 113.538 seconds, Fetched: 487 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.405 seconds
Query ID = boss_20180103015825_867c820d-c8df-4698-aaaa-35b41fddfddc
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160702, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160702/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160702
Hadoop job information for Stage-1: number of mappers: 11; number of reducers: 9
2018-01-03 01:58:36,151 Stage-1 map = 0%,  reduce = 0%
2018-01-03 01:58:45,581 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 23.36 sec
2018-01-03 01:58:46,615 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 74.55 sec
2018-01-03 01:58:47,647 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 86.18 sec
2018-01-03 01:58:48,684 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 94.23 sec
2018-01-03 01:58:49,716 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 106.5 sec
2018-01-03 01:58:50,746 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 113.36 sec
2018-01-03 01:58:51,778 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 122.83 sec
2018-01-03 01:58:52,809 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 138.65 sec
2018-01-03 01:58:53,838 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 171.69 sec
2018-01-03 01:58:55,897 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 178.34 sec
2018-01-03 01:58:56,934 Stage-1 map = 67%,  reduce = 10%, Cumulative CPU 193.33 sec
2018-01-03 01:58:57,971 Stage-1 map = 72%,  reduce = 16%, Cumulative CPU 197.51 sec
2018-01-03 01:58:59,002 Stage-1 map = 75%,  reduce = 16%, Cumulative CPU 204.23 sec
2018-01-03 01:59:00,034 Stage-1 map = 77%,  reduce = 20%, Cumulative CPU 208.19 sec
2018-01-03 01:59:01,065 Stage-1 map = 80%,  reduce = 21%, Cumulative CPU 220.52 sec
2018-01-03 01:59:02,095 Stage-1 map = 90%,  reduce = 21%, Cumulative CPU 230.03 sec
2018-01-03 01:59:03,126 Stage-1 map = 90%,  reduce = 25%, Cumulative CPU 230.63 sec
2018-01-03 01:59:04,155 Stage-1 map = 100%,  reduce = 26%, Cumulative CPU 236.5 sec
2018-01-03 01:59:05,185 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 266.26 sec
MapReduce Total cumulative CPU time: 4 minutes 26 seconds 260 msec
Ended Job = job_1513599404024_160702
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160710, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160710/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160710
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 01:59:12,003 Stage-2 map = 0%,  reduce = 0%
2018-01-03 01:59:18,530 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.42 sec
2018-01-03 01:59:27,814 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.89 sec
MapReduce Total cumulative CPU time: 16 seconds 890 msec
Ended Job = job_1513599404024_160710
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160714, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160714/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160714
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 01:59:33,440 Stage-3 map = 0%,  reduce = 0%
2018-01-03 01:59:38,593 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.01 sec
2018-01-03 01:59:47,850 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.06 sec
MapReduce Total cumulative CPU time: 6 seconds 60 msec
Ended Job = job_1513599404024_160714
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 11  Reduce: 9   Cumulative CPU: 266.26 sec   HDFS Read: 807053319 HDFS Write: 409835 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.89 sec   HDFS Read: 44235483 HDFS Write: 22326 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.06 sec   HDFS Read: 30002 HDFS Write: 2767 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 49 seconds 210 msec
OK
Time taken: 83.449 seconds, Fetched: 390 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.35 seconds
Query ID = boss_20180103015955_32cd0ddd-6a3b-48e4-8eb3-36f14f77b3c4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160719, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160719/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160719
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:00:07,514 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:00:25,122 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 9.33 sec
2018-01-03 02:00:28,222 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 11.21 sec
2018-01-03 02:00:31,317 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 13.33 sec
2018-01-03 02:00:34,409 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 14.19 sec
2018-01-03 02:00:37,501 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 15.2 sec
2018-01-03 02:00:40,589 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.92 sec
2018-01-03 02:00:43,676 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 16.56 sec
2018-01-03 02:00:46,766 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 17.43 sec
2018-01-03 02:00:49,855 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 18.37 sec
2018-01-03 02:00:52,941 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 18.91 sec
2018-01-03 02:00:56,032 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 19.45 sec
2018-01-03 02:00:59,116 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 20.1 sec
2018-01-03 02:01:02,216 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 20.66 sec
2018-01-03 02:01:05,305 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 21.74 sec
2018-01-03 02:01:08,390 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 22.32 sec
2018-01-03 02:01:11,472 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 22.78 sec
2018-01-03 02:01:14,566 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 23.2 sec
2018-01-03 02:01:17,651 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 23.59 sec
2018-01-03 02:01:20,732 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 24.32 sec
2018-01-03 02:01:25,871 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 25.06 sec
2018-01-03 02:01:28,951 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 25.56 sec
2018-01-03 02:01:32,034 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 26.07 sec
2018-01-03 02:01:35,112 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 26.48 sec
2018-01-03 02:01:38,190 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 26.92 sec
2018-01-03 02:01:41,271 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 29.3 sec
2018-01-03 02:01:44,350 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 29.81 sec
2018-01-03 02:01:45,378 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 31.0 sec
2018-01-03 02:01:50,516 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.44 sec
MapReduce Total cumulative CPU time: 35 seconds 440 msec
Ended Job = job_1513599404024_160719
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160734, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160734/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160734
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:01:57,253 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:02:01,370 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.98 sec
2018-01-03 02:02:02,398 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.71 sec
2018-01-03 02:02:06,515 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.78 sec
MapReduce Total cumulative CPU time: 13 seconds 780 msec
Ended Job = job_1513599404024_160734
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160739, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160739/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160739
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:02:54,709 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:03:02,486 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.98 sec
2018-01-03 02:03:08,981 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.94 sec
MapReduce Total cumulative CPU time: 5 seconds 940 msec
Ended Job = job_1513599404024_160739
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.44 sec   HDFS Read: 87682403 HDFS Write: 583480 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.78 sec   HDFS Read: 44406976 HDFS Write: 201731 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.94 sec   HDFS Read: 209368 HDFS Write: 6919 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 160 msec
OK
Time taken: 195.837 seconds, Fetched: 836 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103020318_9ece7c46-0f12-4a88-86e4-f389480096aa
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160749, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160749/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160749
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:03:29,106 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:03:39,461 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 11.43 sec
2018-01-03 02:03:42,561 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 14.47 sec
2018-01-03 02:03:45,655 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 16.1 sec
2018-01-03 02:03:48,745 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 17.18 sec
2018-01-03 02:03:51,837 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 18.47 sec
2018-01-03 02:03:54,926 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 20.08 sec
2018-01-03 02:03:58,013 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 20.85 sec
2018-01-03 02:04:01,104 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 22.05 sec
2018-01-03 02:04:04,189 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 23.52 sec
2018-01-03 02:04:07,275 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 25.78 sec
2018-01-03 02:04:08,308 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 27.33 sec
2018-01-03 02:04:15,515 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 31.22 sec
MapReduce Total cumulative CPU time: 31 seconds 220 msec
Ended Job = job_1513599404024_160749
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160758, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160758/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160758
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:04:21,224 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:04:26,399 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.46 sec
2018-01-03 02:04:27,433 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.8 sec
2018-01-03 02:04:40,829 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.36 sec
MapReduce Total cumulative CPU time: 15 seconds 360 msec
Ended Job = job_1513599404024_160758
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160770, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160770/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160770
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:04:47,628 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:05:01,013 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.48 sec
2018-01-03 02:05:15,403 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.85 sec
MapReduce Total cumulative CPU time: 6 seconds 850 msec
Ended Job = job_1513599404024_160770
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 31.22 sec   HDFS Read: 87682393 HDFS Write: 880317 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.36 sec   HDFS Read: 44703813 HDFS Write: 131626 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.85 sec   HDFS Read: 139264 HDFS Write: 2784 SUCCESS
Total MapReduce CPU Time Spent: 53 seconds 430 msec
OK
Time taken: 118.386 seconds, Fetched: 413 row(s)
开始执行20170905日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.368 seconds
Query ID = boss_20180103020523_8dbb8143-fe59-4bba-aace-5f9005806f3c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160782, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160782/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160782
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 02:05:32,181 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:05:42,536 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 25.87 sec
2018-01-03 02:05:45,635 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 32.81 sec
2018-01-03 02:05:48,729 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 39.77 sec
2018-01-03 02:05:51,820 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 46.48 sec
2018-01-03 02:05:53,887 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 49.87 sec
2018-01-03 02:05:54,921 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 53.26 sec
2018-01-03 02:05:58,010 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 56.61 sec
2018-01-03 02:06:01,098 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 60.65 sec
2018-01-03 02:06:04,189 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 64.16 sec
2018-01-03 02:06:05,222 Stage-1 map = 78%,  reduce = 8%, Cumulative CPU 64.83 sec
2018-01-03 02:06:07,280 Stage-1 map = 81%,  reduce = 8%, Cumulative CPU 68.01 sec
2018-01-03 02:06:08,309 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 70.02 sec
2018-01-03 02:06:10,369 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 75.88 sec
2018-01-03 02:06:13,461 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 80.89 sec
MapReduce Total cumulative CPU time: 1 minutes 20 seconds 890 msec
Ended Job = job_1513599404024_160782
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160794, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160794/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160794
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:06:47,241 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:06:54,452 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.48 sec
2018-01-03 02:06:55,482 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.9 sec
2018-01-03 02:07:00,630 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.2 sec
MapReduce Total cumulative CPU time: 18 seconds 200 msec
Ended Job = job_1513599404024_160794
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160803, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160803/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160803
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:07:07,420 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:07:26,999 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.41 sec
2018-01-03 02:07:33,180 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.88 sec
MapReduce Total cumulative CPU time: 6 seconds 880 msec
Ended Job = job_1513599404024_160803
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 80.89 sec   HDFS Read: 253454160 HDFS Write: 1986616 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.2 sec   HDFS Read: 46398249 HDFS Write: 87663 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.88 sec   HDFS Read: 95338 HDFS Write: 3502 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 45 seconds 970 msec
OK
Time taken: 131.138 seconds, Fetched: 495 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103020740_117fda17-f76d-47ce-813c-1b7ac786c1cb
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160811, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160811/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160811
Hadoop job information for Stage-1: number of mappers: 9; number of reducers: 8
2018-01-03 02:08:05,287 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:08:15,686 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 59.1 sec
2018-01-03 02:08:16,724 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 70.08 sec
2018-01-03 02:08:17,761 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 85.24 sec
2018-01-03 02:08:18,800 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 110.98 sec
2018-01-03 02:08:19,832 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 115.77 sec
2018-01-03 02:08:20,867 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 121.32 sec
2018-01-03 02:08:21,900 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 131.24 sec
2018-01-03 02:08:22,932 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 134.56 sec
2018-01-03 02:08:23,964 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 151.39 sec
2018-01-03 02:08:24,997 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 159.93 sec
2018-01-03 02:08:26,032 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 165.01 sec
2018-01-03 02:08:27,066 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 171.88 sec
2018-01-03 02:08:28,102 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 179.03 sec
2018-01-03 02:08:29,142 Stage-1 map = 81%,  reduce = 11%, Cumulative CPU 181.91 sec
2018-01-03 02:08:30,175 Stage-1 map = 93%,  reduce = 14%, Cumulative CPU 189.58 sec
2018-01-03 02:08:31,208 Stage-1 map = 95%,  reduce = 14%, Cumulative CPU 192.74 sec
2018-01-03 02:08:32,242 Stage-1 map = 95%,  reduce = 21%, Cumulative CPU 193.89 sec
2018-01-03 02:08:33,274 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 197.68 sec
2018-01-03 02:08:34,307 Stage-1 map = 100%,  reduce = 44%, Cumulative CPU 206.19 sec
2018-01-03 02:08:35,341 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 229.09 sec
MapReduce Total cumulative CPU time: 3 minutes 49 seconds 90 msec
Ended Job = job_1513599404024_160811
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160825, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160825/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160825
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:08:56,982 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:09:04,222 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.09 sec
2018-01-03 02:09:18,662 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.86 sec
2018-01-03 02:09:20,724 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.09 sec
MapReduce Total cumulative CPU time: 16 seconds 90 msec
Ended Job = job_1513599404024_160825
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160831, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160831/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160831
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:09:27,394 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:09:32,559 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.69 sec
2018-01-03 02:09:50,081 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.64 sec
MapReduce Total cumulative CPU time: 5 seconds 640 msec
Ended Job = job_1513599404024_160831
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 9  Reduce: 8   Cumulative CPU: 229.09 sec   HDFS Read: 787633910 HDFS Write: 401375 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.09 sec   HDFS Read: 44814580 HDFS Write: 25732 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.64 sec   HDFS Read: 33408 HDFS Write: 2687 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 10 seconds 820 msec
OK
Time taken: 130.186 seconds, Fetched: 389 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103020957_c125e7bf-e192-4f1a-a710-b282e9e6ab0c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160836, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160836/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160836
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:10:08,586 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:10:27,212 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 11.45 sec
2018-01-03 02:10:30,314 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.54 sec
2018-01-03 02:10:33,411 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 15.8 sec
2018-01-03 02:10:36,505 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 17.69 sec
2018-01-03 02:10:39,602 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 18.66 sec
2018-01-03 02:10:42,698 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 19.44 sec
2018-01-03 02:10:45,790 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 20.42 sec
2018-01-03 02:10:48,884 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 21.55 sec
2018-01-03 02:10:51,973 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 22.39 sec
2018-01-03 02:10:55,064 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 23.18 sec
2018-01-03 02:10:58,158 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 24.26 sec
2018-01-03 02:11:01,247 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 25.17 sec
2018-01-03 02:11:04,334 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 25.76 sec
2018-01-03 02:11:07,422 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 27.16 sec
2018-01-03 02:11:10,509 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 27.78 sec
2018-01-03 02:11:12,567 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 28.56 sec
2018-01-03 02:11:15,655 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 29.13 sec
2018-01-03 02:11:18,739 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 29.98 sec
2018-01-03 02:11:21,830 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 32.39 sec
2018-01-03 02:11:24,919 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 34.0 sec
2018-01-03 02:11:31,086 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 38.08 sec
MapReduce Total cumulative CPU time: 38 seconds 80 msec
Ended Job = job_1513599404024_160836
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160847, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160847/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160847
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:11:45,875 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:11:51,094 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.78 sec
2018-01-03 02:11:59,333 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.08 sec
2018-01-03 02:12:01,394 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.93 sec
MapReduce Total cumulative CPU time: 15 seconds 930 msec
Ended Job = job_1513599404024_160847
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160850, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160850/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160850
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:12:08,051 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:12:20,397 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.06 sec
2018-01-03 02:12:28,629 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.01 sec
MapReduce Total cumulative CPU time: 6 seconds 10 msec
Ended Job = job_1513599404024_160850
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 38.08 sec   HDFS Read: 96714058 HDFS Write: 581525 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.93 sec   HDFS Read: 44992840 HDFS Write: 196595 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.01 sec   HDFS Read: 204232 HDFS Write: 6943 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 0 seconds 20 msec
OK
Time taken: 151.86 seconds, Fetched: 841 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103021236_046bfaca-d2d7-464a-86e9-af3fb767eff3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160853, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160853/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160853
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:12:54,648 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:13:13,276 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 12.22 sec
2018-01-03 02:13:16,377 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 14.61 sec
2018-01-03 02:13:19,472 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 16.04 sec
2018-01-03 02:13:22,567 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 17.31 sec
2018-01-03 02:13:25,662 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 18.66 sec
2018-01-03 02:13:28,754 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 20.43 sec
2018-01-03 02:13:31,846 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 21.78 sec
2018-01-03 02:13:34,940 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 23.06 sec
2018-01-03 02:13:37,000 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 24.62 sec
2018-01-03 02:13:40,090 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 27.06 sec
2018-01-03 02:13:42,151 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 28.15 sec
2018-01-03 02:13:49,361 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.33 sec
MapReduce Total cumulative CPU time: 32 seconds 330 msec
Ended Job = job_1513599404024_160853
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160860, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160860/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160860
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:13:55,070 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:14:05,392 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.54 sec
2018-01-03 02:14:07,455 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.76 sec
2018-01-03 02:14:11,584 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.66 sec
MapReduce Total cumulative CPU time: 17 seconds 660 msec
Ended Job = job_1513599404024_160860
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160863, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160863/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160863
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:14:20,280 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:14:25,441 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec
2018-01-03 02:14:54,248 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.73 sec
MapReduce Total cumulative CPU time: 6 seconds 730 msec
Ended Job = job_1513599404024_160863
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 32.33 sec   HDFS Read: 96714048 HDFS Write: 998760 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.66 sec   HDFS Read: 45410075 HDFS Write: 163882 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.73 sec   HDFS Read: 171520 HDFS Write: 2787 SUCCESS
Total MapReduce CPU Time Spent: 56 seconds 720 msec
OK
Time taken: 138.898 seconds, Fetched: 412 row(s)
开始执行20170906日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103021524_9c503620-e284-416c-aa9b-b775c4dc5ca2
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160898, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160898/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160898
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 02:15:49,339 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:15:59,707 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 14.62 sec
2018-01-03 02:16:02,809 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 17.62 sec
2018-01-03 02:16:05,907 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 36.92 sec
2018-01-03 02:16:07,971 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 41.38 sec
2018-01-03 02:16:09,002 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 44.76 sec
2018-01-03 02:16:11,062 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 47.34 sec
2018-01-03 02:16:12,097 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 49.89 sec
2018-01-03 02:16:15,187 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 52.45 sec
2018-01-03 02:16:18,277 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 68.4 sec
2018-01-03 02:16:19,307 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 71.57 sec
2018-01-03 02:16:22,397 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 75.0 sec
2018-01-03 02:16:25,483 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 78.24 sec
2018-01-03 02:16:28,577 Stage-1 map = 62%,  reduce = 8%, Cumulative CPU 82.88 sec
2018-01-03 02:16:30,638 Stage-1 map = 67%,  reduce = 8%, Cumulative CPU 86.24 sec
2018-01-03 02:16:33,728 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 91.1 sec
2018-01-03 02:16:36,815 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 93.58 sec
2018-01-03 02:16:39,900 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 97.02 sec
2018-01-03 02:16:42,988 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 100.27 sec
2018-01-03 02:16:46,073 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 103.9 sec
2018-01-03 02:16:49,157 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 107.55 sec
2018-01-03 02:16:51,218 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 109.7 sec
2018-01-03 02:16:52,245 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 115.62 sec
2018-01-03 02:16:54,302 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 121.22 sec
MapReduce Total cumulative CPU time: 2 minutes 1 seconds 220 msec
Ended Job = job_1513599404024_160898
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160934, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160934/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160934
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:17:09,359 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:17:16,584 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.9 sec
2018-01-03 02:17:31,015 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 15.01 sec
2018-01-03 02:17:34,106 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 18.02 sec
2018-01-03 02:17:35,136 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 22.73 sec
MapReduce Total cumulative CPU time: 22 seconds 730 msec
Ended Job = job_1513599404024_160934
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160949, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160949/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160949
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:17:41,826 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:17:46,065 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec
2018-01-03 02:17:54,325 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.97 sec
MapReduce Total cumulative CPU time: 6 seconds 970 msec
Ended Job = job_1513599404024_160949
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 121.22 sec   HDFS Read: 272178178 HDFS Write: 2646638 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 22.73 sec   HDFS Read: 45563442 HDFS Write: 96822 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.97 sec   HDFS Read: 104497 HDFS Write: 3494 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 30 seconds 920 msec
OK
Time taken: 151.071 seconds, Fetched: 476 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.391 seconds
Query ID = boss_20180103021802_d5d32e23-614a-49e7-80a1-e7f72d8d4007
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160962, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160962/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160962
Hadoop job information for Stage-1: number of mappers: 10; number of reducers: 8
2018-01-03 02:18:19,668 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:18:29,010 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 48.7 sec
2018-01-03 02:18:30,047 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 139.94 sec
2018-01-03 02:18:32,116 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 154.63 sec
2018-01-03 02:18:33,152 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 167.35 sec
2018-01-03 02:18:34,185 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 186.41 sec
2018-01-03 02:18:35,221 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 195.08 sec
2018-01-03 02:18:36,255 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 205.22 sec
2018-01-03 02:18:37,287 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 209.75 sec
2018-01-03 02:18:38,319 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 215.84 sec
2018-01-03 02:18:39,352 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 221.03 sec
2018-01-03 02:18:41,420 Stage-1 map = 72%,  reduce = 4%, Cumulative CPU 237.88 sec
2018-01-03 02:18:42,455 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 259.9 sec
2018-01-03 02:18:44,518 Stage-1 map = 79%,  reduce = 19%, Cumulative CPU 261.43 sec
2018-01-03 02:18:45,550 Stage-1 map = 84%,  reduce = 20%, Cumulative CPU 273.39 sec
2018-01-03 02:18:47,615 Stage-1 map = 84%,  reduce = 21%, Cumulative CPU 273.63 sec
2018-01-03 02:18:48,647 Stage-1 map = 85%,  reduce = 23%, Cumulative CPU 284.74 sec
2018-01-03 02:18:49,680 Stage-1 map = 85%,  reduce = 27%, Cumulative CPU 286.16 sec
2018-01-03 02:18:51,746 Stage-1 map = 90%,  reduce = 28%, Cumulative CPU 290.83 sec
2018-01-03 02:18:53,806 Stage-1 map = 90%,  reduce = 29%, Cumulative CPU 302.34 sec
2018-01-03 02:18:54,838 Stage-1 map = 90%,  reduce = 30%, Cumulative CPU 302.73 sec
2018-01-03 02:18:55,868 Stage-1 map = 92%,  reduce = 30%, Cumulative CPU 304.25 sec
2018-01-03 02:19:07,205 Stage-1 map = 94%,  reduce = 30%, Cumulative CPU 356.58 sec
2018-01-03 02:19:11,334 Stage-1 map = 100%,  reduce = 30%, Cumulative CPU 372.73 sec
2018-01-03 02:19:12,362 Stage-1 map = 100%,  reduce = 43%, Cumulative CPU 378.16 sec
2018-01-03 02:19:13,391 Stage-1 map = 100%,  reduce = 70%, Cumulative CPU 395.83 sec
2018-01-03 02:19:14,420 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 409.23 sec
2018-01-03 02:19:15,448 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 413.82 sec
MapReduce Total cumulative CPU time: 6 minutes 53 seconds 820 msec
Ended Job = job_1513599404024_160962
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160988, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160988/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160988
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:19:22,692 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:19:27,862 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.26 sec
2018-01-03 02:19:43,332 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.46 sec
2018-01-03 02:19:44,366 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 10.09 sec
2018-01-03 02:19:46,424 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.47 sec
MapReduce Total cumulative CPU time: 15 seconds 470 msec
Ended Job = job_1513599404024_160988
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_160996, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_160996/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_160996
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:19:54,250 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:19:58,384 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.53 sec
2018-01-03 02:20:04,561 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.72 sec
MapReduce Total cumulative CPU time: 5 seconds 720 msec
Ended Job = job_1513599404024_160996
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 10  Reduce: 8   Cumulative CPU: 413.82 sec   HDFS Read: 792537840 HDFS Write: 834530 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.47 sec   HDFS Read: 43752906 HDFS Write: 26414 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.72 sec   HDFS Read: 34090 HDFS Write: 2836 SUCCESS
Total MapReduce CPU Time Spent: 7 minutes 15 seconds 10 msec
OK
Time taken: 123.507 seconds, Fetched: 414 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103022020_d29bdc95-4cdf-402b-8b72-85f2a17107c7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161006, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161006/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161006
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:20:38,395 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:20:49,772 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 9.75 sec
2018-01-03 02:20:52,870 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.37 sec
2018-01-03 02:20:55,962 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 13.42 sec
2018-01-03 02:20:59,051 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 14.16 sec
2018-01-03 02:21:02,144 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.01 sec
2018-01-03 02:21:05,235 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.81 sec
2018-01-03 02:21:08,323 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 16.37 sec
2018-01-03 02:21:11,413 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 16.94 sec
2018-01-03 02:21:14,497 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 17.37 sec
2018-01-03 02:21:17,583 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 18.15 sec
2018-01-03 02:21:20,671 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 18.53 sec
2018-01-03 02:21:25,813 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 19.39 sec
2018-01-03 02:21:28,899 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 21.53 sec
2018-01-03 02:21:31,981 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 21.88 sec
2018-01-03 02:21:35,062 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 22.11 sec
2018-01-03 02:21:38,151 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 22.45 sec
2018-01-03 02:21:41,235 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 23.54 sec
2018-01-03 02:21:44,317 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 23.97 sec
2018-01-03 02:21:47,401 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 25.0 sec
2018-01-03 02:21:50,480 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 25.85 sec
2018-01-03 02:21:53,560 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 26.2 sec
2018-01-03 02:21:56,642 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 28.49 sec
2018-01-03 02:21:59,720 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 29.66 sec
2018-01-03 02:22:01,773 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 31.15 sec
2018-01-03 02:22:13,107 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.43 sec
MapReduce Total cumulative CPU time: 35 seconds 430 msec
Ended Job = job_1513599404024_161006
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161040, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161040/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161040
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:22:20,130 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:22:29,410 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.81 sec
2018-01-03 02:22:35,592 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 20.55 sec
2018-01-03 02:22:43,824 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 27.21 sec
MapReduce Total cumulative CPU time: 27 seconds 210 msec
Ended Job = job_1513599404024_161040
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161044, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161044/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161044
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:22:49,452 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:23:01,786 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.24 sec
2018-01-03 02:23:08,978 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.68 sec
MapReduce Total cumulative CPU time: 6 seconds 680 msec
Ended Job = job_1513599404024_161044
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.43 sec   HDFS Read: 93792475 HDFS Write: 567234 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 27.21 sec   HDFS Read: 43483720 HDFS Write: 166228 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.68 sec   HDFS Read: 173865 HDFS Write: 6581 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 9 seconds 320 msec
OK
Time taken: 169.7 seconds, Fetched: 798 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103022316_c4f6d365-1346-4149-b7d8-2807347d5687
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161053, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161053/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161053
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:23:46,877 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:23:59,704 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 10.88 sec
2018-01-03 02:24:03,260 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 14.36 sec
2018-01-03 02:24:06,411 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 21.91 sec
2018-01-03 02:24:09,522 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 23.71 sec
2018-01-03 02:24:11,587 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 24.65 sec
2018-01-03 02:24:14,685 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 34.33 sec
2018-01-03 02:24:17,782 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 35.1 sec
2018-01-03 02:24:20,875 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 36.83 sec
2018-01-03 02:24:23,960 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 37.73 sec
2018-01-03 02:24:27,052 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 39.43 sec
2018-01-03 02:24:30,138 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 40.62 sec
2018-01-03 02:24:33,224 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 41.5 sec
2018-01-03 02:24:36,313 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 42.61 sec
2018-01-03 02:24:39,401 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 43.72 sec
2018-01-03 02:24:42,206 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 44.52 sec
2018-01-03 02:24:45,297 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 47.26 sec
2018-01-03 02:24:46,327 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 48.3 sec
2018-01-03 02:24:54,555 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 53.29 sec
MapReduce Total cumulative CPU time: 53 seconds 290 msec
Ended Job = job_1513599404024_161053
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161073, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161073/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161073
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:25:00,413 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:25:05,564 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.97 sec
2018-01-03 02:25:16,876 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.59 sec
2018-01-03 02:25:18,937 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 12.79 sec
2018-01-03 02:25:19,965 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 14.39 sec
2018-01-03 02:25:22,021 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.19 sec
MapReduce Total cumulative CPU time: 18 seconds 190 msec
Ended Job = job_1513599404024_161073
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161078, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161078/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161078
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:25:46,802 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:25:53,013 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.94 sec
2018-01-03 02:26:05,394 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.17 sec
MapReduce Total cumulative CPU time: 9 seconds 170 msec
Ended Job = job_1513599404024_161078
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 53.29 sec   HDFS Read: 93792465 HDFS Write: 851188 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.19 sec   HDFS Read: 43767674 HDFS Write: 120410 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.17 sec   HDFS Read: 128048 HDFS Write: 2752 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 20 seconds 650 msec
OK
Time taken: 170.768 seconds, Fetched: 397 row(s)
开始执行20170907日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103022614_a8d153b6-0148-4c45-a4ff-8692ede54a89
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161084, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161084/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161084
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 02:26:24,876 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:26:39,400 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 13.28 sec
2018-01-03 02:26:41,471 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 17.25 sec
2018-01-03 02:26:49,738 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 70.73 sec
2018-01-03 02:26:50,769 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 82.26 sec
2018-01-03 02:26:52,832 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 103.55 sec
2018-01-03 02:26:53,864 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 106.97 sec
2018-01-03 02:26:55,928 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 127.73 sec
2018-01-03 02:26:56,964 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 131.0 sec
2018-01-03 02:26:59,026 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 134.15 sec
2018-01-03 02:27:01,087 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 152.18 sec
2018-01-03 02:27:02,119 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 163.13 sec
2018-01-03 02:27:04,181 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 166.18 sec
2018-01-03 02:27:05,212 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 172.25 sec
2018-01-03 02:27:09,337 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 176.01 sec
2018-01-03 02:27:12,429 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 179.26 sec
2018-01-03 02:27:15,524 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 185.53 sec
2018-01-03 02:27:16,560 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 187.73 sec
2018-01-03 02:27:18,622 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 189.37 sec
2018-01-03 02:27:20,686 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 191.78 sec
2018-01-03 02:27:21,719 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 196.62 sec
2018-01-03 02:27:22,750 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 198.86 sec
2018-01-03 02:27:23,780 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 203.07 sec
MapReduce Total cumulative CPU time: 3 minutes 23 seconds 70 msec
Ended Job = job_1513599404024_161084
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161095, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161095/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161095
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:27:38,567 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:27:45,800 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.27 sec
2018-01-03 02:27:55,077 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.43 sec
MapReduce Total cumulative CPU time: 19 seconds 430 msec
Ended Job = job_1513599404024_161095
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161097, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161097/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161097
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:28:00,812 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:28:13,176 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.16 sec
2018-01-03 02:28:24,495 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.15 sec
MapReduce Total cumulative CPU time: 9 seconds 150 msec
Ended Job = job_1513599404024_161097
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 203.07 sec   HDFS Read: 233119106 HDFS Write: 1910463 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.43 sec   HDFS Read: 50715524 HDFS Write: 94781 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.15 sec   HDFS Read: 102456 HDFS Write: 3484 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 51 seconds 650 msec
OK
Time taken: 131.077 seconds, Fetched: 483 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.387 seconds
Query ID = boss_20180103022840_40a0ebb6-1615-4b16-b979-13c0255d2ee2
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161102, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161102/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161102
Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 7
2018-01-03 02:28:58,259 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:29:08,637 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 36.56 sec
2018-01-03 02:29:11,745 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 61.06 sec
2018-01-03 02:29:14,846 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 76.01 sec
2018-01-03 02:29:15,879 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 87.86 sec
2018-01-03 02:29:16,911 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 91.52 sec
2018-01-03 02:29:17,945 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 104.88 sec
2018-01-03 02:29:20,009 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 122.97 sec
2018-01-03 02:29:21,045 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 132.47 sec
2018-01-03 02:29:22,077 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 148.56 sec
2018-01-03 02:29:23,109 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 151.99 sec
2018-01-03 02:29:24,141 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 160.81 sec
2018-01-03 02:29:25,172 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 166.38 sec
2018-01-03 02:29:26,205 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 177.28 sec
2018-01-03 02:29:28,272 Stage-1 map = 88%,  reduce = 7%, Cumulative CPU 181.08 sec
2018-01-03 02:29:29,305 Stage-1 map = 88%,  reduce = 11%, Cumulative CPU 181.61 sec
2018-01-03 02:29:30,342 Stage-1 map = 88%,  reduce = 15%, Cumulative CPU 182.35 sec
2018-01-03 02:29:31,374 Stage-1 map = 88%,  reduce = 17%, Cumulative CPU 182.53 sec
2018-01-03 02:29:34,469 Stage-1 map = 89%,  reduce = 17%, Cumulative CPU 193.36 sec
2018-01-03 02:29:36,532 Stage-1 map = 89%,  reduce = 21%, Cumulative CPU 194.38 sec
2018-01-03 02:29:37,563 Stage-1 map = 92%,  reduce = 21%, Cumulative CPU 198.5 sec
2018-01-03 02:29:39,625 Stage-1 map = 93%,  reduce = 21%, Cumulative CPU 202.5 sec
2018-01-03 02:29:42,717 Stage-1 map = 100%,  reduce = 21%, Cumulative CPU 206.35 sec
2018-01-03 02:29:43,749 Stage-1 map = 100%,  reduce = 32%, Cumulative CPU 207.92 sec
2018-01-03 02:29:44,778 Stage-1 map = 100%,  reduce = 86%, Cumulative CPU 231.94 sec
2018-01-03 02:29:46,837 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 237.98 sec
MapReduce Total cumulative CPU time: 3 minutes 57 seconds 980 msec
Ended Job = job_1513599404024_161102
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161112, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161112/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161112
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:29:55,834 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:30:09,225 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.23 sec
2018-01-03 02:30:10,255 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.72 sec
2018-01-03 02:30:15,444 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.03 sec
MapReduce Total cumulative CPU time: 15 seconds 30 msec
Ended Job = job_1513599404024_161112
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161115, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161115/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161115
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:30:37,136 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:31:00,768 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.05 sec
2018-01-03 02:31:10,016 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.46 sec
MapReduce Total cumulative CPU time: 7 seconds 460 msec
Ended Job = job_1513599404024_161115
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 8  Reduce: 7   Cumulative CPU: 237.98 sec   HDFS Read: 707682628 HDFS Write: 956931 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.03 sec   HDFS Read: 49763302 HDFS Write: 23992 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.46 sec   HDFS Read: 31668 HDFS Write: 2703 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 20 seconds 470 msec
OK
Time taken: 150.791 seconds, Fetched: 397 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103023117_08c6c6ac-a158-4a32-8c86-ba3f2b0c0b35
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161124, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161124/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161124
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:31:27,909 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:31:38,260 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 10.71 sec
2018-01-03 02:31:41,360 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 13.44 sec
2018-01-03 02:31:44,455 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 16.18 sec
2018-01-03 02:31:47,542 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 16.92 sec
2018-01-03 02:31:50,635 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 18.17 sec
2018-01-03 02:31:53,723 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 18.69 sec
2018-01-03 02:31:58,870 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 20.81 sec
2018-01-03 02:32:01,956 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 23.75 sec
2018-01-03 02:32:05,041 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 34.54 sec
2018-01-03 02:32:07,099 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 35.09 sec
2018-01-03 02:32:10,185 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 35.79 sec
2018-01-03 02:32:13,270 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 36.57 sec
2018-01-03 02:32:17,383 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 37.34 sec
2018-01-03 02:32:20,465 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 38.66 sec
2018-01-03 02:32:23,545 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 39.43 sec
2018-01-03 02:32:26,629 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 39.77 sec
2018-01-03 02:32:29,709 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 40.22 sec
2018-01-03 02:32:32,791 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 40.65 sec
2018-01-03 02:32:35,877 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 47.26 sec
2018-01-03 02:32:38,960 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 47.81 sec
2018-01-03 02:32:42,044 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 48.5 sec
2018-01-03 02:32:45,143 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 49.12 sec
2018-01-03 02:32:48,221 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 49.55 sec
2018-01-03 02:32:51,297 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 51.03 sec
2018-01-03 02:32:54,377 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 52.61 sec
2018-01-03 02:32:57,454 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 54.75 sec
2018-01-03 02:33:05,671 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 60.7 sec
MapReduce Total cumulative CPU time: 1 minutes 0 seconds 700 msec
Ended Job = job_1513599404024_161124
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161140, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161140/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161140
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:33:11,414 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:33:29,956 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 8.02 sec
2018-01-03 02:33:35,155 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 20.3 sec
2018-01-03 02:33:37,218 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 26.79 sec
MapReduce Total cumulative CPU time: 26 seconds 790 msec
Ended Job = job_1513599404024_161140
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161144, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161144/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161144
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:33:48,877 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:33:54,046 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.24 sec
2018-01-03 02:34:02,289 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.77 sec
MapReduce Total cumulative CPU time: 6 seconds 770 msec
Ended Job = job_1513599404024_161144
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 60.7 sec   HDFS Read: 99188948 HDFS Write: 616004 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 26.79 sec   HDFS Read: 49420743 HDFS Write: 211148 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.77 sec   HDFS Read: 218781 HDFS Write: 6916 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 34 seconds 260 msec
OK
Time taken: 165.596 seconds, Fetched: 818 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.472 seconds
Query ID = boss_20180103023410_549f0f65-c9d5-435f-987f-91ece14faf25
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161149, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161149/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161149
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:34:20,421 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:34:30,809 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 10.47 sec
2018-01-03 02:34:33,915 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 12.93 sec
2018-01-03 02:34:37,014 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 14.2 sec
2018-01-03 02:34:40,112 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 15.3 sec
2018-01-03 02:34:43,204 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 16.17 sec
2018-01-03 02:34:46,295 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 17.81 sec
2018-01-03 02:34:49,387 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 18.64 sec
2018-01-03 02:34:51,446 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 19.65 sec
2018-01-03 02:34:54,536 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 20.77 sec
2018-01-03 02:34:57,627 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 22.55 sec
2018-01-03 02:35:00,717 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 24.72 sec
2018-01-03 02:35:12,052 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 28.81 sec
MapReduce Total cumulative CPU time: 28 seconds 810 msec
Ended Job = job_1513599404024_161149
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161156, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161156/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161156
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:35:26,795 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:35:31,961 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.34 sec
2018-01-03 02:35:32,991 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.81 sec
2018-01-03 02:35:38,144 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.21 sec
MapReduce Total cumulative CPU time: 14 seconds 210 msec
Ended Job = job_1513599404024_161156
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161159, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161159/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161159
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:35:44,771 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:35:48,905 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.68 sec
2018-01-03 02:35:57,140 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.05 sec
MapReduce Total cumulative CPU time: 6 seconds 50 msec
Ended Job = job_1513599404024_161159
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 28.81 sec   HDFS Read: 99188938 HDFS Write: 942782 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.21 sec   HDFS Read: 49747521 HDFS Write: 125850 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.05 sec   HDFS Read: 133484 HDFS Write: 2983 SUCCESS
Total MapReduce CPU Time Spent: 49 seconds 70 msec
OK
Time taken: 107.882 seconds, Fetched: 432 row(s)
开始执行20170908日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.373 seconds
Query ID = boss_20180103023605_55d98a5d-cd5f-4509-85b7-b8b9d64aa4e7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161163, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161163/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161163
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 02:36:15,186 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:36:25,551 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 13.45 sec
2018-01-03 02:36:28,653 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 30.61 sec
2018-01-03 02:36:31,753 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 43.01 sec
2018-01-03 02:36:34,845 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 47.33 sec
2018-01-03 02:36:37,940 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 65.66 sec
2018-01-03 02:36:41,030 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 69.38 sec
2018-01-03 02:36:44,119 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 72.53 sec
2018-01-03 02:36:45,154 Stage-1 map = 66%,  reduce = 8%, Cumulative CPU 73.25 sec
2018-01-03 02:36:46,187 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 73.91 sec
2018-01-03 02:36:47,219 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 77.51 sec
2018-01-03 02:36:50,308 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 80.86 sec
2018-01-03 02:36:53,397 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 84.23 sec
2018-01-03 02:36:56,489 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 88.01 sec
2018-01-03 02:36:57,519 Stage-1 map = 100%,  reduce = 53%, Cumulative CPU 89.98 sec
2018-01-03 02:36:58,548 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 100.59 sec
MapReduce Total cumulative CPU time: 1 minutes 40 seconds 590 msec
Ended Job = job_1513599404024_161163
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161170, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161170/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161170
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:37:13,293 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:37:19,498 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.47 sec
2018-01-03 02:37:22,598 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.23 sec
2018-01-03 02:37:39,089 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.93 sec
MapReduce Total cumulative CPU time: 17 seconds 930 msec
Ended Job = job_1513599404024_161170
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161176, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161176/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161176
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:37:52,731 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:37:56,852 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.8 sec
2018-01-03 02:38:04,044 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.61 sec
MapReduce Total cumulative CPU time: 5 seconds 610 msec
Ended Job = job_1513599404024_161176
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 100.59 sec   HDFS Read: 254480766 HDFS Write: 1930749 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.93 sec   HDFS Read: 49336875 HDFS Write: 90003 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.61 sec   HDFS Read: 97678 HDFS Write: 3598 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 4 seconds 130 msec
OK
Time taken: 119.928 seconds, Fetched: 482 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.388 seconds
Query ID = boss_20180103023819_a2aa2248-c7cd-4743-a1fa-b646c54be648
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161181, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161181/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161181
Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 8
2018-01-03 02:38:29,961 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:38:40,340 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 24.15 sec
2018-01-03 02:38:41,375 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 36.66 sec
2018-01-03 02:38:43,449 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 38.67 sec
2018-01-03 02:38:44,483 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 70.43 sec
2018-01-03 02:38:46,561 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 83.46 sec
2018-01-03 02:38:47,595 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 99.79 sec
2018-01-03 02:38:48,627 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 142.66 sec
2018-01-03 02:38:49,659 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 146.48 sec
2018-01-03 02:38:50,690 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 168.84 sec
2018-01-03 02:38:51,723 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 183.68 sec
2018-01-03 02:38:52,758 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 190.83 sec
2018-01-03 02:38:53,789 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 197.06 sec
2018-01-03 02:38:54,821 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 206.85 sec
2018-01-03 02:38:55,857 Stage-1 map = 62%,  reduce = 8%, Cumulative CPU 209.92 sec
2018-01-03 02:38:56,889 Stage-1 map = 68%,  reduce = 12%, Cumulative CPU 216.13 sec
2018-01-03 02:38:57,921 Stage-1 map = 70%,  reduce = 15%, Cumulative CPU 234.43 sec
2018-01-03 02:38:58,955 Stage-1 map = 71%,  reduce = 19%, Cumulative CPU 244.86 sec
2018-01-03 02:38:59,988 Stage-1 map = 77%,  reduce = 20%, Cumulative CPU 248.47 sec
2018-01-03 02:39:01,019 Stage-1 map = 77%,  reduce = 22%, Cumulative CPU 248.87 sec
2018-01-03 02:39:02,055 Stage-1 map = 78%,  reduce = 23%, Cumulative CPU 258.46 sec
2018-01-03 02:39:03,087 Stage-1 map = 80%,  reduce = 24%, Cumulative CPU 270.5 sec
2018-01-03 02:39:04,118 Stage-1 map = 80%,  reduce = 25%, Cumulative CPU 271.04 sec
2018-01-03 02:39:07,212 Stage-1 map = 81%,  reduce = 25%, Cumulative CPU 318.94 sec
2018-01-03 02:39:10,310 Stage-1 map = 82%,  reduce = 25%, Cumulative CPU 325.63 sec
2018-01-03 02:39:11,351 Stage-1 map = 83%,  reduce = 25%, Cumulative CPU 330.08 sec
2018-01-03 02:39:12,381 Stage-1 map = 84%,  reduce = 25%, Cumulative CPU 287.31 sec
2018-01-03 02:39:15,471 Stage-1 map = 85%,  reduce = 25%, Cumulative CPU 304.07 sec
2018-01-03 02:39:16,501 Stage-1 map = 86%,  reduce = 25%, Cumulative CPU 311.7 sec
2018-01-03 02:39:18,562 Stage-1 map = 89%,  reduce = 25%, Cumulative CPU 315.97 sec
2018-01-03 02:39:19,591 Stage-1 map = 100%,  reduce = 28%, Cumulative CPU 323.17 sec
2018-01-03 02:39:20,620 Stage-1 map = 100%,  reduce = 43%, Cumulative CPU 329.68 sec
2018-01-03 02:39:21,655 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 353.16 sec
2018-01-03 02:39:23,712 Stage-1 map = 100%,  reduce = 96%, Cumulative CPU 355.53 sec
2018-01-03 02:39:24,741 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 359.37 sec
MapReduce Total cumulative CPU time: 5 minutes 59 seconds 370 msec
Ended Job = job_1513599404024_161181
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161190, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161190/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161190
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:39:41,587 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:39:48,967 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.08 sec
2018-01-03 02:39:51,031 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.83 sec
2018-01-03 02:40:05,439 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.99 sec
MapReduce Total cumulative CPU time: 19 seconds 990 msec
Ended Job = job_1513599404024_161190
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161202, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161202/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161202
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:40:19,079 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:40:27,330 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.91 sec
2018-01-03 02:40:33,513 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.87 sec
MapReduce Total cumulative CPU time: 5 seconds 870 msec
Ended Job = job_1513599404024_161202
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 8  Reduce: 8   Cumulative CPU: 359.37 sec   HDFS Read: 761578479 HDFS Write: 1048785 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.99 sec   HDFS Read: 48456483 HDFS Write: 24432 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.87 sec   HDFS Read: 32108 HDFS Write: 2789 SUCCESS
Total MapReduce CPU Time Spent: 6 minutes 25 seconds 230 msec
OK
Time taken: 134.777 seconds, Fetched: 404 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103024049_cf456175-b8e6-478b-9609-6d6d84ef7e7b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161206, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161206/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161206
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:41:08,689 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:41:25,656 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 12.16 sec
2018-01-03 02:41:28,748 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 16.21 sec
2018-01-03 02:41:31,843 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 17.8 sec
2018-01-03 02:41:34,934 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 19.36 sec
2018-01-03 02:41:36,993 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 20.3 sec
2018-01-03 02:41:40,085 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 21.34 sec
2018-01-03 02:41:43,171 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 22.17 sec
2018-01-03 02:41:46,257 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 23.35 sec
2018-01-03 02:41:49,345 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 24.21 sec
2018-01-03 02:41:52,431 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 25.09 sec
2018-01-03 02:41:55,516 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 26.16 sec
2018-01-03 02:41:58,601 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 26.97 sec
2018-01-03 02:42:01,683 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 27.47 sec
2018-01-03 02:42:04,764 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 28.48 sec
2018-01-03 02:42:07,848 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 29.3 sec
2018-01-03 02:42:10,929 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 30.06 sec
2018-01-03 02:42:14,009 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 30.78 sec
2018-01-03 02:42:17,092 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 32.53 sec
2018-01-03 02:42:20,173 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 34.1 sec
2018-01-03 02:42:33,521 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.33 sec
MapReduce Total cumulative CPU time: 39 seconds 330 msec
Ended Job = job_1513599404024_161206
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161213, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161213/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161213
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:42:39,679 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:42:44,829 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.89 sec
2018-01-03 02:42:53,051 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.13 sec
2018-01-03 02:43:03,322 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.92 sec
MapReduce Total cumulative CPU time: 16 seconds 920 msec
Ended Job = job_1513599404024_161213
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161216, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161216/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161216
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:43:08,917 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:43:14,068 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.65 sec
2018-01-03 02:43:19,209 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.62 sec
MapReduce Total cumulative CPU time: 6 seconds 620 msec
Ended Job = job_1513599404024_161216
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 39.33 sec   HDFS Read: 94462626 HDFS Write: 593519 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.92 sec   HDFS Read: 47999327 HDFS Write: 206057 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.62 sec   HDFS Read: 213694 HDFS Write: 6725 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 2 seconds 870 msec
OK
Time taken: 152.043 seconds, Fetched: 799 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103024328_a2f3d3cf-387e-4942-b46c-4f01abc177a6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161218, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161218/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161218
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:43:38,359 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:43:47,740 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 9.84 sec
2018-01-03 02:43:50,835 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 12.33 sec
2018-01-03 02:43:53,922 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 13.58 sec
2018-01-03 02:43:57,008 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 14.49 sec
2018-01-03 02:44:00,095 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 17.91 sec
2018-01-03 02:44:03,183 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 18.63 sec
2018-01-03 02:44:06,268 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 19.25 sec
2018-01-03 02:44:09,355 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 20.39 sec
2018-01-03 02:44:12,442 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 21.39 sec
2018-01-03 02:44:15,526 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 35.53 sec
2018-01-03 02:44:18,610 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 36.69 sec
2018-01-03 02:44:22,723 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 50.6 sec
2018-01-03 02:44:25,807 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 51.66 sec
2018-01-03 02:44:28,896 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 55.9 sec
2018-01-03 02:44:29,924 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 56.89 sec
2018-01-03 02:44:41,246 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 63.12 sec
MapReduce Total cumulative CPU time: 1 minutes 3 seconds 120 msec
Ended Job = job_1513599404024_161218
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161243, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161243/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161243
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:44:57,361 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:45:13,343 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.96 sec
2018-01-03 02:45:17,474 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 14.86 sec
2018-01-03 02:45:31,155 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 18.72 sec
2018-01-03 02:45:34,246 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 25.84 sec
MapReduce Total cumulative CPU time: 25 seconds 840 msec
Ended Job = job_1513599404024_161243
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161250, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161250/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161250
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:45:42,666 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:45:59,111 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.12 sec
2018-01-03 02:46:29,987 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.97 sec
MapReduce Total cumulative CPU time: 9 seconds 970 msec
Ended Job = job_1513599404024_161250
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 63.12 sec   HDFS Read: 94462616 HDFS Write: 1068251 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 25.84 sec   HDFS Read: 48474059 HDFS Write: 127699 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.97 sec   HDFS Read: 135337 HDFS Write: 2965 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 38 seconds 930 msec
OK
Time taken: 182.735 seconds, Fetched: 432 row(s)
开始执行20170909日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.367 seconds
Query ID = boss_20180103024638_425d7699-90c7-4f7c-8faf-0296b64a419d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161263, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161263/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161263
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 02:46:54,031 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:47:04,397 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 11.55 sec
2018-01-03 02:47:07,496 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 15.5 sec
2018-01-03 02:47:10,589 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 40.2 sec
2018-01-03 02:47:13,679 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 47.13 sec
2018-01-03 02:47:16,773 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 54.1 sec
2018-01-03 02:47:18,836 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 57.21 sec
2018-01-03 02:47:19,867 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 63.15 sec
2018-01-03 02:47:21,923 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 66.13 sec
2018-01-03 02:47:22,954 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 73.75 sec
2018-01-03 02:47:25,011 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 76.77 sec
2018-01-03 02:47:27,071 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 89.98 sec
2018-01-03 02:47:28,099 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 93.63 sec
2018-01-03 02:47:29,128 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 97.07 sec
2018-01-03 02:47:31,185 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 100.69 sec
2018-01-03 02:47:32,213 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 104.5 sec
2018-01-03 02:47:33,242 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 107.12 sec
2018-01-03 02:47:35,302 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 111.88 sec
2018-01-03 02:47:38,387 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 115.17 sec
2018-01-03 02:47:41,472 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 118.42 sec
2018-01-03 02:47:44,562 Stage-1 map = 82%,  reduce = 6%, Cumulative CPU 122.21 sec
2018-01-03 02:47:45,592 Stage-1 map = 100%,  reduce = 11%, Cumulative CPU 124.41 sec
2018-01-03 02:47:47,649 Stage-1 map = 100%,  reduce = 39%, Cumulative CPU 128.85 sec
2018-01-03 02:47:48,677 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 133.39 sec
2018-01-03 02:47:54,856 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 143.01 sec
MapReduce Total cumulative CPU time: 2 minutes 23 seconds 10 msec
Ended Job = job_1513599404024_161263
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161281, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161281/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161281
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:48:11,247 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:48:20,506 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.47 sec
2018-01-03 02:48:30,789 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.92 sec
2018-01-03 02:48:33,871 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 14.43 sec
2018-01-03 02:48:35,926 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.91 sec
MapReduce Total cumulative CPU time: 19 seconds 910 msec
Ended Job = job_1513599404024_161281
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161284, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161284/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161284
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:48:41,606 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:48:55,369 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.13 sec
2018-01-03 02:49:02,586 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.06 sec
MapReduce Total cumulative CPU time: 6 seconds 60 msec
Ended Job = job_1513599404024_161284
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 143.01 sec   HDFS Read: 319603057 HDFS Write: 2158831 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.91 sec   HDFS Read: 55260904 HDFS Write: 99394 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.06 sec   HDFS Read: 107069 HDFS Write: 3601 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 48 seconds 980 msec
OK
Time taken: 145.378 seconds, Fetched: 486 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.402 seconds
Query ID = boss_20180103024910_6de78047-887e-4a20-b093-f38879ec5560
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 10
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161295, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161295/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161295
Hadoop job information for Stage-1: number of mappers: 11; number of reducers: 10
2018-01-03 02:49:21,848 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:49:32,248 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 24.0 sec
2018-01-03 02:49:33,282 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 101.07 sec
2018-01-03 02:49:35,352 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 125.23 sec
2018-01-03 02:49:36,385 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 162.98 sec
2018-01-03 02:49:37,418 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 173.53 sec
2018-01-03 02:49:38,450 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 178.45 sec
2018-01-03 02:49:39,486 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 192.2 sec
2018-01-03 02:49:40,523 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 204.15 sec
2018-01-03 02:49:41,555 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 207.46 sec
2018-01-03 02:49:42,586 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 217.5 sec
2018-01-03 02:49:43,617 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 228.66 sec
2018-01-03 02:49:45,685 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 242.19 sec
2018-01-03 02:49:46,716 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 256.91 sec
2018-01-03 02:49:48,776 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 263.19 sec
2018-01-03 02:49:49,806 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 280.77 sec
2018-01-03 02:49:50,836 Stage-1 map = 57%,  reduce = 1%, Cumulative CPU 283.29 sec
2018-01-03 02:49:51,872 Stage-1 map = 59%,  reduce = 2%, Cumulative CPU 291.27 sec
2018-01-03 02:49:52,903 Stage-1 map = 67%,  reduce = 4%, Cumulative CPU 303.2 sec
2018-01-03 02:49:53,938 Stage-1 map = 71%,  reduce = 5%, Cumulative CPU 306.82 sec
2018-01-03 02:49:54,968 Stage-1 map = 71%,  reduce = 6%, Cumulative CPU 310.68 sec
2018-01-03 02:49:55,998 Stage-1 map = 77%,  reduce = 7%, Cumulative CPU 320.48 sec
2018-01-03 02:49:57,027 Stage-1 map = 82%,  reduce = 10%, Cumulative CPU 323.39 sec
2018-01-03 02:49:58,056 Stage-1 map = 88%,  reduce = 11%, Cumulative CPU 329.29 sec
2018-01-03 02:49:59,086 Stage-1 map = 93%,  reduce = 14%, Cumulative CPU 338.82 sec
2018-01-03 02:50:00,115 Stage-1 map = 100%,  reduce = 19%, Cumulative CPU 343.83 sec
2018-01-03 02:50:01,144 Stage-1 map = 100%,  reduce = 52%, Cumulative CPU 361.24 sec
2018-01-03 02:50:02,174 Stage-1 map = 100%,  reduce = 87%, Cumulative CPU 385.33 sec
2018-01-03 02:50:13,495 Stage-1 map = 100%,  reduce = 90%, Cumulative CPU 396.5 sec
2018-01-03 02:50:16,580 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 398.92 sec
2018-01-03 02:50:24,803 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 401.84 sec
MapReduce Total cumulative CPU time: 6 minutes 41 seconds 840 msec
Ended Job = job_1513599404024_161295
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161303, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161303/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161303
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:50:33,544 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:50:39,810 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.92 sec
2018-01-03 02:50:40,840 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.61 sec
2018-01-03 02:50:45,992 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.21 sec
MapReduce Total cumulative CPU time: 19 seconds 210 msec
Ended Job = job_1513599404024_161303
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161307, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161307/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161307
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:50:51,726 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:50:56,899 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.66 sec
2018-01-03 02:51:04,118 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.7 sec
MapReduce Total cumulative CPU time: 5 seconds 700 msec
Ended Job = job_1513599404024_161307
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 11  Reduce: 10   Cumulative CPU: 401.84 sec   HDFS Read: 962739614 HDFS Write: 1605732 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.21 sec   HDFS Read: 54709639 HDFS Write: 28633 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.7 sec   HDFS Read: 36309 HDFS Write: 2822 SUCCESS
Total MapReduce CPU Time Spent: 7 minutes 6 seconds 750 msec
OK
Time taken: 114.752 seconds, Fetched: 401 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103025119_28205f06-8c64-48e4-a32b-559cc7f995ab
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161315, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161315/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161315
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:51:35,582 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:51:52,145 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 9.91 sec
2018-01-03 02:51:55,240 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 13.28 sec
2018-01-03 02:51:58,339 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 14.57 sec
2018-01-03 02:52:01,434 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 16.01 sec
2018-01-03 02:52:04,542 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 16.87 sec
2018-01-03 02:52:06,607 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 17.72 sec
2018-01-03 02:52:09,699 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 18.4 sec
2018-01-03 02:52:12,789 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 19.05 sec
2018-01-03 02:52:15,882 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 19.67 sec
2018-01-03 02:52:18,971 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 20.39 sec
2018-01-03 02:52:22,059 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 21.4 sec
2018-01-03 02:52:25,150 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 21.93 sec
2018-01-03 02:52:28,238 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 22.55 sec
2018-01-03 02:52:31,323 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 23.28 sec
2018-01-03 02:52:34,411 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 23.64 sec
2018-01-03 02:52:37,497 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 24.0 sec
2018-01-03 02:52:40,583 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 25.16 sec
2018-01-03 02:52:43,671 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 25.64 sec
2018-01-03 02:52:46,755 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 26.18 sec
2018-01-03 02:52:49,840 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 26.91 sec
2018-01-03 02:52:52,926 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 27.39 sec
2018-01-03 02:52:56,009 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 28.13 sec
2018-01-03 02:52:59,089 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 30.11 sec
2018-01-03 02:53:02,172 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 30.52 sec
2018-01-03 02:53:05,255 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 31.15 sec
2018-01-03 02:53:06,282 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.45 sec
2018-01-03 02:53:58,227 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 39.34 sec
2018-01-03 02:54:02,352 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 43.16 sec
2018-01-03 02:54:54,850 Stage-1 map = 100%,  reduce = 73%, Cumulative CPU 72.44 sec
2018-01-03 02:54:57,929 Stage-1 map = 100%,  reduce = 85%, Cumulative CPU 76.11 sec
2018-01-03 02:55:01,008 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 81.38 sec
2018-01-03 02:55:04,085 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 85.02 sec
MapReduce Total cumulative CPU time: 1 minutes 25 seconds 20 msec
Ended Job = job_1513599404024_161315
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161352, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161352/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161352
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:55:17,815 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:55:25,006 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.33 sec
2018-01-03 02:55:34,246 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.94 sec
MapReduce Total cumulative CPU time: 16 seconds 940 msec
Ended Job = job_1513599404024_161352
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161360, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161360/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161360
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:55:51,932 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:56:02,213 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 7.37 sec
2018-01-03 02:56:08,377 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 11.19 sec
MapReduce Total cumulative CPU time: 11 seconds 190 msec
Ended Job = job_1513599404024_161360
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 85.02 sec   HDFS Read: 105249424 HDFS Write: 619875 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.94 sec   HDFS Read: 53721368 HDFS Write: 230913 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 11.19 sec   HDFS Read: 238550 HDFS Write: 7296 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 53 seconds 150 msec
OK
Time taken: 289.52 seconds, Fetched: 846 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.368 seconds
Query ID = boss_20180103025616_e953a016-9701-4924-a4f8-072f28d19583
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161375, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161375/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161375
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 02:56:26,173 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:56:35,488 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 12.9 sec
2018-01-03 02:56:38,591 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 16.1 sec
2018-01-03 02:56:41,683 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 18.26 sec
2018-01-03 02:56:44,769 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 21.68 sec
2018-01-03 02:56:46,829 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 24.37 sec
2018-01-03 02:56:53,024 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.41 sec
MapReduce Total cumulative CPU time: 30 seconds 410 msec
Ended Job = job_1513599404024_161375
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161379, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161379/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161379
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 02:56:59,773 Stage-2 map = 0%,  reduce = 0%
2018-01-03 02:57:05,985 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.12 sec
2018-01-03 02:57:08,046 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.11 sec
2018-01-03 02:57:11,137 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.82 sec
MapReduce Total cumulative CPU time: 15 seconds 820 msec
Ended Job = job_1513599404024_161379
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161385, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161385/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161385
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 02:57:16,793 Stage-3 map = 0%,  reduce = 0%
2018-01-03 02:57:21,945 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.68 sec
2018-01-03 02:57:36,340 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.54 sec
MapReduce Total cumulative CPU time: 7 seconds 540 msec
Ended Job = job_1513599404024_161385
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.41 sec   HDFS Read: 105249414 HDFS Write: 1342723 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.82 sec   HDFS Read: 54444216 HDFS Write: 144306 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.54 sec   HDFS Read: 151944 HDFS Write: 2852 SUCCESS
Total MapReduce CPU Time Spent: 53 seconds 770 msec
OK
Time taken: 81.257 seconds, Fetched: 407 row(s)
开始执行20170910日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.368 seconds
Query ID = boss_20180103025752_62662735-735a-44c5-b4f6-5dec29946af5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161388, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161388/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161388
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 02:59:07,358 Stage-1 map = 0%,  reduce = 0%
2018-01-03 02:59:21,459 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.07 sec
2018-01-03 02:59:24,808 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 28.34 sec
2018-01-03 02:59:25,881 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 44.11 sec
2018-01-03 02:59:28,061 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 47.38 sec
2018-01-03 02:59:29,128 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 50.35 sec
2018-01-03 02:59:30,177 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 53.71 sec
2018-01-03 02:59:31,241 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 57.21 sec
2018-01-03 02:59:33,354 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 60.45 sec
2018-01-03 02:59:34,422 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 63.96 sec
2018-01-03 02:59:36,517 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 67.34 sec
2018-01-03 02:59:37,564 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 73.88 sec
2018-01-03 02:59:39,671 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 77.25 sec
2018-01-03 02:59:41,799 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 81.35 sec
2018-01-03 02:59:42,847 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 84.35 sec
2018-01-03 02:59:44,964 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 88.68 sec
2018-01-03 02:59:49,858 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 120.2 sec
2018-01-03 02:59:53,022 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 123.3 sec
2018-01-03 02:59:56,214 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 132.71 sec
2018-01-03 02:59:58,317 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 134.9 sec
2018-01-03 03:00:05,673 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 139.53 sec
2018-01-03 03:00:08,830 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 145.63 sec
2018-01-03 03:00:09,875 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 154.19 sec
MapReduce Total cumulative CPU time: 2 minutes 34 seconds 190 msec
Ended Job = job_1513599404024_161388
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161402, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161402/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161402
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:00:21,163 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:00:27,459 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 9.59 sec
2018-01-03 03:00:33,644 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 16.81 sec
2018-01-03 03:00:35,708 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.93 sec
MapReduce Total cumulative CPU time: 23 seconds 930 msec
Ended Job = job_1513599404024_161402
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161407, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161407/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161407
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:00:41,681 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:00:45,806 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.73 sec
2018-01-03 03:01:44,356 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 13.42 sec
2018-01-03 03:01:52,615 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 13.42 sec
MapReduce Total cumulative CPU time: 13 seconds 420 msec
Ended Job = job_1513599404024_161407
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 154.19 sec   HDFS Read: 321264842 HDFS Write: 2161768 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.93 sec   HDFS Read: 54925685 HDFS Write: 110164 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 18.97 sec   HDFS Read: 117839 HDFS Write: 3651 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 17 seconds 90 msec
OK
Time taken: 242.309 seconds, Fetched: 485 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.385 seconds
Query ID = boss_20180103030201_0f48f5b0-7b33-478d-848f-1e947d25b7a2
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 10
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161492, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161492/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161492
Hadoop job information for Stage-1: number of mappers: 11; number of reducers: 10
2018-01-03 03:02:35,232 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:02:52,233 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 22.51 sec
2018-01-03 03:02:53,266 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 63.63 sec
2018-01-03 03:02:56,403 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 99.12 sec
2018-01-03 03:02:57,441 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 131.02 sec
2018-01-03 03:02:59,511 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 150.91 sec
2018-01-03 03:03:00,546 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 185.0 sec
2018-01-03 03:03:03,638 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 200.2 sec
2018-01-03 03:03:05,698 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 214.3 sec
2018-01-03 03:03:06,728 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 224.07 sec
2018-01-03 03:03:08,793 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 233.78 sec
2018-01-03 03:03:09,836 Stage-1 map = 30%,  reduce = 1%, Cumulative CPU 239.19 sec
2018-01-03 03:03:10,871 Stage-1 map = 31%,  reduce = 1%, Cumulative CPU 249.15 sec
2018-01-03 03:03:11,903 Stage-1 map = 33%,  reduce = 1%, Cumulative CPU 262.97 sec
2018-01-03 03:03:12,934 Stage-1 map = 40%,  reduce = 1%, Cumulative CPU 268.12 sec
2018-01-03 03:03:14,993 Stage-1 map = 41%,  reduce = 2%, Cumulative CPU 288.68 sec
2018-01-03 03:03:16,024 Stage-1 map = 42%,  reduce = 3%, Cumulative CPU 292.21 sec
2018-01-03 03:03:17,053 Stage-1 map = 42%,  reduce = 5%, Cumulative CPU 293.59 sec
2018-01-03 03:03:18,082 Stage-1 map = 45%,  reduce = 5%, Cumulative CPU 314.49 sec
2018-01-03 03:03:19,115 Stage-1 map = 49%,  reduce = 7%, Cumulative CPU 318.54 sec
2018-01-03 03:03:20,144 Stage-1 map = 49%,  reduce = 8%, Cumulative CPU 318.87 sec
2018-01-03 03:03:21,173 Stage-1 map = 54%,  reduce = 9%, Cumulative CPU 332.23 sec
2018-01-03 03:03:22,205 Stage-1 map = 54%,  reduce = 10%, Cumulative CPU 338.08 sec
2018-01-03 03:03:23,235 Stage-1 map = 58%,  reduce = 11%, Cumulative CPU 342.59 sec
2018-01-03 03:03:24,263 Stage-1 map = 66%,  reduce = 12%, Cumulative CPU 346.99 sec
2018-01-03 03:03:25,293 Stage-1 map = 66%,  reduce = 14%, Cumulative CPU 348.47 sec
2018-01-03 03:03:26,322 Stage-1 map = 66%,  reduce = 16%, Cumulative CPU 350.31 sec
2018-01-03 03:03:27,350 Stage-1 map = 67%,  reduce = 18%, Cumulative CPU 365.32 sec
2018-01-03 03:03:30,510 Stage-1 map = 70%,  reduce = 18%, Cumulative CPU 409.31 sec
2018-01-03 03:03:31,539 Stage-1 map = 77%,  reduce = 18%, Cumulative CPU 454.22 sec
2018-01-03 03:03:32,569 Stage-1 map = 77%,  reduce = 19%, Cumulative CPU 454.43 sec
2018-01-03 03:03:33,645 Stage-1 map = 77%,  reduce = 21%, Cumulative CPU 466.41 sec
2018-01-03 03:03:34,680 Stage-1 map = 77%,  reduce = 22%, Cumulative CPU 470.23 sec
2018-01-03 03:03:35,708 Stage-1 map = 77%,  reduce = 23%, Cumulative CPU 470.36 sec
2018-01-03 03:03:36,736 Stage-1 map = 81%,  reduce = 24%, Cumulative CPU 434.54 sec
2018-01-03 03:03:37,770 Stage-1 map = 82%,  reduce = 24%, Cumulative CPU 440.51 sec
2018-01-03 03:03:39,836 Stage-1 map = 83%,  reduce = 24%, Cumulative CPU 478.55 sec
2018-01-03 03:03:40,866 Stage-1 map = 87%,  reduce = 24%, Cumulative CPU 485.01 sec
2018-01-03 03:03:42,943 Stage-1 map = 88%,  reduce = 25%, Cumulative CPU 496.71 sec
2018-01-03 03:03:43,973 Stage-1 map = 88%,  reduce = 26%, Cumulative CPU 496.8 sec
2018-01-03 03:03:45,002 Stage-1 map = 89%,  reduce = 27%, Cumulative CPU 500.87 sec
2018-01-03 03:03:47,062 Stage-1 map = 93%,  reduce = 27%, Cumulative CPU 509.32 sec
2018-01-03 03:03:48,091 Stage-1 map = 93%,  reduce = 28%, Cumulative CPU 513.41 sec
2018-01-03 03:03:49,122 Stage-1 map = 93%,  reduce = 29%, Cumulative CPU 514.35 sec
2018-01-03 03:03:50,155 Stage-1 map = 93%,  reduce = 30%, Cumulative CPU 515.32 sec
2018-01-03 03:03:58,384 Stage-1 map = 94%,  reduce = 30%, Cumulative CPU 529.85 sec
2018-01-03 03:04:05,570 Stage-1 map = 95%,  reduce = 30%, Cumulative CPU 519.36 sec
2018-01-03 03:04:08,652 Stage-1 map = 96%,  reduce = 30%, Cumulative CPU 527.37 sec
2018-01-03 03:04:12,764 Stage-1 map = 100%,  reduce = 38%, Cumulative CPU 534.11 sec
2018-01-03 03:04:13,792 Stage-1 map = 100%,  reduce = 52%, Cumulative CPU 545.4 sec
2018-01-03 03:04:14,819 Stage-1 map = 100%,  reduce = 72%, Cumulative CPU 562.34 sec
2018-01-03 03:04:16,006 Stage-1 map = 100%,  reduce = 79%, Cumulative CPU 574.78 sec
2018-01-03 03:04:17,084 Stage-1 map = 100%,  reduce = 89%, Cumulative CPU 587.87 sec
2018-01-03 03:04:18,112 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 594.14 sec
2018-01-03 03:04:23,254 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 598.06 sec
2018-01-03 03:04:25,312 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 602.85 sec
MapReduce Total cumulative CPU time: 10 minutes 2 seconds 850 msec
Ended Job = job_1513599404024_161492
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161522, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161522/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161522
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:04:50,479 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:05:50,600 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:06:28,896 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 11.01 sec
2018-01-03 03:06:47,445 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 18.24 sec
2018-01-03 03:06:50,014 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 24.85 sec
MapReduce Total cumulative CPU time: 24 seconds 850 msec
Ended Job = job_1513599404024_161522
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161566, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161566/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161566
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:07:18,291 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:07:45,258 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.71 sec
2018-01-03 03:08:02,392 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.25 sec
MapReduce Total cumulative CPU time: 8 seconds 250 msec
Ended Job = job_1513599404024_161566
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 11  Reduce: 10   Cumulative CPU: 602.85 sec   HDFS Read: 947875978 HDFS Write: 1424371 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 24.85 sec   HDFS Read: 54190122 HDFS Write: 27123 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.25 sec   HDFS Read: 34799 HDFS Write: 2970 SUCCESS
Total MapReduce CPU Time Spent: 10 minutes 35 seconds 950 msec
OK
Time taken: 362.068 seconds, Fetched: 417 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103030810_ea8c2942-5ae2-473f-93c9-cde5af8f340d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161613, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161613/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161613
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 03:08:21,313 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:08:31,675 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 9.59 sec
2018-01-03 03:08:34,782 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.24 sec
2018-01-03 03:08:37,877 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 14.58 sec
2018-01-03 03:08:40,968 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 15.42 sec
2018-01-03 03:08:44,064 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 16.28 sec
2018-01-03 03:08:47,167 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 16.92 sec
2018-01-03 03:08:50,256 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 17.48 sec
2018-01-03 03:08:53,347 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 18.12 sec
2018-01-03 03:08:56,431 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 18.7 sec
2018-01-03 03:08:59,570 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 19.25 sec
2018-01-03 03:09:02,659 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 19.55 sec
2018-01-03 03:09:05,745 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 19.74 sec
2018-01-03 03:09:08,830 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 20.39 sec
2018-01-03 03:09:11,920 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 20.78 sec
2018-01-03 03:09:15,006 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 21.32 sec
2018-01-03 03:09:18,091 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 21.64 sec
2018-01-03 03:09:21,173 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 21.73 sec
2018-01-03 03:09:24,256 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 21.88 sec
2018-01-03 03:09:26,310 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 22.47 sec
2018-01-03 03:09:29,394 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 22.86 sec
2018-01-03 03:09:32,479 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 23.26 sec
2018-01-03 03:09:35,560 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 23.57 sec
2018-01-03 03:09:38,643 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 23.74 sec
2018-01-03 03:09:41,723 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 24.09 sec
2018-01-03 03:09:44,801 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 27.24 sec
2018-01-03 03:09:47,883 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 27.77 sec
2018-01-03 03:09:50,962 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 27.94 sec
2018-01-03 03:09:54,040 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 29.17 sec
2018-01-03 03:10:16,620 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 38.34 sec
MapReduce Total cumulative CPU time: 38 seconds 340 msec
Ended Job = job_1513599404024_161613
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161674, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161674/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161674
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:10:24,083 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:10:45,678 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 8.95 sec
2018-01-03 03:10:46,707 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 17.72 sec
2018-01-03 03:11:15,468 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 28.66 sec
MapReduce Total cumulative CPU time: 28 seconds 660 msec
Ended Job = job_1513599404024_161674
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161701, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161701/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161701
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:11:52,561 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:12:14,159 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.29 sec
2018-01-03 03:12:20,335 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.6 sec
MapReduce Total cumulative CPU time: 7 seconds 600 msec
Ended Job = job_1513599404024_161701
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 38.34 sec   HDFS Read: 103987008 HDFS Write: 635358 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 30.11 sec   HDFS Read: 53398695 HDFS Write: 248591 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.6 sec   HDFS Read: 256228 HDFS Write: 7227 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 16 seconds 50 msec
OK
Time taken: 252.243 seconds, Fetched: 862 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.411 seconds
Query ID = boss_20180103031229_568ddc5c-b3c6-4126-9e32-27681b1fe526
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161741, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161741/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161741
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 03:12:44,451 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:12:56,878 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 12.06 sec
2018-01-03 03:12:58,943 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 14.34 sec
2018-01-03 03:13:04,104 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 17.49 sec
2018-01-03 03:13:10,289 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 40.58 sec
2018-01-03 03:13:13,378 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 41.59 sec
2018-01-03 03:13:16,470 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 41.75 sec
2018-01-03 03:13:21,613 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 44.13 sec
2018-01-03 03:13:24,701 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 47.84 sec
2018-01-03 03:13:27,789 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 48.67 sec
2018-01-03 03:13:30,876 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 50.88 sec
2018-01-03 03:13:33,964 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 51.75 sec
2018-01-03 03:13:37,052 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 52.75 sec
2018-01-03 03:13:40,133 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 53.73 sec
2018-01-03 03:13:47,326 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 77.5 sec
2018-01-03 03:13:50,411 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 79.09 sec
2018-01-03 03:13:56,573 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 81.32 sec
2018-01-03 03:13:59,654 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 81.57 sec
2018-01-03 03:14:02,741 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 82.34 sec
2018-01-03 03:14:05,822 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 83.1 sec
2018-01-03 03:14:08,899 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 84.69 sec
2018-01-03 03:14:11,982 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 85.59 sec
2018-01-03 03:14:15,065 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 90.65 sec
2018-01-03 03:14:18,246 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 92.25 sec
2018-01-03 03:14:21,334 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 93.39 sec
2018-01-03 03:14:24,413 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 93.94 sec
2018-01-03 03:14:27,491 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 96.57 sec
2018-01-03 03:14:33,649 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 111.05 sec
2018-01-03 03:14:36,727 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 112.97 sec
2018-01-03 03:14:55,225 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 118.36 sec
MapReduce Total cumulative CPU time: 1 minutes 58 seconds 360 msec
Ended Job = job_1513599404024_161741
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161821, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161821/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161821
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:15:15,527 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:15:20,710 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.03 sec
2018-01-03 03:15:32,169 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.73 sec
2018-01-03 03:15:38,336 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 13.92 sec
2018-01-03 03:15:40,390 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.57 sec
MapReduce Total cumulative CPU time: 20 seconds 570 msec
Ended Job = job_1513599404024_161821
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161857, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161857/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161857
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:16:06,703 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:16:12,055 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.33 sec
2018-01-03 03:16:18,694 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.83 sec
MapReduce Total cumulative CPU time: 6 seconds 830 msec
Ended Job = job_1513599404024_161857
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 118.36 sec   HDFS Read: 103986997 HDFS Write: 1200411 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.57 sec   HDFS Read: 53963744 HDFS Write: 151650 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.83 sec   HDFS Read: 159284 HDFS Write: 2919 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 25 seconds 760 msec
OK
Time taken: 230.578 seconds, Fetched: 415 row(s)
开始执行20170911日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.375 seconds
Query ID = boss_20180103031648_495a566b-35d2-4147-b4d6-7fc9b8539a5f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161904, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161904/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161904
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 03:16:59,396 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:17:08,776 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 11.21 sec
2018-01-03 03:17:09,809 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 24.25 sec
2018-01-03 03:17:11,872 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 31.94 sec
2018-01-03 03:17:14,969 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 39.55 sec
2018-01-03 03:17:18,061 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 43.2 sec
2018-01-03 03:17:21,151 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 46.85 sec
2018-01-03 03:17:24,247 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 49.95 sec
2018-01-03 03:17:25,282 Stage-1 map = 69%,  reduce = 8%, Cumulative CPU 50.43 sec
2018-01-03 03:17:26,313 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 51.11 sec
2018-01-03 03:17:27,344 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 54.54 sec
2018-01-03 03:17:30,434 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 58.77 sec
2018-01-03 03:17:33,527 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 62.36 sec
2018-01-03 03:17:36,615 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 66.42 sec
2018-01-03 03:17:39,701 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 70.1 sec
2018-01-03 03:17:40,731 Stage-1 map = 100%,  reduce = 53%, Cumulative CPU 74.43 sec
2018-01-03 03:17:41,762 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 82.3 sec
MapReduce Total cumulative CPU time: 1 minutes 22 seconds 300 msec
Ended Job = job_1513599404024_161904
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161929, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161929/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161929
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:17:53,514 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:17:58,690 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.75 sec
2018-01-03 03:18:02,821 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.97 sec
2018-01-03 03:18:09,009 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.71 sec
MapReduce Total cumulative CPU time: 15 seconds 710 msec
Ended Job = job_1513599404024_161929
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161948, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161948/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161948
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:18:14,668 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:18:18,802 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.78 sec
2018-01-03 03:18:26,005 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.65 sec
MapReduce Total cumulative CPU time: 5 seconds 650 msec
Ended Job = job_1513599404024_161948
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 82.3 sec   HDFS Read: 239887892 HDFS Write: 1799126 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.71 sec   HDFS Read: 46446576 HDFS Write: 93662 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.65 sec   HDFS Read: 101337 HDFS Write: 3428 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 43 seconds 660 msec
OK
Time taken: 98.305 seconds, Fetched: 475 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.395 seconds
Query ID = boss_20180103031833_70edbb2f-f33e-4c13-a91e-b4258a8c3ecf
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161963, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161963/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161963
Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 7
2018-01-03 03:18:44,491 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:18:55,972 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 60.51 sec
2018-01-03 03:18:57,006 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 72.04 sec
2018-01-03 03:18:59,080 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 88.93 sec
2018-01-03 03:19:00,113 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 93.03 sec
2018-01-03 03:19:02,176 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 108.92 sec
2018-01-03 03:19:03,207 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 129.28 sec
2018-01-03 03:19:04,238 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 132.34 sec
2018-01-03 03:19:05,269 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 139.03 sec
2018-01-03 03:19:06,300 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 146.69 sec
2018-01-03 03:19:07,333 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 149.87 sec
2018-01-03 03:19:08,364 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 157.13 sec
2018-01-03 03:19:09,395 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 160.56 sec
2018-01-03 03:19:10,425 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 166.43 sec
2018-01-03 03:19:12,484 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 169.77 sec
2018-01-03 03:19:13,520 Stage-1 map = 81%,  reduce = 18%, Cumulative CPU 172.85 sec
2018-01-03 03:19:14,551 Stage-1 map = 81%,  reduce = 21%, Cumulative CPU 173.61 sec
2018-01-03 03:19:15,581 Stage-1 map = 83%,  reduce = 25%, Cumulative CPU 177.42 sec
2018-01-03 03:19:16,616 Stage-1 map = 88%,  reduce = 25%, Cumulative CPU 179.63 sec
2018-01-03 03:19:17,646 Stage-1 map = 88%,  reduce = 26%, Cumulative CPU 179.81 sec
2018-01-03 03:19:19,704 Stage-1 map = 88%,  reduce = 29%, Cumulative CPU 180.17 sec
2018-01-03 03:19:28,962 Stage-1 map = 92%,  reduce = 29%, Cumulative CPU 193.96 sec
2018-01-03 03:19:32,050 Stage-1 map = 100%,  reduce = 30%, Cumulative CPU 199.15 sec
2018-01-03 03:19:33,078 Stage-1 map = 100%,  reduce = 35%, Cumulative CPU 199.31 sec
2018-01-03 03:19:34,106 Stage-1 map = 100%,  reduce = 85%, Cumulative CPU 218.74 sec
2018-01-03 03:19:35,138 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 225.72 sec
MapReduce Total cumulative CPU time: 3 minutes 45 seconds 720 msec
Ended Job = job_1513599404024_161963
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_161996, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_161996/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_161996
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:19:54,960 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:20:00,116 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.37 sec
2018-01-03 03:20:01,148 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.68 sec
2018-01-03 03:20:08,359 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.97 sec
MapReduce Total cumulative CPU time: 14 seconds 970 msec
Ended Job = job_1513599404024_161996
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162013, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162013/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162013
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:20:17,025 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:20:22,197 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.74 sec
2018-01-03 03:20:36,646 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.83 sec
MapReduce Total cumulative CPU time: 5 seconds 830 msec
Ended Job = job_1513599404024_162013
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 8  Reduce: 7   Cumulative CPU: 225.72 sec   HDFS Read: 671512924 HDFS Write: 799174 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.97 sec   HDFS Read: 45447934 HDFS Write: 23838 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.83 sec   HDFS Read: 31514 HDFS Write: 2745 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 6 seconds 520 msec
OK
Time taken: 123.898 seconds, Fetched: 396 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103032044_9013eb7c-7c08-4aa7-89ab-935b11bbb21b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162032, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162032/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162032
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 03:20:54,405 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:21:03,730 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 9.68 sec
2018-01-03 03:21:06,830 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 10.68 sec
2018-01-03 03:21:09,923 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 11.88 sec
2018-01-03 03:21:13,014 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 12.59 sec
2018-01-03 03:21:16,106 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 13.55 sec
2018-01-03 03:21:19,194 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 14.18 sec
2018-01-03 03:21:22,280 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 15.32 sec
2018-01-03 03:21:25,369 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 16.1 sec
2018-01-03 03:21:28,454 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 16.85 sec
2018-01-03 03:21:31,542 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 17.57 sec
2018-01-03 03:21:34,631 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 18.28 sec
2018-01-03 03:21:37,713 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 18.4 sec
2018-01-03 03:21:40,797 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 19.95 sec
2018-01-03 03:21:42,862 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 21.47 sec
2018-01-03 03:21:48,015 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 25.59 sec
MapReduce Total cumulative CPU time: 25 seconds 590 msec
Ended Job = job_1513599404024_162032
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162066, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162066/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162066
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:21:59,816 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:22:05,024 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.5 sec
2018-01-03 03:22:06,054 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.08 sec
2018-01-03 03:22:11,202 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.8 sec
MapReduce Total cumulative CPU time: 16 seconds 800 msec
Ended Job = job_1513599404024_162066
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162078, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162078/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162078
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:22:16,828 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:22:20,954 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.24 sec
2018-01-03 03:22:43,562 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.26 sec
MapReduce Total cumulative CPU time: 6 seconds 260 msec
Ended Job = job_1513599404024_162078
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 25.59 sec   HDFS Read: 95994220 HDFS Write: 652844 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.8 sec   HDFS Read: 45299976 HDFS Write: 234464 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.26 sec   HDFS Read: 242101 HDFS Write: 7031 SUCCESS
Total MapReduce CPU Time Spent: 48 seconds 650 msec
OK
Time taken: 120.209 seconds, Fetched: 815 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103032251_7ca418fc-a655-42bf-aaeb-fb3b9377d920
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162095, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162095/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162095
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 03:23:01,423 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:23:12,813 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 9.78 sec
2018-01-03 03:23:15,909 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 14.0 sec
2018-01-03 03:23:19,001 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 18.27 sec
2018-01-03 03:23:22,096 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 19.5 sec
2018-01-03 03:23:25,186 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 20.68 sec
2018-01-03 03:23:28,274 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 22.14 sec
2018-01-03 03:23:31,365 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 23.47 sec
2018-01-03 03:23:33,425 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 24.92 sec
2018-01-03 03:23:36,509 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 26.96 sec
2018-01-03 03:23:39,596 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 28.27 sec
2018-01-03 03:23:42,685 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 31.45 sec
2018-01-03 03:23:51,945 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 36.66 sec
MapReduce Total cumulative CPU time: 36 seconds 660 msec
Ended Job = job_1513599404024_162095
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162116, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162116/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162116
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:24:21,667 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:24:32,009 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 10.69 sec
2018-01-03 03:24:37,163 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 17.83 sec
2018-01-03 03:24:39,227 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 25.19 sec
MapReduce Total cumulative CPU time: 25 seconds 190 msec
Ended Job = job_1513599404024_162116
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162128, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162128/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162128
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:24:45,335 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:24:50,494 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.27 sec
2018-01-03 03:24:57,706 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.61 sec
MapReduce Total cumulative CPU time: 7 seconds 610 msec
Ended Job = job_1513599404024_162128
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 36.66 sec   HDFS Read: 95994210 HDFS Write: 897103 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 25.19 sec   HDFS Read: 45544235 HDFS Write: 134426 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.61 sec   HDFS Read: 142064 HDFS Write: 2995 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 9 seconds 460 msec
OK
Time taken: 127.469 seconds, Fetched: 421 row(s)
开始执行20170912日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.371 seconds
Query ID = boss_20180103032505_181a1900-df6e-4b82-9211-7fb5188276c1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162139, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162139/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162139
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 03:25:22,982 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:25:33,353 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.18 sec
2018-01-03 03:25:36,457 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 17.08 sec
2018-01-03 03:25:37,492 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 29.04 sec
2018-01-03 03:25:39,558 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 32.4 sec
2018-01-03 03:25:40,590 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 40.63 sec
2018-01-03 03:25:42,655 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 43.7 sec
2018-01-03 03:25:43,693 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 54.96 sec
2018-01-03 03:25:44,727 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 58.3 sec
2018-01-03 03:25:47,823 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 62.4 sec
2018-01-03 03:25:50,918 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 65.64 sec
2018-01-03 03:25:54,019 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 68.88 sec
2018-01-03 03:25:55,055 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 69.53 sec
2018-01-03 03:25:56,088 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 77.44 sec
2018-01-03 03:25:58,149 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 80.88 sec
MapReduce Total cumulative CPU time: 1 minutes 20 seconds 880 msec
Ended Job = job_1513599404024_162139
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162162, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162162/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162162
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:26:10,898 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:26:16,082 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.03 sec
2018-01-03 03:26:22,286 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.79 sec
MapReduce Total cumulative CPU time: 17 seconds 790 msec
Ended Job = job_1513599404024_162162
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162173, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162173/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162173
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:26:29,036 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:26:34,196 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.57 sec
2018-01-03 03:26:40,384 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.98 sec
MapReduce Total cumulative CPU time: 6 seconds 980 msec
Ended Job = job_1513599404024_162173
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 80.88 sec   HDFS Read: 234943535 HDFS Write: 1655540 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.79 sec   HDFS Read: 45892281 HDFS Write: 80234 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.98 sec   HDFS Read: 87905 HDFS Write: 3434 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 45 seconds 650 msec
OK
Time taken: 95.709 seconds, Fetched: 479 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103032648_c8a7ee8e-5563-46c6-9e38-4639765855dd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162185, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162185/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162185
Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 7
2018-01-03 03:26:57,353 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:27:07,735 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 40.84 sec
2018-01-03 03:27:10,843 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 75.94 sec
2018-01-03 03:27:12,908 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 92.14 sec
2018-01-03 03:27:13,940 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 106.51 sec
2018-01-03 03:27:16,004 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 122.41 sec
2018-01-03 03:27:17,035 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 132.92 sec
2018-01-03 03:27:19,096 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 140.18 sec
2018-01-03 03:27:20,130 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 151.79 sec
2018-01-03 03:27:21,162 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 157.05 sec
2018-01-03 03:27:22,193 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 178.09 sec
2018-01-03 03:27:23,228 Stage-1 map = 69%,  reduce = 7%, Cumulative CPU 184.95 sec
2018-01-03 03:27:24,257 Stage-1 map = 69%,  reduce = 12%, Cumulative CPU 186.99 sec
2018-01-03 03:27:25,287 Stage-1 map = 78%,  reduce = 12%, Cumulative CPU 195.35 sec
2018-01-03 03:27:26,318 Stage-1 map = 85%,  reduce = 14%, Cumulative CPU 203.03 sec
2018-01-03 03:27:27,347 Stage-1 map = 90%,  reduce = 16%, Cumulative CPU 205.57 sec
2018-01-03 03:27:28,378 Stage-1 map = 92%,  reduce = 20%, Cumulative CPU 209.74 sec
2018-01-03 03:27:29,411 Stage-1 map = 92%,  reduce = 23%, Cumulative CPU 210.07 sec
2018-01-03 03:27:30,440 Stage-1 map = 92%,  reduce = 24%, Cumulative CPU 210.3 sec
2018-01-03 03:27:31,468 Stage-1 map = 95%,  reduce = 25%, Cumulative CPU 213.87 sec
2018-01-03 03:27:33,525 Stage-1 map = 100%,  reduce = 35%, Cumulative CPU 218.68 sec
2018-01-03 03:27:34,553 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 245.68 sec
MapReduce Total cumulative CPU time: 4 minutes 5 seconds 680 msec
Ended Job = job_1513599404024_162185
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162199, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162199/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162199
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:27:46,570 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:27:52,769 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.97 sec
2018-01-03 03:27:53,800 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.3 sec
2018-01-03 03:27:58,951 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.51 sec
MapReduce Total cumulative CPU time: 16 seconds 510 msec
Ended Job = job_1513599404024_162199
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162210, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162210/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162210
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:28:04,636 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:28:09,791 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.69 sec
2018-01-03 03:28:14,939 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.7 sec
MapReduce Total cumulative CPU time: 4 seconds 700 msec
Ended Job = job_1513599404024_162210
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 8  Reduce: 7   Cumulative CPU: 245.68 sec   HDFS Read: 659599145 HDFS Write: 360765 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.51 sec   HDFS Read: 44598821 HDFS Write: 25098 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.7 sec   HDFS Read: 32774 HDFS Write: 2756 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 26 seconds 890 msec
OK
Time taken: 87.838 seconds, Fetched: 397 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103032822_31ef0d66-651a-4713-8b8f-8bf04cc0ffe6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162219, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162219/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162219
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 03:28:33,272 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:28:43,628 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.72 sec
2018-01-03 03:28:46,726 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 14.27 sec
2018-01-03 03:28:49,819 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 15.02 sec
2018-01-03 03:28:52,909 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 16.01 sec
2018-01-03 03:28:56,004 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 16.52 sec
2018-01-03 03:28:59,094 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 17.41 sec
2018-01-03 03:29:02,182 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 19.63 sec
2018-01-03 03:29:04,249 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 20.15 sec
2018-01-03 03:29:07,339 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 20.89 sec
2018-01-03 03:29:10,426 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 22.25 sec
2018-01-03 03:29:13,517 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 23.09 sec
2018-01-03 03:29:16,602 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 23.56 sec
2018-01-03 03:29:19,688 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 24.04 sec
2018-01-03 03:29:22,778 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 25.35 sec
2018-01-03 03:29:25,862 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 25.9 sec
2018-01-03 03:29:28,945 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 26.51 sec
2018-01-03 03:29:32,030 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 26.96 sec
2018-01-03 03:29:35,111 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 29.09 sec
2018-01-03 03:29:37,166 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 30.65 sec
2018-01-03 03:29:42,311 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 34.95 sec
MapReduce Total cumulative CPU time: 34 seconds 950 msec
Ended Job = job_1513599404024_162219
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162244, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162244/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162244
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:30:00,471 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:30:17,969 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 11.33 sec
2018-01-03 03:30:33,387 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 15.47 sec
2018-01-03 03:30:34,417 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.64 sec
MapReduce Total cumulative CPU time: 19 seconds 640 msec
Ended Job = job_1513599404024_162244
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162257, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162257/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162257
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:31:03,180 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:31:08,349 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec
2018-01-03 03:31:13,513 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.15 sec
MapReduce Total cumulative CPU time: 2 seconds 150 msec
Ended Job = job_1513599404024_162257
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 34.95 sec   HDFS Read: 100317629 HDFS Write: 753645 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 22.56 sec   HDFS Read: 44990073 HDFS Write: 223398 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.13 sec   HDFS Read: 231035 HDFS Write: 7318 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 4 seconds 640 msec
OK
Time taken: 172.921 seconds, Fetched: 915 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103033122_47e93461-1d7e-48b9-b4a4-5042184d67cc
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162269, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162269/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162269
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 03:31:32,426 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:31:42,836 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 8.93 sec
2018-01-03 03:31:45,942 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.14 sec
2018-01-03 03:31:49,041 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 12.83 sec
2018-01-03 03:31:52,138 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 14.71 sec
2018-01-03 03:31:55,237 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 15.29 sec
2018-01-03 03:31:58,330 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 16.21 sec
2018-01-03 03:32:01,421 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 16.99 sec
2018-01-03 03:32:04,519 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 17.77 sec
2018-01-03 03:32:07,610 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 19.0 sec
2018-01-03 03:32:10,702 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 20.1 sec
2018-01-03 03:32:13,795 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 21.48 sec
2018-01-03 03:32:16,884 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 22.53 sec
2018-01-03 03:32:19,975 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 25.46 sec
2018-01-03 03:32:21,005 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 27.23 sec
2018-01-03 03:32:27,186 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 31.32 sec
MapReduce Total cumulative CPU time: 31 seconds 320 msec
Ended Job = job_1513599404024_162269
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162291, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162291/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162291
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:32:34,138 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:32:41,353 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.67 sec
2018-01-03 03:32:46,492 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.04 sec
MapReduce Total cumulative CPU time: 17 seconds 40 msec
Ended Job = job_1513599404024_162291
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162296, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162296/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162296
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:33:02,203 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:33:07,367 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.13 sec
2018-01-03 03:33:15,603 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.03 sec
MapReduce Total cumulative CPU time: 6 seconds 30 msec
Ended Job = job_1513599404024_162296
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 31.32 sec   HDFS Read: 100317619 HDFS Write: 1007779 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.04 sec   HDFS Read: 45244207 HDFS Write: 119463 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.03 sec   HDFS Read: 127101 HDFS Write: 3474 SUCCESS
Total MapReduce CPU Time Spent: 54 seconds 390 msec
OK
Time taken: 114.364 seconds, Fetched: 538 row(s)
开始执行20170913日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103033331_0756925f-dc64-492e-9359-3d9e5487d135
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162306, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162306/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162306
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 03:33:41,591 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:33:51,009 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 23.77 sec
2018-01-03 03:33:54,113 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 31.62 sec
2018-01-03 03:33:57,218 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 34.84 sec
2018-01-03 03:34:00,316 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 38.43 sec
2018-01-03 03:34:03,413 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 41.84 sec
2018-01-03 03:34:04,458 Stage-1 map = 72%,  reduce = 8%, Cumulative CPU 42.28 sec
2018-01-03 03:34:06,524 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 46.6 sec
2018-01-03 03:34:09,625 Stage-1 map = 80%,  reduce = 8%, Cumulative CPU 49.97 sec
2018-01-03 03:34:10,658 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 50.46 sec
2018-01-03 03:34:11,689 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 53.08 sec
2018-01-03 03:34:12,721 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 61.34 sec
MapReduce Total cumulative CPU time: 1 minutes 1 seconds 340 msec
Ended Job = job_1513599404024_162306
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162319, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162319/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162319
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:34:34,446 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:34:40,711 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.45 sec
2018-01-03 03:34:48,964 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 15.48 sec
2018-01-03 03:34:53,081 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 22.34 sec
MapReduce Total cumulative CPU time: 22 seconds 340 msec
Ended Job = job_1513599404024_162319
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162326, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162326/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162326
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:34:59,733 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:35:03,896 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.66 sec
2018-01-03 03:35:15,251 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.13 sec
MapReduce Total cumulative CPU time: 6 seconds 130 msec
Ended Job = job_1513599404024_162326
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 61.34 sec   HDFS Read: 226358506 HDFS Write: 1504405 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 22.34 sec   HDFS Read: 44277329 HDFS Write: 74715 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.13 sec   HDFS Read: 82390 HDFS Write: 3484 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 29 seconds 810 msec
OK
Time taken: 104.72 seconds, Fetched: 492 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.391 seconds
Query ID = boss_20180103033523_3973077e-b43d-447a-957f-4a6f0d0564e9
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162334, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162334/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162334
Hadoop job information for Stage-1: number of mappers: 6; number of reducers: 6
2018-01-03 03:35:33,893 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:35:44,337 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 52.65 sec
2018-01-03 03:35:45,371 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 71.8 sec
2018-01-03 03:35:47,440 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 86.17 sec
2018-01-03 03:35:48,476 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 92.42 sec
2018-01-03 03:35:50,541 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 107.03 sec
2018-01-03 03:35:51,572 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 114.03 sec
2018-01-03 03:35:52,602 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 119.7 sec
2018-01-03 03:35:53,633 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 122.98 sec
2018-01-03 03:35:54,663 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 129.72 sec
2018-01-03 03:35:55,694 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 132.19 sec
2018-01-03 03:35:56,728 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 135.26 sec
2018-01-03 03:35:57,758 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 138.3 sec
2018-01-03 03:35:59,821 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 141.26 sec
2018-01-03 03:36:00,856 Stage-1 map = 83%,  reduce = 4%, Cumulative CPU 144.97 sec
2018-01-03 03:36:01,887 Stage-1 map = 83%,  reduce = 19%, Cumulative CPU 147.62 sec
2018-01-03 03:36:02,918 Stage-1 map = 85%,  reduce = 19%, Cumulative CPU 153.69 sec
2018-01-03 03:36:03,952 Stage-1 map = 92%,  reduce = 19%, Cumulative CPU 154.69 sec
2018-01-03 03:36:04,982 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 157.42 sec
2018-01-03 03:36:06,015 Stage-1 map = 100%,  reduce = 59%, Cumulative CPU 164.63 sec
2018-01-03 03:36:07,045 Stage-1 map = 100%,  reduce = 88%, Cumulative CPU 176.12 sec
2018-01-03 03:36:08,076 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 179.66 sec
MapReduce Total cumulative CPU time: 2 minutes 59 seconds 660 msec
Ended Job = job_1513599404024_162334
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162344, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162344/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162344
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:36:17,271 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:36:22,440 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.24 sec
2018-01-03 03:36:35,851 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.03 sec
2018-01-03 03:36:37,914 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.03 sec
MapReduce Total cumulative CPU time: 15 seconds 30 msec
Ended Job = job_1513599404024_162344
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162350, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162350/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162350
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:36:51,599 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:36:56,752 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.86 sec
2018-01-03 03:37:03,966 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.06 sec
MapReduce Total cumulative CPU time: 6 seconds 60 msec
Ended Job = job_1513599404024_162350
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 6  Reduce: 6   Cumulative CPU: 179.66 sec   HDFS Read: 624934220 HDFS Write: 321032 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.03 sec   HDFS Read: 43095004 HDFS Write: 22537 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.06 sec   HDFS Read: 30213 HDFS Write: 2638 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 20 seconds 750 msec
OK
Time taken: 101.956 seconds, Fetched: 384 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.349 seconds
Query ID = boss_20180103033711_bbc9a18f-91bc-4598-b69a-2fbcbe95b6d4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162361, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162361/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162361
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 03:37:22,756 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:37:33,118 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 11.13 sec
2018-01-03 03:37:36,218 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.52 sec
2018-01-03 03:37:39,312 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 14.35 sec
2018-01-03 03:37:42,401 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 16.38 sec
2018-01-03 03:37:45,494 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 17.5 sec
2018-01-03 03:37:48,583 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 18.43 sec
2018-01-03 03:37:51,671 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 19.33 sec
2018-01-03 03:37:54,763 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 21.69 sec
2018-01-03 03:37:57,848 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 22.56 sec
2018-01-03 03:38:00,933 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 23.79 sec
2018-01-03 03:38:04,022 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 25.04 sec
2018-01-03 03:38:07,105 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 25.74 sec
2018-01-03 03:38:10,192 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 26.55 sec
2018-01-03 03:38:13,277 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 27.43 sec
2018-01-03 03:38:16,360 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 28.53 sec
2018-01-03 03:38:18,413 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 29.42 sec
2018-01-03 03:38:21,498 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 30.49 sec
2018-01-03 03:38:24,579 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 31.19 sec
2018-01-03 03:38:27,660 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 33.89 sec
2018-01-03 03:38:29,718 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 35.44 sec
2018-01-03 03:38:35,883 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.87 sec
MapReduce Total cumulative CPU time: 39 seconds 870 msec
Ended Job = job_1513599404024_162361
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162380, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162380/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162380
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:38:49,553 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:38:54,705 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.99 sec
2018-01-03 03:38:56,762 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.71 sec
2018-01-03 03:39:00,871 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.83 sec
MapReduce Total cumulative CPU time: 15 seconds 830 msec
Ended Job = job_1513599404024_162380
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162383, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162383/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162383
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:39:07,511 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:39:12,671 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.84 sec
2018-01-03 03:39:18,839 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.62 sec
MapReduce Total cumulative CPU time: 5 seconds 620 msec
Ended Job = job_1513599404024_162383
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 39.87 sec   HDFS Read: 112468084 HDFS Write: 651534 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.83 sec   HDFS Read: 43424140 HDFS Write: 190593 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.62 sec   HDFS Read: 198230 HDFS Write: 7084 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 320 msec
OK
Time taken: 128.183 seconds, Fetched: 897 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.368 seconds
Query ID = boss_20180103033926_17702a8d-41fd-4fcd-a599-1264aae2ed06
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162389, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162389/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162389
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 03:39:38,176 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:39:54,711 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 13.52 sec
2018-01-03 03:39:57,804 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 15.74 sec
2018-01-03 03:40:00,906 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 17.26 sec
2018-01-03 03:40:02,967 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 18.97 sec
2018-01-03 03:40:06,056 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 20.46 sec
2018-01-03 03:40:09,150 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 22.18 sec
2018-01-03 03:40:12,237 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 23.65 sec
2018-01-03 03:40:15,322 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 25.66 sec
2018-01-03 03:40:18,411 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 27.0 sec
2018-01-03 03:40:21,496 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 28.46 sec
2018-01-03 03:40:24,590 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 31.96 sec
2018-01-03 03:40:26,649 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 33.85 sec
2018-01-03 03:40:32,820 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.8 sec
MapReduce Total cumulative CPU time: 39 seconds 800 msec
Ended Job = job_1513599404024_162389
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162404, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162404/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162404
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:40:47,615 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:40:52,784 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.65 sec
2018-01-03 03:41:03,090 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.67 sec
2018-01-03 03:41:07,209 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.04 sec
MapReduce Total cumulative CPU time: 17 seconds 40 msec
Ended Job = job_1513599404024_162404
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162406, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162406/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162406
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:41:13,997 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:41:19,213 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.78 sec
2018-01-03 03:41:32,576 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.98 sec
MapReduce Total cumulative CPU time: 6 seconds 980 msec
Ended Job = job_1513599404024_162406
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 39.8 sec   HDFS Read: 112468074 HDFS Write: 914775 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.04 sec   HDFS Read: 43687381 HDFS Write: 111424 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.98 sec   HDFS Read: 119062 HDFS Write: 3334 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 3 seconds 820 msec
OK
Time taken: 126.764 seconds, Fetched: 514 row(s)
开始执行20170914日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.389 seconds
Query ID = boss_20180103034140_5bdb1757-9d67-4b39-896c-e05b4560f30e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162412, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162412/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162412
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 03:41:50,244 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:41:59,565 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.52 sec
2018-01-03 03:42:00,597 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 23.22 sec
2018-01-03 03:42:02,663 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 26.79 sec
2018-01-03 03:42:03,698 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 30.44 sec
2018-01-03 03:42:05,760 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 33.85 sec
2018-01-03 03:42:06,791 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 37.1 sec
2018-01-03 03:42:08,853 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 40.67 sec
2018-01-03 03:42:09,883 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 44.79 sec
2018-01-03 03:42:11,944 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 48.7 sec
2018-01-03 03:42:15,038 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 53.11 sec
2018-01-03 03:42:18,124 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 56.33 sec
2018-01-03 03:42:20,186 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 57.34 sec
2018-01-03 03:42:21,219 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 61.16 sec
2018-01-03 03:42:22,250 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 69.71 sec
MapReduce Total cumulative CPU time: 1 minutes 9 seconds 710 msec
Ended Job = job_1513599404024_162412
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162417, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162417/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162417
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:42:28,936 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:42:35,116 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.47 sec
2018-01-03 03:42:42,323 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.01 sec
2018-01-03 03:42:43,351 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.75 sec
MapReduce Total cumulative CPU time: 16 seconds 750 msec
Ended Job = job_1513599404024_162417
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162421, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162421/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162421
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:42:48,977 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:42:53,147 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.58 sec
2018-01-03 03:42:58,292 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.99 sec
MapReduce Total cumulative CPU time: 4 seconds 990 msec
Ended Job = job_1513599404024_162421
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 69.94 sec   HDFS Read: 224677005 HDFS Write: 1596477 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.75 sec   HDFS Read: 42935138 HDFS Write: 75167 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.99 sec   HDFS Read: 82842 HDFS Write: 3606 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 31 seconds 680 msec
OK
Time taken: 78.503 seconds, Fetched: 506 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.386 seconds
Query ID = boss_20180103034306_7dd97ab1-0373-46ee-8905-a7fcac5f1be4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162423, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162423/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162423
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 7
2018-01-03 03:43:15,232 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:43:24,549 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 12.04 sec
2018-01-03 03:43:27,657 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 43.22 sec
2018-01-03 03:43:29,721 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 58.1 sec
2018-01-03 03:43:30,753 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 65.77 sec
2018-01-03 03:43:32,812 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 83.78 sec
2018-01-03 03:43:33,842 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 104.45 sec
2018-01-03 03:43:34,877 Stage-1 map = 37%,  reduce = 1%, Cumulative CPU 104.93 sec
2018-01-03 03:43:35,907 Stage-1 map = 43%,  reduce = 3%, Cumulative CPU 120.18 sec
2018-01-03 03:43:36,940 Stage-1 map = 53%,  reduce = 3%, Cumulative CPU 127.89 sec
2018-01-03 03:43:37,970 Stage-1 map = 59%,  reduce = 3%, Cumulative CPU 130.29 sec
2018-01-03 03:43:39,000 Stage-1 map = 62%,  reduce = 5%, Cumulative CPU 137.09 sec
2018-01-03 03:43:40,030 Stage-1 map = 72%,  reduce = 5%, Cumulative CPU 144.37 sec
2018-01-03 03:43:41,060 Stage-1 map = 72%,  reduce = 8%, Cumulative CPU 144.5 sec
2018-01-03 03:43:42,089 Stage-1 map = 75%,  reduce = 11%, Cumulative CPU 151.25 sec
2018-01-03 03:43:43,119 Stage-1 map = 77%,  reduce = 19%, Cumulative CPU 156.42 sec
2018-01-03 03:43:45,176 Stage-1 map = 80%,  reduce = 19%, Cumulative CPU 163.1 sec
2018-01-03 03:43:46,209 Stage-1 map = 82%,  reduce = 19%, Cumulative CPU 165.82 sec
2018-01-03 03:43:47,238 Stage-1 map = 93%,  reduce = 21%, Cumulative CPU 171.37 sec
2018-01-03 03:43:48,267 Stage-1 map = 94%,  reduce = 21%, Cumulative CPU 172.29 sec
2018-01-03 03:43:49,295 Stage-1 map = 94%,  reduce = 25%, Cumulative CPU 172.55 sec
2018-01-03 03:43:50,323 Stage-1 map = 94%,  reduce = 29%, Cumulative CPU 172.75 sec
2018-01-03 03:43:51,351 Stage-1 map = 100%,  reduce = 29%, Cumulative CPU 176.8 sec
2018-01-03 03:43:52,379 Stage-1 map = 100%,  reduce = 87%, Cumulative CPU 195.21 sec
2018-01-03 03:43:53,407 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 200.24 sec
MapReduce Total cumulative CPU time: 3 minutes 20 seconds 240 msec
Ended Job = job_1513599404024_162423
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162427, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162427/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162427
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:44:13,339 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:44:20,554 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.73 sec
2018-01-03 03:44:31,888 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.28 sec
2018-01-03 03:44:34,973 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 9.85 sec
2018-01-03 03:44:36,005 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.88 sec
MapReduce Total cumulative CPU time: 13 seconds 880 msec
Ended Job = job_1513599404024_162427
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162431, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162431/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162431
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:44:41,655 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:44:46,827 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.67 sec
2018-01-03 03:44:54,047 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.08 sec
MapReduce Total cumulative CPU time: 5 seconds 80 msec
Ended Job = job_1513599404024_162431
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 7   Cumulative CPU: 200.24 sec   HDFS Read: 647929655 HDFS Write: 346436 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.88 sec   HDFS Read: 41686407 HDFS Write: 20452 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.08 sec   HDFS Read: 28128 HDFS Write: 2639 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 39 seconds 200 msec
OK
Time taken: 109.037 seconds, Fetched: 367 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.413 seconds
Query ID = boss_20180103034501_828e2883-58bc-42ab-8c9b-24f8a799a4a1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162436, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162436/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162436
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 2
2018-01-03 03:45:13,899 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:45:24,258 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 10.34 sec
2018-01-03 03:45:27,357 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 13.09 sec
2018-01-03 03:45:30,452 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 14.81 sec
2018-01-03 03:45:33,543 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.85 sec
2018-01-03 03:45:36,636 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 16.63 sec
2018-01-03 03:45:39,726 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 17.69 sec
2018-01-03 03:45:42,813 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 18.27 sec
2018-01-03 03:45:44,875 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 19.03 sec
2018-01-03 03:45:47,962 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 19.72 sec
2018-01-03 03:45:51,049 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 20.64 sec
2018-01-03 03:45:54,139 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 21.31 sec
2018-01-03 03:45:57,224 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 22.26 sec
2018-01-03 03:46:00,310 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 24.05 sec
2018-01-03 03:46:03,397 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 25.11 sec
2018-01-03 03:46:06,480 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 25.83 sec
2018-01-03 03:46:09,563 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 26.2 sec
2018-01-03 03:46:12,649 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 26.8 sec
2018-01-03 03:46:15,734 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 28.33 sec
2018-01-03 03:46:17,795 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 29.49 sec
2018-01-03 03:46:23,966 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 37.72 sec
MapReduce Total cumulative CPU time: 37 seconds 720 msec
Ended Job = job_1513599404024_162436
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162444, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162444/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162444
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:46:29,719 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:46:34,868 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.44 sec
2018-01-03 03:46:35,897 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.94 sec
2018-01-03 03:46:41,051 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.73 sec
MapReduce Total cumulative CPU time: 16 seconds 730 msec
Ended Job = job_1513599404024_162444
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162445, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162445/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162445
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:46:53,694 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:46:59,883 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.83 sec
2018-01-03 03:47:06,057 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.75 sec
MapReduce Total cumulative CPU time: 6 seconds 750 msec
Ended Job = job_1513599404024_162445
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 2   Cumulative CPU: 37.72 sec   HDFS Read: 118963773 HDFS Write: 703388 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.73 sec   HDFS Read: 42041993 HDFS Write: 191635 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.75 sec   HDFS Read: 199272 HDFS Write: 7179 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 200 msec
OK
Time taken: 126.315 seconds, Fetched: 915 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103034714_3a510099-a9d4-4994-843f-e98a4f3a5bde
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162447, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162447/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162447
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 2
2018-01-03 03:47:26,174 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:47:44,756 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.49 sec
2018-01-03 03:47:47,852 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 15.34 sec
2018-01-03 03:47:50,944 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 17.31 sec
2018-01-03 03:47:54,038 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 18.98 sec
2018-01-03 03:47:57,129 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 21.08 sec
2018-01-03 03:48:00,217 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 22.83 sec
2018-01-03 03:48:03,304 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 24.75 sec
2018-01-03 03:48:06,399 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 26.12 sec
2018-01-03 03:48:09,484 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 28.03 sec
2018-01-03 03:48:11,541 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 29.58 sec
2018-01-03 03:48:14,629 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 31.22 sec
2018-01-03 03:48:17,713 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 33.52 sec
2018-01-03 03:48:20,798 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 36.27 sec
2018-01-03 03:48:25,940 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 44.94 sec
MapReduce Total cumulative CPU time: 44 seconds 940 msec
Ended Job = job_1513599404024_162447
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162455, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162455/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162455
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:48:33,702 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:48:37,886 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.27 sec
2018-01-03 03:48:38,919 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.56 sec
2018-01-03 03:48:46,138 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.98 sec
MapReduce Total cumulative CPU time: 13 seconds 980 msec
Ended Job = job_1513599404024_162455
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162457, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162457/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162457
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:49:01,813 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:49:06,981 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.25 sec
2018-01-03 03:49:13,154 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.68 sec
MapReduce Total cumulative CPU time: 5 seconds 680 msec
Ended Job = job_1513599404024_162457
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 2   Cumulative CPU: 44.94 sec   HDFS Read: 118963756 HDFS Write: 1072015 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.98 sec   HDFS Read: 42410615 HDFS Write: 114034 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.68 sec   HDFS Read: 121668 HDFS Write: 3885 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 4 seconds 600 msec
OK
Time taken: 119.338 seconds, Fetched: 581 row(s)
开始执行20170915日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.371 seconds
Query ID = boss_20180103034921_673a792d-1a7f-4687-ab55-5e7c723f2468
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162461, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162461/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162461
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 03:49:31,588 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:49:41,947 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 14.02 sec
2018-01-03 03:49:45,048 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 17.77 sec
2018-01-03 03:49:47,113 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 29.41 sec
2018-01-03 03:49:48,145 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 32.84 sec
2018-01-03 03:49:50,207 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 36.64 sec
2018-01-03 03:49:51,238 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 40.24 sec
2018-01-03 03:49:53,299 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 45.03 sec
2018-01-03 03:49:54,344 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 57.84 sec
2018-01-03 03:49:57,435 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 61.58 sec
2018-01-03 03:50:00,525 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 65.77 sec
2018-01-03 03:50:02,585 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 69.1 sec
2018-01-03 03:50:05,685 Stage-1 map = 78%,  reduce = 8%, Cumulative CPU 72.85 sec
2018-01-03 03:50:06,717 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 73.46 sec
2018-01-03 03:50:08,777 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 77.35 sec
2018-01-03 03:50:11,867 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 83.86 sec
2018-01-03 03:50:12,898 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 88.13 sec
2018-01-03 03:50:14,957 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 93.8 sec
MapReduce Total cumulative CPU time: 1 minutes 33 seconds 800 msec
Ended Job = job_1513599404024_162461
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162468, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162468/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162468
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:50:30,693 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:50:42,033 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.64 sec
2018-01-03 03:50:46,152 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.38 sec
2018-01-03 03:50:48,212 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.27 sec
MapReduce Total cumulative CPU time: 20 seconds 270 msec
Ended Job = job_1513599404024_162468
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162469, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162469/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162469
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:51:03,884 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:51:16,247 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.7 sec
2018-01-03 03:51:21,389 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.8 sec
MapReduce Total cumulative CPU time: 5 seconds 800 msec
Ended Job = job_1513599404024_162469
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 93.8 sec   HDFS Read: 231758507 HDFS Write: 1645325 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.27 sec   HDFS Read: 44952181 HDFS Write: 63876 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.8 sec   HDFS Read: 71551 HDFS Write: 3245 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 59 seconds 870 msec
OK
Time taken: 122.263 seconds, Fetched: 454 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103035130_c947c281-03e9-4227-9af9-1f421fbeae86
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162474, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162474/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162474
Hadoop job information for Stage-1: number of mappers: 9; number of reducers: 7
2018-01-03 03:51:45,610 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:51:54,956 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 47.62 sec
2018-01-03 03:51:55,992 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 70.18 sec
2018-01-03 03:51:57,027 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 95.33 sec
2018-01-03 03:51:58,062 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 113.14 sec
2018-01-03 03:51:59,098 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 123.15 sec
2018-01-03 03:52:00,130 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 129.44 sec
2018-01-03 03:52:01,165 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 143.9 sec
2018-01-03 03:52:02,198 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 156.57 sec
2018-01-03 03:52:05,295 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 170.57 sec
2018-01-03 03:52:06,328 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 172.44 sec
2018-01-03 03:52:08,401 Stage-1 map = 88%,  reduce = 10%, Cumulative CPU 183.94 sec
2018-01-03 03:52:09,433 Stage-1 map = 88%,  reduce = 16%, Cumulative CPU 185.56 sec
2018-01-03 03:52:10,469 Stage-1 map = 89%,  reduce = 16%, Cumulative CPU 188.54 sec
2018-01-03 03:52:11,502 Stage-1 map = 94%,  reduce = 21%, Cumulative CPU 193.73 sec
2018-01-03 03:52:12,533 Stage-1 map = 94%,  reduce = 22%, Cumulative CPU 193.93 sec
2018-01-03 03:52:14,600 Stage-1 map = 95%,  reduce = 25%, Cumulative CPU 197.32 sec
2018-01-03 03:52:15,638 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 199.27 sec
2018-01-03 03:52:16,669 Stage-1 map = 100%,  reduce = 70%, Cumulative CPU 216.23 sec
2018-01-03 03:52:17,703 Stage-1 map = 100%,  reduce = 90%, Cumulative CPU 222.44 sec
2018-01-03 03:52:19,761 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 229.07 sec
MapReduce Total cumulative CPU time: 3 minutes 49 seconds 70 msec
Ended Job = job_1513599404024_162474
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162481, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162481/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162481
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:52:26,453 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:52:31,606 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.47 sec
2018-01-03 03:52:33,667 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.28 sec
2018-01-03 03:52:37,786 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.54 sec
MapReduce Total cumulative CPU time: 14 seconds 540 msec
Ended Job = job_1513599404024_162481
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162485, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162485/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162485
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:52:43,541 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:52:49,730 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec
2018-01-03 03:52:55,916 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.7 sec
MapReduce Total cumulative CPU time: 5 seconds 700 msec
Ended Job = job_1513599404024_162485
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 9  Reduce: 7   Cumulative CPU: 229.3 sec   HDFS Read: 707691354 HDFS Write: 347145 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.54 sec   HDFS Read: 43655311 HDFS Write: 21952 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.7 sec   HDFS Read: 29628 HDFS Write: 2630 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 9 seconds 540 msec
OK
Time taken: 86.783 seconds, Fetched: 375 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103035303_b26e0867-0831-4853-8cf1-80a904c38485
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162486, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162486/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162486
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 2
2018-01-03 03:53:34,836 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:53:45,190 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.37 sec
2018-01-03 03:53:48,289 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 12.19 sec
2018-01-03 03:53:51,382 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.95 sec
2018-01-03 03:53:54,472 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 13.73 sec
2018-01-03 03:53:56,534 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 14.57 sec
2018-01-03 03:53:59,623 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 15.04 sec
2018-01-03 03:54:02,709 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 15.56 sec
2018-01-03 03:54:05,803 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 16.38 sec
2018-01-03 03:54:08,895 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 17.06 sec
2018-01-03 03:54:11,981 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 17.8 sec
2018-01-03 03:54:15,070 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 18.49 sec
2018-01-03 03:54:18,155 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 19.1 sec
2018-01-03 03:54:21,242 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 19.59 sec
2018-01-03 03:54:24,328 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 20.26 sec
2018-01-03 03:54:27,412 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 20.58 sec
2018-01-03 03:54:30,499 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 22.2 sec
2018-01-03 03:54:33,583 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 22.74 sec
2018-01-03 03:54:34,611 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 23.72 sec
2018-01-03 03:54:39,751 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 27.51 sec
2018-01-03 03:54:40,782 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.59 sec
MapReduce Total cumulative CPU time: 32 seconds 590 msec
Ended Job = job_1513599404024_162486
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162498, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162498/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162498
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:54:46,453 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:54:52,635 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.19 sec
2018-01-03 03:54:59,836 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.28 sec
2018-01-03 03:55:00,868 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.42 sec
MapReduce Total cumulative CPU time: 14 seconds 420 msec
Ended Job = job_1513599404024_162498
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162505, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162505/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162505
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:55:06,468 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:55:12,644 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec
2018-01-03 03:55:17,783 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.9 sec
MapReduce Total cumulative CPU time: 5 seconds 900 msec
Ended Job = job_1513599404024_162505
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 2   Cumulative CPU: 32.59 sec   HDFS Read: 121636782 HDFS Write: 679324 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.42 sec   HDFS Read: 43986124 HDFS Write: 208512 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.9 sec   HDFS Read: 216149 HDFS Write: 7345 SUCCESS
Total MapReduce CPU Time Spent: 52 seconds 910 msec
OK
Time taken: 135.177 seconds, Fetched: 919 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103035525_044b4c3a-3cca-4f09-995e-88631edf479a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162508, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162508/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162508
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 2
2018-01-03 03:55:35,626 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:55:46,002 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 10.28 sec
2018-01-03 03:55:49,109 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 12.06 sec
2018-01-03 03:55:52,208 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 14.27 sec
2018-01-03 03:55:55,304 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 16.32 sec
2018-01-03 03:55:58,401 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 17.68 sec
2018-01-03 03:56:01,494 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 19.06 sec
2018-01-03 03:56:04,586 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 20.26 sec
2018-01-03 03:56:07,681 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 21.82 sec
2018-01-03 03:56:10,770 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 24.09 sec
2018-01-03 03:56:13,859 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 27.03 sec
2018-01-03 03:56:14,893 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 28.35 sec
2018-01-03 03:56:20,048 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 32.94 sec
2018-01-03 03:56:36,531 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 38.34 sec
MapReduce Total cumulative CPU time: 38 seconds 340 msec
Ended Job = job_1513599404024_162508
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162525, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162525/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162525
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:56:51,239 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:56:56,452 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.48 sec
2018-01-03 03:57:03,724 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.52 sec
2018-01-03 03:57:08,869 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.3 sec
MapReduce Total cumulative CPU time: 16 seconds 300 msec
Ended Job = job_1513599404024_162525
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162531, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162531/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162531
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:57:16,554 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:57:22,738 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec
2018-01-03 03:57:28,928 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.28 sec
MapReduce Total cumulative CPU time: 6 seconds 280 msec
Ended Job = job_1513599404024_162531
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 2   Cumulative CPU: 38.34 sec   HDFS Read: 121636767 HDFS Write: 1233915 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.3 sec   HDFS Read: 44540715 HDFS Write: 148012 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.28 sec   HDFS Read: 155650 HDFS Write: 3708 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 0 seconds 920 msec
OK
Time taken: 125.463 seconds, Fetched: 558 row(s)
开始执行20170916日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103035737_4e6c8bb3-133e-4b10-9a26-5451525b70f6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162535, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162535/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162535
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 03:57:47,910 Stage-1 map = 0%,  reduce = 0%
2018-01-03 03:57:58,265 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.37 sec
2018-01-03 03:58:00,330 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 26.6 sec
2018-01-03 03:58:01,365 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 30.49 sec
2018-01-03 03:58:03,429 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 34.26 sec
2018-01-03 03:58:04,460 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 37.07 sec
2018-01-03 03:58:06,522 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 40.96 sec
2018-01-03 03:58:07,552 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 44.59 sec
2018-01-03 03:58:09,613 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 48.26 sec
2018-01-03 03:58:10,647 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 51.8 sec
2018-01-03 03:58:12,707 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 55.21 sec
2018-01-03 03:58:13,739 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 58.84 sec
2018-01-03 03:58:14,769 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 62.51 sec
2018-01-03 03:58:15,798 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 64.67 sec
2018-01-03 03:58:16,829 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 68.52 sec
2018-01-03 03:58:19,920 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 71.52 sec
2018-01-03 03:58:21,977 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 74.8 sec
2018-01-03 03:58:25,061 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 78.34 sec
2018-01-03 03:58:27,123 Stage-1 map = 80%,  reduce = 8%, Cumulative CPU 78.91 sec
2018-01-03 03:58:28,154 Stage-1 map = 83%,  reduce = 8%, Cumulative CPU 82.37 sec
2018-01-03 03:58:29,188 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 82.82 sec
2018-01-03 03:58:30,218 Stage-1 map = 100%,  reduce = 39%, Cumulative CPU 85.19 sec
2018-01-03 03:58:31,248 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 86.57 sec
2018-01-03 03:58:32,276 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 91.89 sec
MapReduce Total cumulative CPU time: 1 minutes 31 seconds 890 msec
Ended Job = job_1513599404024_162535
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162542, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162542/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162542
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 03:58:37,944 Stage-2 map = 0%,  reduce = 0%
2018-01-03 03:58:43,093 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.78 sec
2018-01-03 03:58:51,320 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.2 sec
2018-01-03 03:58:54,401 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.25 sec
MapReduce Total cumulative CPU time: 18 seconds 250 msec
Ended Job = job_1513599404024_162542
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162546, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162546/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162546
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 03:58:59,988 Stage-3 map = 0%,  reduce = 0%
2018-01-03 03:59:08,218 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.3 sec
2018-01-03 03:59:14,389 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.41 sec
MapReduce Total cumulative CPU time: 6 seconds 410 msec
Ended Job = job_1513599404024_162546
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 91.89 sec   HDFS Read: 278882784 HDFS Write: 2052994 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.25 sec   HDFS Read: 48909472 HDFS Write: 81775 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.41 sec   HDFS Read: 89450 HDFS Write: 3316 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 56 seconds 550 msec
OK
Time taken: 97.465 seconds, Fetched: 443 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.408 seconds
Query ID = boss_20180103035922_08e8f6e7-a6a1-48bf-968f-39db318dbc6b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162551, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162551/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162551
Hadoop job information for Stage-1: number of mappers: 12; number of reducers: 9
2018-01-03 04:00:13,531 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:00:27,674 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 25.21 sec
2018-01-03 04:00:28,762 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 39.09 sec
2018-01-03 04:00:29,839 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 62.95 sec
2018-01-03 04:00:30,922 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 130.39 sec
2018-01-03 04:00:33,089 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 153.33 sec
2018-01-03 04:00:34,191 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 189.49 sec
2018-01-03 04:00:37,945 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 203.17 sec
2018-01-03 04:00:38,998 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 239.02 sec
2018-01-03 04:00:40,072 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 246.97 sec
2018-01-03 04:00:41,135 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 248.85 sec
2018-01-03 04:00:42,200 Stage-1 map = 92%,  reduce = 0%, Cumulative CPU 251.78 sec
2018-01-03 04:00:44,317 Stage-1 map = 93%,  reduce = 0%, Cumulative CPU 264.95 sec
2018-01-03 04:00:46,463 Stage-1 map = 93%,  reduce = 14%, Cumulative CPU 267.29 sec
2018-01-03 04:00:47,521 Stage-1 map = 94%,  reduce = 31%, Cumulative CPU 274.8 sec
2018-01-03 04:00:50,749 Stage-1 map = 100%,  reduce = 31%, Cumulative CPU 280.1 sec
2018-01-03 04:00:52,852 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 309.26 sec
MapReduce Total cumulative CPU time: 5 minutes 9 seconds 260 msec
Ended Job = job_1513599404024_162551
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162581, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162581/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162581
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:01:00,752 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:01:07,985 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.17 sec
2018-01-03 04:01:14,177 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.45 sec
2018-01-03 04:01:17,279 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.89 sec
MapReduce Total cumulative CPU time: 16 seconds 890 msec
Ended Job = job_1513599404024_162581
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162590, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162590/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162590
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:01:23,090 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:01:28,262 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2018-01-03 04:01:34,446 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.82 sec
MapReduce Total cumulative CPU time: 4 seconds 820 msec
Ended Job = job_1513599404024_162590
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 12  Reduce: 9   Cumulative CPU: 309.26 sec   HDFS Read: 905853944 HDFS Write: 426948 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.89 sec   HDFS Read: 47285260 HDFS Write: 25099 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.82 sec   HDFS Read: 32775 HDFS Write: 2604 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 30 seconds 970 msec
OK
Time taken: 133.105 seconds, Fetched: 367 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103040150_6eca7925-d5a8-4d37-8392-d55d7b82e6d1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162599, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162599/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162599
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:02:06,271 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:02:16,638 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 12.49 sec
2018-01-03 04:02:17,693 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 24.23 sec
2018-01-03 04:02:19,772 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 28.15 sec
2018-01-03 04:02:22,911 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 30.02 sec
2018-01-03 04:02:26,097 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 31.17 sec
2018-01-03 04:02:28,172 Stage-1 map = 62%,  reduce = 17%, Cumulative CPU 32.3 sec
2018-01-03 04:02:29,204 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 33.33 sec
2018-01-03 04:02:32,295 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 34.23 sec
2018-01-03 04:02:35,384 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 35.8 sec
2018-01-03 04:02:37,447 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 37.5 sec
2018-01-03 04:02:40,536 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 38.97 sec
2018-01-03 04:02:43,623 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 40.22 sec
2018-01-03 04:02:46,720 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 41.8 sec
2018-01-03 04:02:49,805 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 43.38 sec
2018-01-03 04:02:52,889 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 44.41 sec
2018-01-03 04:02:54,949 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 48.69 sec
2018-01-03 04:02:55,977 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 56.57 sec
MapReduce Total cumulative CPU time: 56 seconds 570 msec
Ended Job = job_1513599404024_162599
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162622, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162622/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162622
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:03:02,766 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:03:07,930 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.02 sec
2018-01-03 04:03:16,167 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.29 sec
2018-01-03 04:03:17,197 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.61 sec
MapReduce Total cumulative CPU time: 14 seconds 610 msec
Ended Job = job_1513599404024_162622
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162631, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162631/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162631
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:03:31,979 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:03:42,328 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.0 sec
2018-01-03 04:03:54,690 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.75 sec
MapReduce Total cumulative CPU time: 6 seconds 750 msec
Ended Job = job_1513599404024_162631
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 56.57 sec   HDFS Read: 137397426 HDFS Write: 710790 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.61 sec   HDFS Read: 47567212 HDFS Write: 251305 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.75 sec   HDFS Read: 258942 HDFS Write: 7300 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 17 seconds 930 msec
OK
Time taken: 125.524 seconds, Fetched: 933 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.362 seconds
Query ID = boss_20180103040410_7c1e0eb3-fb4a-40f7-8451-a2fb7305b424
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162645, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162645/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162645
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:04:20,738 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:04:29,074 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 12.84 sec
2018-01-03 04:04:38,347 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 27.56 sec
2018-01-03 04:04:39,384 Stage-1 map = 56%,  reduce = 17%, Cumulative CPU 28.81 sec
2018-01-03 04:04:41,444 Stage-1 map = 60%,  reduce = 17%, Cumulative CPU 31.8 sec
2018-01-03 04:04:44,534 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 35.49 sec
2018-01-03 04:04:47,619 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 39.02 sec
2018-01-03 04:04:50,705 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 41.26 sec
2018-01-03 04:04:53,798 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 44.82 sec
2018-01-03 04:04:56,882 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 47.13 sec
2018-01-03 04:04:58,945 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 40.41 sec
2018-01-03 04:05:01,004 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 48.35 sec
MapReduce Total cumulative CPU time: 48 seconds 350 msec
Ended Job = job_1513599404024_162645
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162660, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162660/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162660
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:05:08,184 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:05:16,436 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.67 sec
2018-01-03 04:05:17,466 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.35 sec
2018-01-03 04:05:22,615 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.16 sec
MapReduce Total cumulative CPU time: 18 seconds 160 msec
Ended Job = job_1513599404024_162660
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162663, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162663/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162663
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:05:29,239 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:05:35,430 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.99 sec
2018-01-03 04:05:43,671 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.91 sec
MapReduce Total cumulative CPU time: 6 seconds 910 msec
Ended Job = job_1513599404024_162663
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 48.35 sec   HDFS Read: 137397406 HDFS Write: 1552826 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.16 sec   HDFS Read: 48409248 HDFS Write: 212393 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.91 sec   HDFS Read: 220031 HDFS Write: 4028 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 13 seconds 420 msec
OK
Time taken: 94.204 seconds, Fetched: 588 row(s)
开始执行20170917日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103040551_47868d2f-f4da-4f7c-8677-0f5acba0537d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162674, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162674/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162674
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:06:01,246 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:06:17,814 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 25.01 sec
2018-01-03 04:06:20,911 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 32.16 sec
2018-01-03 04:06:24,010 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 39.78 sec
2018-01-03 04:06:27,107 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 46.83 sec
2018-01-03 04:06:30,203 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 53.35 sec
2018-01-03 04:06:33,301 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 60.99 sec
2018-01-03 04:06:36,395 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 64.03 sec
2018-01-03 04:06:39,494 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 67.74 sec
2018-01-03 04:06:42,587 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 71.06 sec
2018-01-03 04:06:43,627 Stage-1 map = 75%,  reduce = 8%, Cumulative CPU 71.61 sec
2018-01-03 04:06:45,689 Stage-1 map = 78%,  reduce = 8%, Cumulative CPU 74.71 sec
2018-01-03 04:06:47,758 Stage-1 map = 80%,  reduce = 8%, Cumulative CPU 77.62 sec
2018-01-03 04:06:50,847 Stage-1 map = 82%,  reduce = 8%, Cumulative CPU 80.74 sec
2018-01-03 04:06:51,880 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 82.92 sec
2018-01-03 04:06:52,911 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 87.68 sec
2018-01-03 04:06:53,942 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 92.56 sec
MapReduce Total cumulative CPU time: 1 minutes 32 seconds 560 msec
Ended Job = job_1513599404024_162674
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162683, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162683/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162683
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:07:00,646 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:07:05,811 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.71 sec
2018-01-03 04:07:16,109 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.18 sec
2018-01-03 04:07:20,230 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 10.46 sec
2018-01-03 04:07:21,263 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.75 sec
MapReduce Total cumulative CPU time: 15 seconds 750 msec
Ended Job = job_1513599404024_162683
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162688, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162688/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162688
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:08:16,362 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:08:24,278 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-03 04:08:30,614 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.49 sec
MapReduce Total cumulative CPU time: 6 seconds 490 msec
Ended Job = job_1513599404024_162688
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 92.56 sec   HDFS Read: 276205163 HDFS Write: 2064072 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.75 sec   HDFS Read: 49685709 HDFS Write: 80523 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.49 sec   HDFS Read: 88198 HDFS Write: 3297 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 54 seconds 800 msec
OK
Time taken: 159.968 seconds, Fetched: 434 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.392 seconds
Query ID = boss_20180103040839_42772ad1-83b8-4366-9128-aa2a0ecc024c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162706, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162706/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162706
Hadoop job information for Stage-1: number of mappers: 10; number of reducers: 9
2018-01-03 04:08:49,666 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:09:00,124 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 66.09 sec
2018-01-03 04:09:01,160 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 115.78 sec
2018-01-03 04:09:03,235 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 135.8 sec
2018-01-03 04:09:04,272 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 153.73 sec
2018-01-03 04:09:05,306 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 156.57 sec
2018-01-03 04:09:06,339 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 177.99 sec
2018-01-03 04:09:07,371 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 182.29 sec
2018-01-03 04:09:08,403 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 188.16 sec
2018-01-03 04:09:09,434 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 191.52 sec
2018-01-03 04:09:10,466 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 196.17 sec
2018-01-03 04:09:11,498 Stage-1 map = 90%,  reduce = 0%, Cumulative CPU 198.76 sec
2018-01-03 04:09:15,631 Stage-1 map = 90%,  reduce = 23%, Cumulative CPU 203.72 sec
2018-01-03 04:09:16,663 Stage-1 map = 90%,  reduce = 27%, Cumulative CPU 204.37 sec
2018-01-03 04:09:21,825 Stage-1 map = 90%,  reduce = 30%, Cumulative CPU 206.41 sec
2018-01-03 04:09:38,304 Stage-1 map = 92%,  reduce = 30%, Cumulative CPU 221.69 sec
2018-01-03 04:09:41,395 Stage-1 map = 94%,  reduce = 30%, Cumulative CPU 226.22 sec
2018-01-03 04:09:44,482 Stage-1 map = 100%,  reduce = 30%, Cumulative CPU 232.42 sec
2018-01-03 04:09:45,511 Stage-1 map = 100%,  reduce = 46%, Cumulative CPU 239.11 sec
2018-01-03 04:09:46,541 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 261.51 sec
2018-01-03 04:09:47,569 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 265.3 sec
MapReduce Total cumulative CPU time: 4 minutes 25 seconds 300 msec
Ended Job = job_1513599404024_162706
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162713, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162713/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162713
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:10:05,541 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:10:10,732 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.2 sec
2018-01-03 04:10:16,925 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.12 sec
2018-01-03 04:10:23,109 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.57 sec
MapReduce Total cumulative CPU time: 14 seconds 570 msec
Ended Job = job_1513599404024_162713
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162723, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162723/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162723
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:10:29,760 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:10:34,915 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.76 sec
2018-01-03 04:10:49,316 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.73 sec
MapReduce Total cumulative CPU time: 5 seconds 730 msec
Ended Job = job_1513599404024_162723
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 10  Reduce: 9   Cumulative CPU: 265.3 sec   HDFS Read: 876837760 HDFS Write: 409056 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.57 sec   HDFS Read: 48032527 HDFS Write: 24288 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.73 sec   HDFS Read: 31964 HDFS Write: 2445 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 45 seconds 600 msec
OK
Time taken: 130.419 seconds, Fetched: 350 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103041057_77df0934-f218-4ba4-af6c-22c941074786
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162731, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162731/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162731
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:11:09,825 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:11:18,162 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 8.95 sec
2018-01-03 04:11:20,228 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 19.98 sec
2018-01-03 04:11:23,326 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 22.16 sec
2018-01-03 04:11:26,420 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 24.09 sec
2018-01-03 04:11:29,510 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 25.73 sec
2018-01-03 04:11:30,551 Stage-1 map = 59%,  reduce = 8%, Cumulative CPU 26.26 sec
2018-01-03 04:11:32,615 Stage-1 map = 62%,  reduce = 8%, Cumulative CPU 27.39 sec
2018-01-03 04:11:35,732 Stage-1 map = 64%,  reduce = 8%, Cumulative CPU 28.65 sec
2018-01-03 04:11:37,791 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 29.12 sec
2018-01-03 04:11:38,821 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 30.79 sec
2018-01-03 04:11:40,883 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 32.14 sec
2018-01-03 04:11:43,970 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 33.55 sec
2018-01-03 04:11:47,057 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 35.28 sec
2018-01-03 04:11:50,147 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 28.15 sec
2018-01-03 04:11:53,233 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 28.88 sec
2018-01-03 04:11:56,318 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 30.26 sec
2018-01-03 04:11:58,377 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 32.81 sec
2018-01-03 04:11:59,405 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.38 sec
MapReduce Total cumulative CPU time: 39 seconds 380 msec
Ended Job = job_1513599404024_162731
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162751, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162751/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162751
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:12:07,100 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:12:12,258 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.68 sec
2018-01-03 04:12:16,381 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.97 sec
2018-01-03 04:12:18,440 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.5 sec
MapReduce Total cumulative CPU time: 15 seconds 500 msec
Ended Job = job_1513599404024_162751
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162757, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162757/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162757
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:12:26,118 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:12:30,249 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.9 sec
2018-01-03 04:12:58,029 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.61 sec
MapReduce Total cumulative CPU time: 6 seconds 610 msec
Ended Job = job_1513599404024_162757
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 39.38 sec   HDFS Read: 134771761 HDFS Write: 710911 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.5 sec   HDFS Read: 48332492 HDFS Write: 259672 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.61 sec   HDFS Read: 267309 HDFS Write: 7468 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 490 msec
OK
Time taken: 121.995 seconds, Fetched: 947 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.372 seconds
Query ID = boss_20180103041313_1608bd45-5435-48ce-aaa6-b4e72d7d4c9b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162771, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162771/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162771
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:13:24,617 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:13:30,840 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 8.64 sec
2018-01-03 04:13:34,967 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 23.01 sec
2018-01-03 04:13:38,061 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 25.96 sec
2018-01-03 04:13:41,157 Stage-1 map = 63%,  reduce = 8%, Cumulative CPU 28.71 sec
2018-01-03 04:13:42,189 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 29.28 sec
2018-01-03 04:13:44,249 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 32.57 sec
2018-01-03 04:13:47,342 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 35.23 sec
2018-01-03 04:13:50,435 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 37.47 sec
2018-01-03 04:13:53,523 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 41.25 sec
2018-01-03 04:13:56,612 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 43.96 sec
2018-01-03 04:13:57,641 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 46.7 sec
2018-01-03 04:13:58,671 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 50.55 sec
2018-01-03 04:13:59,699 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 53.58 sec
MapReduce Total cumulative CPU time: 53 seconds 580 msec
Ended Job = job_1513599404024_162771
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162779, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162779/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162779
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:14:05,438 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:14:12,677 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.31 sec
2018-01-03 04:14:20,934 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.08 sec
MapReduce Total cumulative CPU time: 18 seconds 80 msec
Ended Job = job_1513599404024_162779
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162783, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162783/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162783
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:14:28,031 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:14:33,193 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.58 sec
2018-01-03 04:14:46,614 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.28 sec
MapReduce Total cumulative CPU time: 6 seconds 280 msec
Ended Job = job_1513599404024_162783
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 53.58 sec   HDFS Read: 134771741 HDFS Write: 1547190 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.08 sec   HDFS Read: 49168771 HDFS Write: 213945 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.28 sec   HDFS Read: 221583 HDFS Write: 3775 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 17 seconds 940 msec
OK
Time taken: 93.867 seconds, Fetched: 586 row(s)
开始执行20170918日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.389 seconds
Query ID = boss_20180103041455_d8ac11d0-b8aa-4398-87ec-50bd6984476d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162791, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162791/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162791
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:15:04,374 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:15:13,728 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 12.07 sec
2018-01-03 04:15:14,765 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 25.56 sec
2018-01-03 04:15:17,871 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 29.57 sec
2018-01-03 04:15:20,972 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 33.21 sec
2018-01-03 04:15:24,078 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 38.39 sec
2018-01-03 04:15:27,181 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 42.23 sec
2018-01-03 04:15:30,274 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 46.69 sec
2018-01-03 04:15:33,368 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 50.55 sec
2018-01-03 04:15:36,464 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 54.13 sec
2018-01-03 04:15:39,556 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 57.63 sec
2018-01-03 04:15:42,647 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 61.58 sec
2018-01-03 04:15:44,709 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 64.94 sec
2018-01-03 04:15:45,745 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 74.59 sec
MapReduce Total cumulative CPU time: 1 minutes 14 seconds 590 msec
Ended Job = job_1513599404024_162791
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162797, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162797/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162797
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:16:15,549 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:16:27,937 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.95 sec
2018-01-03 04:16:30,002 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.18 sec
2018-01-03 04:16:43,397 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.2 sec
MapReduce Total cumulative CPU time: 19 seconds 200 msec
Ended Job = job_1513599404024_162797
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162808, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162808/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162808
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:16:57,040 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:17:02,189 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.79 sec
2018-01-03 04:17:16,576 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.23 sec
MapReduce Total cumulative CPU time: 6 seconds 230 msec
Ended Job = job_1513599404024_162808
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 74.59 sec   HDFS Read: 197805563 HDFS Write: 1716833 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.2 sec   HDFS Read: 44426987 HDFS Write: 70780 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.23 sec   HDFS Read: 78455 HDFS Write: 3132 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 40 seconds 20 msec
OK
Time taken: 142.502 seconds, Fetched: 426 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103041724_bb492b94-d9d6-4507-ae57-9807d58d08ba
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162812, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162812/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162812
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 7
2018-01-03 04:17:41,849 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:17:57,392 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 36.79 sec
2018-01-03 04:18:00,494 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 49.25 sec
2018-01-03 04:18:03,593 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 55.33 sec
2018-01-03 04:18:05,687 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 98.7 sec
2018-01-03 04:18:06,718 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 101.68 sec
2018-01-03 04:18:07,749 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 103.84 sec
2018-01-03 04:18:08,779 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 117.42 sec
2018-01-03 04:18:11,871 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 125.15 sec
2018-01-03 04:18:12,908 Stage-1 map = 77%,  reduce = 5%, Cumulative CPU 126.1 sec
2018-01-03 04:18:13,944 Stage-1 map = 77%,  reduce = 16%, Cumulative CPU 128.38 sec
2018-01-03 04:18:14,979 Stage-1 map = 80%,  reduce = 16%, Cumulative CPU 131.73 sec
2018-01-03 04:18:16,010 Stage-1 map = 86%,  reduce = 17%, Cumulative CPU 134.18 sec
2018-01-03 04:18:18,071 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 135.25 sec
2018-01-03 04:18:20,132 Stage-1 map = 86%,  reduce = 24%, Cumulative CPU 153.07 sec
2018-01-03 04:18:25,296 Stage-1 map = 86%,  reduce = 29%, Cumulative CPU 169.37 sec
2018-01-03 04:18:40,792 Stage-1 map = 89%,  reduce = 29%, Cumulative CPU 154.07 sec
2018-01-03 04:18:43,881 Stage-1 map = 91%,  reduce = 29%, Cumulative CPU 159.5 sec
2018-01-03 04:18:46,967 Stage-1 map = 94%,  reduce = 29%, Cumulative CPU 163.4 sec
2018-01-03 04:18:47,996 Stage-1 map = 100%,  reduce = 34%, Cumulative CPU 165.41 sec
2018-01-03 04:18:49,024 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 191.12 sec
MapReduce Total cumulative CPU time: 3 minutes 11 seconds 120 msec
Ended Job = job_1513599404024_162812
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162824, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162824/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162824
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:18:54,835 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:19:00,010 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.15 sec
2018-01-03 04:19:08,263 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.19 sec
2018-01-03 04:19:09,299 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.16 sec
MapReduce Total cumulative CPU time: 13 seconds 160 msec
Ended Job = job_1513599404024_162824
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162829, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162829/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162829
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:19:32,995 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:19:37,134 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.42 sec
2018-01-03 04:19:42,292 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.78 sec
MapReduce Total cumulative CPU time: 4 seconds 780 msec
Ended Job = job_1513599404024_162829
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 7   Cumulative CPU: 191.12 sec   HDFS Read: 640304148 HDFS Write: 323818 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.16 sec   HDFS Read: 43035282 HDFS Write: 22944 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.78 sec   HDFS Read: 30620 HDFS Write: 2531 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 29 seconds 60 msec
OK
Time taken: 139.99 seconds, Fetched: 357 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103041951_bdd9d0fb-08f5-42d6-870d-edf921dbcc7b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162843, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162843/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162843
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:20:09,288 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:20:16,551 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 6.06 sec
2018-01-03 04:20:18,623 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 18.42 sec
2018-01-03 04:20:21,720 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 21.51 sec
2018-01-03 04:20:24,813 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 22.68 sec
2018-01-03 04:20:26,882 Stage-1 map = 64%,  reduce = 8%, Cumulative CPU 23.14 sec
2018-01-03 04:20:27,916 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 25.28 sec
2018-01-03 04:20:31,014 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 27.01 sec
2018-01-03 04:20:34,104 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 28.6 sec
2018-01-03 04:20:37,192 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 30.11 sec
2018-01-03 04:20:40,284 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 32.57 sec
2018-01-03 04:20:41,315 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 37.14 sec
2018-01-03 04:20:42,344 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 40.68 sec
MapReduce Total cumulative CPU time: 40 seconds 680 msec
Ended Job = job_1513599404024_162843
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162866, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162866/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162866
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:20:48,135 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:20:53,289 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.27 sec
2018-01-03 04:20:54,318 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.78 sec
2018-01-03 04:20:59,465 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.24 sec
MapReduce Total cumulative CPU time: 15 seconds 240 msec
Ended Job = job_1513599404024_162866
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162870, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162870/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162870
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:21:05,069 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:21:09,191 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec
2018-01-03 04:21:16,400 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.1 sec
MapReduce Total cumulative CPU time: 6 seconds 100 msec
Ended Job = job_1513599404024_162870
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 40.68 sec   HDFS Read: 123628264 HDFS Write: 809814 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.24 sec   HDFS Read: 43519912 HDFS Write: 237155 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.1 sec   HDFS Read: 244792 HDFS Write: 7745 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 2 seconds 20 msec
OK
Time taken: 86.268 seconds, Fetched: 986 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.387 seconds
Query ID = boss_20180103042124_e60b6db8-7bca-4ded-a9cc-a21c0e48073a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162879, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162879/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162879
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:21:35,374 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:21:40,575 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 7.1 sec
2018-01-03 04:21:44,702 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 19.3 sec
2018-01-03 04:21:47,801 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 21.14 sec
2018-01-03 04:21:50,901 Stage-1 map = 69%,  reduce = 8%, Cumulative CPU 23.43 sec
2018-01-03 04:21:53,995 Stage-1 map = 75%,  reduce = 8%, Cumulative CPU 25.4 sec
2018-01-03 04:21:57,090 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 28.29 sec
2018-01-03 04:22:00,184 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 30.86 sec
2018-01-03 04:22:01,213 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 33.44 sec
2018-01-03 04:22:02,243 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 36.98 sec
2018-01-03 04:22:03,272 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 41.63 sec
MapReduce Total cumulative CPU time: 41 seconds 630 msec
Ended Job = job_1513599404024_162879
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162893, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162893/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162893
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:22:08,931 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:22:14,090 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.68 sec
2018-01-03 04:22:17,178 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.72 sec
2018-01-03 04:22:23,354 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.02 sec
MapReduce Total cumulative CPU time: 17 seconds 20 msec
Ended Job = job_1513599404024_162893
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162897, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162897/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162897
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:22:36,992 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:22:47,280 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.32 sec
2018-01-03 04:22:54,482 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.45 sec
MapReduce Total cumulative CPU time: 6 seconds 450 msec
Ended Job = job_1513599404024_162897
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 41.63 sec   HDFS Read: 123628244 HDFS Write: 1235308 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.02 sec   HDFS Read: 43945406 HDFS Write: 179940 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.45 sec   HDFS Read: 187578 HDFS Write: 3840 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 5 seconds 100 msec
OK
Time taken: 91.141 seconds, Fetched: 579 row(s)
开始执行20170919日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.378 seconds
Query ID = boss_20180103042302_35c9c730-3553-47ce-b355-607ea2847756
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162906, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162906/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162906
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:23:19,479 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:23:27,761 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 10.72 sec
2018-01-03 04:23:29,825 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 23.26 sec
2018-01-03 04:23:32,922 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 26.74 sec
2018-01-03 04:23:36,025 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 30.04 sec
2018-01-03 04:23:38,092 Stage-1 map = 57%,  reduce = 17%, Cumulative CPU 31.3 sec
2018-01-03 04:23:39,125 Stage-1 map = 59%,  reduce = 17%, Cumulative CPU 34.74 sec
2018-01-03 04:23:42,228 Stage-1 map = 62%,  reduce = 17%, Cumulative CPU 38.16 sec
2018-01-03 04:23:45,321 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 41.02 sec
2018-01-03 04:23:48,410 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 45.43 sec
2018-01-03 04:23:51,500 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 48.63 sec
2018-01-03 04:23:54,586 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 51.78 sec
2018-01-03 04:23:57,671 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 55.27 sec
2018-01-03 04:24:00,758 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 59.27 sec
2018-01-03 04:24:02,814 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 62.44 sec
2018-01-03 04:24:05,899 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 65.65 sec
2018-01-03 04:24:06,928 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 66.44 sec
2018-01-03 04:24:07,956 Stage-1 map = 100%,  reduce = 72%, Cumulative CPU 70.1 sec
2018-01-03 04:24:08,985 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 76.28 sec
MapReduce Total cumulative CPU time: 1 minutes 16 seconds 280 msec
Ended Job = job_1513599404024_162906
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162931, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162931/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162931
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:24:14,792 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:24:23,054 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.81 sec
2018-01-03 04:24:24,086 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.94 sec
2018-01-03 04:24:29,242 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.59 sec
MapReduce Total cumulative CPU time: 18 seconds 590 msec
Ended Job = job_1513599404024_162931
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162942, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162942/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162942
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:24:34,890 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:24:46,239 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.1 sec
2018-01-03 04:24:51,391 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.1 sec
MapReduce Total cumulative CPU time: 2 seconds 100 msec
Ended Job = job_1513599404024_162942
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 76.28 sec   HDFS Read: 198660479 HDFS Write: 2082429 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.59 sec   HDFS Read: 43044943 HDFS Write: 71329 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.41 sec   HDFS Read: 79004 HDFS Write: 3087 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 41 seconds 280 msec
OK
Time taken: 110.982 seconds, Fetched: 428 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.392 seconds
Query ID = boss_20180103042508_c599b145-abfb-4ead-a9da-a128846943a5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162958, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162958/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162958
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 7
2018-01-03 04:25:29,412 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:25:39,896 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 44.79 sec
2018-01-03 04:25:43,007 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 56.59 sec
2018-01-03 04:25:46,110 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 70.14 sec
2018-01-03 04:25:47,143 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 95.04 sec
2018-01-03 04:25:48,175 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 101.61 sec
2018-01-03 04:25:49,208 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 107.71 sec
2018-01-03 04:25:50,241 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 118.33 sec
2018-01-03 04:25:51,273 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 121.5 sec
2018-01-03 04:25:52,309 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 131.42 sec
2018-01-03 04:25:53,342 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 144.66 sec
2018-01-03 04:25:54,373 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 147.67 sec
2018-01-03 04:25:55,405 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 154.45 sec
2018-01-03 04:25:56,434 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 163.39 sec
2018-01-03 04:25:58,496 Stage-1 map = 90%,  reduce = 0%, Cumulative CPU 167.44 sec
2018-01-03 04:25:59,533 Stage-1 map = 91%,  reduce = 29%, Cumulative CPU 174.63 sec
2018-01-03 04:26:02,633 Stage-1 map = 93%,  reduce = 29%, Cumulative CPU 178.37 sec
2018-01-03 04:26:03,665 Stage-1 map = 100%,  reduce = 29%, Cumulative CPU 179.77 sec
2018-01-03 04:26:04,695 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 202.9 sec
MapReduce Total cumulative CPU time: 3 minutes 22 seconds 900 msec
Ended Job = job_1513599404024_162958
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162979, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162979/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162979
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:26:11,741 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:26:21,023 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.65 sec
2018-01-03 04:26:31,387 Stage-2 map = 50%,  reduce = 100%, Cumulative CPU 4.65 sec
2018-01-03 04:26:32,427 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.65 sec
2018-01-03 04:26:34,494 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.44 sec
2018-01-03 04:26:37,580 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.46 sec
MapReduce Total cumulative CPU time: 15 seconds 460 msec
Ended Job = job_1513599404024_162979
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_162992, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_162992/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_162992
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:26:45,400 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:26:58,784 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.46 sec
2018-01-03 04:27:04,962 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.27 sec
MapReduce Total cumulative CPU time: 5 seconds 270 msec
Ended Job = job_1513599404024_162992
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 7   Cumulative CPU: 202.9 sec   HDFS Read: 646483078 HDFS Write: 329369 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.46 sec   HDFS Read: 41293193 HDFS Write: 22651 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.27 sec   HDFS Read: 30327 HDFS Write: 2490 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 43 seconds 630 msec
OK
Time taken: 117.78 seconds, Fetched: 370 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103042712_ca06d50b-51c0-427d-801a-9266c6a1d77d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163009, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163009/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163009
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:27:25,974 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:28:01,049 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.6 sec
2018-01-03 04:28:02,080 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 25.68 sec
2018-01-03 04:28:04,141 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 26.91 sec
2018-01-03 04:28:05,175 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 30.93 sec
2018-01-03 04:28:07,235 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 32.08 sec
2018-01-03 04:28:08,264 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 33.88 sec
2018-01-03 04:28:10,323 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 35.12 sec
2018-01-03 04:28:11,354 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 36.67 sec
2018-01-03 04:28:12,383 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 38.06 sec
2018-01-03 04:28:13,417 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 38.96 sec
2018-01-03 04:28:16,503 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 40.07 sec
2018-01-03 04:28:19,593 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 40.91 sec
2018-01-03 04:28:22,686 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 41.89 sec
2018-01-03 04:28:25,779 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 44.73 sec
2018-01-03 04:28:26,809 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 45.34 sec
2018-01-03 04:28:27,843 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 49.69 sec
2018-01-03 04:28:28,872 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 53.83 sec
MapReduce Total cumulative CPU time: 53 seconds 830 msec
Ended Job = job_1513599404024_163009
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163044, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163044/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163044
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:28:35,590 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:28:41,771 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.77 sec
2018-01-03 04:28:48,981 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.53 sec
2018-01-03 04:28:54,118 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.07 sec
MapReduce Total cumulative CPU time: 16 seconds 70 msec
Ended Job = job_1513599404024_163044
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163054, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163054/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163054
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:28:59,706 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:29:05,882 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.47 sec
2018-01-03 04:29:11,022 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.37 sec
MapReduce Total cumulative CPU time: 6 seconds 370 msec
Ended Job = job_1513599404024_163054
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 53.83 sec   HDFS Read: 166052627 HDFS Write: 1122619 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.07 sec   HDFS Read: 42085077 HDFS Write: 210758 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.37 sec   HDFS Read: 218395 HDFS Write: 7531 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 16 seconds 270 msec
OK
Time taken: 119.355 seconds, Fetched: 994 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103042918_5f774322-2674-4212-8164-e73b45376142
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163064, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163064/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163064
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:29:29,905 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:29:39,233 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 25.95 sec
2018-01-03 04:29:41,297 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 27.7 sec
2018-01-03 04:29:42,334 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 30.31 sec
2018-01-03 04:29:45,428 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 33.25 sec
2018-01-03 04:29:46,461 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 34.94 sec
2018-01-03 04:29:47,494 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 38.95 sec
2018-01-03 04:29:54,718 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 44.15 sec
MapReduce Total cumulative CPU time: 44 seconds 150 msec
Ended Job = job_1513599404024_163064
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163075, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163075/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163075
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:30:00,561 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:30:05,734 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.46 sec
2018-01-03 04:30:06,768 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.97 sec
2018-01-03 04:30:18,137 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.22 sec
MapReduce Total cumulative CPU time: 16 seconds 220 msec
Ended Job = job_1513599404024_163075
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163085, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163085/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163085
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:30:45,823 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:30:56,389 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.03 sec
2018-01-03 04:31:08,733 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.25 sec
MapReduce Total cumulative CPU time: 6 seconds 250 msec
Ended Job = job_1513599404024_163085
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 44.15 sec   HDFS Read: 166052607 HDFS Write: 1624534 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.22 sec   HDFS Read: 42586992 HDFS Write: 172014 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.25 sec   HDFS Read: 179652 HDFS Write: 3909 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 6 seconds 620 msec
OK
Time taken: 111.01 seconds, Fetched: 599 row(s)
开始执行20170920日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.401 seconds
Query ID = boss_20180103043116_7c369d8f-1367-4b3d-a728-0f37dbdda9d5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163098, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163098/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163098
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:31:28,187 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:31:39,571 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 25.2 sec
2018-01-03 04:31:42,673 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 28.94 sec
2018-01-03 04:31:45,768 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 32.5 sec
2018-01-03 04:31:48,860 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 36.69 sec
2018-01-03 04:31:51,954 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 40.02 sec
2018-01-03 04:31:52,990 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 41.2 sec
2018-01-03 04:31:55,051 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 44.49 sec
2018-01-03 04:31:58,144 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 47.86 sec
2018-01-03 04:32:01,238 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 51.14 sec
2018-01-03 04:32:02,268 Stage-1 map = 100%,  reduce = 38%, Cumulative CPU 53.26 sec
2018-01-03 04:32:04,326 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 61.44 sec
MapReduce Total cumulative CPU time: 1 minutes 1 seconds 440 msec
Ended Job = job_1513599404024_163098
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163115, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163115/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163115
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:32:12,141 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:32:18,329 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.45 sec
2018-01-03 04:32:25,540 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.5 sec
2018-01-03 04:32:27,598 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.36 sec
MapReduce Total cumulative CPU time: 16 seconds 360 msec
Ended Job = job_1513599404024_163115
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163120, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163120/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163120
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:32:42,257 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:32:48,459 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.55 sec
2018-01-03 04:32:54,648 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.82 sec
MapReduce Total cumulative CPU time: 6 seconds 820 msec
Ended Job = job_1513599404024_163120
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 61.44 sec   HDFS Read: 197701486 HDFS Write: 2031484 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.36 sec   HDFS Read: 43232093 HDFS Write: 68942 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.82 sec   HDFS Read: 76617 HDFS Write: 3023 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 24 seconds 620 msec
OK
Time taken: 99.92 seconds, Fetched: 418 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.421 seconds
Query ID = boss_20180103043303_82ec788a-7f89-455b-9a26-3e88d6142a81
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163130, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163130/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163130
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 7
2018-01-03 04:33:12,689 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:33:22,021 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 64.59 sec
2018-01-03 04:33:23,053 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 76.95 sec
2018-01-03 04:33:24,085 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 80.27 sec
2018-01-03 04:33:25,118 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 96.07 sec
2018-01-03 04:33:26,153 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 99.64 sec
2018-01-03 04:33:27,184 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 102.96 sec
2018-01-03 04:33:28,216 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 116.64 sec
2018-01-03 04:33:30,276 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 136.05 sec
2018-01-03 04:33:31,308 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 143.22 sec
2018-01-03 04:33:33,370 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 146.76 sec
2018-01-03 04:33:34,401 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 150.05 sec
2018-01-03 04:33:35,440 Stage-1 map = 90%,  reduce = 20%, Cumulative CPU 154.38 sec
2018-01-03 04:33:36,470 Stage-1 map = 92%,  reduce = 20%, Cumulative CPU 158.53 sec
2018-01-03 04:33:38,530 Stage-1 map = 92%,  reduce = 24%, Cumulative CPU 159.03 sec
2018-01-03 04:33:39,559 Stage-1 map = 93%,  reduce = 24%, Cumulative CPU 162.78 sec
2018-01-03 04:33:41,619 Stage-1 map = 93%,  reduce = 29%, Cumulative CPU 164.11 sec
2018-01-03 04:33:42,649 Stage-1 map = 100%,  reduce = 29%, Cumulative CPU 169.05 sec
2018-01-03 04:33:43,678 Stage-1 map = 100%,  reduce = 49%, Cumulative CPU 176.11 sec
2018-01-03 04:33:44,712 Stage-1 map = 100%,  reduce = 95%, Cumulative CPU 192.49 sec
2018-01-03 04:33:45,741 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 194.18 sec
MapReduce Total cumulative CPU time: 3 minutes 14 seconds 180 msec
Ended Job = job_1513599404024_163130
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163141, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163141/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163141
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:34:05,697 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:34:11,887 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.65 sec
2018-01-03 04:34:19,086 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.55 sec
2018-01-03 04:34:31,431 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.98 sec
MapReduce Total cumulative CPU time: 15 seconds 980 msec
Ended Job = job_1513599404024_163141
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163151, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163151/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163151
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:34:38,111 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:34:44,302 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.66 sec
2018-01-03 04:35:07,029 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.9 sec
MapReduce Total cumulative CPU time: 4 seconds 900 msec
Ended Job = job_1513599404024_163151
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 7   Cumulative CPU: 194.18 sec   HDFS Read: 644173562 HDFS Write: 313227 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.98 sec   HDFS Read: 41515146 HDFS Write: 19812 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.9 sec   HDFS Read: 27488 HDFS Write: 2499 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 35 seconds 60 msec
OK
Time taken: 124.417 seconds, Fetched: 356 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103043514_62174923-d899-4918-8017-9998beefba1c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163160, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163160/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163160
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 04:35:24,849 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:35:35,233 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.26 sec
2018-01-03 04:35:38,329 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 15.88 sec
2018-01-03 04:35:41,420 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 16.87 sec
2018-01-03 04:35:43,480 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 18.07 sec
2018-01-03 04:35:46,572 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 19.12 sec
2018-01-03 04:35:49,660 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 20.61 sec
2018-01-03 04:35:52,745 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 21.85 sec
2018-01-03 04:35:55,834 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 22.88 sec
2018-01-03 04:35:58,919 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 24.29 sec
2018-01-03 04:36:02,003 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 25.36 sec
2018-01-03 04:36:05,092 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 26.52 sec
2018-01-03 04:36:08,177 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 27.87 sec
2018-01-03 04:36:11,263 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 28.63 sec
2018-01-03 04:36:14,354 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 30.82 sec
2018-01-03 04:36:16,411 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.4 sec
2018-01-03 04:36:29,768 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 37.35 sec
MapReduce Total cumulative CPU time: 37 seconds 350 msec
Ended Job = job_1513599404024_163160
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163176, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163176/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163176
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:36:44,494 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:36:50,684 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.99 sec
2018-01-03 04:36:56,864 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.34 sec
MapReduce Total cumulative CPU time: 15 seconds 340 msec
Ended Job = job_1513599404024_163176
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163178, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163178/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163178
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:37:03,515 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:37:22,024 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.14 sec
2018-01-03 04:37:27,167 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.79 sec
MapReduce Total cumulative CPU time: 5 seconds 790 msec
Ended Job = job_1513599404024_163178
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 37.35 sec   HDFS Read: 98783128 HDFS Write: 752779 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.34 sec   HDFS Read: 41953070 HDFS Write: 184177 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.79 sec   HDFS Read: 191814 HDFS Write: 7161 SUCCESS
Total MapReduce CPU Time Spent: 58 seconds 480 msec
OK
Time taken: 133.426 seconds, Fetched: 843 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103043742_d3ba667b-0159-4567-b78d-0bf5f7efb5dc
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163187, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163187/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163187
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 04:37:54,995 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:38:10,528 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 10.06 sec
2018-01-03 04:38:13,626 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 13.19 sec
2018-01-03 04:38:16,726 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 14.89 sec
2018-01-03 04:38:19,820 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 16.34 sec
2018-01-03 04:38:22,912 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 17.63 sec
2018-01-03 04:38:26,007 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 19.1 sec
2018-01-03 04:38:29,100 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 20.44 sec
2018-01-03 04:38:32,195 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 21.28 sec
2018-01-03 04:38:35,288 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 23.09 sec
2018-01-03 04:38:38,377 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 23.98 sec
2018-01-03 04:38:41,467 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 26.15 sec
2018-01-03 04:38:44,556 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 28.58 sec
2018-01-03 04:39:18,514 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 33.28 sec
MapReduce Total cumulative CPU time: 33 seconds 280 msec
Ended Job = job_1513599404024_163187
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163194, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163194/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163194
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:39:32,215 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:39:37,365 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.53 sec
2018-01-03 04:39:45,595 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.33 sec
MapReduce Total cumulative CPU time: 15 seconds 330 msec
Ended Job = job_1513599404024_163194
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163197, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163197/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163197
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:39:55,355 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:40:05,691 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.08 sec
2018-01-03 04:40:11,874 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.54 sec
MapReduce Total cumulative CPU time: 7 seconds 540 msec
Ended Job = job_1513599404024_163197
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 33.28 sec   HDFS Read: 98783118 HDFS Write: 1237414 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.33 sec   HDFS Read: 42437705 HDFS Write: 166183 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.54 sec   HDFS Read: 173821 HDFS Write: 3845 SUCCESS
Total MapReduce CPU Time Spent: 56 seconds 150 msec
OK
Time taken: 150.016 seconds, Fetched: 604 row(s)
开始执行20170921日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.382 seconds
Query ID = boss_20180103044020_59dbc3c2-fe6a-4f36-87d0-996d7e47ec48
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163201, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163201/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163201
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:40:29,603 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:40:39,948 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 24.73 sec
2018-01-03 04:40:42,013 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 27.3 sec
2018-01-03 04:40:43,048 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 31.26 sec
2018-01-03 04:40:46,142 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 34.64 sec
2018-01-03 04:40:49,233 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 39.04 sec
2018-01-03 04:40:52,331 Stage-1 map = 63%,  reduce = 8%, Cumulative CPU 42.71 sec
2018-01-03 04:40:55,422 Stage-1 map = 66%,  reduce = 8%, Cumulative CPU 45.75 sec
2018-01-03 04:40:58,510 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 49.61 sec
2018-01-03 04:40:59,539 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 50.08 sec
2018-01-03 04:41:01,601 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 52.8 sec
2018-01-03 04:41:03,659 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 55.97 sec
2018-01-03 04:41:06,745 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 59.14 sec
2018-01-03 04:41:09,833 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 62.28 sec
2018-01-03 04:41:12,919 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 65.24 sec
2018-01-03 04:41:16,005 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 68.37 sec
2018-01-03 04:41:17,034 Stage-1 map = 100%,  reduce = 76%, Cumulative CPU 74.92 sec
2018-01-03 04:41:18,062 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 78.24 sec
MapReduce Total cumulative CPU time: 1 minutes 18 seconds 240 msec
Ended Job = job_1513599404024_163201
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163216, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163216/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163216
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:41:28,011 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:41:32,169 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.82 sec
2018-01-03 04:41:33,200 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.42 sec
2018-01-03 04:41:52,744 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.88 sec
MapReduce Total cumulative CPU time: 19 seconds 880 msec
Ended Job = job_1513599404024_163216
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163224, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163224/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163224
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:41:59,861 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:42:19,380 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.23 sec
2018-01-03 04:42:26,565 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.23 sec
MapReduce Total cumulative CPU time: 6 seconds 230 msec
Ended Job = job_1513599404024_163224
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 78.24 sec   HDFS Read: 193813429 HDFS Write: 1806753 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.88 sec   HDFS Read: 41616534 HDFS Write: 59474 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.23 sec   HDFS Read: 67149 HDFS Write: 2869 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 44 seconds 350 msec
OK
Time taken: 127.528 seconds, Fetched: 398 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.404 seconds
Query ID = boss_20180103044234_43bfb57e-2e6d-4368-9a8d-83ad5bed584c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163232, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163232/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163232
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 6
2018-01-03 04:42:44,638 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:42:54,006 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 12.0 sec
2018-01-03 04:42:55,042 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 71.44 sec
2018-01-03 04:42:57,112 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 74.73 sec
2018-01-03 04:42:58,150 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 93.11 sec
2018-01-03 04:43:00,221 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 110.99 sec
2018-01-03 04:43:02,289 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 128.64 sec
2018-01-03 04:43:03,322 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 142.12 sec
2018-01-03 04:43:04,363 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 146.36 sec
2018-01-03 04:43:05,397 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 151.16 sec
2018-01-03 04:43:06,430 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 161.5 sec
2018-01-03 04:43:07,470 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 164.45 sec
2018-01-03 04:43:08,502 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 168.11 sec
2018-01-03 04:43:09,534 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 171.09 sec
2018-01-03 04:43:10,565 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 175.86 sec
2018-01-03 04:43:11,596 Stage-1 map = 93%,  reduce = 0%, Cumulative CPU 179.22 sec
2018-01-03 04:43:12,632 Stage-1 map = 93%,  reduce = 10%, Cumulative CPU 180.34 sec
2018-01-03 04:43:13,666 Stage-1 map = 94%,  reduce = 19%, Cumulative CPU 183.87 sec
2018-01-03 04:43:15,729 Stage-1 map = 100%,  reduce = 19%, Cumulative CPU 186.31 sec
2018-01-03 04:43:16,768 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 204.06 sec
2018-01-03 04:43:21,928 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 207.35 sec
MapReduce Total cumulative CPU time: 3 minutes 27 seconds 350 msec
Ended Job = job_1513599404024_163232
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163239, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163239/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163239
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:43:39,694 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:43:45,924 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.47 sec
2018-01-03 04:43:46,955 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.27 sec
2018-01-03 04:43:52,111 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.9 sec
MapReduce Total cumulative CPU time: 15 seconds 900 msec
Ended Job = job_1513599404024_163239
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163243, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163243/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163243
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:44:04,861 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:44:10,012 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.25 sec
2018-01-03 04:44:25,433 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.06 sec
MapReduce Total cumulative CPU time: 5 seconds 60 msec
Ended Job = job_1513599404024_163243
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 6   Cumulative CPU: 207.35 sec   HDFS Read: 637249425 HDFS Write: 293386 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.9 sec   HDFS Read: 40104215 HDFS Write: 19050 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.06 sec   HDFS Read: 26726 HDFS Write: 2283 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 48 seconds 310 msec
OK
Time taken: 112.071 seconds, Fetched: 326 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103044433_194bdeff-4f1c-401c-acaf-d8dea518468d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163249, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163249/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163249
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 04:44:44,310 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:44:58,784 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 16.33 sec
2018-01-03 04:45:01,878 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 17.91 sec
2018-01-03 04:45:06,021 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 22.63 sec
2018-01-03 04:45:09,127 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 25.47 sec
2018-01-03 04:45:12,230 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 26.54 sec
2018-01-03 04:45:15,324 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 27.01 sec
2018-01-03 04:45:18,412 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 27.95 sec
2018-01-03 04:45:21,570 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 29.52 sec
2018-01-03 04:45:24,659 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 30.78 sec
2018-01-03 04:45:27,748 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 31.93 sec
2018-01-03 04:45:30,834 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 32.69 sec
2018-01-03 04:45:33,927 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 33.5 sec
2018-01-03 04:45:37,015 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 34.03 sec
2018-01-03 04:45:40,098 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 35.07 sec
2018-01-03 04:45:43,186 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 35.69 sec
2018-01-03 04:45:46,268 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 36.1 sec
2018-01-03 04:45:49,350 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 38.0 sec
2018-01-03 04:45:50,380 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 39.33 sec
2018-01-03 04:46:02,716 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 43.81 sec
MapReduce Total cumulative CPU time: 43 seconds 810 msec
Ended Job = job_1513599404024_163249
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163261, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163261/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163261
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:46:08,444 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:46:14,616 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.37 sec
2018-01-03 04:46:19,760 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.92 sec
2018-01-03 04:46:21,815 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.01 sec
MapReduce Total cumulative CPU time: 15 seconds 10 msec
Ended Job = job_1513599404024_163261
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163264, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163264/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163264
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:46:30,565 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:46:37,875 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.96 sec
2018-01-03 04:46:43,016 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.12 sec
MapReduce Total cumulative CPU time: 6 seconds 120 msec
Ended Job = job_1513599404024_163264
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 43.81 sec   HDFS Read: 88286749 HDFS Write: 610588 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.01 sec   HDFS Read: 40420051 HDFS Write: 165620 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.12 sec   HDFS Read: 173257 HDFS Write: 6577 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 4 seconds 940 msec
OK
Time taken: 130.88 seconds, Fetched: 766 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103044650_24992123-6bf2-4fb1-a6ae-0b592acd68a7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163271, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163271/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163271
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 04:47:08,831 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:47:24,345 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 10.37 sec
2018-01-03 04:47:27,433 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 12.39 sec
2018-01-03 04:47:29,496 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 13.97 sec
2018-01-03 04:47:32,587 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 14.98 sec
2018-01-03 04:47:35,673 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 16.43 sec
2018-01-03 04:47:38,763 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 18.99 sec
2018-01-03 04:47:41,849 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 20.25 sec
2018-01-03 04:47:44,933 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 21.86 sec
2018-01-03 04:47:48,019 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 22.9 sec
2018-01-03 04:47:51,100 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 25.04 sec
2018-01-03 04:47:52,128 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 26.3 sec
2018-01-03 04:47:58,302 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.59 sec
MapReduce Total cumulative CPU time: 30 seconds 590 msec
Ended Job = job_1513599404024_163271
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163285, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163285/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163285
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:48:04,012 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:48:09,161 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.53 sec
2018-01-03 04:48:14,311 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.84 sec
MapReduce Total cumulative CPU time: 14 seconds 840 msec
Ended Job = job_1513599404024_163285
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163289, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163289/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163289
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:48:28,318 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:48:33,467 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.32 sec
2018-01-03 04:48:40,687 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.13 sec
MapReduce Total cumulative CPU time: 6 seconds 130 msec
Ended Job = job_1513599404024_163289
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.59 sec   HDFS Read: 88286739 HDFS Write: 1122360 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.84 sec   HDFS Read: 40931823 HDFS Write: 147013 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.13 sec   HDFS Read: 154651 HDFS Write: 3679 SUCCESS
Total MapReduce CPU Time Spent: 51 seconds 560 msec
OK
Time taken: 110.965 seconds, Fetched: 562 row(s)
开始执行20170922日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103044848_52c86e86-346f-4918-a5d0-ccf89cd7e576
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163294, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163294/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163294
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:48:57,595 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:49:07,987 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 25.03 sec
2018-01-03 04:49:11,093 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 34.46 sec
2018-01-03 04:49:14,252 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 38.2 sec
2018-01-03 04:49:17,347 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 41.34 sec
2018-01-03 04:49:20,445 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 45.06 sec
2018-01-03 04:49:21,483 Stage-1 map = 61%,  reduce = 8%, Cumulative CPU 45.53 sec
2018-01-03 04:49:23,545 Stage-1 map = 65%,  reduce = 8%, Cumulative CPU 48.62 sec
2018-01-03 04:49:25,608 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 49.42 sec
2018-01-03 04:49:26,639 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 52.57 sec
2018-01-03 04:49:29,737 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 56.48 sec
2018-01-03 04:49:32,830 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 59.23 sec
2018-01-03 04:49:35,922 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 62.49 sec
2018-01-03 04:49:39,020 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 65.79 sec
2018-01-03 04:49:41,081 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 69.02 sec
2018-01-03 04:49:44,171 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 72.48 sec
2018-01-03 04:49:45,202 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 73.31 sec
2018-01-03 04:49:46,233 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 77.6 sec
2018-01-03 04:49:47,267 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 83.88 sec
MapReduce Total cumulative CPU time: 1 minutes 23 seconds 880 msec
Ended Job = job_1513599404024_163294
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163300, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163300/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163300
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:49:52,943 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:50:00,156 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.08 sec
2018-01-03 04:50:06,343 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.62 sec
2018-01-03 04:50:09,432 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.39 sec
MapReduce Total cumulative CPU time: 18 seconds 390 msec
Ended Job = job_1513599404024_163300
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163302, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163302/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163302
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:50:18,091 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:50:22,212 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.89 sec
2018-01-03 04:50:28,388 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.06 sec
MapReduce Total cumulative CPU time: 6 seconds 60 msec
Ended Job = job_1513599404024_163302
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 83.88 sec   HDFS Read: 233622553 HDFS Write: 1710396 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.39 sec   HDFS Read: 42956752 HDFS Write: 57435 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.06 sec   HDFS Read: 65110 HDFS Write: 2790 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 48 seconds 330 msec
OK
Time taken: 100.765 seconds, Fetched: 393 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.397 seconds
Query ID = boss_20180103045044_f28bbf91-4495-48ab-a68d-92b31c176a53
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163306, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163306/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163306
Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 7
2018-01-03 04:50:53,101 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:51:02,425 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.09 sec
2018-01-03 04:51:03,460 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 82.19 sec
2018-01-03 04:51:04,493 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 84.55 sec
2018-01-03 04:51:06,563 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 106.22 sec
2018-01-03 04:51:09,656 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 127.44 sec
2018-01-03 04:51:10,687 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 140.29 sec
2018-01-03 04:51:12,747 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 162.37 sec
2018-01-03 04:51:13,778 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 170.61 sec
2018-01-03 04:51:14,814 Stage-1 map = 78%,  reduce = 11%, Cumulative CPU 172.87 sec
2018-01-03 04:51:15,849 Stage-1 map = 88%,  reduce = 14%, Cumulative CPU 183.19 sec
2018-01-03 04:51:17,911 Stage-1 map = 93%,  reduce = 17%, Cumulative CPU 186.24 sec
2018-01-03 04:51:18,944 Stage-1 map = 95%,  reduce = 18%, Cumulative CPU 189.66 sec
2018-01-03 04:51:21,003 Stage-1 map = 100%,  reduce = 21%, Cumulative CPU 189.91 sec
2018-01-03 04:51:22,034 Stage-1 map = 100%,  reduce = 45%, Cumulative CPU 199.84 sec
2018-01-03 04:51:23,063 Stage-1 map = 100%,  reduce = 80%, Cumulative CPU 208.4 sec
2018-01-03 04:51:24,092 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 216.04 sec
MapReduce Total cumulative CPU time: 3 minutes 36 seconds 40 msec
Ended Job = job_1513599404024_163306
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163310, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163310/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163310
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:51:36,092 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:51:41,273 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.24 sec
2018-01-03 04:51:54,678 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.87 sec
MapReduce Total cumulative CPU time: 12 seconds 870 msec
Ended Job = job_1513599404024_163310
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163314, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163314/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163314
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:52:00,453 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:52:20,042 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.76 sec
2018-01-03 04:52:34,471 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.1 sec
MapReduce Total cumulative CPU time: 6 seconds 100 msec
Ended Job = job_1513599404024_163314
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 8  Reduce: 7   Cumulative CPU: 216.04 sec   HDFS Read: 687671724 HDFS Write: 306917 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.87 sec   HDFS Read: 41554583 HDFS Write: 21634 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.1 sec   HDFS Read: 29310 HDFS Write: 2352 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 55 seconds 10 msec
OK
Time taken: 111.358 seconds, Fetched: 342 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103045250_fdcc5f9b-0f01-4889-8630-db81276edfca
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163318, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163318/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163318
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 04:53:00,321 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:53:10,670 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 11.83 sec
2018-01-03 04:53:13,769 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 15.26 sec
2018-01-03 04:53:16,861 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 16.86 sec
2018-01-03 04:53:19,951 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 18.06 sec
2018-01-03 04:53:23,044 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 19.28 sec
2018-01-03 04:53:25,105 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 20.42 sec
2018-01-03 04:53:28,190 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 21.63 sec
2018-01-03 04:53:31,281 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 23.11 sec
2018-01-03 04:53:34,367 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 23.98 sec
2018-01-03 04:53:37,452 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 25.66 sec
2018-01-03 04:53:40,543 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 25.82 sec
2018-01-03 04:53:43,629 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 26.85 sec
2018-01-03 04:53:46,713 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 29.13 sec
2018-01-03 04:53:49,802 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 31.57 sec
2018-01-03 04:53:59,057 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.94 sec
MapReduce Total cumulative CPU time: 35 seconds 940 msec
Ended Job = job_1513599404024_163318
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163323, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163323/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163323
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:54:13,802 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:54:18,972 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.91 sec
2018-01-03 04:54:20,003 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.22 sec
2018-01-03 04:54:25,162 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.76 sec
MapReduce Total cumulative CPU time: 17 seconds 760 msec
Ended Job = job_1513599404024_163323
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163327, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163327/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163327
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:54:41,881 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:55:00,489 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.67 sec
2018-01-03 04:55:07,690 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.38 sec
MapReduce Total cumulative CPU time: 6 seconds 380 msec
Ended Job = job_1513599404024_163327
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.94 sec   HDFS Read: 88689613 HDFS Write: 577982 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.76 sec   HDFS Read: 41824020 HDFS Write: 169103 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.38 sec   HDFS Read: 176740 HDFS Write: 6506 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 0 seconds 80 msec
OK
Time taken: 138.463 seconds, Fetched: 756 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103045515_31237727-d525-4ed8-8a7a-cd6dc67a6b46
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163332, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163332/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163332
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 04:55:25,530 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:55:35,906 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 7.81 sec
2018-01-03 04:55:39,013 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 10.47 sec
2018-01-03 04:55:42,114 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 12.16 sec
2018-01-03 04:55:45,209 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 13.16 sec
2018-01-03 04:55:47,275 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 14.56 sec
2018-01-03 04:55:50,369 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 15.52 sec
2018-01-03 04:55:53,462 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 17.04 sec
2018-01-03 04:55:56,558 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 17.85 sec
2018-01-03 04:55:59,648 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 19.07 sec
2018-01-03 04:56:02,739 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 20.79 sec
2018-01-03 04:56:05,830 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 22.57 sec
2018-01-03 04:56:07,890 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 24.48 sec
2018-01-03 04:56:15,166 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.08 sec
MapReduce Total cumulative CPU time: 32 seconds 80 msec
Ended Job = job_1513599404024_163332
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163346, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163346/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163346
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:56:21,433 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:56:26,588 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.75 sec
2018-01-03 04:56:28,648 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.28 sec
2018-01-03 04:56:35,856 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.91 sec
MapReduce Total cumulative CPU time: 18 seconds 910 msec
Ended Job = job_1513599404024_163346
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163359, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163359/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163359
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:56:41,831 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:56:49,036 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.3 sec
2018-01-03 04:56:56,236 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.65 sec
MapReduce Total cumulative CPU time: 7 seconds 650 msec
Ended Job = job_1513599404024_163359
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 32.08 sec   HDFS Read: 88689603 HDFS Write: 1403535 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.91 sec   HDFS Read: 42649573 HDFS Write: 157809 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.65 sec   HDFS Read: 165447 HDFS Write: 3579 SUCCESS
Total MapReduce CPU Time Spent: 58 seconds 640 msec
OK
Time taken: 101.881 seconds, Fetched: 550 row(s)
开始执行20170923日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.378 seconds
Query ID = boss_20180103045704_8a0c3190-8068-4f3c-b875-7a4a6b5a51d3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163367, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163367/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163367
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 04:57:13,137 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:57:22,451 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.78 sec
2018-01-03 04:57:24,516 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 23.25 sec
2018-01-03 04:57:25,551 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 27.21 sec
2018-01-03 04:57:27,613 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 30.67 sec
2018-01-03 04:57:28,646 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 33.94 sec
2018-01-03 04:57:30,706 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 37.43 sec
2018-01-03 04:57:31,737 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 41.0 sec
2018-01-03 04:57:33,796 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 44.29 sec
2018-01-03 04:57:34,826 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 48.37 sec
2018-01-03 04:57:36,890 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 51.71 sec
2018-01-03 04:57:37,920 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 54.79 sec
2018-01-03 04:57:39,976 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 57.24 sec
2018-01-03 04:57:41,004 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 60.09 sec
2018-01-03 04:57:43,061 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 63.24 sec
2018-01-03 04:57:44,090 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 68.23 sec
2018-01-03 04:57:46,151 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 71.32 sec
2018-01-03 04:57:50,269 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 77.99 sec
2018-01-03 04:57:51,299 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 82.91 sec
MapReduce Total cumulative CPU time: 1 minutes 22 seconds 910 msec
Ended Job = job_1513599404024_163367
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163378, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163378/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163378
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:57:56,985 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:58:02,142 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.19 sec
2018-01-03 04:58:08,334 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.21 sec
MapReduce Total cumulative CPU time: 18 seconds 210 msec
Ended Job = job_1513599404024_163378
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163381, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163381/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163381
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:58:15,055 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:58:20,218 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.96 sec
2018-01-03 04:58:25,364 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.35 sec
MapReduce Total cumulative CPU time: 5 seconds 350 msec
Ended Job = job_1513599404024_163381
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 82.91 sec   HDFS Read: 262858236 HDFS Write: 1885254 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.21 sec   HDFS Read: 44465188 HDFS Write: 68607 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.35 sec   HDFS Read: 76282 HDFS Write: 3039 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 46 seconds 470 msec
OK
Time taken: 82.159 seconds, Fetched: 417 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.387 seconds
Query ID = boss_20180103045833_25a2aeaf-8e40-442a-b445-aeecd7db65d1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163388, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163388/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163388
Hadoop job information for Stage-1: number of mappers: 10; number of reducers: 9
2018-01-03 04:58:44,551 Stage-1 map = 0%,  reduce = 0%
2018-01-03 04:58:54,923 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 24.29 sec
2018-01-03 04:58:55,957 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 73.82 sec
2018-01-03 04:58:58,026 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 80.85 sec
2018-01-03 04:58:59,058 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 98.33 sec
2018-01-03 04:59:01,122 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 111.31 sec
2018-01-03 04:59:02,153 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 115.68 sec
2018-01-03 04:59:03,183 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 172.09 sec
2018-01-03 04:59:04,214 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 178.95 sec
2018-01-03 04:59:06,275 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 219.76 sec
2018-01-03 04:59:07,311 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 225.56 sec
2018-01-03 04:59:09,383 Stage-1 map = 78%,  reduce = 11%, Cumulative CPU 250.64 sec
2018-01-03 04:59:10,416 Stage-1 map = 79%,  reduce = 16%, Cumulative CPU 256.33 sec
2018-01-03 04:59:11,447 Stage-1 map = 83%,  reduce = 16%, Cumulative CPU 257.12 sec
2018-01-03 04:59:12,478 Stage-1 map = 85%,  reduce = 17%, Cumulative CPU 263.39 sec
2018-01-03 04:59:13,509 Stage-1 map = 92%,  reduce = 18%, Cumulative CPU 268.44 sec
2018-01-03 04:59:15,569 Stage-1 map = 96%,  reduce = 23%, Cumulative CPU 274.37 sec
2018-01-03 04:59:16,605 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 276.66 sec
2018-01-03 04:59:17,635 Stage-1 map = 100%,  reduce = 57%, Cumulative CPU 291.02 sec
2018-01-03 04:59:18,664 Stage-1 map = 100%,  reduce = 87%, Cumulative CPU 305.62 sec
2018-01-03 04:59:19,694 Stage-1 map = 100%,  reduce = 89%, Cumulative CPU 306.81 sec
2018-01-03 04:59:22,782 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 311.12 sec
MapReduce Total cumulative CPU time: 5 minutes 11 seconds 120 msec
Ended Job = job_1513599404024_163388
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163396, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163396/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163396
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 04:59:29,510 Stage-2 map = 0%,  reduce = 0%
2018-01-03 04:59:35,710 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.73 sec
2018-01-03 04:59:36,742 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.87 sec
2018-01-03 04:59:40,864 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.61 sec
MapReduce Total cumulative CPU time: 17 seconds 610 msec
Ended Job = job_1513599404024_163396
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163401, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163401/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163401
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 04:59:48,581 Stage-3 map = 0%,  reduce = 0%
2018-01-03 04:59:54,889 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.96 sec
2018-01-03 05:00:08,282 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.16 sec
MapReduce Total cumulative CPU time: 5 seconds 160 msec
Ended Job = job_1513599404024_163401
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 10  Reduce: 9   Cumulative CPU: 311.12 sec   HDFS Read: 863370991 HDFS Write: 390408 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.61 sec   HDFS Read: 42972176 HDFS Write: 23893 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.16 sec   HDFS Read: 31569 HDFS Write: 2543 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 33 seconds 890 msec
OK
Time taken: 96.193 seconds, Fetched: 364 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103050024_707aff63-6a5d-4972-be08-88990553d5ed
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163407, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163407/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163407
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:00:34,295 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:00:44,679 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 11.17 sec
2018-01-03 05:00:47,787 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 14.76 sec
2018-01-03 05:00:50,884 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 16.31 sec
2018-01-03 05:00:53,980 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 17.23 sec
2018-01-03 05:00:57,079 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 18.04 sec
2018-01-03 05:01:00,174 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 18.67 sec
2018-01-03 05:01:03,265 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 19.81 sec
2018-01-03 05:01:06,362 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 20.54 sec
2018-01-03 05:01:09,452 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 21.43 sec
2018-01-03 05:01:12,543 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 22.51 sec
2018-01-03 05:01:15,636 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 23.39 sec
2018-01-03 05:01:18,724 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 24.54 sec
2018-01-03 05:01:21,813 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 25.11 sec
2018-01-03 05:01:24,904 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 26.03 sec
2018-01-03 05:01:27,992 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 26.74 sec
2018-01-03 05:01:31,078 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 27.76 sec
2018-01-03 05:01:33,135 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 28.34 sec
2018-01-03 05:01:36,225 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 29.95 sec
2018-01-03 05:01:39,311 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 30.85 sec
2018-01-03 05:01:41,368 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.32 sec
2018-01-03 05:01:46,520 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 36.37 sec
MapReduce Total cumulative CPU time: 36 seconds 370 msec
Ended Job = job_1513599404024_163407
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163423, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163423/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163423
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:01:53,228 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:01:58,385 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.45 sec
2018-01-03 05:02:13,814 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.39 sec
MapReduce Total cumulative CPU time: 14 seconds 390 msec
Ended Job = job_1513599404024_163423
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163431, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163431/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163431
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:02:19,432 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:02:29,709 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.23 sec
2018-01-03 05:02:35,875 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.96 sec
MapReduce Total cumulative CPU time: 5 seconds 960 msec
Ended Job = job_1513599404024_163431
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 36.37 sec   HDFS Read: 99640772 HDFS Write: 582287 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.39 sec   HDFS Read: 43161903 HDFS Write: 188233 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.96 sec   HDFS Read: 195870 HDFS Write: 6767 SUCCESS
Total MapReduce CPU Time Spent: 56 seconds 720 msec
OK
Time taken: 132.778 seconds, Fetched: 798 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103050243_0506511c-0878-4b82-96ea-addfb9449bbf
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163442, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163442/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163442
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:03:01,120 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:03:11,480 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 11.29 sec
2018-01-03 05:03:14,580 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 14.27 sec
2018-01-03 05:03:17,675 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 16.54 sec
2018-01-03 05:03:20,766 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 17.75 sec
2018-01-03 05:03:23,860 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 19.62 sec
2018-01-03 05:03:26,948 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 21.12 sec
2018-01-03 05:03:30,037 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 22.62 sec
2018-01-03 05:03:33,128 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 24.53 sec
2018-01-03 05:03:36,214 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 25.57 sec
2018-01-03 05:03:39,300 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 27.54 sec
2018-01-03 05:03:41,361 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 30.2 sec
2018-01-03 05:03:48,565 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 34.73 sec
MapReduce Total cumulative CPU time: 34 seconds 730 msec
Ended Job = job_1513599404024_163442
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163456, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163456/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163456
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:03:54,260 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:04:00,437 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.17 sec
2018-01-03 05:04:01,466 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.46 sec
2018-01-03 05:04:06,607 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.21 sec
MapReduce Total cumulative CPU time: 14 seconds 210 msec
Ended Job = job_1513599404024_163456
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163465, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163465/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163465
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:04:21,255 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:04:26,426 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.18 sec
2018-01-03 05:04:32,603 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.77 sec
MapReduce Total cumulative CPU time: 6 seconds 770 msec
Ended Job = job_1513599404024_163465
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 34.73 sec   HDFS Read: 99640762 HDFS Write: 1429210 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.21 sec   HDFS Read: 44008826 HDFS Write: 163252 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.77 sec   HDFS Read: 170890 HDFS Write: 3498 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 710 msec
OK
Time taken: 109.744 seconds, Fetched: 524 row(s)
开始执行20170924日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.368 seconds
Query ID = boss_20180103050440_01efeae4-19c1-48cb-a208-605cae916dfd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163471, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163471/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163471
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 05:04:49,952 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:04:59,273 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.38 sec
2018-01-03 05:05:00,305 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 24.3 sec
2018-01-03 05:05:02,376 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 27.93 sec
2018-01-03 05:05:03,414 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 31.39 sec
2018-01-03 05:05:05,477 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 34.66 sec
2018-01-03 05:05:06,509 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 37.98 sec
2018-01-03 05:05:08,571 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 41.53 sec
2018-01-03 05:05:09,601 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 44.92 sec
2018-01-03 05:05:11,661 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 48.8 sec
2018-01-03 05:05:12,694 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 51.93 sec
2018-01-03 05:05:14,755 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 57.75 sec
2018-01-03 05:05:17,843 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 61.09 sec
2018-01-03 05:05:20,932 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 64.79 sec
2018-01-03 05:05:22,996 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 74.11 sec
MapReduce Total cumulative CPU time: 1 minutes 14 seconds 110 msec
Ended Job = job_1513599404024_163471
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163482, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163482/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163482
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:05:35,799 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:05:40,970 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.72 sec
2018-01-03 05:05:42,002 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.36 sec
2018-01-03 05:05:47,165 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.86 sec
MapReduce Total cumulative CPU time: 16 seconds 860 msec
Ended Job = job_1513599404024_163482
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163500, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163500/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163500
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:06:15,845 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:06:19,970 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.61 sec
2018-01-03 05:06:28,209 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.19 sec
MapReduce Total cumulative CPU time: 6 seconds 190 msec
Ended Job = job_1513599404024_163500
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 74.11 sec   HDFS Read: 260840151 HDFS Write: 1751449 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.86 sec   HDFS Read: 44475748 HDFS Write: 71759 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.19 sec   HDFS Read: 79434 HDFS Write: 3016 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 37 seconds 160 msec
OK
Time taken: 108.673 seconds, Fetched: 413 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.432 seconds
Query ID = boss_20180103050644_1683aba8-973b-47d4-ad80-257dd33cf6e7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163508, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163508/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163508
Hadoop job information for Stage-1: number of mappers: 9; number of reducers: 9
2018-01-03 05:06:55,525 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:07:04,842 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 37.15 sec
2018-01-03 05:07:05,874 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 50.57 sec
2018-01-03 05:07:06,906 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 75.29 sec
2018-01-03 05:07:07,939 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 86.46 sec
2018-01-03 05:07:08,975 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 99.66 sec
2018-01-03 05:07:10,007 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 106.86 sec
2018-01-03 05:07:11,042 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 116.21 sec
2018-01-03 05:07:12,073 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 119.77 sec
2018-01-03 05:07:13,102 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 128.01 sec
2018-01-03 05:07:14,134 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 140.3 sec
2018-01-03 05:07:15,165 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 143.7 sec
2018-01-03 05:07:16,195 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 146.69 sec
2018-01-03 05:07:18,259 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 149.88 sec
2018-01-03 05:07:19,293 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 153.13 sec
2018-01-03 05:07:20,327 Stage-1 map = 69%,  reduce = 12%, Cumulative CPU 176.03 sec
2018-01-03 05:07:21,356 Stage-1 map = 73%,  reduce = 19%, Cumulative CPU 178.56 sec
2018-01-03 05:07:22,386 Stage-1 map = 78%,  reduce = 19%, Cumulative CPU 185.89 sec
2018-01-03 05:07:23,416 Stage-1 map = 78%,  reduce = 21%, Cumulative CPU 186.51 sec
2018-01-03 05:07:24,445 Stage-1 map = 83%,  reduce = 22%, Cumulative CPU 189.86 sec
2018-01-03 05:07:25,475 Stage-1 map = 90%,  reduce = 22%, Cumulative CPU 208.52 sec
2018-01-03 05:07:26,504 Stage-1 map = 90%,  reduce = 28%, Cumulative CPU 209.44 sec
2018-01-03 05:07:27,537 Stage-1 map = 90%,  reduce = 29%, Cumulative CPU 209.71 sec
2018-01-03 05:07:28,565 Stage-1 map = 91%,  reduce = 29%, Cumulative CPU 213.45 sec
2018-01-03 05:07:29,594 Stage-1 map = 91%,  reduce = 30%, Cumulative CPU 214.6 sec
2018-01-03 05:07:31,650 Stage-1 map = 92%,  reduce = 30%, Cumulative CPU 218.59 sec
2018-01-03 05:07:34,735 Stage-1 map = 93%,  reduce = 30%, Cumulative CPU 222.88 sec
2018-01-03 05:07:37,822 Stage-1 map = 94%,  reduce = 30%, Cumulative CPU 226.91 sec
2018-01-03 05:07:39,877 Stage-1 map = 94%,  reduce = 26%, Cumulative CPU 227.15 sec
2018-01-03 05:07:40,907 Stage-1 map = 100%,  reduce = 30%, Cumulative CPU 232.17 sec
2018-01-03 05:07:41,935 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 242.61 sec
2018-01-03 05:07:42,962 Stage-1 map = 100%,  reduce = 89%, Cumulative CPU 263.5 sec
2018-01-03 05:07:49,130 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 269.37 sec
MapReduce Total cumulative CPU time: 4 minutes 29 seconds 370 msec
Ended Job = job_1513599404024_163508
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163518, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163518/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163518
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:08:03,840 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:08:09,026 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.41 sec
2018-01-03 05:08:37,820 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.49 sec
MapReduce Total cumulative CPU time: 17 seconds 490 msec
Ended Job = job_1513599404024_163518
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163563, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163563/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163563
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:09:42,587 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:10:11,874 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.04 sec
2018-01-03 05:10:27,458 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.3 sec
MapReduce Total cumulative CPU time: 8 seconds 300 msec
Ended Job = job_1513599404024_163563
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 9  Reduce: 9   Cumulative CPU: 269.37 sec   HDFS Read: 854215722 HDFS Write: 400784 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.49 sec   HDFS Read: 43126917 HDFS Write: 23351 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.3 sec   HDFS Read: 31027 HDFS Write: 2536 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 55 seconds 160 msec
OK
Time taken: 225.282 seconds, Fetched: 367 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.365 seconds
Query ID = boss_20180103051044_348ee15c-8831-41e3-96e6-30cbe66baee5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163586, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163586/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163586
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:11:34,860 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:11:54,409 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 10.95 sec
2018-01-03 05:12:00,637 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 14.32 sec
2018-01-03 05:12:04,053 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 14.86 sec
2018-01-03 05:12:07,314 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 15.42 sec
2018-01-03 05:12:14,603 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 17.35 sec
2018-01-03 05:12:17,876 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 19.37 sec
2018-01-03 05:12:20,994 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 21.11 sec
2018-01-03 05:12:24,104 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 22.18 sec
2018-01-03 05:12:28,330 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 23.56 sec
2018-01-03 05:12:31,509 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 24.6 sec
2018-01-03 05:12:34,682 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 25.18 sec
2018-01-03 05:12:37,791 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 25.85 sec
2018-01-03 05:12:40,922 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 26.2 sec
2018-01-03 05:12:44,326 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 26.62 sec
2018-01-03 05:12:48,320 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 27.02 sec
2018-01-03 05:12:51,421 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 27.61 sec
2018-01-03 05:12:55,170 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 28.37 sec
2018-01-03 05:12:57,229 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 28.88 sec
2018-01-03 05:13:00,337 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 29.42 sec
2018-01-03 05:13:03,425 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 29.74 sec
2018-01-03 05:13:06,511 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 30.6 sec
2018-01-03 05:13:09,797 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 31.7 sec
2018-01-03 05:13:12,917 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 32.32 sec
2018-01-03 05:13:16,011 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 33.0 sec
2018-01-03 05:13:19,199 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 34.08 sec
2018-01-03 05:13:22,283 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 34.58 sec
2018-01-03 05:13:25,385 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 35.17 sec
2018-01-03 05:13:27,646 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 35.49 sec
2018-01-03 05:13:30,739 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 35.65 sec
2018-01-03 05:13:34,941 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 35.91 sec
2018-01-03 05:13:38,076 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 36.19 sec
2018-01-03 05:13:42,198 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 36.57 sec
2018-01-03 05:13:45,307 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 39.24 sec
2018-01-03 05:13:48,460 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 39.7 sec
2018-01-03 05:13:49,509 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 41.93 sec
2018-01-03 05:14:08,566 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 47.2 sec
2018-01-03 05:14:09,594 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 52.2 sec
MapReduce Total cumulative CPU time: 52 seconds 200 msec
Ended Job = job_1513599404024_163586
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163652, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163652/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163652
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:14:15,311 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:14:22,515 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.03 sec
2018-01-03 05:14:26,624 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.94 sec
2018-01-03 05:14:28,679 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.58 sec
MapReduce Total cumulative CPU time: 16 seconds 580 msec
Ended Job = job_1513599404024_163652
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163665, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163665/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163665
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:14:38,357 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:14:47,626 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.33 sec
2018-01-03 05:14:54,830 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.64 sec
MapReduce Total cumulative CPU time: 8 seconds 640 msec
Ended Job = job_1513599404024_163665
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 52.2 sec   HDFS Read: 101545166 HDFS Write: 586490 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.58 sec   HDFS Read: 43310471 HDFS Write: 200046 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.64 sec   HDFS Read: 207683 HDFS Write: 6757 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 17 seconds 420 msec
OK
Time taken: 251.615 seconds, Fetched: 798 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103051502_cba17200-d0d8-446b-bc07-22b7e4d29d44
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163696, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163696/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163696
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:15:12,767 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:15:23,133 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.43 sec
2018-01-03 05:15:26,237 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 15.53 sec
2018-01-03 05:15:29,334 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 17.47 sec
2018-01-03 05:15:32,425 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 19.04 sec
2018-01-03 05:15:35,516 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 20.56 sec
2018-01-03 05:15:38,603 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 22.15 sec
2018-01-03 05:15:41,688 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 23.86 sec
2018-01-03 05:15:44,784 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 25.46 sec
2018-01-03 05:15:47,871 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 27.0 sec
2018-01-03 05:15:50,959 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 31.41 sec
2018-01-03 05:15:54,048 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 32.89 sec
2018-01-03 05:15:56,106 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 35.31 sec
2018-01-03 05:15:58,165 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 36.48 sec
2018-01-03 05:16:05,373 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 43.9 sec
MapReduce Total cumulative CPU time: 43 seconds 900 msec
Ended Job = job_1513599404024_163696
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163745, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163745/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163745
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:16:19,253 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:16:25,442 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.86 sec
2018-01-03 05:16:30,594 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.19 sec
MapReduce Total cumulative CPU time: 18 seconds 190 msec
Ended Job = job_1513599404024_163745
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163757, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163757/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163757
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:16:38,534 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:16:43,693 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.54 sec
2018-01-03 05:16:49,879 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.19 sec
MapReduce Total cumulative CPU time: 6 seconds 190 msec
Ended Job = job_1513599404024_163757
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 43.9 sec   HDFS Read: 101545156 HDFS Write: 1373429 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.19 sec   HDFS Read: 44097410 HDFS Write: 189798 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.19 sec   HDFS Read: 197436 HDFS Write: 3785 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 8 seconds 280 msec
OK
Time taken: 108.256 seconds, Fetched: 600 row(s)
开始执行20170925日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103051657_8cb5c5ae-634f-4a48-aae4-930cf8d486d3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163778, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163778/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163778
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 05:17:15,032 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:17:25,397 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 13.64 sec
2018-01-03 05:17:28,505 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 16.38 sec
2018-01-03 05:17:31,605 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 19.58 sec
2018-01-03 05:17:33,678 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 30.79 sec
2018-01-03 05:17:36,774 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 42.36 sec
2018-01-03 05:17:37,808 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 45.46 sec
2018-01-03 05:17:38,839 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 48.39 sec
2018-01-03 05:17:40,899 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 50.22 sec
2018-01-03 05:17:49,138 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 73.51 sec
2018-01-03 05:17:50,173 Stage-1 map = 61%,  reduce = 17%, Cumulative CPU 74.55 sec
2018-01-03 05:17:52,233 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 78.59 sec
2018-01-03 05:17:55,322 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 81.72 sec
2018-01-03 05:17:58,421 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 85.19 sec
2018-01-03 05:18:01,513 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 89.36 sec
2018-01-03 05:18:04,610 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 92.79 sec
2018-01-03 05:18:07,706 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 96.78 sec
2018-01-03 05:18:10,818 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 100.01 sec
2018-01-03 05:18:13,904 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 103.14 sec
2018-01-03 05:18:15,965 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 105.32 sec
2018-01-03 05:18:16,994 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 111.0 sec
2018-01-03 05:18:18,025 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 114.54 sec
MapReduce Total cumulative CPU time: 1 minutes 54 seconds 540 msec
Ended Job = job_1513599404024_163778
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163828, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163828/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163828
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:18:33,981 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:18:42,238 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.02 sec
2018-01-03 05:18:46,357 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.62 sec
2018-01-03 05:18:56,650 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.8 sec
MapReduce Total cumulative CPU time: 16 seconds 800 msec
Ended Job = job_1513599404024_163828
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163845, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163845/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163845
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:19:02,396 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:19:09,603 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.21 sec
2018-01-03 05:19:16,796 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.01 sec
MapReduce Total cumulative CPU time: 6 seconds 10 msec
Ended Job = job_1513599404024_163845
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 114.54 sec   HDFS Read: 190265593 HDFS Write: 1390155 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.8 sec   HDFS Read: 39560804 HDFS Write: 61210 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.01 sec   HDFS Read: 68885 HDFS Write: 2898 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 17 seconds 350 msec
OK
Time taken: 139.964 seconds, Fetched: 403 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.396 seconds
Query ID = boss_20180103051924_bb0d7cad-a932-4e9b-b047-5652ceceab71
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163873, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163873/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163873
Hadoop job information for Stage-1: number of mappers: 6; number of reducers: 7
2018-01-03 05:19:34,538 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:19:43,942 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 50.86 sec
2018-01-03 05:19:44,985 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 91.18 sec
2018-01-03 05:19:47,052 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 110.53 sec
2018-01-03 05:19:48,086 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 119.16 sec
2018-01-03 05:19:50,150 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 132.46 sec
2018-01-03 05:19:51,182 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 138.14 sec
2018-01-03 05:19:53,244 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 151.34 sec
2018-01-03 05:19:54,275 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 155.59 sec
2018-01-03 05:19:56,337 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 166.19 sec
2018-01-03 05:19:57,374 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 170.68 sec
2018-01-03 05:19:59,440 Stage-1 map = 85%,  reduce = 6%, Cumulative CPU 174.23 sec
2018-01-03 05:20:00,472 Stage-1 map = 100%,  reduce = 6%, Cumulative CPU 180.73 sec
2018-01-03 05:20:01,507 Stage-1 map = 100%,  reduce = 21%, Cumulative CPU 183.77 sec
2018-01-03 05:20:02,537 Stage-1 map = 100%,  reduce = 71%, Cumulative CPU 201.74 sec
2018-01-03 05:20:03,570 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 209.94 sec
MapReduce Total cumulative CPU time: 3 minutes 29 seconds 940 msec
Ended Job = job_1513599404024_163873
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163896, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163896/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163896
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:20:12,520 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:20:30,164 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.58 sec
2018-01-03 05:20:40,460 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.08 sec
2018-01-03 05:20:41,490 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 9.54 sec
2018-01-03 05:20:43,549 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 11.44 sec
2018-01-03 05:20:46,641 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.34 sec
MapReduce Total cumulative CPU time: 17 seconds 340 msec
Ended Job = job_1513599404024_163896
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163925, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163925/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163925
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:20:55,415 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:21:06,742 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.24 sec
2018-01-03 05:21:19,082 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.58 sec
MapReduce Total cumulative CPU time: 5 seconds 580 msec
Ended Job = job_1513599404024_163925
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 6  Reduce: 7   Cumulative CPU: 209.94 sec   HDFS Read: 649408568 HDFS Write: 307716 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.34 sec   HDFS Read: 38479675 HDFS Write: 21413 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.58 sec   HDFS Read: 29089 HDFS Write: 2450 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 52 seconds 860 msec
OK
Time taken: 115.536 seconds, Fetched: 356 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103052126_e72784ed-2f50-43c5-a835-da9ae66a3491
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_163952, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_163952/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_163952
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:21:37,962 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:21:47,421 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 9.43 sec
2018-01-03 05:21:50,535 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 13.77 sec
2018-01-03 05:21:53,637 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 14.71 sec
2018-01-03 05:21:56,737 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.6 sec
2018-01-03 05:21:59,835 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 16.07 sec
2018-01-03 05:22:02,930 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 16.45 sec
2018-01-03 05:22:06,023 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 16.98 sec
2018-01-03 05:22:09,120 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 17.93 sec
2018-01-03 05:22:12,211 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 18.45 sec
2018-01-03 05:22:15,354 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 19.34 sec
2018-01-03 05:22:18,447 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 19.87 sec
2018-01-03 05:22:21,534 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 20.47 sec
2018-01-03 05:22:24,624 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 21.04 sec
2018-01-03 05:22:26,685 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 21.81 sec
2018-01-03 05:22:29,770 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 22.41 sec
2018-01-03 05:22:33,883 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 23.77 sec
2018-01-03 05:22:36,970 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 24.81 sec
2018-01-03 05:22:39,026 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 25.36 sec
2018-01-03 05:22:45,196 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 56.45 sec
2018-01-03 05:22:48,278 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 57.32 sec
2018-01-03 05:22:49,319 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 58.57 sec
2018-01-03 05:22:57,550 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 63.0 sec
MapReduce Total cumulative CPU time: 1 minutes 3 seconds 0 msec
Ended Job = job_1513599404024_163952
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164001, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164001/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164001
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:23:03,228 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:23:08,387 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.92 sec
2018-01-03 05:23:19,701 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.52 sec
2018-01-03 05:23:22,786 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 15.85 sec
2018-01-03 05:23:24,841 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.44 sec
MapReduce Total cumulative CPU time: 21 seconds 440 msec
Ended Job = job_1513599404024_164001
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164013, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164013/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164013
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:23:33,523 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:23:37,851 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.94 sec
2018-01-03 05:23:42,992 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.12 sec
MapReduce Total cumulative CPU time: 6 seconds 120 msec
Ended Job = job_1513599404024_164013
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 63.0 sec   HDFS Read: 86366840 HDFS Write: 590072 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 21.44 sec   HDFS Read: 38760399 HDFS Write: 188264 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.12 sec   HDFS Read: 195897 HDFS Write: 6731 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 30 seconds 560 msec
OK
Time taken: 137.226 seconds, Fetched: 794 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103052350_99a7eb30-ff78-421c-a16e-d7b8b195bbf1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164025, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164025/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164025
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:24:02,856 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:24:14,246 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 9.04 sec
2018-01-03 05:24:17,350 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 11.84 sec
2018-01-03 05:24:20,448 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 13.21 sec
2018-01-03 05:24:23,548 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 14.1 sec
2018-01-03 05:24:26,643 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 14.8 sec
2018-01-03 05:24:28,705 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 14.8 sec
2018-01-03 05:24:31,795 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 16.18 sec
2018-01-03 05:24:34,893 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 16.96 sec
2018-01-03 05:24:37,978 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 18.3 sec
2018-01-03 05:24:42,096 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 18.56 sec
2018-01-03 05:24:45,181 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 21.83 sec
2018-01-03 05:24:48,267 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 22.7 sec
2018-01-03 05:24:51,363 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 23.51 sec
2018-01-03 05:24:53,421 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 24.43 sec
2018-01-03 05:24:56,513 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 25.19 sec
2018-01-03 05:24:59,595 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 26.87 sec
2018-01-03 05:25:02,679 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 27.62 sec
2018-01-03 05:25:03,707 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 28.83 sec
2018-01-03 05:25:10,906 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 33.49 sec
MapReduce Total cumulative CPU time: 33 seconds 490 msec
Ended Job = job_1513599404024_164025
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164051, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164051/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164051
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:25:16,640 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:25:22,821 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.59 sec
2018-01-03 05:25:24,881 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.08 sec
2018-01-03 05:25:30,028 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.83 sec
MapReduce Total cumulative CPU time: 16 seconds 830 msec
Ended Job = job_1513599404024_164051
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164058, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164058/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164058
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:25:36,703 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:25:46,052 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.68 sec
2018-01-03 05:25:53,251 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 10.12 sec
MapReduce Total cumulative CPU time: 10 seconds 120 msec
Ended Job = job_1513599404024_164058
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 33.49 sec   HDFS Read: 86366831 HDFS Write: 935183 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.83 sec   HDFS Read: 39105514 HDFS Write: 144841 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 10.12 sec   HDFS Read: 152479 HDFS Write: 3355 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 0 seconds 440 msec
OK
Time taken: 123.524 seconds, Fetched: 520 row(s)
开始执行20170926日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.39 seconds
Query ID = boss_20180103052601_437607de-e217-4320-8c97-fd34a77e04fd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164072, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164072/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164072
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 05:26:22,190 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:26:33,687 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 23.19 sec
2018-01-03 05:26:36,792 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 26.67 sec
2018-01-03 05:26:39,889 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 29.7 sec
2018-01-03 05:26:42,985 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 32.74 sec
2018-01-03 05:26:46,084 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 35.72 sec
2018-01-03 05:26:49,179 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 38.16 sec
2018-01-03 05:26:52,271 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 40.68 sec
2018-01-03 05:26:55,362 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 43.35 sec
2018-01-03 05:26:58,450 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 46.18 sec
2018-01-03 05:27:01,545 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 49.92 sec
2018-01-03 05:27:04,638 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 51.52 sec
2018-01-03 05:27:07,728 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 53.23 sec
2018-01-03 05:27:08,761 Stage-1 map = 75%,  reduce = 8%, Cumulative CPU 53.94 sec
2018-01-03 05:27:10,820 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 56.78 sec
2018-01-03 05:27:12,882 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 59.86 sec
2018-01-03 05:27:13,912 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 62.3 sec
2018-01-03 05:27:16,996 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 65.31 sec
2018-01-03 05:27:19,051 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 67.75 sec
2018-01-03 05:27:20,080 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 73.45 sec
2018-01-03 05:27:24,195 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 77.0 sec
2018-01-03 05:27:27,281 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 86.0 sec
MapReduce Total cumulative CPU time: 1 minutes 26 seconds 0 msec
Ended Job = job_1513599404024_164072
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164099, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164099/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164099
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:28:07,152 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:28:12,315 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.7 sec
2018-01-03 05:28:14,376 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.95 sec
2018-01-03 05:28:20,555 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.26 sec
MapReduce Total cumulative CPU time: 18 seconds 260 msec
Ended Job = job_1513599404024_164099
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164119, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164119/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164119
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:28:27,204 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:28:33,394 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.28 sec
2018-01-03 05:28:39,575 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.73 sec
MapReduce Total cumulative CPU time: 6 seconds 730 msec
Ended Job = job_1513599404024_164119
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 86.0 sec   HDFS Read: 187792818 HDFS Write: 1398158 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.26 sec   HDFS Read: 38741949 HDFS Write: 55088 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.73 sec   HDFS Read: 62763 HDFS Write: 2870 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 50 seconds 990 msec
OK
Time taken: 159.258 seconds, Fetched: 386 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.389 seconds
Query ID = boss_20180103052847_b55052f6-f1cc-4a1c-852a-e3829fbfb261
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164130, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164130/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164130
Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 7
2018-01-03 05:29:01,532 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:29:12,035 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 36.78 sec
2018-01-03 05:29:13,094 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 81.75 sec
2018-01-03 05:29:15,167 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 93.97 sec
2018-01-03 05:29:16,200 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 120.93 sec
2018-01-03 05:29:18,263 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 128.07 sec
2018-01-03 05:29:19,295 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 172.05 sec
2018-01-03 05:29:21,356 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 181.75 sec
2018-01-03 05:29:22,387 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 185.92 sec
2018-01-03 05:29:24,452 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 220.85 sec
2018-01-03 05:29:25,489 Stage-1 map = 66%,  reduce = 7%, Cumulative CPU 226.05 sec
2018-01-03 05:29:26,520 Stage-1 map = 68%,  reduce = 7%, Cumulative CPU 240.46 sec
2018-01-03 05:29:27,551 Stage-1 map = 74%,  reduce = 12%, Cumulative CPU 248.59 sec
2018-01-03 05:29:28,582 Stage-1 map = 74%,  reduce = 13%, Cumulative CPU 248.77 sec
2018-01-03 05:29:29,613 Stage-1 map = 82%,  reduce = 13%, Cumulative CPU 258.47 sec
2018-01-03 05:29:30,643 Stage-1 map = 82%,  reduce = 15%, Cumulative CPU 259.11 sec
2018-01-03 05:29:31,674 Stage-1 map = 82%,  reduce = 21%, Cumulative CPU 260.57 sec
2018-01-03 05:29:32,704 Stage-1 map = 88%,  reduce = 21%, Cumulative CPU 272.83 sec
2018-01-03 05:29:33,738 Stage-1 map = 88%,  reduce = 27%, Cumulative CPU 274.43 sec
2018-01-03 05:29:34,768 Stage-1 map = 90%,  reduce = 29%, Cumulative CPU 287.43 sec
2018-01-03 05:29:40,946 Stage-1 map = 91%,  reduce = 29%, Cumulative CPU 302.71 sec
2018-01-03 05:29:44,035 Stage-1 map = 92%,  reduce = 29%, Cumulative CPU 314.31 sec
2018-01-03 05:29:50,205 Stage-1 map = 100%,  reduce = 29%, Cumulative CPU 325.18 sec
2018-01-03 05:29:51,233 Stage-1 map = 100%,  reduce = 49%, Cumulative CPU 332.56 sec
2018-01-03 05:29:52,265 Stage-1 map = 100%,  reduce = 80%, Cumulative CPU 346.38 sec
2018-01-03 05:29:53,293 Stage-1 map = 100%,  reduce = 90%, Cumulative CPU 352.33 sec
2018-01-03 05:29:54,321 Stage-1 map = 100%,  reduce = 95%, Cumulative CPU 355.29 sec
2018-01-03 05:29:55,349 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 360.66 sec
MapReduce Total cumulative CPU time: 6 minutes 0 seconds 660 msec
Ended Job = job_1513599404024_164130
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164176, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164176/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164176
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:30:10,844 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:30:24,246 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.05 sec
2018-01-03 05:30:32,478 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.22 sec
2018-01-03 05:30:33,506 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.72 sec
MapReduce Total cumulative CPU time: 12 seconds 720 msec
Ended Job = job_1513599404024_164176
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164199, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164199/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164199
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:30:48,178 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:30:53,350 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.69 sec
2018-01-03 05:31:01,620 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.41 sec
MapReduce Total cumulative CPU time: 6 seconds 410 msec
Ended Job = job_1513599404024_164199
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 8  Reduce: 7   Cumulative CPU: 360.66 sec   HDFS Read: 660258982 HDFS Write: 292781 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.72 sec   HDFS Read: 37637882 HDFS Write: 20791 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.41 sec   HDFS Read: 28467 HDFS Write: 2414 SUCCESS
Total MapReduce CPU Time Spent: 6 minutes 19 seconds 790 msec
OK
Time taken: 135.336 seconds, Fetched: 347 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103053109_0f8f533a-6512-4366-88fa-a834eefe0323
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164210, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164210/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164210
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:31:23,678 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:31:48,513 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 13.62 sec
2018-01-03 05:31:51,606 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 14.77 sec
2018-01-03 05:31:54,707 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 17.5 sec
2018-01-03 05:31:57,799 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 18.38 sec
2018-01-03 05:32:00,913 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 19.87 sec
2018-01-03 05:32:04,005 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 20.89 sec
2018-01-03 05:32:07,093 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 23.04 sec
2018-01-03 05:32:10,181 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 23.84 sec
2018-01-03 05:32:13,272 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 24.52 sec
2018-01-03 05:32:17,388 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 25.43 sec
2018-01-03 05:32:20,482 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 26.68 sec
2018-01-03 05:32:23,570 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 27.23 sec
2018-01-03 05:32:26,659 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 28.42 sec
2018-01-03 05:32:29,747 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 29.62 sec
2018-01-03 05:32:32,837 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 30.44 sec
2018-01-03 05:32:35,921 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 31.05 sec
2018-01-03 05:32:39,061 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 32.74 sec
2018-01-03 05:32:42,147 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 33.19 sec
2018-01-03 05:32:45,232 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 33.41 sec
2018-01-03 05:32:48,311 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 33.94 sec
2018-01-03 05:32:51,394 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 34.72 sec
2018-01-03 05:32:54,477 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 35.45 sec
2018-01-03 05:32:57,556 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 38.05 sec
2018-01-03 05:33:00,640 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 38.58 sec
2018-01-03 05:33:01,679 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 39.96 sec
2018-01-03 05:33:07,850 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 45.23 sec
MapReduce Total cumulative CPU time: 45 seconds 230 msec
Ended Job = job_1513599404024_164210
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164282, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164282/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164282
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:33:13,615 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:33:25,950 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.89 sec
2018-01-03 05:33:34,169 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.08 sec
2018-01-03 05:33:36,222 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.21 sec
MapReduce Total cumulative CPU time: 18 seconds 210 msec
Ended Job = job_1513599404024_164282
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164302, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164302/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164302
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:33:42,114 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:33:46,235 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.82 sec
2018-01-03 05:33:52,417 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.76 sec
MapReduce Total cumulative CPU time: 5 seconds 760 msec
Ended Job = job_1513599404024_164302
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 45.23 sec   HDFS Read: 84486949 HDFS Write: 550969 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.21 sec   HDFS Read: 37894442 HDFS Write: 165200 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.76 sec   HDFS Read: 172837 HDFS Write: 6399 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 9 seconds 200 msec
OK
Time taken: 164.062 seconds, Fetched: 754 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103053400_c1cede26-01ba-4fac-9c06-a9e5b4403846
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164314, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164314/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164314
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:34:11,536 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:34:22,946 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 12.14 sec
2018-01-03 05:34:26,053 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 15.0 sec
2018-01-03 05:34:28,121 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.0 sec
2018-01-03 05:34:31,218 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 19.04 sec
2018-01-03 05:34:34,317 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 21.0 sec
2018-01-03 05:34:37,412 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 22.73 sec
2018-01-03 05:34:40,504 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 26.63 sec
2018-01-03 05:34:43,599 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 27.79 sec
2018-01-03 05:34:46,689 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 29.9 sec
2018-01-03 05:34:49,778 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 31.37 sec
2018-01-03 05:34:52,870 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 34.27 sec
2018-01-03 05:34:54,935 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 37.55 sec
2018-01-03 05:35:02,143 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 42.53 sec
MapReduce Total cumulative CPU time: 42 seconds 530 msec
Ended Job = job_1513599404024_164314
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164340, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164340/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164340
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:35:07,816 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:35:12,973 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.32 sec
2018-01-03 05:35:24,293 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 4.91 sec
2018-01-03 05:35:28,408 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 13.42 sec
2018-01-03 05:35:30,463 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.12 sec
MapReduce Total cumulative CPU time: 18 seconds 120 msec
Ended Job = job_1513599404024_164340
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164354, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164354/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164354
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:35:36,068 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:35:42,244 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.6 sec
2018-01-03 05:35:47,391 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.58 sec
MapReduce Total cumulative CPU time: 6 seconds 580 msec
Ended Job = job_1513599404024_164354
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 42.53 sec   HDFS Read: 84486939 HDFS Write: 907914 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.12 sec   HDFS Read: 38251387 HDFS Write: 142525 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.58 sec   HDFS Read: 150163 HDFS Write: 3360 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 7 seconds 230 msec
OK
Time taken: 108.26 seconds, Fetched: 510 row(s)
开始执行20170927日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.362 seconds
Query ID = boss_20180103053555_e2efde7d-3e17-4427-b69c-e00615faf2c6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164368, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164368/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164368
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 05:36:05,675 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:36:13,978 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 10.4 sec
2018-01-03 05:36:18,109 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 23.9 sec
2018-01-03 05:36:21,208 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 27.85 sec
2018-01-03 05:36:24,305 Stage-1 map = 58%,  reduce = 8%, Cumulative CPU 32.12 sec
2018-01-03 05:36:27,399 Stage-1 map = 62%,  reduce = 17%, Cumulative CPU 36.28 sec
2018-01-03 05:36:30,490 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 39.67 sec
2018-01-03 05:36:33,583 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 43.23 sec
2018-01-03 05:36:36,672 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 47.27 sec
2018-01-03 05:36:39,764 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 50.77 sec
2018-01-03 05:36:42,852 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 54.11 sec
2018-01-03 05:36:45,939 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 57.38 sec
2018-01-03 05:36:49,029 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 60.76 sec
2018-01-03 05:36:51,088 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 64.43 sec
2018-01-03 05:36:52,117 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 68.41 sec
2018-01-03 05:36:53,146 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 73.5 sec
MapReduce Total cumulative CPU time: 1 minutes 13 seconds 500 msec
Ended Job = job_1513599404024_164368
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164382, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164382/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164382
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:36:58,836 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:37:03,998 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.65 sec
2018-01-03 05:37:05,033 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.5 sec
2018-01-03 05:37:11,208 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.76 sec
MapReduce Total cumulative CPU time: 16 seconds 760 msec
Ended Job = job_1513599404024_164382
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164390, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164390/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164390
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:37:16,804 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:37:21,955 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.85 sec
2018-01-03 05:37:33,260 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.39 sec
MapReduce Total cumulative CPU time: 5 seconds 390 msec
Ended Job = job_1513599404024_164390
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 73.5 sec   HDFS Read: 191221768 HDFS Write: 1705366 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.76 sec   HDFS Read: 53465956 HDFS Write: 69916 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.39 sec   HDFS Read: 77591 HDFS Write: 3014 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 35 seconds 650 msec
OK
Time taken: 98.707 seconds, Fetched: 410 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.435 seconds
Query ID = boss_20180103053741_7b40cc85-8913-451f-8cf8-cb9bf6fbdccd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164402, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164402/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164402
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 6
2018-01-03 05:37:53,116 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:38:00,486 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 9.74 sec
2018-01-03 05:38:02,552 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 22.16 sec
2018-01-03 05:38:03,586 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 57.77 sec
2018-01-03 05:38:05,650 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 61.33 sec
2018-01-03 05:38:06,685 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 72.89 sec
2018-01-03 05:38:08,748 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 76.18 sec
2018-01-03 05:38:09,781 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 86.52 sec
2018-01-03 05:38:10,816 Stage-1 map = 39%,  reduce = 5%, Cumulative CPU 90.58 sec
2018-01-03 05:38:11,848 Stage-1 map = 60%,  reduce = 5%, Cumulative CPU 100.06 sec
2018-01-03 05:38:12,880 Stage-1 map = 62%,  reduce = 5%, Cumulative CPU 104.13 sec
2018-01-03 05:38:13,911 Stage-1 map = 62%,  reduce = 19%, Cumulative CPU 104.69 sec
2018-01-03 05:38:15,975 Stage-1 map = 64%,  reduce = 19%, Cumulative CPU 107.83 sec
2018-01-03 05:38:18,036 Stage-1 map = 66%,  reduce = 19%, Cumulative CPU 121.94 sec
2018-01-03 05:38:19,066 Stage-1 map = 67%,  reduce = 19%, Cumulative CPU 125.23 sec
2018-01-03 05:38:21,125 Stage-1 map = 69%,  reduce = 19%, Cumulative CPU 133.43 sec
2018-01-03 05:38:22,155 Stage-1 map = 74%,  reduce = 19%, Cumulative CPU 134.58 sec
2018-01-03 05:38:23,184 Stage-1 map = 74%,  reduce = 24%, Cumulative CPU 135.05 sec
2018-01-03 05:38:24,213 Stage-1 map = 79%,  reduce = 24%, Cumulative CPU 151.06 sec
2018-01-03 05:38:27,303 Stage-1 map = 83%,  reduce = 24%, Cumulative CPU 158.61 sec
2018-01-03 05:38:30,390 Stage-1 map = 93%,  reduce = 24%, Cumulative CPU 166.97 sec
2018-01-03 05:38:32,448 Stage-1 map = 93%,  reduce = 29%, Cumulative CPU 168.9 sec
2018-01-03 05:38:33,476 Stage-1 map = 94%,  reduce = 29%, Cumulative CPU 171.99 sec
2018-01-03 05:38:35,535 Stage-1 map = 100%,  reduce = 29%, Cumulative CPU 175.52 sec
2018-01-03 05:38:36,563 Stage-1 map = 100%,  reduce = 52%, Cumulative CPU 183.69 sec
2018-01-03 05:38:37,592 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 200.2 sec
MapReduce Total cumulative CPU time: 3 minutes 20 seconds 200 msec
Ended Job = job_1513599404024_164402
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164417, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164417/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164417
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:38:51,270 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:39:00,533 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.16 sec
2018-01-03 05:39:03,618 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.3 sec
2018-01-03 05:39:06,701 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.71 sec
MapReduce Total cumulative CPU time: 15 seconds 710 msec
Ended Job = job_1513599404024_164417
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164427, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164427/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164427
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:39:15,640 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:39:21,082 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.77 sec
2018-01-03 05:39:34,465 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.83 sec
MapReduce Total cumulative CPU time: 4 seconds 830 msec
Ended Job = job_1513599404024_164427
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 6   Cumulative CPU: 200.2 sec   HDFS Read: 637053784 HDFS Write: 297714 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.71 sec   HDFS Read: 52059352 HDFS Write: 22324 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.83 sec   HDFS Read: 30000 HDFS Write: 2413 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 40 seconds 740 msec
OK
Time taken: 114.166 seconds, Fetched: 340 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103053942_821b3505-0b27-45a2-add1-d36d43bccef1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164439, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164439/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164439
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:39:54,188 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:40:06,654 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 10.89 sec
2018-01-03 05:40:09,751 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 13.57 sec
2018-01-03 05:40:12,843 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 15.54 sec
2018-01-03 05:40:15,937 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 17.17 sec
2018-01-03 05:40:19,027 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 18.01 sec
2018-01-03 05:40:22,115 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 18.93 sec
2018-01-03 05:40:25,209 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 20.26 sec
2018-01-03 05:40:28,299 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 21.58 sec
2018-01-03 05:40:31,388 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 22.33 sec
2018-01-03 05:40:34,477 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 23.23 sec
2018-01-03 05:40:37,561 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 24.09 sec
2018-01-03 05:40:40,649 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 25.1 sec
2018-01-03 05:40:43,737 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 25.79 sec
2018-01-03 05:40:46,824 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 26.81 sec
2018-01-03 05:40:49,908 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 27.29 sec
2018-01-03 05:40:56,078 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 28.59 sec
2018-01-03 05:40:59,163 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 29.06 sec
2018-01-03 05:41:02,247 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 29.82 sec
2018-01-03 05:41:05,332 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 30.36 sec
2018-01-03 05:41:08,414 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 30.62 sec
2018-01-03 05:41:11,510 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 30.93 sec
2018-01-03 05:41:14,591 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 32.83 sec
2018-01-03 05:41:17,671 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 33.45 sec
2018-01-03 05:41:20,754 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 35.56 sec
2018-01-03 05:41:27,943 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.69 sec
MapReduce Total cumulative CPU time: 39 seconds 690 msec
Ended Job = job_1513599404024_164439
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164470, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164470/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164470
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:41:33,838 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:41:39,010 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.67 sec
2018-01-03 05:41:40,042 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.6 sec
2018-01-03 05:41:47,259 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.93 sec
MapReduce Total cumulative CPU time: 13 seconds 930 msec
Ended Job = job_1513599404024_164470
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164477, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164477/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164477
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:42:03,935 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:42:10,151 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.03 sec
2018-01-03 05:42:15,307 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.15 sec
MapReduce Total cumulative CPU time: 7 seconds 150 msec
Ended Job = job_1513599404024_164477
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 39.69 sec   HDFS Read: 89802701 HDFS Write: 591151 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.93 sec   HDFS Read: 52351423 HDFS Write: 200514 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.15 sec   HDFS Read: 208151 HDFS Write: 6603 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 0 seconds 770 msec
OK
Time taken: 154.164 seconds, Fetched: 775 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.397 seconds
Query ID = boss_20180103054223_cf559cff-e033-4f68-9f72-9bb734eec9bd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164486, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164486/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164486
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:42:34,937 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:42:45,295 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.24 sec
2018-01-03 05:42:48,395 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 13.58 sec
2018-01-03 05:42:51,489 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.0 sec
2018-01-03 05:42:54,579 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 16.37 sec
2018-01-03 05:42:57,672 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 16.82 sec
2018-01-03 05:43:00,762 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 17.68 sec
2018-01-03 05:43:03,854 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 19.0 sec
2018-01-03 05:43:06,945 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 20.38 sec
2018-01-03 05:43:10,030 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 21.39 sec
2018-01-03 05:43:13,116 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 22.42 sec
2018-01-03 05:43:16,205 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 23.23 sec
2018-01-03 05:43:19,289 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 24.05 sec
2018-01-03 05:43:22,375 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 25.15 sec
2018-01-03 05:43:25,461 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 25.85 sec
2018-01-03 05:43:28,545 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 27.03 sec
2018-01-03 05:43:31,627 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 27.83 sec
2018-01-03 05:43:34,713 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 28.92 sec
2018-01-03 05:43:37,795 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 29.72 sec
2018-01-03 05:43:39,853 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 32.17 sec
2018-01-03 05:43:42,938 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 34.59 sec
2018-01-03 05:43:49,105 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 40.72 sec
MapReduce Total cumulative CPU time: 40 seconds 720 msec
Ended Job = job_1513599404024_164486
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164522, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164522/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164522
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:43:54,780 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:44:00,965 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.45 sec
2018-01-03 05:44:09,198 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.5 sec
2018-01-03 05:44:15,364 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.02 sec
MapReduce Total cumulative CPU time: 16 seconds 20 msec
Ended Job = job_1513599404024_164522
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164539, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164539/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164539
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:44:24,049 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:44:28,282 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.81 sec
2018-01-03 05:44:40,613 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 10.31 sec
MapReduce Total cumulative CPU time: 10 seconds 310 msec
Ended Job = job_1513599404024_164539
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 40.72 sec   HDFS Read: 89802691 HDFS Write: 914400 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.02 sec   HDFS Read: 52674672 HDFS Write: 160803 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 10.31 sec   HDFS Read: 168441 HDFS Write: 3498 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 7 seconds 50 msec
OK
Time taken: 138.457 seconds, Fetched: 521 row(s)
开始执行20170928日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.367 seconds
Query ID = boss_20180103054448_5328e0ca-9bca-45ef-a22e-1d302fce3471
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164561, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164561/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164561
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 05:44:57,523 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:45:05,844 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 12.98 sec
2018-01-03 05:45:08,984 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 22.33 sec
2018-01-03 05:45:12,146 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 25.17 sec
2018-01-03 05:45:15,246 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 28.14 sec
2018-01-03 05:45:17,319 Stage-1 map = 54%,  reduce = 8%, Cumulative CPU 28.83 sec
2018-01-03 05:45:18,752 Stage-1 map = 56%,  reduce = 8%, Cumulative CPU 31.83 sec
2018-01-03 05:45:20,825 Stage-1 map = 58%,  reduce = 8%, Cumulative CPU 35.09 sec
2018-01-03 05:45:23,758 Stage-1 map = 61%,  reduce = 8%, Cumulative CPU 38.23 sec
2018-01-03 05:45:24,790 Stage-1 map = 61%,  reduce = 17%, Cumulative CPU 39.13 sec
2018-01-03 05:45:26,853 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 42.36 sec
2018-01-03 05:45:30,317 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 44.47 sec
2018-01-03 05:45:33,419 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 48.52 sec
2018-01-03 05:45:36,518 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 51.5 sec
2018-01-03 05:45:39,613 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 55.26 sec
2018-01-03 05:45:42,709 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 59.07 sec
2018-01-03 05:45:45,807 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 62.01 sec
2018-01-03 05:45:49,025 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 65.37 sec
2018-01-03 05:45:51,140 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 68.82 sec
2018-01-03 05:45:54,234 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 72.28 sec
2018-01-03 05:45:55,263 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 72.86 sec
2018-01-03 05:45:56,291 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 78.28 sec
2018-01-03 05:45:59,379 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 90.85 sec
2018-01-03 05:46:00,406 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 95.73 sec
MapReduce Total cumulative CPU time: 1 minutes 35 seconds 730 msec
Ended Job = job_1513599404024_164561
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164587, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164587/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164587
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:46:08,671 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:46:14,874 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.15 sec
2018-01-03 05:46:16,938 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.7 sec
2018-01-03 05:46:21,060 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.07 sec
MapReduce Total cumulative CPU time: 20 seconds 70 msec
Ended Job = job_1513599404024_164587
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164601, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164601/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164601
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:46:32,825 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:46:38,010 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.18 sec
2018-01-03 05:46:47,345 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.73 sec
MapReduce Total cumulative CPU time: 7 seconds 730 msec
Ended Job = job_1513599404024_164601
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 95.73 sec   HDFS Read: 186608312 HDFS Write: 1613456 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.07 sec   HDFS Read: 48250138 HDFS Write: 63376 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.73 sec   HDFS Read: 71051 HDFS Write: 2915 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 3 seconds 530 msec
OK
Time taken: 119.821 seconds, Fetched: 389 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.399 seconds
Query ID = boss_20180103054655_93177f6f-c52d-4d6a-bc93-02ce17cf4ae5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164614, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164614/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164614
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 6
2018-01-03 05:47:05,912 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:47:16,307 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 21.9 sec
2018-01-03 05:47:17,344 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 44.58 sec
2018-01-03 05:47:19,417 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 51.35 sec
2018-01-03 05:47:20,451 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 59.8 sec
2018-01-03 05:47:21,487 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 81.01 sec
2018-01-03 05:47:22,521 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 88.86 sec
2018-01-03 05:47:23,555 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 95.67 sec
2018-01-03 05:47:24,589 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 120.93 sec
2018-01-03 05:47:25,623 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 123.93 sec
2018-01-03 05:47:26,654 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 133.21 sec
2018-01-03 05:47:27,685 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 150.33 sec
2018-01-03 05:47:28,720 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 153.16 sec
2018-01-03 05:47:29,751 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 156.24 sec
2018-01-03 05:47:30,784 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 167.76 sec
2018-01-03 05:47:32,849 Stage-1 map = 85%,  reduce = 3%, Cumulative CPU 173.85 sec
2018-01-03 05:47:33,882 Stage-1 map = 87%,  reduce = 13%, Cumulative CPU 177.61 sec
2018-01-03 05:47:34,914 Stage-1 map = 87%,  reduce = 17%, Cumulative CPU 179.45 sec
2018-01-03 05:47:35,947 Stage-1 map = 93%,  reduce = 24%, Cumulative CPU 184.27 sec
2018-01-03 05:47:36,979 Stage-1 map = 93%,  reduce = 26%, Cumulative CPU 196.9 sec
2018-01-03 05:47:38,014 Stage-1 map = 100%,  reduce = 27%, Cumulative CPU 198.43 sec
2018-01-03 05:47:39,045 Stage-1 map = 100%,  reduce = 64%, Cumulative CPU 208.9 sec
2018-01-03 05:47:40,075 Stage-1 map = 100%,  reduce = 88%, Cumulative CPU 219.12 sec
2018-01-03 05:47:41,106 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 220.84 sec
2018-01-03 05:47:42,136 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 223.55 sec
MapReduce Total cumulative CPU time: 3 minutes 43 seconds 550 msec
Ended Job = job_1513599404024_164614
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164631, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164631/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164631
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:47:48,874 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:47:54,047 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.53 sec
2018-01-03 05:48:08,483 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.82 sec
2018-01-03 05:48:10,545 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.56 sec
MapReduce Total cumulative CPU time: 16 seconds 560 msec
Ended Job = job_1513599404024_164631
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164647, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164647/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164647
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:48:17,258 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:48:21,485 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.49 sec
2018-01-03 05:48:27,676 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.76 sec
MapReduce Total cumulative CPU time: 5 seconds 760 msec
Ended Job = job_1513599404024_164647
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 6   Cumulative CPU: 223.55 sec   HDFS Read: 616519992 HDFS Write: 293450 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.56 sec   HDFS Read: 46931180 HDFS Write: 22275 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.76 sec   HDFS Read: 29951 HDFS Write: 2441 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 5 seconds 870 msec
OK
Time taken: 93.392 seconds, Fetched: 348 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103054835_ec4fbd61-f487-4479-995e-bddb47775d84
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164658, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164658/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164658
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:48:47,373 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:48:57,729 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 10.87 sec
2018-01-03 05:49:00,829 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 12.16 sec
2018-01-03 05:49:03,946 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 14.58 sec
2018-01-03 05:49:07,038 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 15.61 sec
2018-01-03 05:49:10,132 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 16.53 sec
2018-01-03 05:49:13,237 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 17.63 sec
2018-01-03 05:49:16,103 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 18.71 sec
2018-01-03 05:49:19,201 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 19.77 sec
2018-01-03 05:49:22,293 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 20.31 sec
2018-01-03 05:49:25,378 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 22.66 sec
2018-01-03 05:49:28,470 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 23.44 sec
2018-01-03 05:49:31,555 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 24.22 sec
2018-01-03 05:49:34,642 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 24.78 sec
2018-01-03 05:49:37,729 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 25.73 sec
2018-01-03 05:49:40,813 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 26.69 sec
2018-01-03 05:49:43,896 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 27.37 sec
2018-01-03 05:49:46,984 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 27.98 sec
2018-01-03 05:49:49,044 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 27.98 sec
2018-01-03 05:49:52,127 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 29.91 sec
2018-01-03 05:49:55,212 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 30.49 sec
2018-01-03 05:49:58,293 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 30.98 sec
2018-01-03 05:50:01,375 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 31.59 sec
2018-01-03 05:50:04,459 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 31.99 sec
2018-01-03 05:50:07,539 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 32.9 sec
2018-01-03 05:50:10,620 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 34.45 sec
2018-01-03 05:50:13,703 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 36.43 sec
2018-01-03 05:50:19,866 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 40.55 sec
MapReduce Total cumulative CPU time: 40 seconds 550 msec
Ended Job = job_1513599404024_164658
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164700, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164700/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164700
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:50:26,639 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:50:32,827 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.19 sec
2018-01-03 05:50:37,975 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.58 sec
MapReduce Total cumulative CPU time: 16 seconds 580 msec
Ended Job = job_1513599404024_164700
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164707, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164707/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164707
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:50:43,600 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:50:56,955 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.51 sec
2018-01-03 05:51:03,122 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.99 sec
MapReduce Total cumulative CPU time: 7 seconds 990 msec
Ended Job = job_1513599404024_164707
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 40.55 sec   HDFS Read: 85207330 HDFS Write: 603125 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.58 sec   HDFS Read: 47239489 HDFS Write: 182573 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.99 sec   HDFS Read: 190210 HDFS Write: 6423 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 5 seconds 120 msec
OK
Time taken: 148.776 seconds, Fetched: 765 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103055110_01a7782a-715e-4ef3-bb63-a56ebe315411
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164720, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164720/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164720
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 05:51:22,021 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:51:32,410 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 7.84 sec
2018-01-03 05:51:35,518 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 8.65 sec
2018-01-03 05:51:38,618 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 9.7 sec
2018-01-03 05:51:41,714 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 11.57 sec
2018-01-03 05:51:44,813 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 12.86 sec
2018-01-03 05:51:47,907 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 13.09 sec
2018-01-03 05:51:49,967 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 13.5 sec
2018-01-03 05:51:53,064 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 14.07 sec
2018-01-03 05:51:56,155 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 14.7 sec
2018-01-03 05:51:59,246 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 16.0 sec
2018-01-03 05:52:02,340 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 16.43 sec
2018-01-03 05:52:05,428 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 17.46 sec
2018-01-03 05:52:08,515 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 17.96 sec
2018-01-03 05:52:11,603 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 18.29 sec
2018-01-03 05:52:14,688 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 19.69 sec
2018-01-03 05:52:17,774 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 20.43 sec
2018-01-03 05:52:20,861 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 20.99 sec
2018-01-03 05:52:23,946 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 23.44 sec
2018-01-03 05:52:26,004 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.07 sec
2018-01-03 05:52:31,155 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.26 sec
MapReduce Total cumulative CPU time: 30 seconds 260 msec
Ended Job = job_1513599404024_164720
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164752, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164752/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164752
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:52:42,012 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:52:47,187 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.57 sec
2018-01-03 05:52:55,423 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.73 sec
2018-01-03 05:52:57,483 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 13.44 sec
2018-01-03 05:52:58,512 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.3 sec
MapReduce Total cumulative CPU time: 17 seconds 300 msec
Ended Job = job_1513599404024_164752
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164767, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164767/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164767
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:53:04,205 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:53:46,573 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.26 sec
2018-01-03 05:54:17,601 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 5.62 sec
2018-01-03 05:54:18,631 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 11.77 sec
MapReduce Total cumulative CPU time: 11 seconds 770 msec
Ended Job = job_1513599404024_164767
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.26 sec   HDFS Read: 85207319 HDFS Write: 947677 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.3 sec   HDFS Read: 47584037 HDFS Write: 142954 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 11.77 sec   HDFS Read: 150588 HDFS Write: 3640 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 330 msec
OK
Time taken: 191.236 seconds, Fetched: 504 row(s)
开始执行20170929日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103055437_e102a322-0fb5-453e-8f72-33560aa9d295
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164804, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164804/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164804
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 05:55:28,031 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:55:38,412 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 25.24 sec
2018-01-03 05:55:39,447 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 26.5 sec
2018-01-03 05:55:41,525 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 30.59 sec
2018-01-03 05:55:44,625 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 34.29 sec
2018-01-03 05:55:47,718 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 37.87 sec
2018-01-03 05:55:50,816 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 41.8 sec
2018-01-03 05:55:53,911 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 45.39 sec
2018-01-03 05:55:57,003 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 48.61 sec
2018-01-03 05:56:00,103 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 51.71 sec
2018-01-03 05:56:03,201 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 54.96 sec
2018-01-03 05:56:05,271 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 59.44 sec
2018-01-03 05:56:06,303 Stage-1 map = 79%,  reduce = 8%, Cumulative CPU 61.94 sec
2018-01-03 05:56:07,335 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 62.83 sec
2018-01-03 05:56:09,399 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 65.4 sec
2018-01-03 05:56:12,496 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 66.88 sec
2018-01-03 05:56:14,558 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 72.6 sec
2018-01-03 05:56:17,649 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 76.6 sec
2018-01-03 05:56:20,742 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 79.88 sec
2018-01-03 05:56:26,918 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 95.03 sec
2018-01-03 05:56:34,124 Stage-1 map = 100%,  reduce = 87%, Cumulative CPU 110.07 sec
2018-01-03 05:56:37,209 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 115.83 sec
2018-01-03 05:56:41,326 Stage-1 map = 100%,  reduce = 95%, Cumulative CPU 121.89 sec
2018-01-03 05:56:45,435 Stage-1 map = 100%,  reduce = 98%, Cumulative CPU 125.4 sec
2018-01-03 05:56:48,522 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 130.42 sec
MapReduce Total cumulative CPU time: 2 minutes 10 seconds 420 msec
Ended Job = job_1513599404024_164804
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164851, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164851/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164851
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:56:57,332 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:57:02,494 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.99 sec
2018-01-03 05:57:04,553 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.05 sec
2018-01-03 05:57:08,676 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.44 sec
MapReduce Total cumulative CPU time: 19 seconds 440 msec
Ended Job = job_1513599404024_164851
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164874, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164874/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164874
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:57:24,350 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:57:29,527 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.32 sec
2018-01-03 05:57:37,751 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.11 sec
MapReduce Total cumulative CPU time: 8 seconds 110 msec
Ended Job = job_1513599404024_164874
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 131.54 sec   HDFS Read: 191233012 HDFS Write: 1840208 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.44 sec   HDFS Read: 46946477 HDFS Write: 67686 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.11 sec   HDFS Read: 75361 HDFS Write: 2893 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 39 seconds 90 msec
OK
Time taken: 181.68 seconds, Fetched: 402 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.395 seconds
Query ID = boss_20180103055745_b8213f00-f1d8-4e6f-a730-f5d6262afc4a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164886, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164886/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164886
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 6
2018-01-03 05:57:55,902 Stage-1 map = 0%,  reduce = 0%
2018-01-03 05:58:06,298 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 11.85 sec
2018-01-03 05:58:07,332 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 61.66 sec
2018-01-03 05:58:08,368 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 73.12 sec
2018-01-03 05:58:10,442 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 108.36 sec
2018-01-03 05:58:11,477 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 116.32 sec
2018-01-03 05:58:12,510 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 116.32 sec
2018-01-03 05:58:13,543 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 129.77 sec
2018-01-03 05:58:14,576 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 152.18 sec
2018-01-03 05:58:16,638 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 176.56 sec
2018-01-03 05:58:17,668 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 180.85 sec
2018-01-03 05:58:18,704 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 193.62 sec
2018-01-03 05:58:19,736 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 196.47 sec
2018-01-03 05:58:20,767 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 202.65 sec
2018-01-03 05:58:21,797 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 208.08 sec
2018-01-03 05:58:22,828 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 220.58 sec
2018-01-03 05:58:23,858 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 228.94 sec
2018-01-03 05:58:24,888 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 239.01 sec
2018-01-03 05:58:25,918 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 241.07 sec
2018-01-03 05:58:26,948 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 247.51 sec
2018-01-03 05:58:27,981 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 250.32 sec
2018-01-03 05:58:29,010 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 252.46 sec
2018-01-03 05:58:30,045 Stage-1 map = 88%,  reduce = 8%, Cumulative CPU 257.91 sec
2018-01-03 05:58:32,107 Stage-1 map = 94%,  reduce = 16%, Cumulative CPU 265.15 sec
2018-01-03 05:58:33,138 Stage-1 map = 94%,  reduce = 17%, Cumulative CPU 265.37 sec
2018-01-03 05:58:35,198 Stage-1 map = 100%,  reduce = 19%, Cumulative CPU 268.73 sec
2018-01-03 05:58:36,229 Stage-1 map = 100%,  reduce = 46%, Cumulative CPU 279.39 sec
2018-01-03 05:58:37,263 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 297.5 sec
2018-01-03 05:58:46,523 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 309.11 sec
MapReduce Total cumulative CPU time: 5 minutes 9 seconds 110 msec
Ended Job = job_1513599404024_164886
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164914, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164914/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164914
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 05:58:54,635 Stage-2 map = 0%,  reduce = 0%
2018-01-03 05:59:00,849 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.96 sec
2018-01-03 05:59:14,316 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.98 sec
2018-01-03 05:59:16,381 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 16.51 sec
2018-01-03 05:59:20,513 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 19.09 sec
2018-01-03 05:59:24,649 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 26.39 sec
MapReduce Total cumulative CPU time: 26 seconds 390 msec
Ended Job = job_1513599404024_164914
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164922, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164922/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164922
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 05:59:36,972 Stage-3 map = 0%,  reduce = 0%
2018-01-03 05:59:53,426 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.78 sec
2018-01-03 06:00:19,148 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 15.0 sec
2018-01-03 06:00:21,200 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 16.89 sec
MapReduce Total cumulative CPU time: 16 seconds 890 msec
Ended Job = job_1513599404024_164922
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 6   Cumulative CPU: 309.11 sec   HDFS Read: 633290658 HDFS Write: 274778 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 26.39 sec   HDFS Read: 45382095 HDFS Write: 20772 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 16.89 sec   HDFS Read: 28448 HDFS Write: 2477 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 52 seconds 390 msec
OK
Time taken: 156.73 seconds, Fetched: 368 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103060028_fd9568d9-31fa-4f90-9865-73b0087a7eb6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164938, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164938/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164938
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:00:41,669 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:00:56,140 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 6.37 sec
2018-01-03 06:00:59,229 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 8.78 sec
2018-01-03 06:01:02,322 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 9.77 sec
2018-01-03 06:01:05,409 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.14 sec
2018-01-03 06:01:08,496 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 12.88 sec
2018-01-03 06:01:11,589 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 14.33 sec
2018-01-03 06:01:14,679 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.99 sec
2018-01-03 06:01:17,765 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 16.42 sec
2018-01-03 06:01:20,859 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 16.97 sec
2018-01-03 06:01:23,943 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 17.54 sec
2018-01-03 06:01:27,027 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 18.05 sec
2018-01-03 06:01:30,112 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 18.56 sec
2018-01-03 06:01:36,276 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 19.2 sec
2018-01-03 06:01:39,359 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 20.62 sec
2018-01-03 06:01:42,439 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 21.2 sec
2018-01-03 06:01:44,493 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 21.38 sec
2018-01-03 06:01:47,578 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 21.79 sec
2018-01-03 06:01:53,739 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 22.64 sec
2018-01-03 06:01:56,822 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 22.99 sec
2018-01-03 06:01:59,901 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 23.96 sec
2018-01-03 06:02:02,979 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 25.0 sec
2018-01-03 06:02:06,060 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 25.32 sec
2018-01-03 06:02:09,137 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 25.6 sec
2018-01-03 06:02:12,421 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 26.04 sec
2018-01-03 06:02:15,505 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 26.49 sec
2018-01-03 06:02:18,585 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 27.16 sec
2018-01-03 06:02:21,662 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 28.92 sec
2018-01-03 06:02:24,743 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 29.03 sec
2018-01-03 06:02:26,793 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 30.03 sec
2018-01-03 06:02:42,188 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 34.58 sec
MapReduce Total cumulative CPU time: 34 seconds 580 msec
Ended Job = job_1513599404024_164938
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164975, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164975/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164975
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:03:18,491 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:03:26,732 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.6 sec
2018-01-03 06:03:36,006 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.17 sec
2018-01-03 06:03:40,129 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.35 sec
MapReduce Total cumulative CPU time: 21 seconds 350 msec
Ended Job = job_1513599404024_164975
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_164987, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_164987/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_164987
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:03:52,152 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:04:03,493 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.96 sec
2018-01-03 06:04:15,856 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 10.87 sec
MapReduce Total cumulative CPU time: 10 seconds 870 msec
Ended Job = job_1513599404024_164987
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 34.58 sec   HDFS Read: 83961243 HDFS Write: 570865 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 21.35 sec   HDFS Read: 45676816 HDFS Write: 190612 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 10.87 sec   HDFS Read: 198249 HDFS Write: 6200 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 6 seconds 800 msec
OK
Time taken: 227.955 seconds, Fetched: 741 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103060423_6ceadcab-9827-4627-8075-483ecdcb9805
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165000, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165000/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165000
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:04:36,692 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:04:52,345 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 9.33 sec
2018-01-03 06:04:58,548 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.33 sec
2018-01-03 06:05:01,640 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.93 sec
2018-01-03 06:05:04,729 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 29.51 sec
2018-01-03 06:05:07,823 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 31.81 sec
2018-01-03 06:05:10,913 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 33.24 sec
2018-01-03 06:05:13,999 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 34.02 sec
2018-01-03 06:05:17,089 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 34.88 sec
2018-01-03 06:05:20,175 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 35.92 sec
2018-01-03 06:05:23,262 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 36.82 sec
2018-01-03 06:05:26,354 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 38.24 sec
2018-01-03 06:05:30,468 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 40.1 sec
2018-01-03 06:05:36,645 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 59.04 sec
2018-01-03 06:05:39,728 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 60.02 sec
2018-01-03 06:05:42,813 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 60.89 sec
2018-01-03 06:05:45,899 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 61.92 sec
2018-01-03 06:05:48,981 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 62.72 sec
2018-01-03 06:05:52,062 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 63.45 sec
2018-01-03 06:05:55,147 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 63.99 sec
2018-01-03 06:05:58,227 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 64.27 sec
2018-01-03 06:06:01,305 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 65.56 sec
2018-01-03 06:06:04,388 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 66.0 sec
2018-01-03 06:06:07,466 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 66.65 sec
2018-01-03 06:06:10,546 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 67.61 sec
2018-01-03 06:06:13,629 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 68.02 sec
2018-01-03 06:06:16,708 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 71.06 sec
2018-01-03 06:06:19,788 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 73.27 sec
2018-01-03 06:06:25,040 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 77.68 sec
MapReduce Total cumulative CPU time: 1 minutes 17 seconds 680 msec
Ended Job = job_1513599404024_165000
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165038, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165038/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165038
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:06:47,853 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:06:54,059 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.98 sec
2018-01-03 06:07:03,336 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.33 sec
MapReduce Total cumulative CPU time: 17 seconds 330 msec
Ended Job = job_1513599404024_165038
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165047, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165047/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165047
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:07:18,155 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:07:23,312 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.48 sec
2018-01-03 06:07:32,595 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.1 sec
MapReduce Total cumulative CPU time: 8 seconds 100 msec
Ended Job = job_1513599404024_165047
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 77.68 sec   HDFS Read: 83961233 HDFS Write: 1023208 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.33 sec   HDFS Read: 46129159 HDFS Write: 134831 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.1 sec   HDFS Read: 142469 HDFS Write: 3290 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 43 seconds 110 msec
OK
Time taken: 190.049 seconds, Fetched: 502 row(s)
开始执行20170930日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.368 seconds
Query ID = boss_20180103060740_208743cf-48cc-4362-ad70-11c8b29608d5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165059, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165059/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165059
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 06:07:49,965 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:08:00,340 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 14.6 sec
2018-01-03 06:08:01,377 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 25.85 sec
2018-01-03 06:08:03,447 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 30.19 sec
2018-01-03 06:08:04,482 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 33.66 sec
2018-01-03 06:08:06,551 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 38.12 sec
2018-01-03 06:08:07,586 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 41.68 sec
2018-01-03 06:08:10,721 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 44.95 sec
2018-01-03 06:08:12,791 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 47.94 sec
2018-01-03 06:08:15,887 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 51.0 sec
2018-01-03 06:08:18,985 Stage-1 map = 67%,  reduce = 8%, Cumulative CPU 54.74 sec
2018-01-03 06:08:22,084 Stage-1 map = 69%,  reduce = 8%, Cumulative CPU 59.37 sec
2018-01-03 06:08:25,177 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 62.94 sec
2018-01-03 06:08:28,268 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 66.01 sec
2018-01-03 06:08:31,366 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 68.66 sec
2018-01-03 06:08:34,457 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 72.13 sec
2018-01-03 06:08:37,548 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 75.15 sec
2018-01-03 06:08:39,613 Stage-1 map = 100%,  reduce = 26%, Cumulative CPU 77.41 sec
2018-01-03 06:08:41,675 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 83.74 sec
2018-01-03 06:08:43,736 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 96.19 sec
MapReduce Total cumulative CPU time: 1 minutes 36 seconds 190 msec
Ended Job = job_1513599404024_165059
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165074, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165074/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165074
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:08:57,489 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:09:02,653 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.37 sec
2018-01-03 06:09:06,786 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.11 sec
2018-01-03 06:09:08,854 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.66 sec
MapReduce Total cumulative CPU time: 17 seconds 660 msec
Ended Job = job_1513599404024_165074
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165084, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165084/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165084
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:09:15,534 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:09:20,691 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.17 sec
2018-01-03 06:09:26,866 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.62 sec
MapReduce Total cumulative CPU time: 5 seconds 620 msec
Ended Job = job_1513599404024_165084
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 96.19 sec   HDFS Read: 218982948 HDFS Write: 1766436 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.66 sec   HDFS Read: 49477198 HDFS Write: 65957 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.62 sec   HDFS Read: 73632 HDFS Write: 3049 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 59 seconds 470 msec
OK
Time taken: 107.177 seconds, Fetched: 411 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.394 seconds
Query ID = boss_20180103060934_645b98f0-93d9-432c-b382-b06380826b4b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165092, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165092/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165092
Hadoop job information for Stage-1: number of mappers: 9; number of reducers: 7
2018-01-03 06:09:44,425 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:09:54,849 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 38.24 sec
2018-01-03 06:09:55,889 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 89.37 sec
2018-01-03 06:09:57,966 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 111.4 sec
2018-01-03 06:09:59,001 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 115.19 sec
2018-01-03 06:10:01,067 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 132.45 sec
2018-01-03 06:10:02,099 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 137.08 sec
2018-01-03 06:10:03,132 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 163.9 sec
2018-01-03 06:10:04,165 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 170.27 sec
2018-01-03 06:10:05,196 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 173.46 sec
2018-01-03 06:10:06,236 Stage-1 map = 80%,  reduce = 2%, Cumulative CPU 187.41 sec
2018-01-03 06:10:07,269 Stage-1 map = 92%,  reduce = 4%, Cumulative CPU 193.03 sec
2018-01-03 06:10:08,301 Stage-1 map = 92%,  reduce = 11%, Cumulative CPU 194.58 sec
2018-01-03 06:10:09,333 Stage-1 map = 93%,  reduce = 13%, Cumulative CPU 197.79 sec
2018-01-03 06:10:10,366 Stage-1 map = 93%,  reduce = 16%, Cumulative CPU 198.03 sec
2018-01-03 06:10:11,397 Stage-1 map = 93%,  reduce = 17%, Cumulative CPU 198.13 sec
2018-01-03 06:10:12,430 Stage-1 map = 95%,  reduce = 25%, Cumulative CPU 203.0 sec
2018-01-03 06:10:13,462 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 205.21 sec
2018-01-03 06:10:14,495 Stage-1 map = 100%,  reduce = 80%, Cumulative CPU 226.03 sec
2018-01-03 06:10:15,529 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 231.61 sec
MapReduce Total cumulative CPU time: 3 minutes 51 seconds 610 msec
Ended Job = job_1513599404024_165092
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165106, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165106/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165106
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:10:21,268 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:10:26,427 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.6 sec
2018-01-03 06:10:32,607 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.15 sec
2018-01-03 06:10:34,666 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.46 sec
MapReduce Total cumulative CPU time: 17 seconds 460 msec
Ended Job = job_1513599404024_165106
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165110, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165110/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165110
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:10:42,310 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:10:47,504 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.69 sec
2018-01-03 06:10:53,681 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.06 sec
MapReduce Total cumulative CPU time: 6 seconds 60 msec
Ended Job = job_1513599404024_165110
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 9  Reduce: 7   Cumulative CPU: 231.61 sec   HDFS Read: 729249818 HDFS Write: 367813 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.46 sec   HDFS Read: 48079885 HDFS Write: 20709 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.06 sec   HDFS Read: 28385 HDFS Write: 2335 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 15 seconds 130 msec
OK
Time taken: 80.062 seconds, Fetched: 335 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103061101_4d5d6689-a99a-4e36-b9fc-bdb80841c97a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165117, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165117/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165117
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:11:11,461 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:11:22,870 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 7.43 sec
2018-01-03 06:11:25,976 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 9.87 sec
2018-01-03 06:11:29,075 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 10.7 sec
2018-01-03 06:11:32,171 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 12.4 sec
2018-01-03 06:11:35,270 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 13.75 sec
2018-01-03 06:11:38,366 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 14.59 sec
2018-01-03 06:11:41,464 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 15.34 sec
2018-01-03 06:11:43,527 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 16.1 sec
2018-01-03 06:11:46,615 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 16.47 sec
2018-01-03 06:11:49,703 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 17.06 sec
2018-01-03 06:11:52,795 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 17.49 sec
2018-01-03 06:11:55,884 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 17.92 sec
2018-01-03 06:11:58,972 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 18.28 sec
2018-01-03 06:12:02,061 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 18.77 sec
2018-01-03 06:12:05,147 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 19.34 sec
2018-01-03 06:12:08,231 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 19.96 sec
2018-01-03 06:12:11,318 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 20.36 sec
2018-01-03 06:12:14,403 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 20.75 sec
2018-01-03 06:12:17,490 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 21.03 sec
2018-01-03 06:12:20,576 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 21.89 sec
2018-01-03 06:12:23,661 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 22.26 sec
2018-01-03 06:12:26,747 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 22.84 sec
2018-01-03 06:12:29,828 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 23.09 sec
2018-01-03 06:12:31,882 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 23.81 sec
2018-01-03 06:12:34,961 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 24.33 sec
2018-01-03 06:12:38,043 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 26.47 sec
2018-01-03 06:12:40,098 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 27.37 sec
2018-01-03 06:12:47,297 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 31.61 sec
MapReduce Total cumulative CPU time: 31 seconds 610 msec
Ended Job = job_1513599404024_165117
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165140, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165140/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165140
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:12:54,008 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:12:59,161 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.84 sec
2018-01-03 06:13:00,190 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.57 sec
2018-01-03 06:13:05,337 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.7 sec
MapReduce Total cumulative CPU time: 13 seconds 700 msec
Ended Job = job_1513599404024_165140
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165152, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165152/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165152
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:13:11,982 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:13:17,188 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.56 sec
2018-01-03 06:13:22,346 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.2 sec
MapReduce Total cumulative CPU time: 6 seconds 200 msec
Ended Job = job_1513599404024_165152
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 31.61 sec   HDFS Read: 85202611 HDFS Write: 520050 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.7 sec   HDFS Read: 48230494 HDFS Write: 162555 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.2 sec   HDFS Read: 170192 HDFS Write: 6167 SUCCESS
Total MapReduce CPU Time Spent: 51 seconds 510 msec
OK
Time taken: 142.003 seconds, Fetched: 748 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.35 seconds
Query ID = boss_20180103061330_83375af6-e2c5-4060-9dd6-e2b5974f844e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165164, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165164/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165164
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:13:39,977 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:13:49,290 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.56 sec
2018-01-03 06:13:52,387 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 14.31 sec
2018-01-03 06:13:55,477 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 16.36 sec
2018-01-03 06:13:58,565 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 17.95 sec
2018-01-03 06:14:01,652 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 19.37 sec
2018-01-03 06:14:04,737 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 20.26 sec
2018-01-03 06:14:07,820 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 20.69 sec
2018-01-03 06:14:10,908 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 22.95 sec
2018-01-03 06:14:13,995 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 24.29 sec
2018-01-03 06:14:17,076 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 25.33 sec
2018-01-03 06:14:20,160 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 27.09 sec
2018-01-03 06:14:23,240 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 28.08 sec
2018-01-03 06:14:26,322 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 29.47 sec
2018-01-03 06:14:29,405 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 31.71 sec
2018-01-03 06:14:32,483 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 34.75 sec
2018-01-03 06:14:40,700 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.3 sec
MapReduce Total cumulative CPU time: 39 seconds 300 msec
Ended Job = job_1513599404024_165164
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165189, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165189/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165189
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:15:04,546 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:15:11,772 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.88 sec
2018-01-03 06:15:17,955 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.53 sec
2018-01-03 06:15:20,018 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.35 sec
MapReduce Total cumulative CPU time: 16 seconds 350 msec
Ended Job = job_1513599404024_165189
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165196, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165196/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165196
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:15:27,708 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:15:41,086 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.44 sec
2018-01-03 06:16:01,657 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.96 sec
MapReduce Total cumulative CPU time: 5 seconds 960 msec
Ended Job = job_1513599404024_165196
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 39.3 sec   HDFS Read: 85202601 HDFS Write: 1075188 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.35 sec   HDFS Read: 48785632 HDFS Write: 138606 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.96 sec   HDFS Read: 146244 HDFS Write: 3559 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 610 msec
OK
Time taken: 152.67 seconds, Fetched: 549 row(s)
开始执行20171001日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.365 seconds
Query ID = boss_20180103061609_eddad1e5-47d1-43e3-bc29-789dd4930dad
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165217, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165217/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165217
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 06:16:18,630 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:16:27,952 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.19 sec
2018-01-03 06:16:28,984 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 25.09 sec
2018-01-03 06:16:31,052 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 28.83 sec
2018-01-03 06:16:32,084 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 32.25 sec
2018-01-03 06:16:34,147 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 35.67 sec
2018-01-03 06:16:35,181 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 38.92 sec
2018-01-03 06:16:37,243 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 45.57 sec
2018-01-03 06:16:38,273 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 48.72 sec
2018-01-03 06:16:40,332 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 63.65 sec
2018-01-03 06:16:41,366 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 67.27 sec
2018-01-03 06:16:43,425 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 70.93 sec
2018-01-03 06:16:44,454 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 73.94 sec
2018-01-03 06:16:46,511 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 78.67 sec
2018-01-03 06:16:47,540 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 81.74 sec
2018-01-03 06:16:48,570 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 83.86 sec
2018-01-03 06:16:49,599 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 87.05 sec
2018-01-03 06:16:52,689 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 92.61 sec
2018-01-03 06:16:55,773 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 100.33 sec
2018-01-03 06:16:58,859 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 106.12 sec
2018-01-03 06:16:59,898 Stage-1 map = 81%,  reduce = 8%, Cumulative CPU 107.0 sec
2018-01-03 06:17:00,927 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 109.27 sec
2018-01-03 06:17:02,984 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 119.95 sec
MapReduce Total cumulative CPU time: 1 minutes 59 seconds 950 msec
Ended Job = job_1513599404024_165217
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165234, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165234/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165234
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:17:08,851 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:17:15,053 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.93 sec
2018-01-03 06:17:18,154 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.31 sec
2018-01-03 06:17:29,471 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.66 sec
MapReduce Total cumulative CPU time: 18 seconds 660 msec
Ended Job = job_1513599404024_165234
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165241, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165241/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165241
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:17:43,145 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:17:50,372 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.66 sec
2018-01-03 06:17:59,654 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.35 sec
MapReduce Total cumulative CPU time: 8 seconds 350 msec
Ended Job = job_1513599404024_165241
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 119.95 sec   HDFS Read: 263655690 HDFS Write: 2241479 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.66 sec   HDFS Read: 74822810 HDFS Write: 74905 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.35 sec   HDFS Read: 82580 HDFS Write: 3057 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 26 seconds 960 msec
OK
Time taken: 111.023 seconds, Fetched: 415 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.399 seconds
Query ID = boss_20180103061807_634aefca-a622-46ff-a412-c7d11936d13e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165256, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165256/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165256
Hadoop job information for Stage-1: number of mappers: 10; number of reducers: 9
2018-01-03 06:18:19,569 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:18:29,955 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 33.74 sec
2018-01-03 06:18:30,988 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 96.65 sec
2018-01-03 06:18:33,058 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 125.41 sec
2018-01-03 06:18:34,090 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 139.59 sec
2018-01-03 06:18:36,153 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 162.69 sec
2018-01-03 06:18:37,184 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 175.53 sec
2018-01-03 06:18:38,215 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 181.41 sec
2018-01-03 06:18:39,245 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 189.69 sec
2018-01-03 06:18:40,276 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 192.69 sec
2018-01-03 06:18:42,338 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 212.15 sec
2018-01-03 06:18:43,369 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 216.79 sec
2018-01-03 06:18:44,400 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 231.78 sec
2018-01-03 06:18:46,465 Stage-1 map = 73%,  reduce = 11%, Cumulative CPU 250.73 sec
2018-01-03 06:18:47,498 Stage-1 map = 75%,  reduce = 13%, Cumulative CPU 259.28 sec
2018-01-03 06:18:48,529 Stage-1 map = 80%,  reduce = 13%, Cumulative CPU 262.19 sec
2018-01-03 06:18:49,563 Stage-1 map = 86%,  reduce = 16%, Cumulative CPU 266.84 sec
2018-01-03 06:18:50,594 Stage-1 map = 89%,  reduce = 16%, Cumulative CPU 273.94 sec
2018-01-03 06:18:51,629 Stage-1 map = 89%,  reduce = 18%, Cumulative CPU 274.13 sec
2018-01-03 06:18:52,659 Stage-1 map = 90%,  reduce = 21%, Cumulative CPU 277.87 sec
2018-01-03 06:18:53,688 Stage-1 map = 95%,  reduce = 27%, Cumulative CPU 283.1 sec
2018-01-03 06:18:54,718 Stage-1 map = 100%,  reduce = 34%, Cumulative CPU 286.47 sec
2018-01-03 06:18:55,747 Stage-1 map = 100%,  reduce = 66%, Cumulative CPU 301.81 sec
2018-01-03 06:18:56,776 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 318.0 sec
2018-01-03 06:18:57,805 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 323.67 sec
MapReduce Total cumulative CPU time: 5 minutes 23 seconds 670 msec
Ended Job = job_1513599404024_165256
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165270, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165270/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165270
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:19:04,742 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:19:10,940 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.47 sec
2018-01-03 06:19:18,148 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.94 sec
MapReduce Total cumulative CPU time: 16 seconds 940 msec
Ended Job = job_1513599404024_165270
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165275, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165275/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165275
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:19:28,834 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:19:34,012 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.68 sec
2018-01-03 06:19:40,199 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.68 sec
MapReduce Total cumulative CPU time: 5 seconds 680 msec
Ended Job = job_1513599404024_165275
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 10  Reduce: 9   Cumulative CPU: 323.67 sec   HDFS Read: 866972820 HDFS Write: 569468 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.94 sec   HDFS Read: 73152633 HDFS Write: 24046 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.68 sec   HDFS Read: 31722 HDFS Write: 2603 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 46 seconds 290 msec
OK
Time taken: 93.787 seconds, Fetched: 367 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103061947_530c2122-f264-477a-9f58-d459a1388571
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165283, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165283/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165283
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:20:03,989 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:20:20,045 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 8.27 sec
2018-01-03 06:20:23,148 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.83 sec
2018-01-03 06:20:26,242 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.59 sec
2018-01-03 06:20:29,338 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 13.19 sec
2018-01-03 06:20:32,425 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 13.84 sec
2018-01-03 06:20:35,518 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 14.48 sec
2018-01-03 06:20:38,613 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.25 sec
2018-01-03 06:20:41,703 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 15.84 sec
2018-01-03 06:20:44,794 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 16.43 sec
2018-01-03 06:20:47,887 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 17.02 sec
2018-01-03 06:20:49,947 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 17.36 sec
2018-01-03 06:20:53,037 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 17.81 sec
2018-01-03 06:20:56,129 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 18.37 sec
2018-01-03 06:20:59,218 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 18.95 sec
2018-01-03 06:21:02,304 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 19.39 sec
2018-01-03 06:21:05,394 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 19.87 sec
2018-01-03 06:21:08,478 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 20.45 sec
2018-01-03 06:21:11,561 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 20.99 sec
2018-01-03 06:21:14,649 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 21.32 sec
2018-01-03 06:21:17,734 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 21.61 sec
2018-01-03 06:21:20,830 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 22.97 sec
2018-01-03 06:21:23,916 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 23.38 sec
2018-01-03 06:21:26,995 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 23.93 sec
2018-01-03 06:21:30,075 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 24.04 sec
2018-01-03 06:21:33,155 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 24.24 sec
2018-01-03 06:21:36,239 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 24.51 sec
2018-01-03 06:21:42,402 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 26.29 sec
2018-01-03 06:21:44,460 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 27.28 sec
2018-01-03 06:21:45,488 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 28.28 sec
2018-01-03 06:21:59,871 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 33.75 sec
MapReduce Total cumulative CPU time: 33 seconds 750 msec
Ended Job = job_1513599404024_165283
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165320, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165320/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165320
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:22:13,574 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:22:19,765 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.71 sec
2018-01-03 06:22:27,157 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.61 sec
MapReduce Total cumulative CPU time: 15 seconds 610 msec
Ended Job = job_1513599404024_165320
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165324, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165324/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165324
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:22:33,931 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:23:02,707 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.72 sec
2018-01-03 06:23:09,902 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.87 sec
MapReduce Total cumulative CPU time: 8 seconds 870 msec
Ended Job = job_1513599404024_165324
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 33.75 sec   HDFS Read: 101790806 HDFS Write: 484583 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.61 sec   HDFS Read: 73065588 HDFS Write: 174757 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.87 sec   HDFS Read: 182386 HDFS Write: 6686 SUCCESS
Total MapReduce CPU Time Spent: 58 seconds 230 msec
OK
Time taken: 202.995 seconds, Fetched: 782 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103062317_d1a83333-47e5-4fd5-aeb1-94301ea65a06
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165343, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165343/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165343
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:23:38,821 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:23:51,397 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 7.12 sec
2018-01-03 06:23:54,511 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 8.5 sec
2018-01-03 06:23:56,584 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 9.26 sec
2018-01-03 06:23:59,690 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 10.28 sec
2018-01-03 06:24:02,793 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 12.25 sec
2018-01-03 06:24:06,244 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 12.78 sec
2018-01-03 06:24:09,508 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 13.31 sec
2018-01-03 06:24:12,650 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 14.42 sec
2018-01-03 06:24:14,886 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 15.07 sec
2018-01-03 06:24:17,990 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 15.54 sec
2018-01-03 06:24:21,112 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 16.3 sec
2018-01-03 06:24:24,218 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 17.75 sec
2018-01-03 06:24:27,473 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 18.67 sec
2018-01-03 06:24:30,578 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 19.92 sec
2018-01-03 06:24:33,689 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 20.72 sec
2018-01-03 06:24:36,799 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 21.13 sec
2018-01-03 06:24:39,886 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 21.72 sec
2018-01-03 06:24:43,368 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 23.7 sec
2018-01-03 06:24:46,494 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 24.84 sec
2018-01-03 06:24:49,579 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 26.47 sec
2018-01-03 06:24:52,712 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 28.71 sec
2018-01-03 06:24:55,810 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 29.34 sec
2018-01-03 06:24:58,904 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 30.33 sec
2018-01-03 06:25:00,961 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 30.91 sec
2018-01-03 06:25:04,422 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 32.21 sec
2018-01-03 06:25:06,477 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 33.9 sec
2018-01-03 06:25:15,799 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.37 sec
MapReduce Total cumulative CPU time: 39 seconds 370 msec
Ended Job = job_1513599404024_165343
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165368, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165368/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165368
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:25:23,619 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:25:31,873 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.13 sec
2018-01-03 06:25:32,903 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.3 sec
2018-01-03 06:25:41,134 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.23 sec
MapReduce Total cumulative CPU time: 19 seconds 230 msec
Ended Job = job_1513599404024_165368
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165374, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165374/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165374
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:25:47,991 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:26:21,885 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 6.19 sec
2018-01-03 06:26:45,502 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 14.05 sec
MapReduce Total cumulative CPU time: 14 seconds 50 msec
Ended Job = job_1513599404024_165374
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 39.37 sec   HDFS Read: 101790798 HDFS Write: 1351753 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.23 sec   HDFS Read: 73932766 HDFS Write: 185522 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 14.05 sec   HDFS Read: 193160 HDFS Write: 3478 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 12 seconds 650 msec
OK
Time taken: 208.862 seconds, Fetched: 511 row(s)
开始执行20171002日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.376 seconds
Query ID = boss_20180103062653_13c464bf-1ff7-47b5-9b2f-92bee7a91d1f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165388, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165388/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165388
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 06:27:21,105 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:27:32,333 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 11.11 sec
2018-01-03 06:27:34,414 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 14.27 sec
2018-01-03 06:27:37,608 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 17.47 sec
2018-01-03 06:27:40,846 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 20.78 sec
2018-01-03 06:27:44,093 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 31.59 sec
2018-01-03 06:27:47,197 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 39.55 sec
2018-01-03 06:27:49,262 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 51.48 sec
2018-01-03 06:27:50,303 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 54.43 sec
2018-01-03 06:27:52,372 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 58.51 sec
2018-01-03 06:27:53,406 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 61.76 sec
2018-01-03 06:27:55,473 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 83.82 sec
2018-01-03 06:27:56,508 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 86.97 sec
2018-01-03 06:27:58,570 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 90.62 sec
2018-01-03 06:27:59,600 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 93.72 sec
2018-01-03 06:28:01,661 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 115.72 sec
2018-01-03 06:28:02,691 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 119.49 sec
2018-01-03 06:28:07,845 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 121.44 sec
2018-01-03 06:28:14,023 Stage-1 map = 71%,  reduce = 8%, Cumulative CPU 131.96 sec
2018-01-03 06:28:19,163 Stage-1 map = 72%,  reduce = 8%, Cumulative CPU 171.88 sec
2018-01-03 06:28:22,251 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 185.83 sec
2018-01-03 06:28:24,307 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 186.76 sec
2018-01-03 06:28:26,361 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 201.42 sec
2018-01-03 06:28:29,441 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 203.35 sec
2018-01-03 06:28:32,525 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 208.43 sec
2018-01-03 06:28:34,580 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 215.36 sec
2018-01-03 06:28:37,704 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 223.39 sec
2018-01-03 06:28:39,944 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 225.39 sec
MapReduce Total cumulative CPU time: 3 minutes 45 seconds 390 msec
Ended Job = job_1513599404024_165388
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165403, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165403/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165403
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:28:56,389 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:29:16,967 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 12.88 sec
2018-01-03 06:29:33,408 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 18.91 sec
2018-01-03 06:29:39,572 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 31.65 sec
MapReduce Total cumulative CPU time: 31 seconds 650 msec
Ended Job = job_1513599404024_165403
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165414, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165414/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165414
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:29:57,557 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:30:30,877 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.65 sec
2018-01-03 06:30:54,559 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 10.27 sec
MapReduce Total cumulative CPU time: 10 seconds 270 msec
Ended Job = job_1513599404024_165414
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 225.39 sec   HDFS Read: 263592637 HDFS Write: 2295200 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 32.14 sec   HDFS Read: 53372510 HDFS Write: 79337 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 10.27 sec   HDFS Read: 87012 HDFS Write: 3172 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 27 seconds 800 msec
OK
Time taken: 242.169 seconds, Fetched: 412 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.384 seconds
Query ID = boss_20180103063110_11b34b18-fb2b-4fff-9b2d-62fd781a3c49
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165427, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165427/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165427
Hadoop job information for Stage-1: number of mappers: 10; number of reducers: 9
2018-01-03 06:31:21,480 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:31:31,895 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 12.22 sec
2018-01-03 06:31:32,928 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 25.03 sec
2018-01-03 06:31:33,962 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 48.04 sec
2018-01-03 06:31:34,998 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 61.5 sec
2018-01-03 06:31:36,030 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 134.96 sec
2018-01-03 06:31:37,062 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 147.09 sec
2018-01-03 06:31:38,093 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 154.08 sec
2018-01-03 06:31:39,125 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 160.81 sec
2018-01-03 06:31:40,156 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 174.14 sec
2018-01-03 06:31:41,188 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 194.19 sec
2018-01-03 06:31:42,218 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 213.18 sec
2018-01-03 06:31:44,284 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 228.66 sec
2018-01-03 06:31:45,315 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 281.11 sec
2018-01-03 06:31:46,346 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 290.53 sec
2018-01-03 06:31:47,376 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 319.55 sec
2018-01-03 06:31:49,435 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 327.55 sec
2018-01-03 06:31:51,502 Stage-1 map = 66%,  reduce = 7%, Cumulative CPU 348.49 sec
2018-01-03 06:31:52,533 Stage-1 map = 67%,  reduce = 7%, Cumulative CPU 356.43 sec
2018-01-03 06:31:53,567 Stage-1 map = 73%,  reduce = 7%, Cumulative CPU 363.44 sec
2018-01-03 06:31:54,598 Stage-1 map = 75%,  reduce = 9%, Cumulative CPU 384.17 sec
2018-01-03 06:31:55,627 Stage-1 map = 80%,  reduce = 9%, Cumulative CPU 386.59 sec
2018-01-03 06:31:57,687 Stage-1 map = 87%,  reduce = 14%, Cumulative CPU 398.02 sec
2018-01-03 06:31:59,745 Stage-1 map = 91%,  reduce = 23%, Cumulative CPU 402.33 sec
2018-01-03 06:32:00,776 Stage-1 map = 92%,  reduce = 26%, Cumulative CPU 407.63 sec
2018-01-03 06:32:02,832 Stage-1 map = 92%,  reduce = 27%, Cumulative CPU 407.87 sec
2018-01-03 06:32:03,865 Stage-1 map = 93%,  reduce = 27%, Cumulative CPU 411.68 sec
2018-01-03 06:32:06,952 Stage-1 map = 94%,  reduce = 30%, Cumulative CPU 416.69 sec
2018-01-03 06:32:10,036 Stage-1 map = 96%,  reduce = 30%, Cumulative CPU 421.54 sec
2018-01-03 06:32:13,123 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 428.32 sec
2018-01-03 06:32:14,152 Stage-1 map = 100%,  reduce = 84%, Cumulative CPU 454.16 sec
2018-01-03 06:32:15,182 Stage-1 map = 100%,  reduce = 96%, Cumulative CPU 460.71 sec
2018-01-03 06:32:16,210 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 464.69 sec
MapReduce Total cumulative CPU time: 7 minutes 44 seconds 690 msec
Ended Job = job_1513599404024_165427
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165440, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165440/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165440
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:32:23,690 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:32:36,042 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 8.88 sec
2018-01-03 06:32:42,215 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 19.99 sec
2018-01-03 06:32:57,621 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 27.55 sec
MapReduce Total cumulative CPU time: 27 seconds 550 msec
Ended Job = job_1513599404024_165440
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165450, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165450/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165450
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:33:12,354 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:33:41,402 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 9.16 sec
2018-01-03 06:34:03,069 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 13.21 sec
MapReduce Total cumulative CPU time: 13 seconds 210 msec
Ended Job = job_1513599404024_165450
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 10  Reduce: 9   Cumulative CPU: 464.69 sec   HDFS Read: 854216996 HDFS Write: 395482 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 27.55 sec   HDFS Read: 51474626 HDFS Write: 24660 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 13.21 sec   HDFS Read: 32336 HDFS Write: 2535 SUCCESS
Total MapReduce CPU Time Spent: 8 minutes 25 seconds 450 msec
OK
Time taken: 173.763 seconds, Fetched: 365 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.396 seconds
Query ID = boss_20180103063410_086e4fac-4149-4e26-a6e7-bde88c47b2c7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165460, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165460/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165460
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:34:29,046 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:34:44,532 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 9.86 sec
2018-01-03 06:34:47,626 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 11.56 sec
2018-01-03 06:34:50,723 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 13.52 sec
2018-01-03 06:34:53,816 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 14.7 sec
2018-01-03 06:34:56,902 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 16.04 sec
2018-01-03 06:34:59,991 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 16.97 sec
2018-01-03 06:35:03,076 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 17.82 sec
2018-01-03 06:35:06,168 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 19.11 sec
2018-01-03 06:35:09,263 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 19.7 sec
2018-01-03 06:35:12,349 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 21.3 sec
2018-01-03 06:35:15,432 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 22.65 sec
2018-01-03 06:35:18,517 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 22.87 sec
2018-01-03 06:35:21,598 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 23.29 sec
2018-01-03 06:35:24,675 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 24.1 sec
2018-01-03 06:35:27,758 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 24.6 sec
2018-01-03 06:35:30,836 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 25.11 sec
2018-01-03 06:35:33,915 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 25.62 sec
2018-01-03 06:35:36,998 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 26.19 sec
2018-01-03 06:35:40,077 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 26.75 sec
2018-01-03 06:35:43,155 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 27.02 sec
2018-01-03 06:35:46,237 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 27.64 sec
2018-01-03 06:35:49,317 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 28.52 sec
2018-01-03 06:35:52,396 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 28.97 sec
2018-01-03 06:35:55,478 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 29.28 sec
2018-01-03 06:35:57,531 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 29.92 sec
2018-01-03 06:36:00,609 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 30.2 sec
2018-01-03 06:36:03,692 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 30.82 sec
2018-01-03 06:36:06,771 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 31.29 sec
2018-01-03 06:36:09,847 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 33.47 sec
2018-01-03 06:36:11,898 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 34.79 sec
2018-01-03 06:36:18,060 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.98 sec
MapReduce Total cumulative CPU time: 39 seconds 980 msec
Ended Job = job_1513599404024_165460
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165483, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165483/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165483
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:36:23,725 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:36:29,902 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.31 sec
2018-01-03 06:36:43,264 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.82 sec
MapReduce Total cumulative CPU time: 18 seconds 820 msec
Ended Job = job_1513599404024_165483
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165490, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165490/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165490
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:36:59,957 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:37:04,179 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.41 sec
2018-01-03 06:38:04,346 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.41 sec
2018-01-03 06:38:07,820 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 6.21 sec
2018-01-03 06:38:32,095 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 17.49 sec
MapReduce Total cumulative CPU time: 17 seconds 490 msec
Ended Job = job_1513599404024_165490
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 39.98 sec   HDFS Read: 107869691 HDFS Write: 503962 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.82 sec   HDFS Read: 51580954 HDFS Write: 184278 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 17.49 sec   HDFS Read: 191915 HDFS Write: 6709 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 16 seconds 290 msec
OK
Time taken: 264.671 seconds, Fetched: 792 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.344 seconds
Query ID = boss_20180103063842_9dfa71ad-7987-49f9-8299-ce78fb95498c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165502, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165502/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165502
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:39:02,165 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:39:27,998 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 9.48 sec
2018-01-03 06:39:31,094 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 10.69 sec
2018-01-03 06:39:34,195 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 11.86 sec
2018-01-03 06:39:37,287 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 12.94 sec
2018-01-03 06:39:39,348 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 13.71 sec
2018-01-03 06:39:42,440 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 14.77 sec
2018-01-03 06:39:45,527 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 15.7 sec
2018-01-03 06:39:48,618 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 18.46 sec
2018-01-03 06:39:51,707 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 19.76 sec
2018-01-03 06:39:54,795 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 20.82 sec
2018-01-03 06:39:57,883 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 21.4 sec
2018-01-03 06:40:00,973 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 23.25 sec
2018-01-03 06:40:11,265 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 29.22 sec
MapReduce Total cumulative CPU time: 29 seconds 220 msec
Ended Job = job_1513599404024_165502
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165521, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165521/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165521
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:40:18,046 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:40:24,233 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.09 sec
2018-01-03 06:40:26,302 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.47 sec
2018-01-03 06:40:30,430 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.12 sec
MapReduce Total cumulative CPU time: 18 seconds 120 msec
Ended Job = job_1513599404024_165521
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165524, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165524/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165524
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:40:43,143 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:41:01,721 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec
2018-01-03 06:41:12,009 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.87 sec
MapReduce Total cumulative CPU time: 6 seconds 870 msec
Ended Job = job_1513599404024_165524
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 29.22 sec   HDFS Read: 107869681 HDFS Write: 1622006 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.12 sec   HDFS Read: 52698998 HDFS Write: 184757 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.87 sec   HDFS Read: 192395 HDFS Write: 3520 SUCCESS
Total MapReduce CPU Time Spent: 54 seconds 210 msec
OK
Time taken: 150.82 seconds, Fetched: 526 row(s)
开始执行20171003日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.384 seconds
Query ID = boss_20180103064120_504988d9-6508-43fc-98e5-d0f2aaa2de60
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165535, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165535/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165535
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 06:41:31,774 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:41:42,142 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.43 sec
2018-01-03 06:41:45,244 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 17.64 sec
2018-01-03 06:41:48,371 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 20.93 sec
2018-01-03 06:41:49,402 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 33.6 sec
2018-01-03 06:41:50,437 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 37.16 sec
2018-01-03 06:41:52,499 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 41.35 sec
2018-01-03 06:41:53,530 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 45.34 sec
2018-01-03 06:41:55,595 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 48.66 sec
2018-01-03 06:41:56,626 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 51.76 sec
2018-01-03 06:41:58,686 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 55.32 sec
2018-01-03 06:41:59,717 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 60.0 sec
2018-01-03 06:42:02,809 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 63.32 sec
2018-01-03 06:42:05,905 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 67.22 sec
2018-01-03 06:42:07,970 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 71.67 sec
2018-01-03 06:42:09,012 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 77.81 sec
MapReduce Total cumulative CPU time: 1 minutes 17 seconds 810 msec
Ended Job = job_1513599404024_165535
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165546, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165546/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165546
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:42:29,764 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:42:37,007 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.37 sec
2018-01-03 06:42:38,042 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 27.76 sec
2018-01-03 06:42:47,325 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 35.19 sec
MapReduce Total cumulative CPU time: 35 seconds 190 msec
Ended Job = job_1513599404024_165546
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165551, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165551/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165551
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:43:01,998 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:43:10,241 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.77 sec
2018-01-03 06:43:18,471 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.09 sec
MapReduce Total cumulative CPU time: 7 seconds 90 msec
Ended Job = job_1513599404024_165551
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 77.81 sec   HDFS Read: 264388866 HDFS Write: 2316696 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 35.19 sec   HDFS Read: 52607416 HDFS Write: 76408 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.09 sec   HDFS Read: 84079 HDFS Write: 2983 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 0 seconds 90 msec
OK
Time taken: 119.517 seconds, Fetched: 401 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.413 seconds
Query ID = boss_20180103064334_954e5ccb-b857-4326-948f-fb22292960b2
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 9
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165557, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165557/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165557
Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 9
2018-01-03 06:43:44,636 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:43:53,979 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 49.81 sec
2018-01-03 06:43:55,012 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 74.54 sec
2018-01-03 06:43:57,080 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 95.71 sec
2018-01-03 06:43:58,116 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 99.1 sec
2018-01-03 06:44:00,184 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 126.28 sec
2018-01-03 06:44:01,218 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 129.51 sec
2018-01-03 06:44:02,249 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 145.5 sec
2018-01-03 06:44:03,280 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 159.78 sec
2018-01-03 06:44:04,315 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 162.87 sec
2018-01-03 06:44:05,347 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 166.85 sec
2018-01-03 06:44:06,378 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 176.35 sec
2018-01-03 06:44:07,412 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 179.53 sec
2018-01-03 06:44:08,447 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 191.46 sec
2018-01-03 06:44:09,479 Stage-1 map = 81%,  reduce = 13%, Cumulative CPU 199.99 sec
2018-01-03 06:44:11,542 Stage-1 map = 93%,  reduce = 20%, Cumulative CPU 207.31 sec
2018-01-03 06:44:12,573 Stage-1 map = 95%,  reduce = 22%, Cumulative CPU 210.75 sec
2018-01-03 06:44:14,633 Stage-1 map = 100%,  reduce = 31%, Cumulative CPU 214.63 sec
2018-01-03 06:44:15,665 Stage-1 map = 100%,  reduce = 73%, Cumulative CPU 231.79 sec
2018-01-03 06:44:16,694 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 246.96 sec
MapReduce Total cumulative CPU time: 4 minutes 6 seconds 960 msec
Ended Job = job_1513599404024_165557
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165563, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165563/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165563
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:44:22,396 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:44:29,609 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.83 sec
2018-01-03 06:44:34,757 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.06 sec
2018-01-03 06:44:42,981 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.46 sec
MapReduce Total cumulative CPU time: 15 seconds 460 msec
Ended Job = job_1513599404024_165563
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165569, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165569/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165569
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:44:56,602 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:45:02,779 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.91 sec
2018-01-03 06:45:17,162 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.03 sec
MapReduce Total cumulative CPU time: 7 seconds 30 msec
Ended Job = job_1513599404024_165569
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 8  Reduce: 9   Cumulative CPU: 246.96 sec   HDFS Read: 862914458 HDFS Write: 1083951 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.46 sec   HDFS Read: 51376510 HDFS Write: 23504 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.03 sec   HDFS Read: 31180 HDFS Write: 2528 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 29 seconds 450 msec
OK
Time taken: 103.927 seconds, Fetched: 359 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103064524_27fa3830-5bb6-412f-9a97-fdc40fc2f9df
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165578, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165578/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165578
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:45:35,444 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:45:54,076 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 10.71 sec
2018-01-03 06:45:57,176 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.12 sec
2018-01-03 06:46:00,271 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 14.32 sec
2018-01-03 06:46:03,363 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 15.66 sec
2018-01-03 06:46:06,458 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 16.55 sec
2018-01-03 06:46:09,551 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 17.56 sec
2018-01-03 06:46:12,640 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 18.43 sec
2018-01-03 06:46:15,733 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 19.05 sec
2018-01-03 06:46:18,823 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 19.86 sec
2018-01-03 06:46:21,913 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 20.86 sec
2018-01-03 06:46:25,004 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 21.4 sec
2018-01-03 06:46:27,064 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 22.45 sec
2018-01-03 06:46:30,150 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 23.19 sec
2018-01-03 06:46:33,238 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 23.87 sec
2018-01-03 06:46:36,328 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 24.58 sec
2018-01-03 06:46:39,415 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 24.94 sec
2018-01-03 06:46:42,502 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 25.41 sec
2018-01-03 06:46:45,588 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 26.57 sec
2018-01-03 06:46:48,671 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 27.06 sec
2018-01-03 06:46:51,754 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 27.55 sec
2018-01-03 06:46:54,839 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 27.9 sec
2018-01-03 06:46:57,921 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 28.38 sec
2018-01-03 06:47:01,002 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 29.77 sec
2018-01-03 06:47:04,085 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 30.55 sec
2018-01-03 06:47:05,114 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.14 sec
2018-01-03 06:47:12,331 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 36.11 sec
MapReduce Total cumulative CPU time: 36 seconds 110 msec
Ended Job = job_1513599404024_165578
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165601, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165601/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165601
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:47:18,171 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:47:23,379 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.84 sec
2018-01-03 06:47:24,408 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.25 sec
2018-01-03 06:47:28,519 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.46 sec
MapReduce Total cumulative CPU time: 16 seconds 460 msec
Ended Job = job_1513599404024_165601
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165604, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165604/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165604
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:47:49,229 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:47:54,397 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.87 sec
2018-01-03 06:48:07,785 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.48 sec
MapReduce Total cumulative CPU time: 6 seconds 480 msec
Ended Job = job_1513599404024_165604
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 36.11 sec   HDFS Read: 102560752 HDFS Write: 512077 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.46 sec   HDFS Read: 50802484 HDFS Write: 193768 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.48 sec   HDFS Read: 201405 HDFS Write: 7252 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 50 msec
OK
Time taken: 163.953 seconds, Fetched: 822 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103064815_bea73767-17fe-440e-ab5e-ccbe95ea0e2b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165614, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165614/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165614
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:48:26,727 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:48:52,676 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 29.93 sec
2018-01-03 06:48:55,767 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 31.21 sec
2018-01-03 06:48:58,905 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 32.58 sec
2018-01-03 06:49:01,995 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 33.24 sec
2018-01-03 06:49:05,084 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 35.74 sec
2018-01-03 06:49:08,174 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 36.58 sec
2018-01-03 06:49:11,259 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 37.62 sec
2018-01-03 06:49:14,345 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 39.03 sec
2018-01-03 06:49:17,434 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 40.57 sec
2018-01-03 06:49:20,518 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 41.36 sec
2018-01-03 06:49:23,603 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 42.0 sec
2018-01-03 06:49:26,689 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 43.88 sec
2018-01-03 06:49:27,717 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 44.89 sec
2018-01-03 06:49:34,918 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 51.1 sec
MapReduce Total cumulative CPU time: 51 seconds 100 msec
Ended Job = job_1513599404024_165614
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165633, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165633/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165633
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:49:49,744 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:49:54,939 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.79 sec
2018-01-03 06:50:02,145 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.49 sec
MapReduce Total cumulative CPU time: 15 seconds 490 msec
Ended Job = job_1513599404024_165633
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165637, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165637/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165637
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:50:07,775 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:50:11,903 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.88 sec
2018-01-03 06:50:18,084 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.34 sec
MapReduce Total cumulative CPU time: 6 seconds 340 msec
Ended Job = job_1513599404024_165637
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 51.1 sec   HDFS Read: 102560742 HDFS Write: 1497096 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.49 sec   HDFS Read: 51787503 HDFS Write: 181264 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.34 sec   HDFS Read: 188902 HDFS Write: 3817 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 12 seconds 930 msec
OK
Time taken: 123.593 seconds, Fetched: 535 row(s)
开始执行20171004日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.378 seconds
Query ID = boss_20180103065026_6be36568-1b4f-47e7-8913-ec9b966b32ee
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165642, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165642/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165642
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 06:50:35,191 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:50:53,781 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 26.06 sec
2018-01-03 06:50:56,872 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 33.85 sec
2018-01-03 06:50:58,935 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 36.78 sec
2018-01-03 06:50:59,965 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 40.61 sec
2018-01-03 06:51:02,025 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 44.28 sec
2018-01-03 06:51:03,055 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 47.63 sec
2018-01-03 06:51:05,114 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 53.99 sec
2018-01-03 06:51:08,210 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 56.88 sec
2018-01-03 06:51:11,298 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 60.1 sec
2018-01-03 06:51:14,387 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 63.29 sec
2018-01-03 06:51:15,422 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 65.14 sec
2018-01-03 06:51:17,486 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 70.11 sec
2018-01-03 06:51:21,603 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 80.89 sec
MapReduce Total cumulative CPU time: 1 minutes 20 seconds 890 msec
Ended Job = job_1513599404024_165642
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165652, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165652/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165652
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:51:35,446 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:51:41,631 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.45 sec
2018-01-03 06:52:03,226 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.31 sec
MapReduce Total cumulative CPU time: 18 seconds 310 msec
Ended Job = job_1513599404024_165652
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165659, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165659/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165659
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:52:14,914 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:52:19,254 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-03 06:52:26,648 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.81 sec
MapReduce Total cumulative CPU time: 6 seconds 810 msec
Ended Job = job_1513599404024_165659
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 80.89 sec   HDFS Read: 242634609 HDFS Write: 1995825 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.31 sec   HDFS Read: 50059262 HDFS Write: 72239 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.81 sec   HDFS Read: 79914 HDFS Write: 2903 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 46 seconds 10 msec
OK
Time taken: 121.619 seconds, Fetched: 395 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.409 seconds
Query ID = boss_20180103065234_178c5592-01f4-4b81-a8f9-232c9eba46ef
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165667, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165667/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165667
Hadoop job information for Stage-1: number of mappers: 10; number of reducers: 8
2018-01-03 06:52:47,923 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:52:56,529 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 12.11 sec
2018-01-03 06:52:57,568 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 73.72 sec
2018-01-03 06:52:58,606 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 116.33 sec
2018-01-03 06:53:00,676 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 143.76 sec
2018-01-03 06:53:01,712 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 156.51 sec
2018-01-03 06:53:03,776 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 169.66 sec
2018-01-03 06:53:04,812 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 176.07 sec
2018-01-03 06:53:05,849 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 189.51 sec
2018-01-03 06:53:06,891 Stage-1 map = 74%,  reduce = 13%, Cumulative CPU 201.0 sec
2018-01-03 06:53:07,923 Stage-1 map = 79%,  reduce = 15%, Cumulative CPU 207.3 sec
2018-01-03 06:53:08,955 Stage-1 map = 80%,  reduce = 15%, Cumulative CPU 210.93 sec
2018-01-03 06:53:09,987 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 214.83 sec
2018-01-03 06:53:11,020 Stage-1 map = 82%,  reduce = 18%, Cumulative CPU 218.02 sec
2018-01-03 06:53:12,051 Stage-1 map = 84%,  reduce = 18%, Cumulative CPU 221.54 sec
2018-01-03 06:53:14,113 Stage-1 map = 89%,  reduce = 18%, Cumulative CPU 228.91 sec
2018-01-03 06:53:15,145 Stage-1 map = 95%,  reduce = 21%, Cumulative CPU 236.48 sec
2018-01-03 06:53:16,175 Stage-1 map = 95%,  reduce = 24%, Cumulative CPU 237.11 sec
2018-01-03 06:53:17,206 Stage-1 map = 95%,  reduce = 25%, Cumulative CPU 237.18 sec
2018-01-03 06:53:18,236 Stage-1 map = 96%,  reduce = 26%, Cumulative CPU 239.28 sec
2018-01-03 06:53:20,300 Stage-1 map = 100%,  reduce = 26%, Cumulative CPU 242.65 sec
2018-01-03 06:53:21,329 Stage-1 map = 100%,  reduce = 61%, Cumulative CPU 259.15 sec
2018-01-03 06:53:22,358 Stage-1 map = 100%,  reduce = 88%, Cumulative CPU 270.85 sec
2018-01-03 06:53:34,706 Stage-1 map = 100%,  reduce = 96%, Cumulative CPU 282.23 sec
2018-01-03 06:53:39,849 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 275.86 sec
MapReduce Total cumulative CPU time: 4 minutes 35 seconds 860 msec
Ended Job = job_1513599404024_165667
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165679, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165679/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165679
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:53:46,617 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:53:52,806 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.19 sec
2018-01-03 06:53:54,864 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.61 sec
2018-01-03 06:53:58,982 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.69 sec
MapReduce Total cumulative CPU time: 16 seconds 690 msec
Ended Job = job_1513599404024_165679
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165685, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165685/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165685
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:54:06,621 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:54:13,837 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.36 sec
2018-01-03 06:54:18,985 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.18 sec
MapReduce Total cumulative CPU time: 7 seconds 180 msec
Ended Job = job_1513599404024_165685
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 10  Reduce: 8   Cumulative CPU: 275.86 sec   HDFS Read: 797286361 HDFS Write: 572546 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.69 sec   HDFS Read: 48637544 HDFS Write: 23209 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.18 sec   HDFS Read: 30881 HDFS Write: 2353 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 59 seconds 730 msec
OK
Time taken: 105.596 seconds, Fetched: 342 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103065426_fe08a3ec-e6f7-45d7-af76-9ff5dc44bd74
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165690, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165690/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165690
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:54:38,373 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:54:47,749 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 8.66 sec
2018-01-03 06:54:50,857 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.32 sec
2018-01-03 06:54:53,957 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 10.84 sec
2018-01-03 06:54:57,055 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 11.66 sec
2018-01-03 06:55:00,154 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.38 sec
2018-01-03 06:55:03,249 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 12.95 sec
2018-01-03 06:55:06,341 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 13.38 sec
2018-01-03 06:55:09,436 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 13.94 sec
2018-01-03 06:55:12,527 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 14.3 sec
2018-01-03 06:55:15,616 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 16.61 sec
2018-01-03 06:55:17,679 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 17.02 sec
2018-01-03 06:55:20,767 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 17.41 sec
2018-01-03 06:55:23,854 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 17.92 sec
2018-01-03 06:55:26,946 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 18.44 sec
2018-01-03 06:55:30,034 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 18.69 sec
2018-01-03 06:55:33,119 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 19.18 sec
2018-01-03 06:55:36,207 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 19.47 sec
2018-01-03 06:55:39,291 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 19.72 sec
2018-01-03 06:55:42,376 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 20.01 sec
2018-01-03 06:55:45,464 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 20.69 sec
2018-01-03 06:55:48,550 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 21.0 sec
2018-01-03 06:55:51,634 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 21.69 sec
2018-01-03 06:55:54,719 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 21.92 sec
2018-01-03 06:55:57,801 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 22.33 sec
2018-01-03 06:56:00,883 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 23.93 sec
2018-01-03 06:56:02,938 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.02 sec
2018-01-03 06:56:14,243 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.59 sec
MapReduce Total cumulative CPU time: 30 seconds 590 msec
Ended Job = job_1513599404024_165690
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165703, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165703/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165703
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:56:25,024 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:56:30,269 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.81 sec
2018-01-03 06:56:45,707 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 24.4 sec
2018-01-03 06:56:50,846 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 30.66 sec
MapReduce Total cumulative CPU time: 30 seconds 660 msec
Ended Job = job_1513599404024_165703
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165707, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165707/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165707
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:57:03,497 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:57:10,721 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.54 sec
2018-01-03 06:57:31,301 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.87 sec
MapReduce Total cumulative CPU time: 8 seconds 870 msec
Ended Job = job_1513599404024_165707
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.59 sec   HDFS Read: 102893599 HDFS Write: 450715 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 30.66 sec   HDFS Read: 48513834 HDFS Write: 173409 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.87 sec   HDFS Read: 181046 HDFS Write: 6512 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 10 seconds 120 msec
OK
Time taken: 185.641 seconds, Fetched: 772 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103065739_27c462d0-b45d-41a3-9330-3fc26b292057
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165709, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165709/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165709
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 06:58:00,195 Stage-1 map = 0%,  reduce = 0%
2018-01-03 06:58:11,379 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 12.3 sec
2018-01-03 06:58:14,480 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 14.09 sec
2018-01-03 06:58:17,576 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 16.26 sec
2018-01-03 06:58:20,677 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 20.36 sec
2018-01-03 06:58:23,776 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 21.6 sec
2018-01-03 06:58:25,843 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 24.17 sec
2018-01-03 06:59:02,366 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 29.41 sec
MapReduce Total cumulative CPU time: 29 seconds 410 msec
Ended Job = job_1513599404024_165709
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165715, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165715/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165715
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 06:59:12,209 Stage-2 map = 0%,  reduce = 0%
2018-01-03 06:59:18,402 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.74 sec
2018-01-03 06:59:21,499 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.99 sec
2018-01-03 06:59:26,650 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.86 sec
MapReduce Total cumulative CPU time: 17 seconds 860 msec
Ended Job = job_1513599404024_165715
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165719, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165719/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165719
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 06:59:32,331 Stage-3 map = 0%,  reduce = 0%
2018-01-03 06:59:37,484 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.02 sec
2018-01-03 06:59:54,953 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.51 sec
MapReduce Total cumulative CPU time: 8 seconds 510 msec
Ended Job = job_1513599404024_165719
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 29.41 sec   HDFS Read: 102893589 HDFS Write: 1572774 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.86 sec   HDFS Read: 49635893 HDFS Write: 164479 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.51 sec   HDFS Read: 172117 HDFS Write: 3187 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 780 msec
OK
Time taken: 136.933 seconds, Fetched: 471 row(s)
开始执行20171005日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103070002_4f6d0626-f462-4ae2-98c5-8befb01f5306
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165724, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165724/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165724
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 07:00:22,381 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:00:42,057 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 37.26 sec
2018-01-03 07:00:45,160 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 52.32 sec
2018-01-03 07:00:48,256 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 58.96 sec
2018-01-03 07:00:51,348 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 68.71 sec
2018-01-03 07:00:55,473 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 95.06 sec
2018-01-03 07:00:58,565 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 101.61 sec
2018-01-03 07:01:00,632 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 105.04 sec
2018-01-03 07:01:01,664 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 111.38 sec
2018-01-03 07:01:04,759 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 125.12 sec
2018-01-03 07:01:07,853 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 128.24 sec
2018-01-03 07:01:10,948 Stage-1 map = 69%,  reduce = 8%, Cumulative CPU 132.15 sec
2018-01-03 07:01:11,981 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 132.76 sec
2018-01-03 07:01:14,047 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 136.36 sec
2018-01-03 07:01:16,106 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 139.56 sec
2018-01-03 07:01:19,197 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 142.71 sec
2018-01-03 07:01:22,289 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 145.92 sec
2018-01-03 07:01:25,379 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 149.08 sec
2018-01-03 07:01:26,409 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 150.35 sec
2018-01-03 07:01:28,469 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 152.16 sec
2018-01-03 07:01:29,497 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 157.92 sec
2018-01-03 07:01:32,586 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 164.03 sec
MapReduce Total cumulative CPU time: 2 minutes 44 seconds 30 msec
Ended Job = job_1513599404024_165724
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165741, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165741/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165741
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:01:56,289 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:02:01,445 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.96 sec
2018-01-03 07:02:09,684 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 17.0 sec
2018-01-03 07:02:12,772 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 25.02 sec
MapReduce Total cumulative CPU time: 25 seconds 20 msec
Ended Job = job_1513599404024_165741
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165746, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165746/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165746
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:02:19,460 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:02:41,063 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.39 sec
2018-01-03 07:02:49,287 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.56 sec
MapReduce Total cumulative CPU time: 7 seconds 560 msec
Ended Job = job_1513599404024_165746
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 164.03 sec   HDFS Read: 250132024 HDFS Write: 2154527 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 25.02 sec   HDFS Read: 49257676 HDFS Write: 71869 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.56 sec   HDFS Read: 79544 HDFS Write: 2942 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 16 seconds 610 msec
OK
Time taken: 167.433 seconds, Fetched: 407 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.413 seconds
Query ID = boss_20180103070257_80ce1d1f-934a-4ade-a9fb-52ca4ebe7eff
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165752, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165752/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165752
Hadoop job information for Stage-1: number of mappers: 9; number of reducers: 8
2018-01-03 07:03:11,885 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:03:23,276 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 48.96 sec
2018-01-03 07:03:24,312 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 69.68 sec
2018-01-03 07:03:26,379 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 78.8 sec
2018-01-03 07:03:27,415 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 113.74 sec
2018-01-03 07:03:29,497 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 123.66 sec
2018-01-03 07:03:30,533 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 157.89 sec
2018-01-03 07:03:32,599 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 171.42 sec
2018-01-03 07:03:33,637 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 191.33 sec
2018-01-03 07:03:35,702 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 250.84 sec
2018-01-03 07:03:36,734 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 254.49 sec
2018-01-03 07:03:38,794 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 270.52 sec
2018-01-03 07:03:39,827 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 280.52 sec
2018-01-03 07:03:41,886 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 299.57 sec
2018-01-03 07:03:42,920 Stage-1 map = 64%,  reduce = 6%, Cumulative CPU 310.17 sec
2018-01-03 07:03:44,986 Stage-1 map = 65%,  reduce = 10%, Cumulative CPU 321.05 sec
2018-01-03 07:03:46,104 Stage-1 map = 67%,  reduce = 12%, Cumulative CPU 336.69 sec
2018-01-03 07:03:48,170 Stage-1 map = 72%,  reduce = 12%, Cumulative CPU 359.73 sec
2018-01-03 07:03:49,200 Stage-1 map = 78%,  reduce = 14%, Cumulative CPU 361.3 sec
2018-01-03 07:03:51,262 Stage-1 map = 78%,  reduce = 21%, Cumulative CPU 364.16 sec
2018-01-03 07:03:52,291 Stage-1 map = 78%,  reduce = 26%, Cumulative CPU 372.66 sec
2018-01-03 07:03:54,353 Stage-1 map = 79%,  reduce = 26%, Cumulative CPU 403.74 sec
2018-01-03 07:03:58,476 Stage-1 map = 80%,  reduce = 26%, Cumulative CPU 421.63 sec
2018-01-03 07:03:59,507 Stage-1 map = 81%,  reduce = 26%, Cumulative CPU 427.12 sec
2018-01-03 07:04:05,682 Stage-1 map = 83%,  reduce = 26%, Cumulative CPU 411.77 sec
2018-01-03 07:04:07,738 Stage-1 map = 86%,  reduce = 26%, Cumulative CPU 417.06 sec
2018-01-03 07:04:10,819 Stage-1 map = 87%,  reduce = 26%, Cumulative CPU 447.59 sec
2018-01-03 07:04:11,850 Stage-1 map = 92%,  reduce = 26%, Cumulative CPU 449.73 sec
2018-01-03 07:04:13,905 Stage-1 map = 92%,  reduce = 28%, Cumulative CPU 452.81 sec
2018-01-03 07:04:14,933 Stage-1 map = 92%,  reduce = 29%, Cumulative CPU 453.39 sec
2018-01-03 07:04:15,961 Stage-1 map = 94%,  reduce = 29%, Cumulative CPU 455.38 sec
2018-01-03 07:04:16,989 Stage-1 map = 94%,  reduce = 30%, Cumulative CPU 456.73 sec
2018-01-03 07:04:20,070 Stage-1 map = 95%,  reduce = 30%, Cumulative CPU 469.97 sec
2018-01-03 07:04:25,206 Stage-1 map = 100%,  reduce = 30%, Cumulative CPU 479.68 sec
2018-01-03 07:04:26,231 Stage-1 map = 100%,  reduce = 47%, Cumulative CPU 485.47 sec
2018-01-03 07:04:27,258 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 498.19 sec
2018-01-03 07:04:28,284 Stage-1 map = 100%,  reduce = 82%, Cumulative CPU 502.59 sec
2018-01-03 07:04:29,310 Stage-1 map = 100%,  reduce = 91%, Cumulative CPU 508.46 sec
2018-01-03 07:04:30,341 Stage-1 map = 100%,  reduce = 96%, Cumulative CPU 511.02 sec
2018-01-03 07:04:34,445 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 515.66 sec
2018-01-03 07:04:35,472 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 518.8 sec
MapReduce Total cumulative CPU time: 8 minutes 38 seconds 800 msec
Ended Job = job_1513599404024_165752
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165766, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165766/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165766
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:04:49,193 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:04:54,346 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.78 sec
2018-01-03 07:04:56,409 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.13 sec
2018-01-03 07:05:00,521 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.13 sec
MapReduce Total cumulative CPU time: 20 seconds 130 msec
Ended Job = job_1513599404024_165766
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165771, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165771/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165771
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:05:07,348 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:05:13,533 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.96 sec
2018-01-03 07:06:00,791 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 5.84 sec
2018-01-03 07:06:05,924 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 11.17 sec
MapReduce Total cumulative CPU time: 11 seconds 170 msec
Ended Job = job_1513599404024_165771
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 9  Reduce: 8   Cumulative CPU: 518.8 sec   HDFS Read: 774530189 HDFS Write: 502274 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.13 sec   HDFS Read: 47606995 HDFS Write: 23941 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 11.17 sec   HDFS Read: 31617 HDFS Write: 2535 SUCCESS
Total MapReduce CPU Time Spent: 9 minutes 10 seconds 100 msec
OK
Time taken: 189.89 seconds, Fetched: 353 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103070613_5053f7f8-6a5b-4b1b-9f6f-d3d53a3a2148
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165786, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165786/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165786
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:06:24,691 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:06:34,042 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 7.86 sec
2018-01-03 07:06:37,151 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 9.89 sec
2018-01-03 07:06:40,249 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 10.82 sec
2018-01-03 07:06:43,347 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 11.99 sec
2018-01-03 07:06:49,538 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 12.88 sec
2018-01-03 07:06:52,632 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 13.82 sec
2018-01-03 07:06:55,732 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 14.51 sec
2018-01-03 07:06:58,824 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 14.92 sec
2018-01-03 07:07:01,913 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 15.58 sec
2018-01-03 07:07:05,006 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 15.78 sec
2018-01-03 07:07:07,067 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 15.89 sec
2018-01-03 07:07:10,156 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 16.33 sec
2018-01-03 07:07:13,246 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 16.54 sec
2018-01-03 07:07:16,336 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 16.95 sec
2018-01-03 07:07:19,422 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 17.36 sec
2018-01-03 07:07:25,598 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 18.11 sec
2018-01-03 07:07:31,769 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 18.55 sec
2018-01-03 07:07:34,850 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 18.85 sec
2018-01-03 07:07:37,934 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 19.78 sec
2018-01-03 07:07:41,019 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 20.17 sec
2018-01-03 07:07:44,103 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 20.49 sec
2018-01-03 07:07:47,185 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 20.82 sec
2018-01-03 07:07:50,270 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 21.22 sec
2018-01-03 07:07:53,352 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 23.65 sec
2018-01-03 07:07:54,380 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.03 sec
2018-01-03 07:08:06,737 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 29.2 sec
MapReduce Total cumulative CPU time: 29 seconds 200 msec
Ended Job = job_1513599404024_165786
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165799, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165799/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165799
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:08:15,861 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:08:21,020 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.24 sec
2018-01-03 07:08:38,507 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 15.88 sec
2018-01-03 07:08:40,561 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.31 sec
MapReduce Total cumulative CPU time: 21 seconds 310 msec
Ended Job = job_1513599404024_165799
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165807, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165807/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165807
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:08:49,392 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:09:02,764 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.43 sec
2018-01-03 07:09:08,934 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.49 sec
MapReduce Total cumulative CPU time: 6 seconds 490 msec
Ended Job = job_1513599404024_165807
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 29.2 sec   HDFS Read: 103849928 HDFS Write: 458135 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 21.31 sec   HDFS Read: 47560966 HDFS Write: 165997 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.49 sec   HDFS Read: 173634 HDFS Write: 6790 SUCCESS
Total MapReduce CPU Time Spent: 57 seconds 0 msec
OK
Time taken: 177.346 seconds, Fetched: 793 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.386 seconds
Query ID = boss_20180103070917_e6d34c8f-7c8f-405b-b949-b66acdd8e87f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165813, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165813/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165813
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:09:29,023 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:09:39,391 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 8.73 sec
2018-01-03 07:09:42,494 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.32 sec
2018-01-03 07:09:45,594 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 12.71 sec
2018-01-03 07:09:48,692 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 13.98 sec
2018-01-03 07:09:51,792 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 14.8 sec
2018-01-03 07:09:54,887 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 15.39 sec
2018-01-03 07:09:57,980 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 16.76 sec
2018-01-03 07:10:01,077 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 17.99 sec
2018-01-03 07:10:04,168 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 18.82 sec
2018-01-03 07:10:07,258 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 19.87 sec
2018-01-03 07:10:10,351 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 20.51 sec
2018-01-03 07:10:13,438 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 21.64 sec
2018-01-03 07:10:16,526 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 22.32 sec
2018-01-03 07:10:18,589 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 23.16 sec
2018-01-03 07:10:21,675 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 23.92 sec
2018-01-03 07:10:24,766 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 28.16 sec
2018-01-03 07:10:41,255 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.8 sec
MapReduce Total cumulative CPU time: 35 seconds 800 msec
Ended Job = job_1513599404024_165813
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165834, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165834/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165834
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:10:46,914 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:10:53,092 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.13 sec
2018-01-03 07:11:09,548 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.92 sec
2018-01-03 07:11:12,633 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.19 sec
MapReduce Total cumulative CPU time: 19 seconds 190 msec
Ended Job = job_1513599404024_165834
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165839, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165839/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165839
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:11:19,305 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:11:27,534 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.9 sec
2018-01-03 07:11:35,762 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.05 sec
MapReduce Total cumulative CPU time: 8 seconds 50 msec
Ended Job = job_1513599404024_165839
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.8 sec   HDFS Read: 103849918 HDFS Write: 1345693 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.19 sec   HDFS Read: 48448524 HDFS Write: 159719 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.05 sec   HDFS Read: 167357 HDFS Write: 3286 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 3 seconds 40 msec
OK
Time taken: 138.847 seconds, Fetched: 494 row(s)
开始执行20171006日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.38 seconds
Query ID = boss_20180103071143_85d38a01-8c9e-4fa4-b9fd-d2b0f5ef25e5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165840, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165840/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165840
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 07:12:00,356 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:12:10,729 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.13 sec
2018-01-03 07:12:13,837 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 15.52 sec
2018-01-03 07:12:16,937 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 18.91 sec
2018-01-03 07:12:20,035 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 22.02 sec
2018-01-03 07:12:23,136 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 24.88 sec
2018-01-03 07:12:25,198 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 38.83 sec
2018-01-03 07:12:26,229 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 41.72 sec
2018-01-03 07:12:27,260 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 45.39 sec
2018-01-03 07:12:29,324 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 49.12 sec
2018-01-03 07:12:30,356 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 52.86 sec
2018-01-03 07:12:32,422 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 56.9 sec
2018-01-03 07:12:33,453 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 60.48 sec
2018-01-03 07:12:35,514 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 63.82 sec
2018-01-03 07:12:36,544 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 67.07 sec
2018-01-03 07:12:37,577 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 68.6 sec
2018-01-03 07:12:40,671 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 74.82 sec
2018-01-03 07:12:43,765 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 78.23 sec
2018-01-03 07:12:46,859 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 81.46 sec
2018-01-03 07:12:47,893 Stage-1 map = 100%,  reduce = 96%, Cumulative CPU 90.38 sec
2018-01-03 07:12:48,924 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 91.93 sec
MapReduce Total cumulative CPU time: 1 minutes 31 seconds 930 msec
Ended Job = job_1513599404024_165840
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165848, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165848/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165848
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:12:57,710 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:13:08,025 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 8.41 sec
2018-01-03 07:13:14,216 Stage-2 map = 83%,  reduce = 0%, Cumulative CPU 21.54 sec
2018-01-03 07:13:15,247 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 22.56 sec
2018-01-03 07:13:17,309 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 29.44 sec
MapReduce Total cumulative CPU time: 29 seconds 440 msec
Ended Job = job_1513599404024_165848
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165854, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165854/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165854
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:13:32,995 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:13:38,160 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.89 sec
2018-01-03 07:13:49,492 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.34 sec
MapReduce Total cumulative CPU time: 6 seconds 340 msec
Ended Job = job_1513599404024_165854
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 91.93 sec   HDFS Read: 245776797 HDFS Write: 2054118 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 29.44 sec   HDFS Read: 47510838 HDFS Write: 74399 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.34 sec   HDFS Read: 82074 HDFS Write: 2924 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 7 seconds 710 msec
OK
Time taken: 126.618 seconds, Fetched: 395 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.396 seconds
Query ID = boss_20180103071357_49bbf5bf-c64b-4e9d-a7cb-bade10df8a58
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165857, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165857/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165857
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 7
2018-01-03 07:14:10,971 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:14:22,398 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 57.6 sec
2018-01-03 07:14:25,506 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 90.71 sec
2018-01-03 07:14:27,574 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 113.1 sec
2018-01-03 07:14:28,608 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 122.81 sec
2018-01-03 07:14:30,675 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 136.41 sec
2018-01-03 07:14:31,708 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 146.76 sec
2018-01-03 07:14:33,777 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 155.6 sec
2018-01-03 07:14:34,809 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 164.69 sec
2018-01-03 07:14:36,873 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 174.08 sec
2018-01-03 07:14:37,904 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 181.33 sec
2018-01-03 07:14:38,936 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 183.05 sec
2018-01-03 07:14:39,968 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 189.2 sec
2018-01-03 07:14:42,035 Stage-1 map = 87%,  reduce = 7%, Cumulative CPU 190.44 sec
2018-01-03 07:14:43,073 Stage-1 map = 88%,  reduce = 14%, Cumulative CPU 197.85 sec
2018-01-03 07:14:44,105 Stage-1 map = 100%,  reduce = 14%, Cumulative CPU 200.84 sec
2018-01-03 07:14:45,136 Stage-1 map = 100%,  reduce = 61%, Cumulative CPU 215.2 sec
2018-01-03 07:14:46,167 Stage-1 map = 100%,  reduce = 86%, Cumulative CPU 223.22 sec
2018-01-03 07:14:51,323 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 228.49 sec
MapReduce Total cumulative CPU time: 3 minutes 48 seconds 490 msec
Ended Job = job_1513599404024_165857
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165861, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165861/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165861
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:14:57,033 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:15:02,188 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.54 sec
2018-01-03 07:15:03,218 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.72 sec
2018-01-03 07:15:09,405 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.55 sec
MapReduce Total cumulative CPU time: 14 seconds 550 msec
Ended Job = job_1513599404024_165861
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165868, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165868/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165868
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:15:16,109 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:15:28,529 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 9.47 sec
2018-01-03 07:15:34,716 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 13.32 sec
MapReduce Total cumulative CPU time: 13 seconds 320 msec
Ended Job = job_1513599404024_165868
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 7   Cumulative CPU: 228.49 sec   HDFS Read: 733563320 HDFS Write: 419415 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.55 sec   HDFS Read: 45877445 HDFS Write: 23322 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 13.32 sec   HDFS Read: 30998 HDFS Write: 2492 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 16 seconds 360 msec
OK
Time taken: 98.38 seconds, Fetched: 344 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103071542_2cf1caa8-af8a-4a7b-b8e3-375685484710
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165880, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165880/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165880
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:15:52,510 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:16:19,373 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 10.02 sec
2018-01-03 07:16:22,474 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 12.03 sec
2018-01-03 07:16:25,567 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 14.04 sec
2018-01-03 07:16:28,656 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 15.19 sec
2018-01-03 07:16:31,749 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 16.1 sec
2018-01-03 07:16:33,809 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 16.94 sec
2018-01-03 07:16:36,897 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 17.79 sec
2018-01-03 07:16:39,985 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 18.42 sec
2018-01-03 07:16:43,079 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 19.03 sec
2018-01-03 07:16:46,165 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 20.11 sec
2018-01-03 07:16:49,251 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 20.46 sec
2018-01-03 07:16:52,335 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 20.88 sec
2018-01-03 07:16:55,417 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 21.43 sec
2018-01-03 07:16:58,504 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 22.28 sec
2018-01-03 07:17:01,588 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 23.02 sec
2018-01-03 07:17:04,671 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 23.75 sec
2018-01-03 07:17:07,756 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 24.3 sec
2018-01-03 07:17:10,840 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 24.65 sec
2018-01-03 07:17:13,922 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 25.61 sec
2018-01-03 07:17:17,005 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 26.13 sec
2018-01-03 07:17:20,084 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 26.74 sec
2018-01-03 07:17:23,165 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 27.29 sec
2018-01-03 07:17:26,248 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 27.81 sec
2018-01-03 07:17:29,328 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 28.97 sec
2018-01-03 07:17:32,410 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 31.37 sec
2018-01-03 07:17:37,551 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.31 sec
MapReduce Total cumulative CPU time: 35 seconds 310 msec
Ended Job = job_1513599404024_165880
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165894, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165894/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165894
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:17:44,497 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:17:51,698 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.31 sec
2018-01-03 07:17:57,864 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.91 sec
2018-01-03 07:18:13,457 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.76 sec
MapReduce Total cumulative CPU time: 18 seconds 760 msec
Ended Job = job_1513599404024_165894
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165898, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165898/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165898
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:18:21,153 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:18:33,506 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.85 sec
2018-01-03 07:18:43,779 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.41 sec
MapReduce Total cumulative CPU time: 7 seconds 410 msec
Ended Job = job_1513599404024_165898
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.31 sec   HDFS Read: 95890862 HDFS Write: 484158 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.76 sec   HDFS Read: 45940560 HDFS Write: 184311 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.41 sec   HDFS Read: 191948 HDFS Write: 6941 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 480 msec
OK
Time taken: 182.377 seconds, Fetched: 789 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103071851_2affd29c-3158-4d11-91ab-a7be3b9e7492
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165900, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165900/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165900
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:19:06,532 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:19:17,106 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.82 sec
2018-01-03 07:19:20,207 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 14.92 sec
2018-01-03 07:19:23,302 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 17.38 sec
2018-01-03 07:19:26,392 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 18.54 sec
2018-01-03 07:19:29,488 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 20.22 sec
2018-01-03 07:19:32,578 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 21.9 sec
2018-01-03 07:19:35,666 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 23.39 sec
2018-01-03 07:19:38,757 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 25.83 sec
2018-01-03 07:19:41,843 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 27.98 sec
2018-01-03 07:19:44,930 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 29.99 sec
2018-01-03 07:19:48,018 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 31.4 sec
2018-01-03 07:19:50,084 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 34.99 sec
2018-01-03 07:20:05,528 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 41.02 sec
MapReduce Total cumulative CPU time: 41 seconds 20 msec
Ended Job = job_1513599404024_165900
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165904, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165904/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165904
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:20:11,258 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:20:19,522 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 9.24 sec
2018-01-03 07:20:24,684 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 14.27 sec
2018-01-03 07:20:26,746 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.12 sec
MapReduce Total cumulative CPU time: 20 seconds 120 msec
Ended Job = job_1513599404024_165904
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165916, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165916/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165916
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:20:34,412 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:20:46,762 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.86 sec
2018-01-03 07:20:52,930 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.77 sec
MapReduce Total cumulative CPU time: 6 seconds 770 msec
Ended Job = job_1513599404024_165916
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 41.02 sec   HDFS Read: 95890852 HDFS Write: 1561056 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.12 sec   HDFS Read: 47017458 HDFS Write: 163047 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.77 sec   HDFS Read: 170685 HDFS Write: 3341 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 7 seconds 910 msec
OK
Time taken: 122.427 seconds, Fetched: 505 row(s)
开始执行20171007日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103072100_758fe791-5dd6-4909-99bc-19eabd5227b6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165918, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165918/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165918
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 07:21:10,182 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:21:20,569 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 25.03 sec
2018-01-03 07:21:23,680 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 32.39 sec
2018-01-03 07:21:26,783 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 39.44 sec
2018-01-03 07:21:29,883 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 46.56 sec
2018-01-03 07:21:31,948 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 49.87 sec
2018-01-03 07:21:32,984 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 52.99 sec
2018-01-03 07:21:36,077 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 56.07 sec
2018-01-03 07:21:39,171 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 59.96 sec
2018-01-03 07:21:42,274 Stage-1 map = 72%,  reduce = 8%, Cumulative CPU 63.88 sec
2018-01-03 07:21:43,306 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 64.45 sec
2018-01-03 07:21:45,371 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 67.16 sec
2018-01-03 07:21:48,464 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 70.73 sec
2018-01-03 07:21:51,563 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 73.84 sec
2018-01-03 07:21:53,624 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 76.85 sec
2018-01-03 07:21:54,655 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 78.11 sec
2018-01-03 07:21:55,688 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 78.17 sec
2018-01-03 07:21:56,718 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 88.2 sec
MapReduce Total cumulative CPU time: 1 minutes 28 seconds 200 msec
Ended Job = job_1513599404024_165918
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165924, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165924/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165924
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:22:05,449 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:22:13,701 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.49 sec
2018-01-03 07:22:14,732 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.12 sec
2018-01-03 07:22:20,920 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.93 sec
MapReduce Total cumulative CPU time: 19 seconds 930 msec
Ended Job = job_1513599404024_165924
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165927, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165927/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165927
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:22:27,600 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:22:35,862 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.05 sec
2018-01-03 07:22:41,019 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.29 sec
MapReduce Total cumulative CPU time: 7 seconds 290 msec
Ended Job = job_1513599404024_165927
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 88.2 sec   HDFS Read: 254995192 HDFS Write: 2168218 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.93 sec   HDFS Read: 48391174 HDFS Write: 76389 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.29 sec   HDFS Read: 84064 HDFS Write: 3039 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 55 seconds 420 msec
OK
Time taken: 101.187 seconds, Fetched: 392 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.408 seconds
Query ID = boss_20180103072248_289da4d8-ab17-4c54-a55f-db09306125ad
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165931, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165931/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165931
Hadoop job information for Stage-1: number of mappers: 9; number of reducers: 7
2018-01-03 07:24:27,069 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:24:40,077 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 25.78 sec
2018-01-03 07:24:41,215 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 44.27 sec
2018-01-03 07:24:42,349 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 55.63 sec
2018-01-03 07:24:43,416 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 71.85 sec
2018-01-03 07:24:44,476 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 99.52 sec
2018-01-03 07:24:45,547 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 103.51 sec
2018-01-03 07:24:48,909 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 111.71 sec
2018-01-03 07:24:50,370 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 166.66 sec
2018-01-03 07:24:52,502 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 174.04 sec
2018-01-03 07:24:53,578 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 188.05 sec
2018-01-03 07:24:54,642 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 211.93 sec
2018-01-03 07:24:56,761 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 221.37 sec
2018-01-03 07:24:57,826 Stage-1 map = 73%,  reduce = 2%, Cumulative CPU 232.21 sec
2018-01-03 07:24:58,885 Stage-1 map = 78%,  reduce = 11%, Cumulative CPU 236.94 sec
2018-01-03 07:24:59,953 Stage-1 map = 81%,  reduce = 14%, Cumulative CPU 243.51 sec
2018-01-03 07:25:01,005 Stage-1 map = 82%,  reduce = 18%, Cumulative CPU 247.67 sec
2018-01-03 07:25:02,149 Stage-1 map = 89%,  reduce = 22%, Cumulative CPU 253.8 sec
2018-01-03 07:25:03,213 Stage-1 map = 95%,  reduce = 23%, Cumulative CPU 257.68 sec
2018-01-03 07:25:04,277 Stage-1 map = 95%,  reduce = 26%, Cumulative CPU 258.23 sec
2018-01-03 07:25:05,330 Stage-1 map = 100%,  reduce = 29%, Cumulative CPU 262.46 sec
2018-01-03 07:25:07,453 Stage-1 map = 100%,  reduce = 90%, Cumulative CPU 284.21 sec
2018-01-03 07:25:08,497 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 293.08 sec
MapReduce Total cumulative CPU time: 4 minutes 53 seconds 80 msec
Ended Job = job_1513599404024_165931
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165941, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165941/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165941
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:25:15,650 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:25:20,823 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.18 sec
2018-01-03 07:25:27,012 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.37 sec
2018-01-03 07:25:29,076 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.37 sec
MapReduce Total cumulative CPU time: 14 seconds 370 msec
Ended Job = job_1513599404024_165941
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165945, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165945/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165945
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:25:42,878 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:25:58,339 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.42 sec
2018-01-03 07:26:04,530 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.63 sec
MapReduce Total cumulative CPU time: 6 seconds 630 msec
Ended Job = job_1513599404024_165945
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 9  Reduce: 7   Cumulative CPU: 293.08 sec   HDFS Read: 761312636 HDFS Write: 415135 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.37 sec   HDFS Read: 46639401 HDFS Write: 24371 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.63 sec   HDFS Read: 32047 HDFS Write: 2426 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 14 seconds 80 msec
OK
Time taken: 196.637 seconds, Fetched: 347 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103072612_b5384180-7408-45e4-bd1a-7f1ecca34dba
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165947, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165947/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165947
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:26:29,311 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:26:39,684 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 9.87 sec
2018-01-03 07:26:42,785 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 12.02 sec
2018-01-03 07:26:45,875 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 13.27 sec
2018-01-03 07:26:48,966 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 14.43 sec
2018-01-03 07:26:51,028 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 15.18 sec
2018-01-03 07:26:54,118 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 15.9 sec
2018-01-03 07:26:57,205 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 16.81 sec
2018-01-03 07:27:00,296 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 17.36 sec
2018-01-03 07:27:03,383 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 18.42 sec
2018-01-03 07:27:06,469 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 19.19 sec
2018-01-03 07:27:09,561 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 19.82 sec
2018-01-03 07:27:12,647 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 20.28 sec
2018-01-03 07:27:15,733 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 21.21 sec
2018-01-03 07:27:18,827 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 21.72 sec
2018-01-03 07:27:21,910 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 22.22 sec
2018-01-03 07:27:24,992 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 22.86 sec
2018-01-03 07:27:28,078 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 26.34 sec
2018-01-03 07:27:33,218 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.55 sec
MapReduce Total cumulative CPU time: 30 seconds 550 msec
Ended Job = job_1513599404024_165947
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165958, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165958/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165958
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:27:40,906 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:27:46,066 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.27 sec
2018-01-03 07:27:47,096 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.18 sec
2018-01-03 07:27:52,241 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.24 sec
MapReduce Total cumulative CPU time: 16 seconds 240 msec
Ended Job = job_1513599404024_165958
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165960, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165960/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165960
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:28:12,892 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:28:20,120 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.82 sec
2018-01-03 07:28:26,301 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.47 sec
MapReduce Total cumulative CPU time: 7 seconds 470 msec
Ended Job = job_1513599404024_165960
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.55 sec   HDFS Read: 102396234 HDFS Write: 522130 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.24 sec   HDFS Read: 46744768 HDFS Write: 192437 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.47 sec   HDFS Read: 200074 HDFS Write: 6786 SUCCESS
Total MapReduce CPU Time Spent: 54 seconds 260 msec
OK
Time taken: 136.132 seconds, Fetched: 791 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.365 seconds
Query ID = boss_20180103072835_2786f6b8-9018-4869-b272-a1517ee46fe3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165968, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165968/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165968
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:28:45,133 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:28:54,514 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 9.42 sec
2018-01-03 07:28:57,613 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 10.95 sec
2018-01-03 07:29:00,704 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 11.96 sec
2018-01-03 07:29:03,792 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 13.1 sec
2018-01-03 07:29:06,888 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 14.36 sec
2018-01-03 07:29:09,980 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 15.64 sec
2018-01-03 07:29:13,067 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 16.62 sec
2018-01-03 07:29:16,156 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 17.68 sec
2018-01-03 07:29:19,239 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 18.96 sec
2018-01-03 07:29:20,266 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 21.44 sec
2018-01-03 07:29:26,441 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 27.1 sec
MapReduce Total cumulative CPU time: 27 seconds 100 msec
Ended Job = job_1513599404024_165968
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165973, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165973/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165973
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:29:33,273 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:29:40,496 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.61 sec
2018-01-03 07:29:46,676 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.68 sec
2018-01-03 07:29:48,735 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.28 sec
MapReduce Total cumulative CPU time: 17 seconds 280 msec
Ended Job = job_1513599404024_165973
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165977, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165977/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165977
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:30:41,802 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:30:50,335 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.08 sec
2018-01-03 07:30:58,961 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.1 sec
MapReduce Total cumulative CPU time: 7 seconds 100 msec
Ended Job = job_1513599404024_165977
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 27.1 sec   HDFS Read: 102396224 HDFS Write: 1353681 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.28 sec   HDFS Read: 47576319 HDFS Write: 171256 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.1 sec   HDFS Read: 178894 HDFS Write: 3390 SUCCESS
Total MapReduce CPU Time Spent: 51 seconds 480 msec
OK
Time taken: 146.213 seconds, Fetched: 515 row(s)
开始执行20171008日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103073108_2ec903c6-35bc-4d8d-8801-35b82837ea86
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_165996, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_165996/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_165996
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 07:31:18,429 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:31:27,787 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 13.38 sec
2018-01-03 07:31:28,820 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 54.98 sec
2018-01-03 07:31:30,884 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 58.92 sec
2018-01-03 07:31:31,919 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 62.42 sec
2018-01-03 07:31:33,981 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 66.14 sec
2018-01-03 07:31:35,012 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 69.74 sec
2018-01-03 07:31:37,073 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 73.21 sec
2018-01-03 07:31:38,104 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 91.25 sec
2018-01-03 07:31:40,163 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 94.72 sec
2018-01-03 07:31:41,197 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 99.33 sec
2018-01-03 07:31:44,284 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 103.26 sec
2018-01-03 07:31:47,371 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 106.38 sec
2018-01-03 07:31:50,459 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 109.45 sec
2018-01-03 07:31:52,530 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 110.03 sec
2018-01-03 07:31:53,562 Stage-1 map = 80%,  reduce = 8%, Cumulative CPU 113.03 sec
2018-01-03 07:31:55,629 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 115.87 sec
2018-01-03 07:31:57,695 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 125.95 sec
MapReduce Total cumulative CPU time: 2 minutes 5 seconds 950 msec
Ended Job = job_1513599404024_165996
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166008, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166008/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166008
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:32:20,613 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:32:26,965 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.15 sec
2018-01-03 07:32:36,359 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.88 sec
2018-01-03 07:32:38,420 Stage-2 map = 100%,  reduce = 78%, Cumulative CPU 17.0 sec
2018-01-03 07:32:39,449 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.85 sec
MapReduce Total cumulative CPU time: 19 seconds 850 msec
Ended Job = job_1513599404024_166008
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166011, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166011/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166011
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:32:46,094 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:33:07,885 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.46 sec
2018-01-03 07:33:14,053 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.03 sec
MapReduce Total cumulative CPU time: 6 seconds 30 msec
Ended Job = job_1513599404024_166011
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 125.95 sec   HDFS Read: 257696380 HDFS Write: 2408694 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.85 sec   HDFS Read: 57460821 HDFS Write: 80810 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.03 sec   HDFS Read: 88485 HDFS Write: 3157 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 31 seconds 830 msec
OK
Time taken: 126.583 seconds, Fetched: 423 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.389 seconds
Query ID = boss_20180103073321_15f1c6a8-b049-4b47-b7f3-2060e636c7f9
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 7
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166016, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166016/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166016
Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 7
2018-01-03 07:33:31,363 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:33:40,835 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 40.08 sec
2018-01-03 07:33:43,948 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 71.07 sec
2018-01-03 07:33:46,017 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 74.65 sec
2018-01-03 07:33:47,801 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 89.42 sec
2018-01-03 07:33:49,314 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 105.82 sec
2018-01-03 07:33:50,347 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 111.63 sec
2018-01-03 07:33:51,380 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 160.24 sec
2018-01-03 07:33:53,606 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 160.24 sec
2018-01-03 07:33:54,639 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 178.51 sec
2018-01-03 07:33:56,706 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 182.73 sec
2018-01-03 07:33:57,739 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 196.55 sec
2018-01-03 07:33:58,772 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 199.47 sec
2018-01-03 07:33:59,804 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 202.01 sec
2018-01-03 07:34:00,836 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 210.99 sec
2018-01-03 07:34:01,871 Stage-1 map = 81%,  reduce = 9%, Cumulative CPU 214.3 sec
2018-01-03 07:34:02,903 Stage-1 map = 81%,  reduce = 15%, Cumulative CPU 215.63 sec
2018-01-03 07:34:03,964 Stage-1 map = 81%,  reduce = 18%, Cumulative CPU 226.59 sec
2018-01-03 07:34:04,995 Stage-1 map = 81%,  reduce = 20%, Cumulative CPU 226.8 sec
2018-01-03 07:34:06,032 Stage-1 map = 81%,  reduce = 21%, Cumulative CPU 226.96 sec
2018-01-03 07:34:07,064 Stage-1 map = 88%,  reduce = 21%, Cumulative CPU 241.94 sec
2018-01-03 07:34:08,099 Stage-1 map = 88%,  reduce = 23%, Cumulative CPU 242.37 sec
2018-01-03 07:34:09,129 Stage-1 map = 89%,  reduce = 24%, Cumulative CPU 255.43 sec
2018-01-03 07:34:10,161 Stage-1 map = 89%,  reduce = 29%, Cumulative CPU 256.09 sec
2018-01-03 07:34:12,222 Stage-1 map = 91%,  reduce = 29%, Cumulative CPU 260.72 sec
2018-01-03 07:34:15,319 Stage-1 map = 93%,  reduce = 29%, Cumulative CPU 264.28 sec
2018-01-03 07:34:18,411 Stage-1 map = 95%,  reduce = 29%, Cumulative CPU 268.25 sec
2018-01-03 07:34:19,441 Stage-1 map = 100%,  reduce = 29%, Cumulative CPU 270.06 sec
2018-01-03 07:34:20,471 Stage-1 map = 100%,  reduce = 75%, Cumulative CPU 284.38 sec
2018-01-03 07:34:21,501 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 296.4 sec
MapReduce Total cumulative CPU time: 4 minutes 56 seconds 400 msec
Ended Job = job_1513599404024_166016
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166021, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166021/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166021
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:34:28,209 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:34:33,375 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.3 sec
2018-01-03 07:34:40,592 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.6 sec
MapReduce Total cumulative CPU time: 14 seconds 600 msec
Ended Job = job_1513599404024_166021
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166022, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166022/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166022
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:34:47,295 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:34:52,458 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.61 sec
2018-01-03 07:34:58,633 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.56 sec
MapReduce Total cumulative CPU time: 5 seconds 560 msec
Ended Job = job_1513599404024_166022
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 8  Reduce: 7   Cumulative CPU: 296.4 sec   HDFS Read: 732556347 HDFS Write: 715043 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.6 sec   HDFS Read: 55768480 HDFS Write: 24172 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.56 sec   HDFS Read: 31848 HDFS Write: 2364 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 16 seconds 560 msec
OK
Time taken: 97.881 seconds, Fetched: 343 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103073506_67c50176-1ae7-41a8-b9d3-459e3464f8c0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166024, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166024/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166024
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:35:38,415 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:35:47,757 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 10.04 sec
2018-01-03 07:35:50,862 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 13.38 sec
2018-01-03 07:35:53,962 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 14.41 sec
2018-01-03 07:35:57,080 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.27 sec
2018-01-03 07:36:00,175 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 16.02 sec
2018-01-03 07:36:03,267 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 16.79 sec
2018-01-03 07:36:06,356 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 17.25 sec
2018-01-03 07:36:09,454 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 17.81 sec
2018-01-03 07:36:12,550 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 18.4 sec
2018-01-03 07:36:16,278 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 19.33 sec
2018-01-03 07:36:18,348 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 19.77 sec
2018-01-03 07:36:21,436 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 20.11 sec
2018-01-03 07:36:24,531 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 20.97 sec
2018-01-03 07:36:27,626 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 21.64 sec
2018-01-03 07:36:30,714 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 21.97 sec
2018-01-03 07:36:33,799 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 24.05 sec
2018-01-03 07:36:35,855 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.42 sec
2018-01-03 07:36:42,058 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 29.61 sec
MapReduce Total cumulative CPU time: 29 seconds 610 msec
Ended Job = job_1513599404024_166024
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166040, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166040/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166040
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:36:49,474 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:36:54,651 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.63 sec
2018-01-03 07:36:55,686 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 4.63 sec
2018-01-03 07:37:09,129 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.49 sec
MapReduce Total cumulative CPU time: 17 seconds 490 msec
Ended Job = job_1513599404024_166040
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166042, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166042/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166042
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:37:25,351 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:37:33,588 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.49 sec
2018-01-03 07:37:39,755 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.31 sec
MapReduce Total cumulative CPU time: 7 seconds 310 msec
Ended Job = job_1513599404024_166042
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 29.61 sec   HDFS Read: 104791449 HDFS Write: 544779 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.49 sec   HDFS Read: 55596588 HDFS Write: 204211 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.31 sec   HDFS Read: 211848 HDFS Write: 7116 SUCCESS
Total MapReduce CPU Time Spent: 54 seconds 410 msec
OK
Time taken: 154.401 seconds, Fetched: 841 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.344 seconds
Query ID = boss_20180103073747_24817d09-0297-42e2-b423-48e266e962c1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166045, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166045/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166045
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:37:57,483 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:38:07,838 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 11.8 sec
2018-01-03 07:38:10,938 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 14.6 sec
2018-01-03 07:38:14,031 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 16.42 sec
2018-01-03 07:38:17,128 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 18.18 sec
2018-01-03 07:38:20,226 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 19.78 sec
2018-01-03 07:38:23,325 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 21.58 sec
2018-01-03 07:38:26,412 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 23.37 sec
2018-01-03 07:38:29,503 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 25.15 sec
2018-01-03 07:38:32,590 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 28.15 sec
2018-01-03 07:38:35,678 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 29.54 sec
2018-01-03 07:38:38,769 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 31.82 sec
2018-01-03 07:38:40,826 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 35.39 sec
2018-01-03 07:38:47,009 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 39.96 sec
MapReduce Total cumulative CPU time: 39 seconds 960 msec
Ended Job = job_1513599404024_166045
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166050, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166050/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166050
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:39:09,746 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:39:14,922 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.64 sec
2018-01-03 07:39:23,164 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.08 sec
MapReduce Total cumulative CPU time: 16 seconds 80 msec
Ended Job = job_1513599404024_166050
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166053, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166053/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166053
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:39:29,789 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:39:37,115 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.45 sec
2018-01-03 07:39:48,453 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.29 sec
MapReduce Total cumulative CPU time: 9 seconds 290 msec
Ended Job = job_1513599404024_166053
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 39.96 sec   HDFS Read: 104791439 HDFS Write: 1589573 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.08 sec   HDFS Read: 56641382 HDFS Write: 174758 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.29 sec   HDFS Read: 182396 HDFS Write: 3569 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 5 seconds 330 msec
OK
Time taken: 122.011 seconds, Fetched: 598 row(s)
开始执行20171009日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.362 seconds
Query ID = boss_20180103073956_48ee3272-8a18-4eef-a029-d18cd486ba05
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166058, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166058/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166058
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 07:40:05,412 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:40:15,800 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 25.81 sec
2018-01-03 07:40:18,915 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 34.2 sec
2018-01-03 07:40:20,985 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 36.14 sec
2018-01-03 07:40:22,020 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 54.02 sec
2018-01-03 07:40:25,123 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 61.7 sec
2018-01-03 07:40:28,222 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 64.46 sec
2018-01-03 07:40:31,321 Stage-1 map = 63%,  reduce = 8%, Cumulative CPU 68.44 sec
2018-01-03 07:40:34,418 Stage-1 map = 64%,  reduce = 8%, Cumulative CPU 72.19 sec
2018-01-03 07:40:38,542 Stage-1 map = 66%,  reduce = 8%, Cumulative CPU 75.48 sec
2018-01-03 07:40:41,634 Stage-1 map = 67%,  reduce = 8%, Cumulative CPU 78.02 sec
2018-01-03 07:40:44,728 Stage-1 map = 69%,  reduce = 8%, Cumulative CPU 82.47 sec
2018-01-03 07:40:45,758 Stage-1 map = 70%,  reduce = 8%, Cumulative CPU 51.57 sec
2018-01-03 07:40:47,821 Stage-1 map = 72%,  reduce = 8%, Cumulative CPU 85.55 sec
2018-01-03 07:40:48,850 Stage-1 map = 73%,  reduce = 8%, Cumulative CPU 54.7 sec
2018-01-03 07:40:50,909 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 89.65 sec
2018-01-03 07:40:51,939 Stage-1 map = 76%,  reduce = 8%, Cumulative CPU 58.05 sec
2018-01-03 07:40:52,968 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 59.07 sec
2018-01-03 07:40:55,027 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 62.31 sec
2018-01-03 07:40:58,116 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 65.93 sec
2018-01-03 07:41:01,204 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 75.9 sec
2018-01-03 07:41:03,261 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 85.49 sec
MapReduce Total cumulative CPU time: 1 minutes 25 seconds 490 msec
Ended Job = job_1513599404024_166058
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166075, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166075/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166075
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:41:11,081 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:41:16,384 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.69 sec
2018-01-03 07:41:26,709 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 10.73 sec
2018-01-03 07:41:27,741 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.96 sec
MapReduce Total cumulative CPU time: 15 seconds 960 msec
Ended Job = job_1513599404024_166075
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166078, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166078/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166078
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:41:51,446 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:41:55,576 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.18 sec
2018-01-03 07:42:01,767 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.3 sec
MapReduce Total cumulative CPU time: 6 seconds 300 msec
Ended Job = job_1513599404024_166078
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 85.49 sec   HDFS Read: 201216930 HDFS Write: 1923642 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.96 sec   HDFS Read: 50267779 HDFS Write: 79041 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.3 sec   HDFS Read: 86716 HDFS Write: 3076 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 47 seconds 750 msec
OK
Time taken: 127.396 seconds, Fetched: 412 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.425 seconds
Query ID = boss_20180103074218_a95b7050-a3af-4b4d-8173-bce551bc2976
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166085, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166085/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166085
Hadoop job information for Stage-1: number of mappers: 6; number of reducers: 6
2018-01-03 07:42:34,777 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:42:44,816 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.79 sec
2018-01-03 07:42:45,850 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 24.83 sec
2018-01-03 07:42:46,884 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 37.3 sec
2018-01-03 07:42:47,919 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 41.93 sec
2018-01-03 07:42:48,956 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 54.69 sec
2018-01-03 07:42:49,989 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 75.57 sec
2018-01-03 07:42:51,731 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 78.2 sec
2018-01-03 07:42:53,594 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 103.54 sec
2018-01-03 07:42:56,899 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 109.71 sec
2018-01-03 07:42:57,942 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 123.44 sec
2018-01-03 07:42:58,972 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 128.2 sec
2018-01-03 07:43:00,002 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 138.92 sec
2018-01-03 07:43:03,097 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 148.05 sec
2018-01-03 07:43:05,170 Stage-1 map = 93%,  reduce = 0%, Cumulative CPU 154.54 sec
2018-01-03 07:43:06,204 Stage-1 map = 100%,  reduce = 15%, Cumulative CPU 161.05 sec
2018-01-03 07:43:07,234 Stage-1 map = 100%,  reduce = 87%, Cumulative CPU 181.79 sec
2018-01-03 07:43:08,263 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 186.81 sec
MapReduce Total cumulative CPU time: 3 minutes 6 seconds 810 msec
Ended Job = job_1513599404024_166085
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166088, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166088/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166088
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:43:13,949 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:43:20,135 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.26 sec
2018-01-03 07:43:25,282 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.42 sec
2018-01-03 07:43:27,340 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.54 sec
MapReduce Total cumulative CPU time: 16 seconds 540 msec
Ended Job = job_1513599404024_166088
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166089, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166089/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166089
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:43:40,989 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:43:46,145 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.02 sec
2018-01-03 07:43:55,402 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.08 sec
MapReduce Total cumulative CPU time: 6 seconds 80 msec
Ended Job = job_1513599404024_166089
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 6  Reduce: 6   Cumulative CPU: 186.81 sec   HDFS Read: 582944415 HDFS Write: 505545 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.54 sec   HDFS Read: 48850730 HDFS Write: 20822 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.08 sec   HDFS Read: 28498 HDFS Write: 2311 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 29 seconds 430 msec
OK
Time taken: 97.76 seconds, Fetched: 332 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103074403_b41b2fb5-8f92-4c93-b346-c8b1c60f7722
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166093, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166093/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166093
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:44:14,558 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:44:25,118 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.9 sec
2018-01-03 07:44:28,216 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 14.7 sec
2018-01-03 07:44:31,308 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 16.54 sec
2018-01-03 07:44:34,400 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 17.78 sec
2018-01-03 07:44:37,493 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 18.56 sec
2018-01-03 07:44:40,582 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 19.27 sec
2018-01-03 07:44:43,672 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 20.42 sec
2018-01-03 07:44:46,765 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 21.45 sec
2018-01-03 07:44:49,850 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 22.45 sec
2018-01-03 07:44:52,935 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 23.56 sec
2018-01-03 07:44:56,024 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 24.22 sec
2018-01-03 07:44:59,113 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 25.03 sec
2018-01-03 07:45:02,200 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 25.93 sec
2018-01-03 07:45:05,287 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 26.82 sec
2018-01-03 07:45:08,369 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 27.6 sec
2018-01-03 07:45:11,451 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 28.41 sec
2018-01-03 07:45:14,537 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 31.25 sec
2018-01-03 07:45:15,564 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.76 sec
2018-01-03 07:45:22,765 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 36.44 sec
MapReduce Total cumulative CPU time: 36 seconds 440 msec
Ended Job = job_1513599404024_166093
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166100, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166100/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166100
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:45:44,441 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:45:49,588 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.59 sec
2018-01-03 07:45:56,791 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.55 sec
MapReduce Total cumulative CPU time: 13 seconds 550 msec
Ended Job = job_1513599404024_166100
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166101, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166101/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166101
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:46:30,614 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:46:36,998 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.04 sec
2018-01-03 07:46:42,399 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.12 sec
MapReduce Total cumulative CPU time: 6 seconds 120 msec
Ended Job = job_1513599404024_166101
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 36.44 sec   HDFS Read: 87804689 HDFS Write: 564284 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.55 sec   HDFS Read: 48908103 HDFS Write: 187905 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.12 sec   HDFS Read: 195542 HDFS Write: 6675 SUCCESS
Total MapReduce CPU Time Spent: 56 seconds 110 msec
OK
Time taken: 161.437 seconds, Fetched: 799 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103074651_38c0a724-e9f0-4899-82a3-32a48446cda8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166109, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166109/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166109
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:47:03,847 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:47:14,339 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 9.28 sec
2018-01-03 07:47:17,438 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 11.82 sec
2018-01-03 07:47:20,532 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 14.44 sec
2018-01-03 07:47:23,622 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 15.86 sec
2018-01-03 07:47:26,713 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 16.94 sec
2018-01-03 07:47:28,772 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 17.67 sec
2018-01-03 07:47:31,859 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 18.91 sec
2018-01-03 07:47:34,951 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 20.09 sec
2018-01-03 07:47:38,037 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 21.47 sec
2018-01-03 07:47:41,122 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 22.73 sec
2018-01-03 07:47:44,210 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.54 sec
2018-01-03 07:47:50,389 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 29.99 sec
MapReduce Total cumulative CPU time: 29 seconds 990 msec
Ended Job = job_1513599404024_166109
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166113, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166113/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166113
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:47:57,622 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:48:02,795 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.55 sec
2018-01-03 07:48:10,015 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.56 sec
2018-01-03 07:48:24,434 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.02 sec
MapReduce Total cumulative CPU time: 15 seconds 20 msec
Ended Job = job_1513599404024_166113
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166115, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166115/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166115
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:48:30,103 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:48:34,223 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.73 sec
2018-01-03 07:48:40,385 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.43 sec
MapReduce Total cumulative CPU time: 6 seconds 430 msec
Ended Job = job_1513599404024_166115
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 29.99 sec   HDFS Read: 87804679 HDFS Write: 1116331 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.02 sec   HDFS Read: 49460150 HDFS Write: 159614 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.43 sec   HDFS Read: 167252 HDFS Write: 3266 SUCCESS
Total MapReduce CPU Time Spent: 51 seconds 440 msec
OK
Time taken: 110.166 seconds, Fetched: 467 row(s)
开始执行20171010日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103074848_6fd9e3af-de48-4ef3-9a22-14882304d4dd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166116, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166116/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166116
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 07:48:57,230 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:49:07,582 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 13.92 sec
2018-01-03 07:49:08,614 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 26.33 sec
2018-01-03 07:49:10,682 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 31.12 sec
2018-01-03 07:49:11,714 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 35.97 sec
2018-01-03 07:49:12,746 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 38.64 sec
2018-01-03 07:49:13,778 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 42.26 sec
2018-01-03 07:49:16,870 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 46.63 sec
2018-01-03 07:49:19,963 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 50.25 sec
2018-01-03 07:49:23,053 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 54.45 sec
2018-01-03 07:49:24,088 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 55.65 sec
2018-01-03 07:49:26,149 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 59.19 sec
2018-01-03 07:49:29,246 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 62.81 sec
2018-01-03 07:49:32,335 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 66.48 sec
2018-01-03 07:49:34,392 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 70.35 sec
2018-01-03 07:49:35,421 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 71.22 sec
2018-01-03 07:49:37,479 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 79.63 sec
MapReduce Total cumulative CPU time: 1 minutes 19 seconds 630 msec
Ended Job = job_1513599404024_166116
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166119, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166119/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166119
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:49:44,183 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:49:49,349 Stage-2 map = 50%,  reduce = 0%
2018-01-03 07:49:55,529 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.05 sec
2018-01-03 07:49:58,621 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.58 sec
MapReduce Total cumulative CPU time: 17 seconds 580 msec
Ended Job = job_1513599404024_166119
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166122, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166122/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166122
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:50:12,259 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:50:22,548 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.16 sec
2018-01-03 07:50:28,723 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.62 sec
MapReduce Total cumulative CPU time: 5 seconds 620 msec
Ended Job = job_1513599404024_166122
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 79.63 sec   HDFS Read: 200871885 HDFS Write: 1716919 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.58 sec   HDFS Read: 47714939 HDFS Write: 67520 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.62 sec   HDFS Read: 75195 HDFS Write: 2853 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 42 seconds 830 msec
OK
Time taken: 101.401 seconds, Fetched: 385 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.391 seconds
Query ID = boss_20180103075036_5d2ebb70-81e0-4831-a85e-1ffbb0916a6f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166129, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166129/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166129
Hadoop job information for Stage-1: number of mappers: 6; number of reducers: 6
2018-01-03 07:50:45,655 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:50:56,005 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 48.76 sec
2018-01-03 07:50:57,039 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 60.46 sec
2018-01-03 07:50:59,108 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 80.86 sec
2018-01-03 07:51:02,210 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 94.46 sec
2018-01-03 07:51:03,241 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 96.78 sec
2018-01-03 07:51:05,301 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 106.09 sec
2018-01-03 07:51:07,360 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 112.34 sec
2018-01-03 07:51:08,393 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 115.79 sec
2018-01-03 07:51:09,427 Stage-1 map = 74%,  reduce = 7%, Cumulative CPU 116.7 sec
2018-01-03 07:51:10,457 Stage-1 map = 74%,  reduce = 11%, Cumulative CPU 117.36 sec
2018-01-03 07:51:11,487 Stage-1 map = 75%,  reduce = 11%, Cumulative CPU 120.39 sec
2018-01-03 07:51:13,546 Stage-1 map = 77%,  reduce = 11%, Cumulative CPU 134.99 sec
2018-01-03 07:51:14,576 Stage-1 map = 79%,  reduce = 11%, Cumulative CPU 138.07 sec
2018-01-03 07:51:16,635 Stage-1 map = 87%,  reduce = 11%, Cumulative CPU 144.93 sec
2018-01-03 07:51:17,668 Stage-1 map = 87%,  reduce = 23%, Cumulative CPU 146.54 sec
2018-01-03 07:51:18,697 Stage-1 map = 87%,  reduce = 25%, Cumulative CPU 146.81 sec
2018-01-03 07:51:19,727 Stage-1 map = 89%,  reduce = 26%, Cumulative CPU 150.43 sec
2018-01-03 07:51:20,756 Stage-1 map = 89%,  reduce = 28%, Cumulative CPU 150.56 sec
2018-01-03 07:51:22,813 Stage-1 map = 90%,  reduce = 28%, Cumulative CPU 154.14 sec
2018-01-03 07:51:25,898 Stage-1 map = 91%,  reduce = 28%, Cumulative CPU 157.82 sec
2018-01-03 07:51:28,986 Stage-1 map = 92%,  reduce = 28%, Cumulative CPU 160.73 sec
2018-01-03 07:51:32,070 Stage-1 map = 93%,  reduce = 28%, Cumulative CPU 161.82 sec
2018-01-03 07:51:35,157 Stage-1 map = 100%,  reduce = 28%, Cumulative CPU 155.38 sec
2018-01-03 07:51:36,192 Stage-1 map = 100%,  reduce = 41%, Cumulative CPU 156.97 sec
2018-01-03 07:51:37,220 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 176.12 sec
MapReduce Total cumulative CPU time: 2 minutes 56 seconds 120 msec
Ended Job = job_1513599404024_166129
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166133, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166133/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166133
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:51:50,906 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:51:56,058 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.08 sec
2018-01-03 07:51:58,117 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.96 sec
2018-01-03 07:52:08,402 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.44 sec
MapReduce Total cumulative CPU time: 17 seconds 440 msec
Ended Job = job_1513599404024_166133
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166135, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166135/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166135
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:52:14,011 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:52:26,347 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.32 sec
2018-01-03 07:52:32,517 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.2 sec
MapReduce Total cumulative CPU time: 5 seconds 200 msec
Ended Job = job_1513599404024_166135
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 6  Reduce: 6   Cumulative CPU: 176.12 sec   HDFS Read: 568248861 HDFS Write: 372065 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.44 sec   HDFS Read: 46371133 HDFS Write: 19988 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.2 sec   HDFS Read: 27664 HDFS Write: 2222 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 18 seconds 760 msec
OK
Time taken: 118.13 seconds, Fetched: 317 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103075241_b4df9887-73eb-4817-86a8-c2062020fab4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166137, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166137/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166137
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:52:51,499 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:53:00,820 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 8.28 sec
2018-01-03 07:53:03,947 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.25 sec
2018-01-03 07:53:07,052 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.23 sec
2018-01-03 07:53:10,149 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 12.9 sec
2018-01-03 07:53:13,246 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 13.34 sec
2018-01-03 07:53:16,345 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 14.0 sec
2018-01-03 07:53:19,439 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 14.59 sec
2018-01-03 07:53:22,541 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 15.51 sec
2018-01-03 07:53:25,630 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 16.14 sec
2018-01-03 07:53:28,719 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 17.2 sec
2018-01-03 07:53:31,814 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 17.55 sec
2018-01-03 07:53:33,874 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 18.46 sec
2018-01-03 07:53:36,960 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 18.9 sec
2018-01-03 07:53:40,049 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 19.37 sec
2018-01-03 07:53:43,133 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 21.07 sec
2018-01-03 07:53:46,214 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 22.64 sec
2018-01-03 07:54:00,610 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 27.56 sec
MapReduce Total cumulative CPU time: 27 seconds 560 msec
Ended Job = job_1513599404024_166137
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166141, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166141/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166141
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:54:06,316 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:54:12,513 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.71 sec
2018-01-03 07:54:17,660 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.81 sec
MapReduce Total cumulative CPU time: 14 seconds 810 msec
Ended Job = job_1513599404024_166141
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166144, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166144/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166144
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:54:23,325 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:54:28,474 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.95 sec
2018-01-03 07:54:33,628 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.53 sec
MapReduce Total cumulative CPU time: 5 seconds 530 msec
Ended Job = job_1513599404024_166144
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 27.56 sec   HDFS Read: 85453758 HDFS Write: 532158 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.81 sec   HDFS Read: 46529856 HDFS Write: 174283 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.53 sec   HDFS Read: 181916 HDFS Write: 6448 SUCCESS
Total MapReduce CPU Time Spent: 47 seconds 900 msec
OK
Time taken: 113.436 seconds, Fetched: 766 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103075441_6bc9c0ba-9d0c-4431-b0f9-0ad6f557a7fa
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166145, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166145/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166145
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 07:54:51,404 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:55:00,736 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 10.26 sec
2018-01-03 07:55:03,832 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 11.83 sec
2018-01-03 07:55:06,922 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 12.8 sec
2018-01-03 07:55:10,009 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 14.1 sec
2018-01-03 07:55:13,098 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 15.52 sec
2018-01-03 07:55:16,185 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 16.44 sec
2018-01-03 07:55:19,273 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 17.65 sec
2018-01-03 07:55:22,364 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 18.55 sec
2018-01-03 07:55:24,422 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 21.45 sec
2018-01-03 07:55:35,736 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 26.6 sec
MapReduce Total cumulative CPU time: 26 seconds 600 msec
Ended Job = job_1513599404024_166145
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166154, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166154/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166154
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:55:41,621 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:55:45,794 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.59 sec
2018-01-03 07:55:47,857 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.26 sec
2018-01-03 07:55:54,039 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.12 sec
MapReduce Total cumulative CPU time: 16 seconds 120 msec
Ended Job = job_1513599404024_166154
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166156, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166156/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166156
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:56:07,695 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:56:15,924 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.41 sec
2018-01-03 07:56:21,067 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.07 sec
MapReduce Total cumulative CPU time: 6 seconds 70 msec
Ended Job = job_1513599404024_166156
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 26.6 sec   HDFS Read: 85453749 HDFS Write: 1073602 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.12 sec   HDFS Read: 47071304 HDFS Write: 161578 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.07 sec   HDFS Read: 169216 HDFS Write: 3310 SUCCESS
Total MapReduce CPU Time Spent: 48 seconds 790 msec
OK
Time taken: 100.753 seconds, Fetched: 499 row(s)
开始执行20171011日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103075637_a71e8b69-af15-4281-b21e-3ae3d9f82cc7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166161, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166161/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166161
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 07:56:52,282 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:57:02,659 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 13.24 sec
2018-01-03 07:57:05,760 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 31.19 sec
2018-01-03 07:57:07,823 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 33.55 sec
2018-01-03 07:57:08,856 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 37.09 sec
2018-01-03 07:57:11,951 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 40.12 sec
2018-01-03 07:57:15,046 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 43.63 sec
2018-01-03 07:57:17,109 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 47.45 sec
2018-01-03 07:57:18,146 Stage-1 map = 71%,  reduce = 8%, Cumulative CPU 47.9 sec
2018-01-03 07:57:19,177 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 48.54 sec
2018-01-03 07:57:20,208 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 51.62 sec
2018-01-03 07:57:23,300 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 54.91 sec
2018-01-03 07:57:26,396 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 58.36 sec
2018-01-03 07:57:27,426 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 62.51 sec
2018-01-03 07:57:28,455 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 67.91 sec
MapReduce Total cumulative CPU time: 1 minutes 7 seconds 910 msec
Ended Job = job_1513599404024_166161
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166165, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166165/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166165
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:57:35,215 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:57:40,469 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.68 sec
2018-01-03 07:57:42,535 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.67 sec
2018-01-03 07:57:46,654 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.83 sec
MapReduce Total cumulative CPU time: 15 seconds 830 msec
Ended Job = job_1513599404024_166165
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166167, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166167/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166167
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:57:52,345 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:57:57,516 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.64 sec
2018-01-03 07:58:08,866 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.2 sec
MapReduce Total cumulative CPU time: 5 seconds 200 msec
Ended Job = job_1513599404024_166167
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 67.91 sec   HDFS Read: 198652826 HDFS Write: 1564851 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.83 sec   HDFS Read: 46574373 HDFS Write: 72185 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.2 sec   HDFS Read: 79860 HDFS Write: 3007 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 28 seconds 940 msec
OK
Time taken: 92.603 seconds, Fetched: 408 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.397 seconds
Query ID = boss_20180103075816_f26a2988-6b88-437d-8c22-9683c20250b6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166171, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166171/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166171
Hadoop job information for Stage-1: number of mappers: 5; number of reducers: 6
2018-01-03 07:58:26,607 Stage-1 map = 0%,  reduce = 0%
2018-01-03 07:58:35,949 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 38.49 sec
2018-01-03 07:58:39,043 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 62.33 sec
2018-01-03 07:58:42,141 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 75.99 sec
2018-01-03 07:58:45,234 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 101.66 sec
2018-01-03 07:58:47,294 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 107.15 sec
2018-01-03 07:58:48,325 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 118.14 sec
2018-01-03 07:58:49,359 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 121.24 sec
2018-01-03 07:58:51,419 Stage-1 map = 89%,  reduce = 0%, Cumulative CPU 124.76 sec
2018-01-03 07:58:54,507 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 129.86 sec
2018-01-03 07:58:55,540 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 132.88 sec
2018-01-03 07:58:56,570 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 142.81 sec
2018-01-03 07:58:58,633 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 147.61 sec
2018-01-03 07:59:00,691 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 153.46 sec
2018-01-03 07:59:07,901 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 157.83 sec
MapReduce Total cumulative CPU time: 2 minutes 37 seconds 830 msec
Ended Job = job_1513599404024_166171
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166174, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166174/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166174
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 07:59:13,798 Stage-2 map = 0%,  reduce = 0%
2018-01-03 07:59:18,959 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.32 sec
2018-01-03 07:59:24,108 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.09 sec
2018-01-03 07:59:26,171 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.8 sec
MapReduce Total cumulative CPU time: 12 seconds 800 msec
Ended Job = job_1513599404024_166174
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166176, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166176/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166176
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 07:59:33,824 Stage-3 map = 0%,  reduce = 0%
2018-01-03 07:59:54,405 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.37 sec
2018-01-03 08:00:02,631 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.55 sec
MapReduce Total cumulative CPU time: 6 seconds 550 msec
Ended Job = job_1513599404024_166176
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 5  Reduce: 6   Cumulative CPU: 157.83 sec   HDFS Read: 561286117 HDFS Write: 337728 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.8 sec   HDFS Read: 45348298 HDFS Write: 23739 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.55 sec   HDFS Read: 31415 HDFS Write: 2350 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 57 seconds 180 msec
OK
Time taken: 107.02 seconds, Fetched: 344 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103080010_d56e43d8-5036-4f0e-9f4f-3baa6149dcd4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166179, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166179/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166179
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:00:21,478 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:00:30,810 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 8.9 sec
2018-01-03 08:00:33,913 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.54 sec
2018-01-03 08:00:37,013 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.63 sec
2018-01-03 08:00:40,104 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 13.31 sec
2018-01-03 08:00:43,198 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 13.83 sec
2018-01-03 08:00:46,288 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 14.44 sec
2018-01-03 08:00:49,377 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 15.08 sec
2018-01-03 08:00:52,468 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 15.75 sec
2018-01-03 08:00:55,555 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 16.4 sec
2018-01-03 08:00:58,641 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 17.25 sec
2018-01-03 08:01:01,730 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 17.72 sec
2018-01-03 08:01:04,816 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 18.4 sec
2018-01-03 08:01:07,901 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 18.74 sec
2018-01-03 08:01:10,989 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 19.19 sec
2018-01-03 08:01:14,072 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 19.49 sec
2018-01-03 08:01:17,154 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 20.87 sec
2018-01-03 08:01:18,181 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 21.82 sec
2018-01-03 08:01:23,325 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 25.84 sec
MapReduce Total cumulative CPU time: 25 seconds 840 msec
Ended Job = job_1513599404024_166179
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166188, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166188/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166188
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:01:37,053 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:01:42,199 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.26 sec
2018-01-03 08:01:49,399 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.14 sec
2018-01-03 08:01:55,566 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.43 sec
MapReduce Total cumulative CPU time: 15 seconds 430 msec
Ended Job = job_1513599404024_166188
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166192, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166192/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166192
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:02:05,179 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:02:10,327 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.06 sec
2018-01-03 08:02:17,523 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.21 sec
MapReduce Total cumulative CPU time: 6 seconds 210 msec
Ended Job = job_1513599404024_166192
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 25.84 sec   HDFS Read: 81646949 HDFS Write: 517540 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.43 sec   HDFS Read: 45526744 HDFS Write: 177335 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.21 sec   HDFS Read: 184972 HDFS Write: 6606 SUCCESS
Total MapReduce CPU Time Spent: 47 seconds 480 msec
OK
Time taken: 128.188 seconds, Fetched: 775 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103080225_010548bc-bac9-45ee-a4f4-4a6588367774
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166200, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166200/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166200
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:02:35,421 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:02:46,791 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 9.26 sec
2018-01-03 08:02:49,890 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 12.63 sec
2018-01-03 08:02:52,983 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 15.11 sec
2018-01-03 08:02:55,043 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 16.84 sec
2018-01-03 08:02:58,135 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 18.07 sec
2018-01-03 08:03:01,222 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 19.52 sec
2018-01-03 08:03:04,308 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 21.53 sec
2018-01-03 08:03:07,397 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 23.01 sec
2018-01-03 08:03:10,481 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 24.09 sec
2018-01-03 08:03:13,565 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 25.13 sec
2018-01-03 08:03:16,654 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 28.06 sec
2018-01-03 08:03:22,824 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.01 sec
MapReduce Total cumulative CPU time: 32 seconds 10 msec
Ended Job = job_1513599404024_166200
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166214, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166214/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166214
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:03:28,509 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:03:32,640 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.56 sec
2018-01-03 08:03:35,729 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.71 sec
2018-01-03 08:03:39,841 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.58 sec
MapReduce Total cumulative CPU time: 17 seconds 580 msec
Ended Job = job_1513599404024_166214
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166218, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166218/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166218
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:03:47,501 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:03:52,657 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.32 sec
2018-01-03 08:04:07,058 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.15 sec
MapReduce Total cumulative CPU time: 7 seconds 150 msec
Ended Job = job_1513599404024_166218
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 32.01 sec   HDFS Read: 81646939 HDFS Write: 996827 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.58 sec   HDFS Read: 46006031 HDFS Write: 160445 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.15 sec   HDFS Read: 168083 HDFS Write: 3248 SUCCESS
Total MapReduce CPU Time Spent: 56 seconds 740 msec
OK
Time taken: 102.813 seconds, Fetched: 495 row(s)
开始执行20171012日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.366 seconds
Query ID = boss_20180103080423_1ba5594d-ac1c-47b0-9598-895a354afa3c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166230, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166230/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166230
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 08:04:48,444 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:04:58,793 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 14.16 sec
2018-01-03 08:05:01,891 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 18.27 sec
2018-01-03 08:05:04,986 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 22.78 sec
2018-01-03 08:05:06,016 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 35.4 sec
2018-01-03 08:05:08,077 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 39.02 sec
2018-01-03 08:05:09,106 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 42.66 sec
2018-01-03 08:05:10,137 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 44.41 sec
2018-01-03 08:05:11,171 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 48.02 sec
2018-01-03 08:05:14,260 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 51.89 sec
2018-01-03 08:05:17,349 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 55.32 sec
2018-01-03 08:05:20,441 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 58.67 sec
2018-01-03 08:05:21,475 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 59.85 sec
2018-01-03 08:05:23,536 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 63.1 sec
2018-01-03 08:05:25,596 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 67.02 sec
2018-01-03 08:05:27,657 Stage-1 map = 100%,  reduce = 86%, Cumulative CPU 73.07 sec
2018-01-03 08:05:28,685 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 75.04 sec
MapReduce Total cumulative CPU time: 1 minutes 15 seconds 40 msec
Ended Job = job_1513599404024_166230
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166243, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166243/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166243
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:05:34,501 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:05:39,653 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.41 sec
2018-01-03 08:05:47,885 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.46 sec
2018-01-03 08:05:51,997 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.18 sec
MapReduce Total cumulative CPU time: 16 seconds 180 msec
Ended Job = job_1513599404024_166243
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166246, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166246/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166246
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:05:58,628 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:06:09,950 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.9 sec
2018-01-03 08:06:43,868 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.61 sec
MapReduce Total cumulative CPU time: 5 seconds 610 msec
Ended Job = job_1513599404024_166246
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 75.04 sec   HDFS Read: 228246878 HDFS Write: 1471287 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.18 sec   HDFS Read: 45433611 HDFS Write: 63728 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.61 sec   HDFS Read: 71403 HDFS Write: 2860 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 36 seconds 830 msec
OK
Time taken: 141.835 seconds, Fetched: 402 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103080659_ee61b656-174b-44a6-b15d-53e720e872f3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166258, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166258/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166258
Hadoop job information for Stage-1: number of mappers: 6; number of reducers: 6
2018-01-03 08:07:08,573 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:07:17,927 Stage-1 map = 4%,  reduce = 0%
2018-01-03 08:07:18,968 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 50.72 sec
2018-01-03 08:07:21,033 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 58.37 sec
2018-01-03 08:07:22,067 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 65.4 sec
2018-01-03 08:07:23,096 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 78.0 sec
2018-01-03 08:07:24,127 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 92.22 sec
2018-01-03 08:07:26,188 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 98.4 sec
2018-01-03 08:07:27,218 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 108.35 sec
2018-01-03 08:07:28,247 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 109.9 sec
2018-01-03 08:07:29,276 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 113.18 sec
2018-01-03 08:07:30,307 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 119.38 sec
2018-01-03 08:07:31,340 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 122.32 sec
2018-01-03 08:07:32,368 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 124.56 sec
2018-01-03 08:07:33,398 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 127.53 sec
2018-01-03 08:07:34,427 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 139.2 sec
2018-01-03 08:07:35,461 Stage-1 map = 81%,  reduce = 7%, Cumulative CPU 139.71 sec
2018-01-03 08:07:36,491 Stage-1 map = 90%,  reduce = 19%, Cumulative CPU 148.96 sec
2018-01-03 08:07:38,551 Stage-1 map = 100%,  reduce = 20%, Cumulative CPU 151.88 sec
2018-01-03 08:07:39,581 Stage-1 map = 100%,  reduce = 24%, Cumulative CPU 152.16 sec
2018-01-03 08:07:40,615 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 177.86 sec
MapReduce Total cumulative CPU time: 2 minutes 57 seconds 860 msec
Ended Job = job_1513599404024_166258
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166267, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166267/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166267
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:07:47,465 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:07:53,676 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.81 sec
2018-01-03 08:08:00,906 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.19 sec
2018-01-03 08:08:01,937 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.92 sec
MapReduce Total cumulative CPU time: 13 seconds 920 msec
Ended Job = job_1513599404024_166267
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166270, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166270/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166270
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:08:07,555 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:08:11,678 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.24 sec
2018-01-03 08:08:31,228 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.37 sec
MapReduce Total cumulative CPU time: 4 seconds 370 msec
Ended Job = job_1513599404024_166270
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 6  Reduce: 6   Cumulative CPU: 177.86 sec   HDFS Read: 605182738 HDFS Write: 311759 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.92 sec   HDFS Read: 44275131 HDFS Write: 21195 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.37 sec   HDFS Read: 28871 HDFS Write: 2200 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 16 seconds 150 msec
OK
Time taken: 92.63 seconds, Fetched: 320 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103080838_85236d14-5c65-4deb-ba16-f9d3fc2767f6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166275, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166275/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166275
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:08:49,856 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:09:00,216 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 11.23 sec
2018-01-03 08:09:03,315 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 13.62 sec
2018-01-03 08:09:06,407 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 15.17 sec
2018-01-03 08:09:09,496 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 16.24 sec
2018-01-03 08:09:12,588 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 17.06 sec
2018-01-03 08:09:15,676 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 17.76 sec
2018-01-03 08:09:18,763 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 18.97 sec
2018-01-03 08:09:21,852 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 19.84 sec
2018-01-03 08:09:24,937 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 20.82 sec
2018-01-03 08:09:28,024 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 21.91 sec
2018-01-03 08:09:31,112 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 22.84 sec
2018-01-03 08:09:34,196 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 23.38 sec
2018-01-03 08:09:37,280 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 24.36 sec
2018-01-03 08:09:40,365 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 24.95 sec
2018-01-03 08:09:42,419 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 25.64 sec
2018-01-03 08:09:45,500 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 27.78 sec
2018-01-03 08:09:48,584 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 28.82 sec
2018-01-03 08:09:49,611 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 29.93 sec
2018-01-03 08:10:03,992 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.18 sec
MapReduce Total cumulative CPU time: 35 seconds 180 msec
Ended Job = job_1513599404024_166275
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166285, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166285/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166285
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:10:26,712 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:10:32,005 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.54 sec
2018-01-03 08:10:33,035 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.71 sec
2018-01-03 08:10:45,391 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.03 sec
MapReduce Total cumulative CPU time: 16 seconds 30 msec
Ended Job = job_1513599404024_166285
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166290, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166290/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166290
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:11:00,099 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:11:11,416 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.37 sec
2018-01-03 08:11:17,594 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.03 sec
MapReduce Total cumulative CPU time: 6 seconds 30 msec
Ended Job = job_1513599404024_166290
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.18 sec   HDFS Read: 78916652 HDFS Write: 493678 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.03 sec   HDFS Read: 44455684 HDFS Write: 175216 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.03 sec   HDFS Read: 182853 HDFS Write: 6288 SUCCESS
Total MapReduce CPU Time Spent: 57 seconds 240 msec
OK
Time taken: 160.744 seconds, Fetched: 742 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103081126_3064ef33-9c04-4ae9-8e99-9c72e96dade8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166293, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166293/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166293
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:11:36,296 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:11:46,637 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.39 sec
2018-01-03 08:11:49,734 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 13.39 sec
2018-01-03 08:11:52,826 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 14.83 sec
2018-01-03 08:11:55,913 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 15.73 sec
2018-01-03 08:11:59,005 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 16.95 sec
2018-01-03 08:12:02,093 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 18.11 sec
2018-01-03 08:12:04,150 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 19.4 sec
2018-01-03 08:12:07,239 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 20.86 sec
2018-01-03 08:12:10,323 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 21.81 sec
2018-01-03 08:12:13,407 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.76 sec
2018-01-03 08:12:19,581 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.96 sec
MapReduce Total cumulative CPU time: 30 seconds 960 msec
Ended Job = job_1513599404024_166293
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166299, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166299/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166299
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:12:25,272 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:12:30,420 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.69 sec
2018-01-03 08:12:49,947 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.23 sec
MapReduce Total cumulative CPU time: 15 seconds 230 msec
Ended Job = job_1513599404024_166299
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166304, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166304/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166304
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:13:17,573 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:13:22,723 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-03 08:13:27,860 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.89 sec
MapReduce Total cumulative CPU time: 5 seconds 890 msec
Ended Job = job_1513599404024_166304
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.96 sec   HDFS Read: 78916642 HDFS Write: 949550 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.23 sec   HDFS Read: 44911556 HDFS Write: 154734 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.89 sec   HDFS Read: 162372 HDFS Write: 3088 SUCCESS
Total MapReduce CPU Time Spent: 52 seconds 80 msec
OK
Time taken: 122.574 seconds, Fetched: 462 row(s)
开始执行20171013日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103081335_3063e493-026b-40f8-ae4f-bbc30b5f26b7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166305, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166305/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166305
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 08:13:44,850 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:13:54,163 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 12.92 sec
2018-01-03 08:13:57,259 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 16.73 sec
2018-01-03 08:14:00,354 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 20.17 sec
2018-01-03 08:14:02,415 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 32.37 sec
2018-01-03 08:14:03,446 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 36.4 sec
2018-01-03 08:14:05,504 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 39.76 sec
2018-01-03 08:14:08,597 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 43.22 sec
2018-01-03 08:14:11,684 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 46.88 sec
2018-01-03 08:14:12,720 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 47.36 sec
2018-01-03 08:14:14,778 Stage-1 map = 73%,  reduce = 8%, Cumulative CPU 51.37 sec
2018-01-03 08:14:17,869 Stage-1 map = 76%,  reduce = 8%, Cumulative CPU 54.52 sec
2018-01-03 08:14:20,956 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 58.34 sec
2018-01-03 08:14:21,985 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 60.8 sec
2018-01-03 08:14:23,016 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 64.7 sec
2018-01-03 08:14:24,045 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 69.0 sec
MapReduce Total cumulative CPU time: 1 minutes 9 seconds 0 msec
Ended Job = job_1513599404024_166305
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166310, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166310/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166310
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:14:29,727 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:14:34,886 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.27 sec
2018-01-03 08:14:42,097 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.46 sec
MapReduce Total cumulative CPU time: 15 seconds 460 msec
Ended Job = job_1513599404024_166310
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166312, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166312/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166312
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:14:48,737 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:14:53,903 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.84 sec
2018-01-03 08:15:00,079 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.34 sec
MapReduce Total cumulative CPU time: 5 seconds 340 msec
Ended Job = job_1513599404024_166312
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 69.0 sec   HDFS Read: 266815788 HDFS Write: 1871300 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.46 sec   HDFS Read: 43571901 HDFS Write: 66218 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.34 sec   HDFS Read: 73893 HDFS Write: 2950 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 29 seconds 800 msec
OK
Time taken: 85.338 seconds, Fetched: 400 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.4 seconds
Query ID = boss_20180103081507_322dde1a-2424-41ea-97a1-d46ead41b482
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166317, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166317/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166317
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 6
2018-01-03 08:15:17,814 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:15:27,229 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 63.79 sec
2018-01-03 08:15:30,337 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 89.22 sec
2018-01-03 08:15:32,405 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 93.5 sec
2018-01-03 08:15:33,441 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 103.37 sec
2018-01-03 08:15:35,506 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 122.33 sec
2018-01-03 08:15:36,539 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 128.93 sec
2018-01-03 08:15:37,571 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 130.94 sec
2018-01-03 08:15:38,610 Stage-1 map = 73%,  reduce = 14%, Cumulative CPU 141.61 sec
2018-01-03 08:15:39,644 Stage-1 map = 82%,  reduce = 14%, Cumulative CPU 147.17 sec
2018-01-03 08:15:40,681 Stage-1 map = 88%,  reduce = 14%, Cumulative CPU 148.96 sec
2018-01-03 08:15:41,714 Stage-1 map = 90%,  reduce = 25%, Cumulative CPU 152.47 sec
2018-01-03 08:15:44,810 Stage-1 map = 92%,  reduce = 29%, Cumulative CPU 155.9 sec
2018-01-03 08:15:51,001 Stage-1 map = 94%,  reduce = 29%, Cumulative CPU 163.52 sec
2018-01-03 08:15:53,062 Stage-1 map = 100%,  reduce = 41%, Cumulative CPU 167.94 sec
2018-01-03 08:15:54,093 Stage-1 map = 100%,  reduce = 64%, Cumulative CPU 177.88 sec
2018-01-03 08:15:55,125 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 190.72 sec
MapReduce Total cumulative CPU time: 3 minutes 10 seconds 720 msec
Ended Job = job_1513599404024_166317
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166322, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166322/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166322
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:16:02,934 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:16:10,167 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.68 sec
2018-01-03 08:16:16,343 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.53 sec
2018-01-03 08:16:17,376 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.23 sec
MapReduce Total cumulative CPU time: 15 seconds 230 msec
Ended Job = job_1513599404024_166322
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166325, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166325/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166325
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:16:32,070 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:16:37,246 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.47 sec
2018-01-03 08:17:07,110 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 14.03 sec
2018-01-03 08:17:10,196 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 25.77 sec
MapReduce Total cumulative CPU time: 25 seconds 770 msec
Ended Job = job_1513599404024_166325
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 6   Cumulative CPU: 190.72 sec   HDFS Read: 670520980 HDFS Write: 342064 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.23 sec   HDFS Read: 42043713 HDFS Write: 21609 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 25.77 sec   HDFS Read: 29285 HDFS Write: 2322 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 51 seconds 720 msec
OK
Time taken: 123.374 seconds, Fetched: 318 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103081717_d721c1f3-a80f-4d40-b01e-7dd649ffd163
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166328, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166328/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166328
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:17:44,011 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:17:54,353 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.11 sec
2018-01-03 08:17:57,456 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 15.53 sec
2018-01-03 08:18:00,548 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 17.24 sec
2018-01-03 08:18:03,637 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 18.48 sec
2018-01-03 08:18:06,731 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 19.23 sec
2018-01-03 08:18:09,818 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 20.0 sec
2018-01-03 08:18:12,904 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 21.25 sec
2018-01-03 08:18:15,993 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 22.01 sec
2018-01-03 08:18:18,048 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 22.5 sec
2018-01-03 08:18:21,132 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 23.42 sec
2018-01-03 08:18:24,218 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 24.19 sec
2018-01-03 08:18:27,300 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 25.28 sec
2018-01-03 08:18:30,385 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 26.01 sec
2018-01-03 08:18:33,470 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 26.91 sec
2018-01-03 08:18:36,552 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 27.63 sec
2018-01-03 08:18:39,633 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 28.4 sec
2018-01-03 08:18:42,722 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 30.42 sec
2018-01-03 08:18:44,775 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.15 sec
2018-01-03 08:18:51,974 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.6 sec
MapReduce Total cumulative CPU time: 35 seconds 600 msec
Ended Job = job_1513599404024_166328
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166335, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166335/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166335
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:18:57,661 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:19:04,883 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.88 sec
2018-01-03 08:19:15,179 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.51 sec
2018-01-03 08:19:17,240 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 10.4 sec
2018-01-03 08:19:18,269 Stage-2 map = 100%,  reduce = 68%, Cumulative CPU 12.89 sec
2018-01-03 08:19:19,298 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.49 sec
MapReduce Total cumulative CPU time: 14 seconds 490 msec
Ended Job = job_1513599404024_166335
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166338, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166338/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166338
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:19:24,912 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:19:30,062 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.04 sec
2018-01-03 08:19:36,229 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.71 sec
MapReduce Total cumulative CPU time: 5 seconds 710 msec
Ended Job = job_1513599404024_166338
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.6 sec   HDFS Read: 88778732 HDFS Write: 452023 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.49 sec   HDFS Read: 42152306 HDFS Write: 160173 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.71 sec   HDFS Read: 167810 HDFS Write: 5897 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 800 msec
OK
Time taken: 139.317 seconds, Fetched: 685 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103081943_64288923-39d3-407e-b28a-b8b3d8696e62
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166339, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166339/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166339
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:19:59,961 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:20:10,321 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 11.08 sec
2018-01-03 08:20:13,419 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 13.3 sec
2018-01-03 08:20:16,512 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 14.46 sec
2018-01-03 08:20:19,602 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 15.65 sec
2018-01-03 08:20:22,694 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 16.9 sec
2018-01-03 08:20:25,783 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 18.28 sec
2018-01-03 08:20:28,870 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 19.24 sec
2018-01-03 08:20:31,961 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 20.88 sec
2018-01-03 08:20:35,047 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 21.76 sec
2018-01-03 08:20:37,104 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.09 sec
2018-01-03 08:20:44,310 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 29.78 sec
MapReduce Total cumulative CPU time: 29 seconds 780 msec
Ended Job = job_1513599404024_166339
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166348, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166348/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166348
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:20:50,063 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:20:55,213 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.2 sec
2018-01-03 08:21:02,417 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.66 sec
MapReduce Total cumulative CPU time: 13 seconds 660 msec
Ended Job = job_1513599404024_166348
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166352, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166352/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166352
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:21:10,149 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:21:15,305 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.98 sec
2018-01-03 08:21:21,484 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.57 sec
MapReduce Total cumulative CPU time: 5 seconds 570 msec
Ended Job = job_1513599404024_166352
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 29.78 sec   HDFS Read: 88778722 HDFS Write: 936706 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.66 sec   HDFS Read: 42636989 HDFS Write: 155207 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.57 sec   HDFS Read: 162845 HDFS Write: 3383 SUCCESS
Total MapReduce CPU Time Spent: 49 seconds 10 msec
OK
Time taken: 99.59 seconds, Fetched: 535 row(s)
开始执行20171014日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103082130_98e61c76-7bb2-4696-ba2a-821dac4834b3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166355, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166355/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166355
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 08:21:39,618 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:21:49,962 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 11.39 sec
2018-01-03 08:21:53,059 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 14.77 sec
2018-01-03 08:21:55,122 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 26.38 sec
2018-01-03 08:21:56,152 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 29.9 sec
2018-01-03 08:21:58,212 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 33.59 sec
2018-01-03 08:21:59,244 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 36.94 sec
2018-01-03 08:22:00,274 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 40.14 sec
2018-01-03 08:22:01,302 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 43.31 sec
2018-01-03 08:22:03,364 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 46.53 sec
2018-01-03 08:22:04,393 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 49.5 sec
2018-01-03 08:22:06,450 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 52.48 sec
2018-01-03 08:22:07,480 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 55.63 sec
2018-01-03 08:22:09,538 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 58.75 sec
2018-01-03 08:22:10,566 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 62.22 sec
2018-01-03 08:22:12,628 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 65.38 sec
2018-01-03 08:22:13,657 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 68.98 sec
2018-01-03 08:22:15,714 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 72.93 sec
2018-01-03 08:22:16,743 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 76.01 sec
2018-01-03 08:22:18,800 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 79.26 sec
2018-01-03 08:22:19,828 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 82.15 sec
2018-01-03 08:22:20,862 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 84.81 sec
2018-01-03 08:22:22,916 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 87.7 sec
2018-01-03 08:22:23,944 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 88.99 sec
2018-01-03 08:22:26,010 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 93.03 sec
2018-01-03 08:22:27,040 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 102.95 sec
MapReduce Total cumulative CPU time: 1 minutes 42 seconds 950 msec
Ended Job = job_1513599404024_166355
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166363, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166363/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166363
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:22:33,774 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:22:39,003 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.55 sec
2018-01-03 08:22:40,033 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.34 sec
2018-01-03 08:22:44,150 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.59 sec
MapReduce Total cumulative CPU time: 17 seconds 590 msec
Ended Job = job_1513599404024_166363
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166366, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166366/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166366
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:22:51,841 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:22:57,009 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.14 sec
2018-01-03 08:23:03,184 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.36 sec
MapReduce Total cumulative CPU time: 6 seconds 360 msec
Ended Job = job_1513599404024_166366
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 102.95 sec   HDFS Read: 320037427 HDFS Write: 1822112 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.59 sec   HDFS Read: 47938382 HDFS Write: 73457 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.36 sec   HDFS Read: 81132 HDFS Write: 3002 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 6 seconds 900 msec
OK
Time taken: 93.703 seconds, Fetched: 404 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.397 seconds
Query ID = boss_20180103082310_db40da78-6fdb-4ce8-9963-f1822ec1a324
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166371, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166371/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166371
Hadoop job information for Stage-1: number of mappers: 8; number of reducers: 8
2018-01-03 08:23:21,035 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:23:31,450 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 74.96 sec
2018-01-03 08:23:32,486 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 87.17 sec
2018-01-03 08:23:34,562 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 114.67 sec
2018-01-03 08:23:37,664 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 135.36 sec
2018-01-03 08:23:39,728 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 148.83 sec
2018-01-03 08:23:40,760 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 165.53 sec
2018-01-03 08:23:41,792 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 167.78 sec
2018-01-03 08:23:42,828 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 177.69 sec
2018-01-03 08:23:43,860 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 180.93 sec
2018-01-03 08:23:44,897 Stage-1 map = 92%,  reduce = 13%, Cumulative CPU 185.2 sec
2018-01-03 08:23:45,930 Stage-1 map = 93%,  reduce = 27%, Cumulative CPU 191.87 sec
2018-01-03 08:23:47,993 Stage-1 map = 93%,  reduce = 29%, Cumulative CPU 192.47 sec
2018-01-03 08:23:50,056 Stage-1 map = 100%,  reduce = 38%, Cumulative CPU 199.54 sec
2018-01-03 08:23:51,088 Stage-1 map = 100%,  reduce = 93%, Cumulative CPU 219.75 sec
2018-01-03 08:23:52,121 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 223.68 sec
MapReduce Total cumulative CPU time: 3 minutes 43 seconds 680 msec
Ended Job = job_1513599404024_166371
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166376, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166376/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166376
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:24:05,820 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:24:12,011 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.52 sec
2018-01-03 08:24:22,303 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 4.99 sec
2018-01-03 08:24:25,388 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 10.85 sec
2018-01-03 08:24:26,420 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.4 sec
MapReduce Total cumulative CPU time: 15 seconds 400 msec
Ended Job = job_1513599404024_166376
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166379, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166379/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166379
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:24:32,050 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:24:39,263 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.47 sec
2018-01-03 08:24:46,466 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.84 sec
MapReduce Total cumulative CPU time: 5 seconds 840 msec
Ended Job = job_1513599404024_166379
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 8  Reduce: 8   Cumulative CPU: 223.68 sec   HDFS Read: 814712573 HDFS Write: 375000 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.4 sec   HDFS Read: 46492580 HDFS Write: 23154 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.84 sec   HDFS Read: 30830 HDFS Write: 2427 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 4 seconds 920 msec
OK
Time taken: 96.568 seconds, Fetched: 346 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103082454_93962def-bc5a-4897-96aa-a7381b8e5efe
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166381, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166381/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166381
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:25:06,216 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:25:16,570 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 10.69 sec
2018-01-03 08:25:19,670 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 14.08 sec
2018-01-03 08:25:22,763 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 18.0 sec
2018-01-03 08:25:25,854 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 19.87 sec
2018-01-03 08:25:28,947 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 20.72 sec
2018-01-03 08:25:32,037 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 21.95 sec
2018-01-03 08:25:35,125 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 22.87 sec
2018-01-03 08:25:38,216 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 23.5 sec
2018-01-03 08:25:41,301 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 23.73 sec
2018-01-03 08:25:44,386 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 24.88 sec
2018-01-03 08:25:47,475 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 26.0 sec
2018-01-03 08:25:50,558 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 26.7 sec
2018-01-03 08:25:53,645 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 27.54 sec
2018-01-03 08:25:56,731 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 28.08 sec
2018-01-03 08:25:59,814 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 29.52 sec
2018-01-03 08:26:02,895 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 30.18 sec
2018-01-03 08:26:05,987 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 30.77 sec
2018-01-03 08:26:09,069 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 31.48 sec
2018-01-03 08:26:12,154 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 33.66 sec
2018-01-03 08:26:13,181 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 35.05 sec
2018-01-03 08:26:18,319 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 40.15 sec
MapReduce Total cumulative CPU time: 40 seconds 150 msec
Ended Job = job_1513599404024_166381
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166387, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166387/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166387
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:26:31,999 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:26:37,156 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.54 sec
2018-01-03 08:26:48,463 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.25 sec
2018-01-03 08:26:51,544 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 9.76 sec
2018-01-03 08:26:53,601 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.31 sec
MapReduce Total cumulative CPU time: 16 seconds 310 msec
Ended Job = job_1513599404024_166387
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166392, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166392/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166392
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:27:00,216 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:27:04,347 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec
2018-01-03 08:27:10,518 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 1.92 sec
MapReduce Total cumulative CPU time: 1 seconds 920 msec
Ended Job = job_1513599404024_166392
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 40.15 sec   HDFS Read: 98685075 HDFS Write: 490111 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.31 sec   HDFS Read: 46605801 HDFS Write: 177103 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.61 sec   HDFS Read: 184740 HDFS Write: 6585 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 2 seconds 70 msec
OK
Time taken: 138.421 seconds, Fetched: 775 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103082719_22740a90-e4c0-4e20-bfb9-6ff5fc30d692
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166395, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166395/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166395
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:27:29,259 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:27:38,571 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 10.3 sec
2018-01-03 08:27:41,667 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 11.48 sec
2018-01-03 08:27:44,757 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 12.49 sec
2018-01-03 08:27:47,846 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 14.31 sec
2018-01-03 08:27:50,935 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 15.96 sec
2018-01-03 08:27:54,023 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 16.82 sec
2018-01-03 08:27:57,107 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 18.94 sec
2018-01-03 08:28:00,195 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 19.94 sec
2018-01-03 08:28:03,277 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 22.69 sec
2018-01-03 08:28:09,452 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 28.59 sec
MapReduce Total cumulative CPU time: 28 seconds 590 msec
Ended Job = job_1513599404024_166395
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166401, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166401/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166401
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:28:16,147 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:28:21,307 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.14 sec
2018-01-03 08:28:32,636 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 4.79 sec
2018-01-03 08:28:33,665 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 9.62 sec
2018-01-03 08:28:35,723 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.57 sec
MapReduce Total cumulative CPU time: 15 seconds 570 msec
Ended Job = job_1513599404024_166401
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166403, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166403/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166403
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:28:49,356 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:28:53,546 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.6 sec
2018-01-03 08:28:59,722 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.42 sec
MapReduce Total cumulative CPU time: 6 seconds 420 msec
Ended Job = job_1513599404024_166403
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 28.59 sec   HDFS Read: 98685065 HDFS Write: 1142930 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.57 sec   HDFS Read: 47258620 HDFS Write: 174416 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.42 sec   HDFS Read: 182054 HDFS Write: 3324 SUCCESS
Total MapReduce CPU Time Spent: 50 seconds 580 msec
OK
Time taken: 102.479 seconds, Fetched: 471 row(s)
开始执行20171015日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.351 seconds
Query ID = boss_20180103082908_0307d278-e5a8-420f-a925-15d6a3365055
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166407, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166407/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166407
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 08:29:25,999 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:29:36,384 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 11.98 sec
2018-01-03 08:29:38,457 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 16.22 sec
2018-01-03 08:29:41,559 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 31.09 sec
2018-01-03 08:29:44,653 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 38.73 sec
2018-01-03 08:29:47,751 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 46.13 sec
2018-01-03 08:29:50,850 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 52.69 sec
2018-01-03 08:29:53,943 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 59.11 sec
2018-01-03 08:29:56,006 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 61.26 sec
2018-01-03 08:29:57,037 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 64.39 sec
2018-01-03 08:30:00,133 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 67.55 sec
2018-01-03 08:30:03,230 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 71.21 sec
2018-01-03 08:30:05,292 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 74.86 sec
2018-01-03 08:30:06,328 Stage-1 map = 78%,  reduce = 11%, Cumulative CPU 75.76 sec
2018-01-03 08:30:08,396 Stage-1 map = 82%,  reduce = 11%, Cumulative CPU 79.14 sec
2018-01-03 08:30:10,460 Stage-1 map = 100%,  reduce = 11%, Cumulative CPU 80.92 sec
2018-01-03 08:30:11,492 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 93.96 sec
MapReduce Total cumulative CPU time: 1 minutes 33 seconds 960 msec
Ended Job = job_1513599404024_166407
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166416, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166416/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166416
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:30:18,358 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:30:25,580 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.78 sec
2018-01-03 08:30:32,785 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.8 sec
2018-01-03 08:30:34,848 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.26 sec
MapReduce Total cumulative CPU time: 18 seconds 260 msec
Ended Job = job_1513599404024_166416
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166418, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166418/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166418
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:30:40,490 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:30:45,646 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.01 sec
2018-01-03 08:30:50,788 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.49 sec
MapReduce Total cumulative CPU time: 5 seconds 490 msec
Ended Job = job_1513599404024_166418
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 93.96 sec   HDFS Read: 326169993 HDFS Write: 1713237 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.26 sec   HDFS Read: 49463537 HDFS Write: 80260 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.49 sec   HDFS Read: 87935 HDFS Write: 2917 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 57 seconds 710 msec
OK
Time taken: 103.029 seconds, Fetched: 399 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.4 seconds
Query ID = boss_20180103083058_7b1c10a6-1c95-4f3b-92b7-7282123c7549
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 8
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166421, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166421/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166421
Hadoop job information for Stage-1: number of mappers: 10; number of reducers: 8
2018-01-03 08:31:09,187 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:31:19,580 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 24.6 sec
2018-01-03 08:31:20,614 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 86.96 sec
2018-01-03 08:31:22,683 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 102.59 sec
2018-01-03 08:31:23,714 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 115.51 sec
2018-01-03 08:31:25,778 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 138.42 sec
2018-01-03 08:31:26,809 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 147.47 sec
2018-01-03 08:31:27,840 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 170.32 sec
2018-01-03 08:31:28,870 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 173.85 sec
2018-01-03 08:31:29,900 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 175.82 sec
2018-01-03 08:31:30,931 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 182.63 sec
2018-01-03 08:31:31,965 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 184.35 sec
2018-01-03 08:31:34,031 Stage-1 map = 85%,  reduce = 20%, Cumulative CPU 191.11 sec
2018-01-03 08:31:35,063 Stage-1 map = 87%,  reduce = 20%, Cumulative CPU 205.24 sec
2018-01-03 08:31:37,125 Stage-1 map = 88%,  reduce = 20%, Cumulative CPU 209.22 sec
2018-01-03 08:31:38,156 Stage-1 map = 95%,  reduce = 20%, Cumulative CPU 216.07 sec
2018-01-03 08:31:40,216 Stage-1 map = 100%,  reduce = 23%, Cumulative CPU 219.23 sec
2018-01-03 08:31:41,250 Stage-1 map = 100%,  reduce = 91%, Cumulative CPU 243.9 sec
2018-01-03 08:31:42,278 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 247.58 sec
MapReduce Total cumulative CPU time: 4 minutes 7 seconds 580 msec
Ended Job = job_1513599404024_166421
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166426, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166426/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166426
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:31:48,982 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:31:54,152 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.91 sec
2018-01-03 08:32:04,453 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.39 sec
2018-01-03 08:32:20,917 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.51 sec
2018-01-03 08:32:21,945 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.05 sec
MapReduce Total cumulative CPU time: 16 seconds 50 msec
Ended Job = job_1513599404024_166426
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166434, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166434/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166434
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:32:35,593 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:32:40,745 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.61 sec
2018-01-03 08:32:48,974 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.46 sec
MapReduce Total cumulative CPU time: 5 seconds 460 msec
Ended Job = job_1513599404024_166434
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 10  Reduce: 8   Cumulative CPU: 247.58 sec   HDFS Read: 826338257 HDFS Write: 380061 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.05 sec   HDFS Read: 48131671 HDFS Write: 21748 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.46 sec   HDFS Read: 29424 HDFS Write: 2327 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 29 seconds 90 msec
OK
Time taken: 111.427 seconds, Fetched: 333 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103083256_eb1228c6-3cca-444f-951d-596cf6312752
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166438, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166438/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166438
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:33:06,859 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:33:17,244 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 7.91 sec
2018-01-03 08:33:20,352 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 9.69 sec
2018-01-03 08:33:23,451 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 10.45 sec
2018-01-03 08:33:26,549 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 11.07 sec
2018-01-03 08:33:29,649 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 11.5 sec
2018-01-03 08:33:31,712 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 13.02 sec
2018-01-03 08:33:34,804 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 13.62 sec
2018-01-03 08:33:37,901 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 14.2 sec
2018-01-03 08:33:40,993 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 14.85 sec
2018-01-03 08:33:44,085 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 16.21 sec
2018-01-03 08:33:47,179 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 16.95 sec
2018-01-03 08:33:50,268 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 17.84 sec
2018-01-03 08:33:53,356 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 18.18 sec
2018-01-03 08:33:56,448 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 18.72 sec
2018-01-03 08:33:59,536 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 19.08 sec
2018-01-03 08:34:02,623 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 20.73 sec
2018-01-03 08:34:03,655 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 21.7 sec
2018-01-03 08:34:09,835 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 25.37 sec
MapReduce Total cumulative CPU time: 25 seconds 370 msec
Ended Job = job_1513599404024_166438
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166442, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166442/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166442
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:34:16,534 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:34:21,718 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.7 sec
2018-01-03 08:34:33,064 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.35 sec
2018-01-03 08:34:38,221 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 9.92 sec
2018-01-03 08:34:40,286 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.26 sec
MapReduce Total cumulative CPU time: 14 seconds 260 msec
Ended Job = job_1513599404024_166442
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166447, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166447/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166447
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:34:54,081 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:35:29,065 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec
2018-01-03 08:35:43,465 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.53 sec
MapReduce Total cumulative CPU time: 6 seconds 530 msec
Ended Job = job_1513599404024_166447
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 25.37 sec   HDFS Read: 95009391 HDFS Write: 504498 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.26 sec   HDFS Read: 48254218 HDFS Write: 200061 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.53 sec   HDFS Read: 207698 HDFS Write: 7008 SUCCESS
Total MapReduce CPU Time Spent: 46 seconds 160 msec
OK
Time taken: 167.775 seconds, Fetched: 815 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103083559_9c31c44b-52c4-4d90-a534-131e3b0a5617
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166451, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166451/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166451
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:36:15,340 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:36:25,708 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.25 sec
2018-01-03 08:36:28,813 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 13.24 sec
2018-01-03 08:36:31,911 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 14.44 sec
2018-01-03 08:36:35,006 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 15.3 sec
2018-01-03 08:36:38,105 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 16.45 sec
2018-01-03 08:36:41,210 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 18.44 sec
2018-01-03 08:36:44,303 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 19.73 sec
2018-01-03 08:36:47,406 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 20.8 sec
2018-01-03 08:36:50,494 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 22.81 sec
2018-01-03 08:36:53,583 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 24.31 sec
2018-01-03 08:36:55,646 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 26.83 sec
2018-01-03 08:37:01,831 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 31.09 sec
MapReduce Total cumulative CPU time: 31 seconds 90 msec
Ended Job = job_1513599404024_166451
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166458, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166458/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166458
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:37:15,505 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:37:20,660 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.21 sec
2018-01-03 08:37:21,690 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.43 sec
2018-01-03 08:37:26,834 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.26 sec
MapReduce Total cumulative CPU time: 16 seconds 260 msec
Ended Job = job_1513599404024_166458
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166460, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166460/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166460
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:37:41,543 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:37:46,718 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.12 sec
2018-01-03 08:37:51,885 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.29 sec
MapReduce Total cumulative CPU time: 7 seconds 290 msec
Ended Job = job_1513599404024_166460
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 31.09 sec   HDFS Read: 95009381 HDFS Write: 1152061 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.26 sec   HDFS Read: 48901781 HDFS Write: 181965 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.29 sec   HDFS Read: 189603 HDFS Write: 3332 SUCCESS
Total MapReduce CPU Time Spent: 54 seconds 640 msec
OK
Time taken: 113.695 seconds, Fetched: 487 row(s)
开始执行20171016日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103083759_30e8d0c4-7717-454f-8dd7-0cca87cd2e61
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166464, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166464/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166464
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 08:38:16,890 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:38:27,239 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 26.25 sec
2018-01-03 08:38:30,338 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 33.96 sec
2018-01-03 08:38:33,430 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 41.23 sec
2018-01-03 08:38:36,521 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 49.12 sec
2018-01-03 08:38:39,613 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 56.06 sec
2018-01-03 08:38:40,643 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 58.39 sec
2018-01-03 08:38:42,703 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 62.1 sec
2018-01-03 08:38:44,762 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 65.13 sec
2018-01-03 08:38:47,847 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 67.8 sec
2018-01-03 08:38:49,916 Stage-1 map = 72%,  reduce = 8%, Cumulative CPU 68.34 sec
2018-01-03 08:38:50,946 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 71.56 sec
2018-01-03 08:38:54,033 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 74.6 sec
2018-01-03 08:38:56,093 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 75.14 sec
2018-01-03 08:38:57,124 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 77.89 sec
2018-01-03 08:39:00,216 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 80.65 sec
2018-01-03 08:39:02,274 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 83.3 sec
2018-01-03 08:39:03,303 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 87.21 sec
2018-01-03 08:39:04,332 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 91.55 sec
MapReduce Total cumulative CPU time: 1 minutes 31 seconds 550 msec
Ended Job = job_1513599404024_166464
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166469, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166469/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166469
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:39:13,040 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:39:18,202 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.5 sec
2018-01-03 08:39:20,262 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.57 sec
2018-01-03 08:39:25,406 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.25 sec
MapReduce Total cumulative CPU time: 18 seconds 250 msec
Ended Job = job_1513599404024_166469
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166472, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166472/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166472
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:39:40,068 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:39:46,365 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.58 sec
2018-01-03 08:39:51,515 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.83 sec
MapReduce Total cumulative CPU time: 5 seconds 830 msec
Ended Job = job_1513599404024_166472
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 91.55 sec   HDFS Read: 260083899 HDFS Write: 1438013 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.25 sec   HDFS Read: 44065340 HDFS Write: 70597 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.83 sec   HDFS Read: 78272 HDFS Write: 2844 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 55 seconds 630 msec
OK
Time taken: 112.661 seconds, Fetched: 394 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.383 seconds
Query ID = boss_20180103083959_3c68ca26-c0f0-4c5f-afeb-923555bea010
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 6
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166474, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166474/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166474
Hadoop job information for Stage-1: number of mappers: 7; number of reducers: 6
2018-01-03 08:40:08,157 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:40:17,476 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.19 sec
2018-01-03 08:40:18,509 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 76.37 sec
2018-01-03 08:40:19,541 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 88.39 sec
2018-01-03 08:40:20,573 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 92.2 sec
2018-01-03 08:40:21,608 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 106.8 sec
2018-01-03 08:40:22,639 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 126.08 sec
2018-01-03 08:40:24,703 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 141.58 sec
2018-01-03 08:40:25,735 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 157.49 sec
2018-01-03 08:40:27,797 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 173.16 sec
2018-01-03 08:40:28,826 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 181.79 sec
2018-01-03 08:40:29,855 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 183.94 sec
2018-01-03 08:40:30,890 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 189.31 sec
2018-01-03 08:40:31,926 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 195.28 sec
2018-01-03 08:40:32,962 Stage-1 map = 70%,  reduce = 3%, Cumulative CPU 195.94 sec
2018-01-03 08:40:33,993 Stage-1 map = 72%,  reduce = 10%, Cumulative CPU 222.15 sec
2018-01-03 08:40:37,087 Stage-1 map = 77%,  reduce = 10%, Cumulative CPU 230.42 sec
2018-01-03 08:40:38,121 Stage-1 map = 77%,  reduce = 13%, Cumulative CPU 231.9 sec
2018-01-03 08:40:40,186 Stage-1 map = 79%,  reduce = 13%, Cumulative CPU 248.94 sec
2018-01-03 08:40:41,215 Stage-1 map = 79%,  reduce = 19%, Cumulative CPU 250.38 sec
2018-01-03 08:40:42,244 Stage-1 map = 85%,  reduce = 19%, Cumulative CPU 253.38 sec
2018-01-03 08:40:43,272 Stage-1 map = 88%,  reduce = 20%, Cumulative CPU 269.9 sec
2018-01-03 08:40:44,300 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 270.82 sec
2018-01-03 08:40:45,330 Stage-1 map = 94%,  reduce = 24%, Cumulative CPU 274.14 sec
2018-01-03 08:40:46,359 Stage-1 map = 95%,  reduce = 26%, Cumulative CPU 278.49 sec
2018-01-03 08:40:47,387 Stage-1 map = 95%,  reduce = 28%, Cumulative CPU 278.73 sec
2018-01-03 08:40:48,415 Stage-1 map = 95%,  reduce = 29%, Cumulative CPU 279.94 sec
2018-01-03 08:40:51,507 Stage-1 map = 100%,  reduce = 29%, Cumulative CPU 284.84 sec
2018-01-03 08:40:52,536 Stage-1 map = 100%,  reduce = 30%, Cumulative CPU 285.69 sec
2018-01-03 08:40:53,566 Stage-1 map = 100%,  reduce = 66%, Cumulative CPU 302.68 sec
2018-01-03 08:40:54,595 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 312.31 sec
2018-01-03 08:40:57,677 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 323.17 sec
2018-01-03 08:41:03,848 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 328.76 sec
MapReduce Total cumulative CPU time: 5 minutes 28 seconds 760 msec
Ended Job = job_1513599404024_166474
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166488, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166488/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166488
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:41:10,881 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:41:16,036 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.37 sec
2018-01-03 08:41:30,425 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.66 sec
2018-01-03 08:41:32,479 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.68 sec
MapReduce Total cumulative CPU time: 15 seconds 680 msec
Ended Job = job_1513599404024_166488
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166489, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166489/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166489
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:41:39,108 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:41:43,241 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.34 sec
2018-01-03 08:41:48,381 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.47 sec
MapReduce Total cumulative CPU time: 4 seconds 470 msec
Ended Job = job_1513599404024_166489
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 7  Reduce: 6   Cumulative CPU: 328.76 sec   HDFS Read: 652626061 HDFS Write: 340354 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.68 sec   HDFS Read: 42968729 HDFS Write: 20595 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.47 sec   HDFS Read: 28271 HDFS Write: 2321 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 48 seconds 910 msec
OK
Time taken: 111.215 seconds, Fetched: 323 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103084157_7e13fd19-c1a2-4e06-aaaa-7846c422b2ab
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166492, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166492/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166492
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:42:08,282 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:42:17,606 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 8.29 sec
2018-01-03 08:42:20,706 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 11.0 sec
2018-01-03 08:42:23,807 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 11.73 sec
2018-01-03 08:42:26,898 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 12.66 sec
2018-01-03 08:42:29,991 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 13.09 sec
2018-01-03 08:42:33,081 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 13.46 sec
2018-01-03 08:42:36,169 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 14.15 sec
2018-01-03 08:42:39,261 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 14.61 sec
2018-01-03 08:42:42,344 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 15.15 sec
2018-01-03 08:42:45,430 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 15.85 sec
2018-01-03 08:42:48,519 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 16.23 sec
2018-01-03 08:42:51,604 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 16.66 sec
2018-01-03 08:42:54,689 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 17.34 sec
2018-01-03 08:42:57,776 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 17.62 sec
2018-01-03 08:43:00,860 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 17.94 sec
2018-01-03 08:43:02,915 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 19.31 sec
2018-01-03 08:43:06,023 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 20.14 sec
2018-01-03 08:43:07,051 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 20.84 sec
2018-01-03 08:43:13,223 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 24.28 sec
MapReduce Total cumulative CPU time: 24 seconds 280 msec
Ended Job = job_1513599404024_166492
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166499, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166499/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166499
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:43:20,084 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:43:27,335 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.04 sec
2018-01-03 08:43:32,578 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.13 sec
MapReduce Total cumulative CPU time: 18 seconds 130 msec
Ended Job = job_1513599404024_166499
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166501, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166501/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166501
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:43:40,216 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:43:45,376 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.34 sec
2018-01-03 08:43:52,580 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.0 sec
MapReduce Total cumulative CPU time: 6 seconds 0 msec
Ended Job = job_1513599404024_166501
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 24.28 sec   HDFS Read: 80938323 HDFS Write: 504296 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.13 sec   HDFS Read: 43131301 HDFS Write: 177545 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.0 sec   HDFS Read: 185178 HDFS Write: 6217 SUCCESS
Total MapReduce CPU Time Spent: 48 seconds 410 msec
OK
Time taken: 116.462 seconds, Fetched: 741 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103084400_61307f9b-5323-457e-b8c1-ec72bccad3d5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166502, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166502/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166502
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:44:10,464 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:44:19,778 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 10.98 sec
2018-01-03 08:44:22,876 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 12.52 sec
2018-01-03 08:44:25,969 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 13.26 sec
2018-01-03 08:44:29,059 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 14.58 sec
2018-01-03 08:44:32,150 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 15.76 sec
2018-01-03 08:44:35,239 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 17.01 sec
2018-01-03 08:44:38,323 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 18.05 sec
2018-01-03 08:44:41,410 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 19.07 sec
2018-01-03 08:44:44,495 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 23.86 sec
2018-01-03 08:44:50,670 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 29.13 sec
MapReduce Total cumulative CPU time: 29 seconds 130 msec
Ended Job = job_1513599404024_166502
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166513, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166513/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166513
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:45:11,404 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:45:16,584 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.43 sec
2018-01-03 08:45:17,616 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.38 sec
2018-01-03 08:45:23,807 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.38 sec
MapReduce Total cumulative CPU time: 15 seconds 380 msec
Ended Job = job_1513599404024_166513
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166520, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166520/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166520
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:45:30,474 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:45:36,673 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.47 sec
2018-01-03 08:45:42,863 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.11 sec
MapReduce Total cumulative CPU time: 6 seconds 110 msec
Ended Job = job_1513599404024_166520
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 29.13 sec   HDFS Read: 80938314 HDFS Write: 1276641 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.38 sec   HDFS Read: 43903650 HDFS Write: 166013 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.11 sec   HDFS Read: 173651 HDFS Write: 3306 SUCCESS
Total MapReduce CPU Time Spent: 50 seconds 620 msec
OK
Time taken: 103.578 seconds, Fetched: 507 row(s)
开始执行20171017日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103084550_5f19ccc7-bf6c-4d22-b235-2c9605da9b33
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166524, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166524/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166524
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 08:45:59,756 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:46:10,112 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 13.81 sec
2018-01-03 08:46:11,145 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 24.93 sec
2018-01-03 08:46:13,212 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 29.0 sec
2018-01-03 08:46:14,243 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 32.4 sec
2018-01-03 08:46:16,305 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 36.15 sec
2018-01-03 08:46:17,334 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 39.31 sec
2018-01-03 08:46:19,393 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 43.16 sec
2018-01-03 08:46:20,422 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 46.53 sec
2018-01-03 08:46:22,484 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 50.01 sec
2018-01-03 08:46:23,515 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 53.18 sec
2018-01-03 08:46:25,575 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 56.99 sec
2018-01-03 08:46:26,604 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 60.23 sec
2018-01-03 08:46:28,664 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 64.44 sec
2018-01-03 08:46:31,754 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 67.72 sec
2018-01-03 08:46:34,839 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 70.88 sec
2018-01-03 08:46:36,900 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 72.14 sec
2018-01-03 08:46:37,930 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 75.64 sec
2018-01-03 08:46:38,959 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 77.94 sec
2018-01-03 08:46:41,020 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 87.22 sec
MapReduce Total cumulative CPU time: 1 minutes 27 seconds 220 msec
Ended Job = job_1513599404024_166524
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166533, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166533/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166533
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:46:47,717 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:46:52,883 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.37 sec
2018-01-03 08:47:00,096 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.32 sec
MapReduce Total cumulative CPU time: 15 seconds 320 msec
Ended Job = job_1513599404024_166533
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166538, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166538/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166538
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:47:06,726 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:47:11,890 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.16 sec
2018-01-03 08:47:18,070 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.37 sec
MapReduce Total cumulative CPU time: 6 seconds 370 msec
Ended Job = job_1513599404024_166538
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 87.22 sec   HDFS Read: 255201721 HDFS Write: 1420653 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.32 sec   HDFS Read: 41873867 HDFS Write: 63183 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.37 sec   HDFS Read: 70858 HDFS Write: 2946 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 48 seconds 910 msec
OK
Time taken: 88.223 seconds, Fetched: 399 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.397 seconds
Query ID = boss_20180103084725_1bb5d09d-17c1-49f4-b826-a5d1ed41cab0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 5
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166544, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166544/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166544
Hadoop job information for Stage-1: number of mappers: 5; number of reducers: 5
2018-01-03 08:47:35,973 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:47:45,301 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.86 sec
2018-01-03 08:47:46,334 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 47.34 sec
2018-01-03 08:47:48,400 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 51.11 sec
2018-01-03 08:47:49,436 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 62.3 sec
2018-01-03 08:47:50,469 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 62.3 sec
2018-01-03 08:47:51,503 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 75.01 sec
2018-01-03 08:47:52,535 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 85.07 sec
2018-01-03 08:47:54,596 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 88.46 sec
2018-01-03 08:47:55,626 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 97.96 sec
2018-01-03 08:47:57,687 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 101.33 sec
2018-01-03 08:47:58,721 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 110.82 sec
2018-01-03 08:48:00,780 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 113.75 sec
2018-01-03 08:48:01,815 Stage-1 map = 68%,  reduce = 5%, Cumulative CPU 120.86 sec
2018-01-03 08:48:02,846 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 121.43 sec
2018-01-03 08:48:03,877 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 131.03 sec
2018-01-03 08:48:06,968 Stage-1 map = 92%,  reduce = 8%, Cumulative CPU 140.43 sec
2018-01-03 08:48:08,003 Stage-1 map = 92%,  reduce = 13%, Cumulative CPU 140.67 sec
2018-01-03 08:48:09,032 Stage-1 map = 100%,  reduce = 16%, Cumulative CPU 143.39 sec
2018-01-03 08:48:10,062 Stage-1 map = 100%,  reduce = 71%, Cumulative CPU 155.18 sec
2018-01-03 08:48:11,091 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 163.7 sec
MapReduce Total cumulative CPU time: 2 minutes 43 seconds 700 msec
Ended Job = job_1513599404024_166544
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166551, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166551/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166551
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:48:25,829 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:48:30,993 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.24 sec
2018-01-03 08:48:32,024 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.11 sec
2018-01-03 08:48:37,178 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.88 sec
MapReduce Total cumulative CPU time: 13 seconds 880 msec
Ended Job = job_1513599404024_166551
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166554, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166554/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166554
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:48:42,827 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:48:47,972 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.65 sec
2018-01-03 08:49:01,337 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.0 sec
MapReduce Total cumulative CPU time: 5 seconds 0 msec
Ended Job = job_1513599404024_166554
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 5  Reduce: 5   Cumulative CPU: 163.7 sec   HDFS Read: 549859277 HDFS Write: 321226 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.88 sec   HDFS Read: 40775226 HDFS Write: 20664 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.0 sec   HDFS Read: 28340 HDFS Write: 2279 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 2 seconds 580 msec
OK
Time taken: 96.521 seconds, Fetched: 333 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103084909_125798b0-2c65-407a-93f7-d189b702f343
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166560, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166560/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166560
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:49:20,271 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:49:29,599 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 9.27 sec
2018-01-03 08:49:32,700 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 12.13 sec
2018-01-03 08:49:35,794 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.95 sec
2018-01-03 08:49:38,885 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 13.66 sec
2018-01-03 08:49:41,978 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 14.09 sec
2018-01-03 08:49:45,069 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 14.9 sec
2018-01-03 08:49:48,158 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 15.18 sec
2018-01-03 08:49:51,250 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 15.52 sec
2018-01-03 08:49:54,336 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 16.21 sec
2018-01-03 08:49:57,422 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 16.77 sec
2018-01-03 08:50:00,510 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 17.39 sec
2018-01-03 08:50:03,595 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 17.68 sec
2018-01-03 08:50:06,682 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 18.33 sec
2018-01-03 08:50:09,770 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 18.67 sec
2018-01-03 08:50:12,853 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 19.02 sec
2018-01-03 08:50:15,935 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 20.44 sec
2018-01-03 08:50:17,990 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 21.17 sec
2018-01-03 08:50:19,021 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 22.18 sec
2018-01-03 08:50:24,164 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 27.31 sec
MapReduce Total cumulative CPU time: 27 seconds 310 msec
Ended Job = job_1513599404024_166560
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166569, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166569/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166569
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:50:30,876 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:50:37,054 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.31 sec
2018-01-03 08:50:42,192 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.09 sec
2018-01-03 08:50:58,641 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.64 sec
MapReduce Total cumulative CPU time: 15 seconds 640 msec
Ended Job = job_1513599404024_166569
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166573, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166573/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166573
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:51:04,349 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:51:09,527 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec
2018-01-03 08:51:23,963 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.88 sec
MapReduce Total cumulative CPU time: 6 seconds 880 msec
Ended Job = job_1513599404024_166573
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 27.31 sec   HDFS Read: 81666641 HDFS Write: 484919 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.64 sec   HDFS Read: 40937815 HDFS Write: 165141 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.88 sec   HDFS Read: 172778 HDFS Write: 6443 SUCCESS
Total MapReduce CPU Time Spent: 49 seconds 830 msec
OK
Time taken: 135.81 seconds, Fetched: 788 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103085145_7fe5265a-c6ee-448e-89c5-82c3a8a72996
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166578, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166578/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166578
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:51:55,868 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:52:06,207 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.07 sec
2018-01-03 08:52:09,304 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 13.76 sec
2018-01-03 08:52:12,396 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 14.89 sec
2018-01-03 08:52:15,482 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 16.46 sec
2018-01-03 08:52:18,572 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 17.3 sec
2018-01-03 08:52:21,658 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 18.13 sec
2018-01-03 08:52:24,742 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 19.67 sec
2018-01-03 08:52:27,830 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 21.06 sec
2018-01-03 08:52:29,887 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 22.23 sec
2018-01-03 08:52:32,971 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 24.15 sec
2018-01-03 08:52:35,027 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 27.38 sec
2018-01-03 08:52:41,202 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 31.34 sec
MapReduce Total cumulative CPU time: 31 seconds 340 msec
Ended Job = job_1513599404024_166578
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166584, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166584/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166584
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:52:47,886 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:52:54,068 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.19 sec
2018-01-03 08:53:00,240 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.18 sec
MapReduce Total cumulative CPU time: 17 seconds 180 msec
Ended Job = job_1513599404024_166584
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166587, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166587/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166587
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:53:05,956 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:53:12,150 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.9 sec
2018-01-03 08:53:18,346 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.48 sec
MapReduce Total cumulative CPU time: 6 seconds 480 msec
Ended Job = job_1513599404024_166587
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 31.34 sec   HDFS Read: 81666631 HDFS Write: 1150279 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.18 sec   HDFS Read: 41603175 HDFS Write: 162071 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.48 sec   HDFS Read: 169709 HDFS Write: 3161 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 0 msec
OK
Time taken: 93.484 seconds, Fetched: 487 row(s)
开始执行20171018日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.367 seconds
Query ID = boss_20180103085326_0e44f7e3-2739-4306-b017-37dad9b57d0b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166590, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166590/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166590
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 08:53:35,344 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:53:44,668 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.43 sec
2018-01-03 08:53:45,700 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 26.02 sec
2018-01-03 08:53:47,765 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 30.5 sec
2018-01-03 08:53:48,800 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 34.17 sec
2018-01-03 08:53:50,867 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 37.5 sec
2018-01-03 08:53:51,899 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 42.52 sec
2018-01-03 08:53:54,992 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 45.69 sec
2018-01-03 08:53:58,087 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 48.86 sec
2018-01-03 08:54:01,178 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 51.95 sec
2018-01-03 08:54:03,241 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 53.31 sec
2018-01-03 08:54:04,271 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 56.37 sec
2018-01-03 08:54:07,363 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 59.88 sec
2018-01-03 08:54:09,421 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 63.37 sec
2018-01-03 08:54:12,510 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 66.85 sec
2018-01-03 08:54:15,596 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 69.85 sec
2018-01-03 08:54:18,683 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 72.69 sec
2018-01-03 08:54:19,711 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 74.1 sec
2018-01-03 08:54:21,768 Stage-1 map = 100%,  reduce = 87%, Cumulative CPU 81.46 sec
2018-01-03 08:54:22,797 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 83.31 sec
MapReduce Total cumulative CPU time: 1 minutes 23 seconds 310 msec
Ended Job = job_1513599404024_166590
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166593, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166593/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166593
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:54:29,518 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:54:34,696 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.59 sec
2018-01-03 08:54:36,765 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.15 sec
2018-01-03 08:54:40,894 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.61 sec
MapReduce Total cumulative CPU time: 17 seconds 610 msec
Ended Job = job_1513599404024_166593
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166595, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166595/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166595
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:54:47,795 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:54:51,925 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.88 sec
2018-01-03 08:54:57,080 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.13 sec
MapReduce Total cumulative CPU time: 5 seconds 130 msec
Ended Job = job_1513599404024_166595
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 83.31 sec   HDFS Read: 243612544 HDFS Write: 1455003 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.61 sec   HDFS Read: 44599050 HDFS Write: 63198 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.13 sec   HDFS Read: 70873 HDFS Write: 2813 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 46 seconds 50 msec
OK
Time taken: 92.737 seconds, Fetched: 397 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.392 seconds
Query ID = boss_20180103085505_a1e77ac6-8542-46e0-a1cf-a5e0169ae384
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166597, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166597/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166597
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 4
2018-01-03 08:55:15,508 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:55:25,850 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 36.03 sec
2018-01-03 08:55:28,949 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 47.53 sec
2018-01-03 08:55:31,013 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 50.84 sec
2018-01-03 08:55:32,045 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 59.81 sec
2018-01-03 08:55:34,106 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 63.13 sec
2018-01-03 08:55:35,137 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 71.28 sec
2018-01-03 08:55:36,168 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 73.48 sec
2018-01-03 08:55:38,233 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 79.6 sec
2018-01-03 08:55:41,321 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 86.37 sec
2018-01-03 08:55:44,408 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 93.03 sec
2018-01-03 08:55:46,470 Stage-1 map = 63%,  reduce = 3%, Cumulative CPU 93.75 sec
2018-01-03 08:55:47,504 Stage-1 map = 67%,  reduce = 11%, Cumulative CPU 102.04 sec
2018-01-03 08:55:50,592 Stage-1 map = 72%,  reduce = 11%, Cumulative CPU 108.84 sec
2018-01-03 08:55:53,679 Stage-1 map = 87%,  reduce = 11%, Cumulative CPU 116.66 sec
2018-01-03 08:55:54,708 Stage-1 map = 100%,  reduce = 11%, Cumulative CPU 118.87 sec
2018-01-03 08:55:55,738 Stage-1 map = 100%,  reduce = 77%, Cumulative CPU 130.59 sec
2018-01-03 08:55:56,771 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 135.69 sec
MapReduce Total cumulative CPU time: 2 minutes 15 seconds 690 msec
Ended Job = job_1513599404024_166597
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166604, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166604/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166604
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:56:10,450 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:56:15,607 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.03 sec
2018-01-03 08:56:19,728 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.45 sec
MapReduce Total cumulative CPU time: 12 seconds 450 msec
Ended Job = job_1513599404024_166604
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166606, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166606/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166606
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:56:27,398 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:56:32,561 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.74 sec
2018-01-03 08:56:39,761 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.52 sec
MapReduce Total cumulative CPU time: 5 seconds 520 msec
Ended Job = job_1513599404024_166606
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 4   Cumulative CPU: 135.69 sec   HDFS Read: 410461027 HDFS Write: 295209 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.45 sec   HDFS Read: 43439780 HDFS Write: 21037 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.52 sec   HDFS Read: 28713 HDFS Write: 2283 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 33 seconds 660 msec
OK
Time taken: 94.86 seconds, Fetched: 333 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103085647_3bc2db9e-48d5-48d6-b7de-f483f5660a82
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166610, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166610/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166610
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:57:05,532 Stage-1 map = 0%,  reduce = 0%
2018-01-03 08:57:15,882 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 8.58 sec
2018-01-03 08:57:18,986 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.78 sec
2018-01-03 08:57:22,082 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.62 sec
2018-01-03 08:57:25,169 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 12.55 sec
2018-01-03 08:57:27,231 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 13.43 sec
2018-01-03 08:57:30,318 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 14.05 sec
2018-01-03 08:57:33,404 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 14.67 sec
2018-01-03 08:57:36,493 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 15.23 sec
2018-01-03 08:57:39,578 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 15.58 sec
2018-01-03 08:57:42,663 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 16.16 sec
2018-01-03 08:57:45,751 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 16.54 sec
2018-01-03 08:57:48,835 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 17.03 sec
2018-01-03 08:57:51,921 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 17.75 sec
2018-01-03 08:57:55,007 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 18.18 sec
2018-01-03 08:57:58,089 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 18.85 sec
2018-01-03 08:58:01,169 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 19.21 sec
2018-01-03 08:58:04,252 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 19.75 sec
2018-01-03 08:58:07,331 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 20.67 sec
2018-01-03 08:58:10,410 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 21.09 sec
2018-01-03 08:58:13,492 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 21.48 sec
2018-01-03 08:58:16,571 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 22.46 sec
2018-01-03 08:58:18,624 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 23.05 sec
2018-01-03 08:58:21,705 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 25.3 sec
2018-01-03 08:58:24,784 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 26.16 sec
2018-01-03 08:58:26,837 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 27.15 sec
2018-01-03 08:58:33,001 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.04 sec
MapReduce Total cumulative CPU time: 32 seconds 40 msec
Ended Job = job_1513599404024_166610
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166620, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166620/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166620
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 08:58:39,728 Stage-2 map = 0%,  reduce = 0%
2018-01-03 08:58:45,916 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.66 sec
2018-01-03 08:58:53,123 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.35 sec
2018-01-03 08:58:54,152 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.33 sec
MapReduce Total cumulative CPU time: 15 seconds 330 msec
Ended Job = job_1513599404024_166620
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166621, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166621/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166621
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 08:59:00,827 Stage-3 map = 0%,  reduce = 0%
2018-01-03 08:59:04,989 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.81 sec
2018-01-03 08:59:19,380 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.67 sec
MapReduce Total cumulative CPU time: 6 seconds 670 msec
Ended Job = job_1513599404024_166621
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 32.04 sec   HDFS Read: 77183120 HDFS Write: 450634 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.33 sec   HDFS Read: 43594363 HDFS Write: 158062 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.67 sec   HDFS Read: 165699 HDFS Write: 6087 SUCCESS
Total MapReduce CPU Time Spent: 54 seconds 40 msec
OK
Time taken: 152.878 seconds, Fetched: 750 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.372 seconds
Query ID = boss_20180103085927_333b219b-f042-430d-99ef-cc44b2fcb3cb
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166626, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166626/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166626
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 08:59:40,222 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:00:37,978 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 50.05 sec
2018-01-03 09:00:41,063 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 59.2 sec
2018-01-03 09:00:44,147 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 67.35 sec
2018-01-03 09:00:48,260 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 76.27 sec
2018-01-03 09:00:51,342 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 83.31 sec
2018-01-03 09:00:54,424 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 88.54 sec
2018-01-03 09:00:58,534 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 93.99 sec
2018-01-03 09:01:04,693 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 101.06 sec
2018-01-03 09:01:08,804 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 105.2 sec
2018-01-03 09:01:11,882 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 109.73 sec
2018-01-03 09:01:14,964 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 114.41 sec
2018-01-03 09:01:19,068 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 118.16 sec
2018-01-03 09:01:22,146 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 122.17 sec
2018-01-03 09:01:25,227 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 126.0 sec
2018-01-03 09:01:28,304 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 130.82 sec
2018-01-03 09:01:31,381 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 133.34 sec
2018-01-03 09:01:34,460 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 137.54 sec
2018-01-03 09:01:37,537 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 140.96 sec
2018-01-03 09:01:40,613 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 144.8 sec
2018-01-03 09:01:43,694 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 148.79 sec
2018-01-03 09:01:46,771 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 150.99 sec
2018-01-03 09:01:49,847 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 153.89 sec
2018-01-03 09:01:52,927 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 156.36 sec
2018-01-03 09:01:57,028 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 159.22 sec
2018-01-03 09:02:00,104 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 164.52 sec
2018-01-03 09:02:03,183 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 167.5 sec
2018-01-03 09:02:06,258 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 171.44 sec
2018-01-03 09:02:09,336 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 175.5 sec
2018-01-03 09:02:12,421 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 180.67 sec
2018-01-03 09:02:15,495 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 187.5 sec
2018-01-03 09:02:18,569 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 196.56 sec
2018-01-03 09:02:21,645 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 204.88 sec
2018-01-03 09:02:27,806 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 210.66 sec
MapReduce Total cumulative CPU time: 3 minutes 30 seconds 660 msec
Ended Job = job_1513599404024_166626
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166644, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166644/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166644
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:02:35,488 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:02:40,657 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.03 sec
2018-01-03 09:02:45,797 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.27 sec
MapReduce Total cumulative CPU time: 14 seconds 270 msec
Ended Job = job_1513599404024_166644
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166647, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166647/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166647
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:02:52,552 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:02:57,706 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec
2018-01-03 09:03:02,851 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.82 sec
MapReduce Total cumulative CPU time: 5 seconds 820 msec
Ended Job = job_1513599404024_166647
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 210.66 sec   HDFS Read: 77183110 HDFS Write: 1036701 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.27 sec   HDFS Read: 44180430 HDFS Write: 159452 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.82 sec   HDFS Read: 167090 HDFS Write: 3647 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 50 seconds 750 msec
OK
Time taken: 216.518 seconds, Fetched: 511 row(s)
开始执行20171019日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.388 seconds
Query ID = boss_20180103090310_4264bdab-48a8-44d1-b3d0-29f34ceede71
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166654, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166654/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166654
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 09:03:20,785 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:03:30,110 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 12.34 sec
2018-01-03 09:03:31,143 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 24.92 sec
2018-01-03 09:03:33,208 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 28.62 sec
2018-01-03 09:03:34,243 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 32.12 sec
2018-01-03 09:03:36,306 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 35.48 sec
2018-01-03 09:03:37,338 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 38.85 sec
2018-01-03 09:03:38,369 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 41.56 sec
2018-01-03 09:03:40,431 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 44.92 sec
2018-01-03 09:03:43,525 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 47.93 sec
2018-01-03 09:03:46,615 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 50.93 sec
2018-01-03 09:03:48,680 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 52.03 sec
2018-01-03 09:03:49,711 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 54.95 sec
2018-01-03 09:03:52,804 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 58.69 sec
2018-01-03 09:03:54,863 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 62.01 sec
2018-01-03 09:03:57,952 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 65.34 sec
2018-01-03 09:04:01,045 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 68.39 sec
2018-01-03 09:04:04,141 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 71.44 sec
2018-01-03 09:04:07,227 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 72.18 sec
2018-01-03 09:04:08,255 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 73.24 sec
2018-01-03 09:04:09,285 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 77.04 sec
2018-01-03 09:04:10,314 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 81.31 sec
MapReduce Total cumulative CPU time: 1 minutes 21 seconds 310 msec
Ended Job = job_1513599404024_166654
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166662, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166662/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166662
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:04:24,008 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:04:30,190 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.54 sec
2018-01-03 09:04:37,408 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.51 sec
2018-01-03 09:04:43,574 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.33 sec
MapReduce Total cumulative CPU time: 16 seconds 330 msec
Ended Job = job_1513599404024_166662
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166668, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166668/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166668
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:04:49,222 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:05:24,199 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 18.77 sec
2018-01-03 09:05:30,370 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 22.12 sec
MapReduce Total cumulative CPU time: 22 seconds 120 msec
Ended Job = job_1513599404024_166668
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 81.31 sec   HDFS Read: 260687037 HDFS Write: 1354663 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.33 sec   HDFS Read: 42086416 HDFS Write: 63210 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 22.12 sec   HDFS Read: 70885 HDFS Write: 2914 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 59 seconds 760 msec
OK
Time taken: 140.564 seconds, Fetched: 401 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.4 seconds
Query ID = boss_20180103090538_be4e546a-d16e-44e0-ad33-84742c1558f8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166675, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166675/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166675
Hadoop job information for Stage-1: number of mappers: 4; number of reducers: 4
2018-01-03 09:05:47,122 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:05:56,450 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.47 sec
2018-01-03 09:05:57,484 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 51.83 sec
2018-01-03 09:05:59,548 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 55.14 sec
2018-01-03 09:06:00,584 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 68.2 sec
2018-01-03 09:06:02,647 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 71.28 sec
2018-01-03 09:06:03,679 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 81.83 sec
2018-01-03 09:06:05,740 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 88.74 sec
2018-01-03 09:06:06,772 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 97.51 sec
2018-01-03 09:06:08,832 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 104.95 sec
2018-01-03 09:06:09,868 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 108.38 sec
2018-01-03 09:06:11,937 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 111.75 sec
2018-01-03 09:06:12,967 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 115.15 sec
2018-01-03 09:06:15,025 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 122.43 sec
2018-01-03 09:06:17,088 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 123.7 sec
2018-01-03 09:06:18,118 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 132.28 sec
2018-01-03 09:06:19,152 Stage-1 map = 90%,  reduce = 17%, Cumulative CPU 134.38 sec
2018-01-03 09:06:21,210 Stage-1 map = 100%,  reduce = 21%, Cumulative CPU 138.89 sec
2018-01-03 09:06:22,238 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 142.67 sec
2018-01-03 09:06:23,267 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 153.85 sec
MapReduce Total cumulative CPU time: 2 minutes 33 seconds 850 msec
Ended Job = job_1513599404024_166675
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166680, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166680/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166680
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:06:28,945 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:06:34,101 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 7.68 sec
2018-01-03 09:06:39,269 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.38 sec
MapReduce Total cumulative CPU time: 12 seconds 380 msec
Ended Job = job_1513599404024_166680
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166682, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166682/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166682
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:06:52,966 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:06:58,136 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.33 sec
2018-01-03 09:07:04,326 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.74 sec
MapReduce Total cumulative CPU time: 4 seconds 740 msec
Ended Job = job_1513599404024_166682
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 4  Reduce: 4   Cumulative CPU: 153.85 sec   HDFS Read: 483738708 HDFS Write: 293976 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.38 sec   HDFS Read: 41026253 HDFS Write: 19589 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.74 sec   HDFS Read: 27265 HDFS Write: 2341 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 50 seconds 970 msec
OK
Time taken: 87.214 seconds, Fetched: 328 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103090712_bc2347b1-e684-459b-a75f-f41aeba56328
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166686, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166686/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166686
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 09:07:24,050 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:07:33,519 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 8.26 sec
2018-01-03 09:07:36,624 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 9.8 sec
2018-01-03 09:07:39,723 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 10.8 sec
2018-01-03 09:07:42,818 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 11.52 sec
2018-01-03 09:07:45,914 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 11.97 sec
2018-01-03 09:07:49,007 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 12.49 sec
2018-01-03 09:07:52,097 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 13.24 sec
2018-01-03 09:07:55,191 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 13.79 sec
2018-01-03 09:07:58,279 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 14.34 sec
2018-01-03 09:08:01,366 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 15.07 sec
2018-01-03 09:08:04,469 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 15.37 sec
2018-01-03 09:08:07,553 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 16.19 sec
2018-01-03 09:08:09,612 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 16.44 sec
2018-01-03 09:08:12,700 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 16.83 sec
2018-01-03 09:08:15,785 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 17.24 sec
2018-01-03 09:08:18,870 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 18.77 sec
2018-01-03 09:08:21,959 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 20.38 sec
2018-01-03 09:08:29,376 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 24.39 sec
MapReduce Total cumulative CPU time: 24 seconds 390 msec
Ended Job = job_1513599404024_166686
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166694, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166694/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166694
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:08:35,364 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:08:47,701 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.71 sec
2018-01-03 09:08:54,893 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 26.8 sec
2018-01-03 09:08:56,951 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 33.41 sec
MapReduce Total cumulative CPU time: 33 seconds 410 msec
Ended Job = job_1513599404024_166694
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166697, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166697/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166697
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:09:04,726 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:09:21,243 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.23 sec
2018-01-03 09:09:38,718 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.81 sec
MapReduce Total cumulative CPU time: 7 seconds 810 msec
Ended Job = job_1513599404024_166697
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 24.39 sec   HDFS Read: 75407964 HDFS Write: 460703 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 33.41 sec   HDFS Read: 41192138 HDFS Write: 154251 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.81 sec   HDFS Read: 161888 HDFS Write: 6087 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 5 seconds 610 msec
OK
Time taken: 147.688 seconds, Fetched: 756 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103090946_c45123ff-dff4-4ca6-97fa-0975fdb81e7e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166703, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166703/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166703
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 09:10:01,514 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:10:12,962 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 10.81 sec
2018-01-03 09:10:16,067 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 15.8 sec
2018-01-03 09:10:19,164 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 17.27 sec
2018-01-03 09:10:22,259 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 18.55 sec
2018-01-03 09:10:25,359 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 19.87 sec
2018-01-03 09:10:28,455 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 20.52 sec
2018-01-03 09:10:31,552 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 21.64 sec
2018-01-03 09:10:34,645 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 22.86 sec
2018-01-03 09:10:37,733 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 24.18 sec
2018-01-03 09:10:40,821 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 25.5 sec
2018-01-03 09:10:43,908 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 26.21 sec
2018-01-03 09:10:46,996 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 27.16 sec
2018-01-03 09:10:49,057 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 27.16 sec
2018-01-03 09:10:52,151 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 30.13 sec
2018-01-03 09:10:53,181 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 31.29 sec
2018-01-03 09:11:25,077 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 38.51 sec
MapReduce Total cumulative CPU time: 38 seconds 510 msec
Ended Job = job_1513599404024_166703
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166712, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166712/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166712
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:11:35,310 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:11:40,469 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.21 sec
2018-01-03 09:11:45,634 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 17.05 sec
2018-01-03 09:11:49,748 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.06 sec
MapReduce Total cumulative CPU time: 23 seconds 60 msec
Ended Job = job_1513599404024_166712
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166714, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166714/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166714
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:11:58,700 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:12:20,328 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.18 sec
2018-01-03 09:12:26,503 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.89 sec
MapReduce Total cumulative CPU time: 6 seconds 890 msec
Ended Job = job_1513599404024_166714
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 38.51 sec   HDFS Read: 75407954 HDFS Write: 944051 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.06 sec   HDFS Read: 41675486 HDFS Write: 153348 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.89 sec   HDFS Read: 160986 HDFS Write: 3539 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 8 seconds 460 msec
OK
Time taken: 161.09 seconds, Fetched: 495 row(s)
开始执行20171020日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103091234_08e8d899-321f-41d6-999c-f2b461bcbeaf
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166717, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166717/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166717
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 09:12:49,599 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:12:59,987 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 13.68 sec
2018-01-03 09:13:03,093 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 17.89 sec
2018-01-03 09:13:04,127 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 33.63 sec
2018-01-03 09:13:06,193 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 37.77 sec
2018-01-03 09:13:07,226 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 41.18 sec
2018-01-03 09:13:09,290 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 44.72 sec
2018-01-03 09:13:10,322 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 48.39 sec
2018-01-03 09:13:12,390 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 51.77 sec
2018-01-03 09:13:13,423 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 57.54 sec
2018-01-03 09:13:16,516 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 60.71 sec
2018-01-03 09:13:19,610 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 63.79 sec
2018-01-03 09:13:22,702 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 67.23 sec
2018-01-03 09:13:23,737 Stage-1 map = 70%,  reduce = 8%, Cumulative CPU 67.69 sec
2018-01-03 09:13:25,798 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 71.66 sec
2018-01-03 09:13:28,891 Stage-1 map = 78%,  reduce = 8%, Cumulative CPU 74.82 sec
2018-01-03 09:13:30,961 Stage-1 map = 81%,  reduce = 8%, Cumulative CPU 78.52 sec
2018-01-03 09:13:33,033 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 80.71 sec
2018-01-03 09:13:35,093 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 91.06 sec
MapReduce Total cumulative CPU time: 1 minutes 31 seconds 60 msec
Ended Job = job_1513599404024_166717
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166722, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166722/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166722
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:13:42,080 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:13:49,336 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.4 sec
2018-01-03 09:13:55,513 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.0 sec
2018-01-03 09:13:57,572 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.28 sec
MapReduce Total cumulative CPU time: 17 seconds 280 msec
Ended Job = job_1513599404024_166722
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166724, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166724/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166724
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:14:29,512 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:14:37,753 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.38 sec
2018-01-03 09:14:51,144 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.03 sec
MapReduce Total cumulative CPU time: 7 seconds 30 msec
Ended Job = job_1513599404024_166724
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 91.06 sec   HDFS Read: 258740509 HDFS Write: 1324461 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.28 sec   HDFS Read: 42379364 HDFS Write: 61497 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.03 sec   HDFS Read: 69172 HDFS Write: 2766 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 55 seconds 370 msec
OK
Time taken: 137.693 seconds, Fetched: 387 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.4 seconds
Query ID = boss_20180103091458_9ca22d2e-135c-4724-80f2-36a68ca403c5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166727, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166727/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166727
Hadoop job information for Stage-1: number of mappers: 4; number of reducers: 4
2018-01-03 09:15:08,247 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:15:18,615 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 25.62 sec
2018-01-03 09:15:21,723 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 41.83 sec
2018-01-03 09:15:24,824 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 66.53 sec
2018-01-03 09:15:26,907 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 80.62 sec
2018-01-03 09:15:27,946 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 92.5 sec
2018-01-03 09:15:31,519 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 95.68 sec
2018-01-03 09:15:32,562 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 108.37 sec
2018-01-03 09:15:35,675 Stage-1 map = 47%,  reduce = 2%, Cumulative CPU 131.85 sec
2018-01-03 09:15:38,775 Stage-1 map = 49%,  reduce = 4%, Cumulative CPU 162.89 sec
2018-01-03 09:15:41,874 Stage-1 map = 51%,  reduce = 4%, Cumulative CPU 184.17 sec
2018-01-03 09:15:42,907 Stage-1 map = 53%,  reduce = 4%, Cumulative CPU 187.82 sec
2018-01-03 09:15:45,082 Stage-1 map = 55%,  reduce = 4%, Cumulative CPU 187.99 sec
2018-01-03 09:15:46,372 Stage-1 map = 56%,  reduce = 6%, Cumulative CPU 212.38 sec
2018-01-03 09:15:47,406 Stage-1 map = 56%,  reduce = 8%, Cumulative CPU 214.55 sec
2018-01-03 09:15:48,440 Stage-1 map = 59%,  reduce = 8%, Cumulative CPU 236.87 sec
2018-01-03 09:15:51,539 Stage-1 map = 63%,  reduce = 8%, Cumulative CPU 250.53 sec
2018-01-03 09:15:54,634 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 263.74 sec
2018-01-03 09:15:55,666 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 276.44 sec
2018-01-03 09:15:56,698 Stage-1 map = 77%,  reduce = 13%, Cumulative CPU 277.43 sec
2018-01-03 09:15:57,728 Stage-1 map = 80%,  reduce = 13%, Cumulative CPU 283.52 sec
2018-01-03 09:15:59,794 Stage-1 map = 90%,  reduce = 19%, Cumulative CPU 291.82 sec
2018-01-03 09:16:00,832 Stage-1 map = 90%,  reduce = 21%, Cumulative CPU 292.18 sec
2018-01-03 09:16:01,866 Stage-1 map = 91%,  reduce = 21%, Cumulative CPU 299.22 sec
2018-01-03 09:16:02,900 Stage-1 map = 91%,  reduce = 25%, Cumulative CPU 299.86 sec
2018-01-03 09:16:05,013 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 304.2 sec
2018-01-03 09:16:06,408 Stage-1 map = 100%,  reduce = 54%, Cumulative CPU 311.16 sec
2018-01-03 09:16:07,472 Stage-1 map = 100%,  reduce = 75%, Cumulative CPU 314.33 sec
2018-01-03 09:16:10,857 Stage-1 map = 100%,  reduce = 81%, Cumulative CPU 324.02 sec
2018-01-03 09:16:11,892 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 327.17 sec
2018-01-03 09:16:13,964 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 334.75 sec
2018-01-03 09:16:16,041 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 345.11 sec
MapReduce Total cumulative CPU time: 5 minutes 45 seconds 110 msec
Ended Job = job_1513599404024_166727
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166736, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166736/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166736
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:17:06,406 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:17:33,719 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 10.14 sec
2018-01-03 09:17:49,196 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 19.65 sec
2018-01-03 09:18:06,669 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 25.71 sec
MapReduce Total cumulative CPU time: 25 seconds 710 msec
Ended Job = job_1513599404024_166736
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166748, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166748/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166748
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:18:21,370 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:18:27,559 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.07 sec
2018-01-03 09:18:33,734 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.43 sec
MapReduce Total cumulative CPU time: 5 seconds 430 msec
Ended Job = job_1513599404024_166748
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 4  Reduce: 4   Cumulative CPU: 345.11 sec   HDFS Read: 439340916 HDFS Write: 565623 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 25.71 sec   HDFS Read: 41621050 HDFS Write: 19556 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.43 sec   HDFS Read: 27232 HDFS Write: 2174 SUCCESS
Total MapReduce CPU Time Spent: 6 minutes 16 seconds 250 msec
OK
Time taken: 215.845 seconds, Fetched: 317 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103091841_1b5a5323-8cf7-420f-a7d8-8c99802193be
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166751, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166751/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166751
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 09:18:52,418 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:19:02,782 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 8.76 sec
2018-01-03 09:19:05,884 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 11.77 sec
2018-01-03 09:19:08,977 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 13.89 sec
2018-01-03 09:19:12,066 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.27 sec
2018-01-03 09:19:15,158 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.88 sec
2018-01-03 09:19:18,246 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 16.99 sec
2018-01-03 09:19:21,332 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 17.55 sec
2018-01-03 09:19:24,423 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 18.03 sec
2018-01-03 09:19:27,508 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 18.48 sec
2018-01-03 09:19:30,594 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 19.59 sec
2018-01-03 09:19:33,682 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 20.25 sec
2018-01-03 09:19:36,766 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 20.61 sec
2018-01-03 09:19:38,824 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 21.26 sec
2018-01-03 09:19:41,908 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 21.68 sec
2018-01-03 09:19:44,989 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 22.67 sec
2018-01-03 09:19:48,069 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 23.12 sec
2018-01-03 09:19:51,157 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 23.59 sec
2018-01-03 09:19:54,251 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 24.06 sec
2018-01-03 09:19:57,340 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 25.28 sec
2018-01-03 09:20:00,432 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 25.92 sec
2018-01-03 09:20:01,460 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 27.3 sec
2018-01-03 09:20:30,225 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 36.53 sec
MapReduce Total cumulative CPU time: 36 seconds 530 msec
Ended Job = job_1513599404024_166751
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166763, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166763/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166763
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:21:16,351 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:21:37,172 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 9.5 sec
2018-01-03 09:21:45,562 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 23.21 sec
2018-01-03 09:21:56,394 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 31.7 sec
MapReduce Total cumulative CPU time: 31 seconds 700 msec
Ended Job = job_1513599404024_166763
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166768, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166768/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166768
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:22:20,540 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:22:48,531 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.89 sec
2018-01-03 09:23:28,090 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 11.54 sec
2018-01-03 09:23:39,941 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 18.9 sec
MapReduce Total cumulative CPU time: 18 seconds 900 msec
Ended Job = job_1513599404024_166768
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 36.53 sec   HDFS Read: 78955205 HDFS Write: 469808 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 31.7 sec   HDFS Read: 41524393 HDFS Write: 162921 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 18.9 sec   HDFS Read: 170558 HDFS Write: 6499 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 27 seconds 130 msec
OK
Time taken: 300.874 seconds, Fetched: 806 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103092349_3949d8f2-6d32-4e6e-90a2-0955149bbe38
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166772, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166772/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166772
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 09:24:03,895 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:24:42,060 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 14.26 sec
2018-01-03 09:24:50,294 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 17.14 sec
2018-01-03 09:24:58,525 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 19.98 sec
2018-01-03 09:25:05,721 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 21.95 sec
2018-01-03 09:25:25,248 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 24.79 sec
2018-01-03 09:25:37,567 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 25.42 sec
2018-01-03 09:25:50,908 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 29.98 sec
2018-01-03 09:25:57,064 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 32.49 sec
2018-01-03 09:26:00,139 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 32.94 sec
2018-01-03 09:26:03,216 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 33.12 sec
2018-01-03 09:26:09,370 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 33.47 sec
2018-01-03 09:26:15,527 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 34.07 sec
2018-01-03 09:26:18,602 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 34.56 sec
2018-01-03 09:26:22,705 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 35.24 sec
2018-01-03 09:26:28,854 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 37.16 sec
2018-01-03 09:26:31,932 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 37.78 sec
2018-01-03 09:26:35,007 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 38.09 sec
2018-01-03 09:26:41,159 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 38.75 sec
2018-01-03 09:26:44,233 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 39.11 sec
2018-01-03 09:26:47,309 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 39.29 sec
2018-01-03 09:26:50,386 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 39.98 sec
2018-01-03 09:26:53,460 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 40.44 sec
2018-01-03 09:26:59,617 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 41.45 sec
2018-01-03 09:27:05,774 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 41.91 sec
2018-01-03 09:27:15,006 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 42.69 sec
2018-01-03 09:27:18,084 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 42.85 sec
2018-01-03 09:27:21,159 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 43.08 sec
2018-01-03 09:27:25,258 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 43.48 sec
2018-01-03 09:27:32,436 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 44.53 sec
2018-01-03 09:27:35,509 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 45.18 sec
2018-01-03 09:27:41,662 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 45.77 sec
2018-01-03 09:27:44,734 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 46.14 sec
2018-01-03 09:27:50,883 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 47.16 sec
2018-01-03 09:27:57,030 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 47.79 sec
2018-01-03 09:28:06,252 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 52.57 sec
2018-01-03 09:28:12,403 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 52.57 sec
2018-01-03 09:28:15,499 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 53.08 sec
2018-01-03 09:28:19,599 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 53.51 sec
2018-01-03 09:28:22,672 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 54.13 sec
2018-01-03 09:28:25,746 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 54.89 sec
2018-01-03 09:28:34,965 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 55.85 sec
2018-01-03 09:28:43,163 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 56.83 sec
2018-01-03 09:28:50,338 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 57.53 sec
2018-01-03 09:28:53,419 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 58.14 sec
2018-01-03 09:28:59,565 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 59.45 sec
2018-01-03 09:29:04,688 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 59.85 sec
2018-01-03 09:29:11,864 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 60.42 sec
2018-01-03 09:29:22,106 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 64.47 sec
2018-01-03 09:29:28,252 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 64.86 sec
2018-01-03 09:29:34,399 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 65.14 sec
2018-01-03 09:29:49,758 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 65.88 sec
2018-01-03 09:29:55,903 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 66.49 sec
2018-01-03 09:30:22,528 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 69.59 sec
2018-01-03 09:30:34,817 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 70.42 sec
2018-01-03 09:30:44,033 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 73.03 sec
2018-01-03 09:30:47,105 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 73.53 sec
2018-01-03 09:30:53,250 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 75.13 sec
2018-01-03 09:30:59,391 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 75.81 sec
2018-01-03 09:31:05,536 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 82.37 sec
2018-01-03 09:31:16,803 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 83.5 sec
2018-01-03 09:31:30,112 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 84.86 sec
2018-01-03 09:31:42,404 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 85.37 sec
2018-01-03 09:31:48,547 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 85.67 sec
2018-01-03 09:31:49,570 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 88.44 sec
2018-01-03 09:32:04,935 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 95.37 sec
MapReduce Total cumulative CPU time: 1 minutes 35 seconds 370 msec
Ended Job = job_1513599404024_166772
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166797, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166797/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166797
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:32:25,500 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:32:53,259 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 9.84 sec
2018-01-03 09:33:01,483 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 20.56 sec
2018-01-03 09:33:05,591 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 29.67 sec
MapReduce Total cumulative CPU time: 29 seconds 670 msec
Ended Job = job_1513599404024_166797
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166800, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166800/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166800
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:33:58,653 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:34:12,876 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.71 sec
2018-01-03 09:34:28,357 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.71 sec
MapReduce Total cumulative CPU time: 2 seconds 710 msec
Ended Job = job_1513599404024_166800
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 95.37 sec   HDFS Read: 78955195 HDFS Write: 974271 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 29.67 sec   HDFS Read: 42028856 HDFS Write: 156957 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.85 sec   HDFS Read: 164595 HDFS Write: 3667 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 12 seconds 890 msec
OK
Time taken: 646.086 seconds, Fetched: 513 row(s)
开始执行20171021日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103093442_349fee54-624d-4bf0-8c9e-cd11db6c881f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166810, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166810/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166810
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 09:35:14,122 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:35:36,879 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 12.26 sec
2018-01-03 09:35:39,990 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 13.72 sec
2018-01-03 09:35:46,198 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 18.77 sec
2018-01-03 09:35:58,628 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 35.05 sec
2018-01-03 09:36:01,715 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 47.37 sec
2018-01-03 09:36:04,805 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 48.74 sec
2018-01-03 09:36:14,068 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 97.29 sec
2018-01-03 09:36:17,154 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 107.93 sec
2018-01-03 09:36:22,296 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 113.26 sec
2018-01-03 09:36:25,383 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 114.6 sec
2018-01-03 09:36:26,412 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 116.16 sec
2018-01-03 09:36:29,493 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 116.85 sec
2018-01-03 09:36:35,663 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 120.77 sec
2018-01-03 09:36:38,745 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 122.16 sec
2018-01-03 09:36:40,800 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 126.03 sec
2018-01-03 09:36:47,992 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 130.14 sec
2018-01-03 09:36:53,131 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 143.4 sec
2018-01-03 09:36:55,183 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 145.32 sec
2018-01-03 09:36:58,261 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 147.42 sec
2018-01-03 09:37:04,423 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 150.97 sec
2018-01-03 09:37:05,450 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 154.81 sec
2018-01-03 09:37:08,528 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 158.42 sec
2018-01-03 09:37:10,585 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 170.52 sec
2018-01-03 09:37:11,612 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 170.93 sec
2018-01-03 09:37:14,690 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 171.39 sec
2018-01-03 09:37:20,851 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 177.14 sec
2018-01-03 09:37:23,929 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 184.43 sec
2018-01-03 09:37:27,009 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 194.7 sec
2018-01-03 09:37:28,034 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 195.56 sec
2018-01-03 09:37:30,090 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 198.26 sec
2018-01-03 09:37:33,167 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 202.03 sec
2018-01-03 09:37:34,195 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 203.75 sec
2018-01-03 09:37:43,430 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 213.84 sec
2018-01-03 09:37:46,512 Stage-1 map = 72%,  reduce = 8%, Cumulative CPU 215.2 sec
2018-01-03 09:37:52,672 Stage-1 map = 73%,  reduce = 8%, Cumulative CPU 217.18 sec
2018-01-03 09:37:53,699 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 217.95 sec
2018-01-03 09:38:12,177 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 222.36 sec
2018-01-03 09:38:18,335 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 229.31 sec
2018-01-03 09:38:21,412 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 231.13 sec
2018-01-03 09:38:29,617 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 240.98 sec
2018-01-03 09:38:31,669 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 243.68 sec
2018-01-03 09:38:32,695 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 245.29 sec
2018-01-03 09:38:33,723 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 249.53 sec
2018-01-03 09:38:34,749 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 256.02 sec
MapReduce Total cumulative CPU time: 4 minutes 16 seconds 20 msec
Ended Job = job_1513599404024_166810
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166824, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166824/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166824
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:39:37,192 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:39:43,698 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 7.18 sec
2018-01-03 09:40:02,669 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 18.96 sec
2018-01-03 09:40:06,972 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 23.31 sec
2018-01-03 09:40:08,001 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 29.3 sec
MapReduce Total cumulative CPU time: 29 seconds 300 msec
Ended Job = job_1513599404024_166824
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166837, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166837/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166837
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:40:31,388 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:40:59,429 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 7.13 sec
2018-01-03 09:41:30,273 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 9.07 sec
2018-01-03 09:41:40,543 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 17.36 sec
MapReduce Total cumulative CPU time: 17 seconds 360 msec
Ended Job = job_1513599404024_166837
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 256.02 sec   HDFS Read: 249983468 HDFS Write: 1488540 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 29.3 sec   HDFS Read: 47277008 HDFS Write: 65566 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 17.36 sec   HDFS Read: 73241 HDFS Write: 2957 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 2 seconds 680 msec
OK
Time taken: 419.55 seconds, Fetched: 402 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.386 seconds
Query ID = boss_20180103094148_fda31ef6-59d7-4546-97b0-2075d8a7f07e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166841, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166841/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166841
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 4
2018-01-03 09:42:36,891 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:42:58,333 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 13.89 sec
2018-01-03 09:43:01,465 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 37.94 sec
2018-01-03 09:43:04,569 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 42.42 sec
2018-01-03 09:43:08,140 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 57.06 sec
2018-01-03 09:43:10,629 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 60.96 sec
2018-01-03 09:43:15,192 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 64.17 sec
2018-01-03 09:43:18,314 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 68.97 sec
2018-01-03 09:43:21,720 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 73.69 sec
2018-01-03 09:43:24,832 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 80.36 sec
2018-01-03 09:43:27,940 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 85.65 sec
2018-01-03 09:43:32,825 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 90.61 sec
2018-01-03 09:43:33,882 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 97.02 sec
2018-01-03 09:43:37,588 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 104.02 sec
2018-01-03 09:43:42,248 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 108.75 sec
2018-01-03 09:43:43,277 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 111.45 sec
2018-01-03 09:43:55,394 Stage-1 map = 70%,  reduce = 6%, Cumulative CPU 125.75 sec
2018-01-03 09:43:56,424 Stage-1 map = 71%,  reduce = 6%, Cumulative CPU 127.47 sec
2018-01-03 09:43:59,544 Stage-1 map = 72%,  reduce = 6%, Cumulative CPU 130.01 sec
2018-01-03 09:44:02,642 Stage-1 map = 73%,  reduce = 6%, Cumulative CPU 137.06 sec
2018-01-03 09:44:04,849 Stage-1 map = 73%,  reduce = 11%, Cumulative CPU 137.75 sec
2018-01-03 09:44:06,105 Stage-1 map = 74%,  reduce = 11%, Cumulative CPU 140.33 sec
2018-01-03 09:44:07,137 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 143.35 sec
2018-01-03 09:44:09,216 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 152.53 sec
2018-01-03 09:44:12,662 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 157.52 sec
2018-01-03 09:44:15,745 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 160.93 sec
2018-01-03 09:44:18,832 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 176.95 sec
2018-01-03 09:44:21,469 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 180.83 sec
2018-01-03 09:44:30,716 Stage-1 map = 85%,  reduce = 17%, Cumulative CPU 188.57 sec
2018-01-03 09:44:33,800 Stage-1 map = 86%,  reduce = 17%, Cumulative CPU 191.86 sec
2018-01-03 09:44:35,853 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 195.49 sec
2018-01-03 09:44:39,971 Stage-1 map = 100%,  reduce = 28%, Cumulative CPU 197.47 sec
2018-01-03 09:44:40,998 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 211.05 sec
2018-01-03 09:44:42,025 Stage-1 map = 100%,  reduce = 75%, Cumulative CPU 217.08 sec
2018-01-03 09:44:43,052 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 223.62 sec
2018-01-03 09:44:45,110 Stage-1 map = 100%,  reduce = 87%, Cumulative CPU 228.1 sec
2018-01-03 09:44:47,163 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 233.21 sec
2018-01-03 09:45:01,528 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 243.11 sec
2018-01-03 09:45:02,554 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 246.84 sec
MapReduce Total cumulative CPU time: 4 minutes 6 seconds 840 msec
Ended Job = job_1513599404024_166841
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166849, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166849/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166849
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:45:11,354 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:45:17,549 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.23 sec
2018-01-03 09:45:22,703 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.85 sec
2018-01-03 09:45:24,762 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.54 sec
MapReduce Total cumulative CPU time: 16 seconds 540 msec
Ended Job = job_1513599404024_166849
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166852, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166852/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166852
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:45:32,522 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:45:42,819 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.72 sec
2018-01-03 09:45:48,994 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.72 sec
MapReduce Total cumulative CPU time: 7 seconds 720 msec
Ended Job = job_1513599404024_166852
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 4   Cumulative CPU: 246.84 sec   HDFS Read: 424798658 HDFS Write: 822633 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.54 sec   HDFS Read: 46611625 HDFS Write: 20033 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.72 sec   HDFS Read: 27709 HDFS Write: 2342 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 31 seconds 100 msec
OK
Time taken: 241.763 seconds, Fetched: 335 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.348 seconds
Query ID = boss_20180103094556_9956cd51-0f26-4684-a16a-8673f6ed031e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166857, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166857/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166857
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 09:46:06,730 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:46:18,115 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 9.46 sec
2018-01-03 09:46:21,219 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 10.67 sec
2018-01-03 09:46:23,286 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 13.04 sec
2018-01-03 09:46:26,384 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 14.14 sec
2018-01-03 09:46:30,629 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 14.86 sec
2018-01-03 09:46:32,691 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 15.56 sec
2018-01-03 09:46:35,783 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 16.05 sec
2018-01-03 09:46:38,877 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 16.67 sec
2018-01-03 09:46:41,961 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 17.51 sec
2018-01-03 09:46:45,048 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 18.3 sec
2018-01-03 09:46:48,138 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 19.09 sec
2018-01-03 09:46:51,223 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 19.8 sec
2018-01-03 09:46:54,307 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 20.27 sec
2018-01-03 09:46:57,393 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 20.65 sec
2018-01-03 09:47:00,476 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 21.55 sec
2018-01-03 09:47:03,563 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 22.98 sec
2018-01-03 09:47:06,653 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 23.45 sec
2018-01-03 09:47:09,742 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 24.66 sec
2018-01-03 09:47:11,798 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 26.11 sec
2018-01-03 09:47:32,353 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 31.79 sec
MapReduce Total cumulative CPU time: 31 seconds 790 msec
Ended Job = job_1513599404024_166857
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166866, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166866/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166866
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:47:54,161 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:48:00,340 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.1 sec
2018-01-03 09:48:08,563 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.8 sec
2018-01-03 09:48:14,729 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.79 sec
MapReduce Total cumulative CPU time: 18 seconds 790 msec
Ended Job = job_1513599404024_166866
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166868, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166868/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166868
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:48:35,742 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:48:43,987 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.11 sec
2018-01-03 09:48:56,340 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.27 sec
MapReduce Total cumulative CPU time: 8 seconds 270 msec
Ended Job = job_1513599404024_166868
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 31.79 sec   HDFS Read: 86386521 HDFS Write: 458521 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.79 sec   HDFS Read: 46246671 HDFS Write: 174436 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.27 sec   HDFS Read: 182073 HDFS Write: 6737 SUCCESS
Total MapReduce CPU Time Spent: 58 seconds 850 msec
OK
Time taken: 180.658 seconds, Fetched: 803 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.479 seconds
Query ID = boss_20180103094904_a55b2594-260b-4dff-8420-23df588841ba
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166872, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166872/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166872
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 09:49:15,509 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:49:25,971 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 12.04 sec
2018-01-03 09:49:29,076 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 14.81 sec
2018-01-03 09:49:32,170 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 16.94 sec
2018-01-03 09:49:35,264 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 18.19 sec
2018-01-03 09:49:38,381 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 19.41 sec
2018-01-03 09:49:41,587 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 20.43 sec
2018-01-03 09:49:44,687 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 21.91 sec
2018-01-03 09:49:47,790 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 23.52 sec
2018-01-03 09:49:50,985 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 24.86 sec
2018-01-03 09:49:54,074 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 25.78 sec
2018-01-03 09:49:57,166 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 27.22 sec
2018-01-03 09:50:00,251 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 28.15 sec
2018-01-03 09:50:03,346 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 29.94 sec
2018-01-03 09:50:06,435 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 30.95 sec
2018-01-03 09:50:09,519 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 34.27 sec
2018-01-03 09:50:11,576 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 35.66 sec
2018-01-03 09:50:20,831 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 41.51 sec
MapReduce Total cumulative CPU time: 41 seconds 510 msec
Ended Job = job_1513599404024_166872
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166880, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166880/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166880
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:50:40,063 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:50:47,324 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.16 sec
2018-01-03 09:50:52,481 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 14.84 sec
2018-01-03 09:50:57,632 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 24.18 sec
MapReduce Total cumulative CPU time: 24 seconds 180 msec
Ended Job = job_1513599404024_166880
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166883, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166883/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166883
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:51:05,600 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:51:12,828 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.19 sec
2018-01-03 09:51:23,135 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.87 sec
MapReduce Total cumulative CPU time: 8 seconds 870 msec
Ended Job = job_1513599404024_166883
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 41.51 sec   HDFS Read: 86386511 HDFS Write: 1207579 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 24.18 sec   HDFS Read: 46995729 HDFS Write: 170411 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.87 sec   HDFS Read: 178049 HDFS Write: 3519 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 14 seconds 560 msec
OK
Time taken: 140.064 seconds, Fetched: 557 row(s)
开始执行20171022日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.367 seconds
Query ID = boss_20180103095131_edbcba01-8cba-466d-9ba8-6d5a48df38a6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166887, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166887/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166887
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 09:51:42,449 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:51:53,858 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 12.03 sec
2018-01-03 09:51:56,965 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 15.62 sec
2018-01-03 09:52:00,062 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 17.78 sec
2018-01-03 09:52:03,154 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 20.32 sec
2018-01-03 09:52:05,220 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 23.1 sec
2018-01-03 09:52:08,314 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 25.41 sec
2018-01-03 09:52:09,344 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 46.77 sec
2018-01-03 09:52:11,406 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 49.1 sec
2018-01-03 09:52:12,438 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 52.6 sec
2018-01-03 09:52:14,503 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 55.91 sec
2018-01-03 09:52:17,590 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 63.39 sec
2018-01-03 09:52:18,620 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 66.05 sec
2018-01-03 09:52:20,683 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 68.54 sec
2018-01-03 09:52:21,719 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 71.84 sec
2018-01-03 09:52:23,781 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 74.66 sec
2018-01-03 09:52:24,811 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 89.54 sec
2018-01-03 09:52:26,872 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 92.5 sec
2018-01-03 09:52:27,905 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 95.19 sec
2018-01-03 09:52:29,961 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 97.78 sec
2018-01-03 09:52:30,995 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 114.04 sec
2018-01-03 09:52:33,054 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 116.68 sec
2018-01-03 09:52:34,084 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 120.49 sec
2018-01-03 09:52:35,112 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 121.79 sec
2018-01-03 09:52:36,141 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 123.98 sec
2018-01-03 09:52:39,227 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 126.26 sec
2018-01-03 09:52:40,261 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 127.49 sec
2018-01-03 09:52:41,292 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 132.83 sec
2018-01-03 09:52:42,324 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 139.35 sec
MapReduce Total cumulative CPU time: 2 minutes 19 seconds 350 msec
Ended Job = job_1513599404024_166887
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166893, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166893/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166893
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:52:58,204 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:53:04,691 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.02 sec
2018-01-03 09:53:08,823 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.69 sec
2018-01-03 09:53:18,218 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.98 sec
MapReduce Total cumulative CPU time: 20 seconds 980 msec
Ended Job = job_1513599404024_166893
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166898, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166898/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166898
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:53:36,514 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:53:46,841 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.84 sec
2018-01-03 09:53:53,025 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.08 sec
MapReduce Total cumulative CPU time: 8 seconds 80 msec
Ended Job = job_1513599404024_166898
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 139.35 sec   HDFS Read: 244545549 HDFS Write: 1446503 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.98 sec   HDFS Read: 45454939 HDFS Write: 72023 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.08 sec   HDFS Read: 79698 HDFS Write: 2978 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 48 seconds 410 msec
OK
Time taken: 143.883 seconds, Fetched: 400 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.387 seconds
Query ID = boss_20180103095401_1a7c5621-5ad8-4137-b85f-2e899fdfaf44
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166901, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166901/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166901
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 4
2018-01-03 09:54:15,322 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:54:25,693 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.48 sec
2018-01-03 09:54:28,797 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 25.55 sec
2018-01-03 09:54:29,830 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 28.71 sec
2018-01-03 09:54:31,894 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 38.3 sec
2018-01-03 09:54:32,927 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 41.12 sec
2018-01-03 09:54:34,993 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 54.7 sec
2018-01-03 09:54:36,025 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 57.64 sec
2018-01-03 09:54:38,090 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 62.87 sec
2018-01-03 09:54:39,121 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 65.99 sec
2018-01-03 09:54:41,182 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 72.34 sec
2018-01-03 09:54:42,213 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 75.26 sec
2018-01-03 09:54:43,243 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 75.26 sec
2018-01-03 09:54:44,275 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 80.58 sec
2018-01-03 09:54:45,308 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 83.26 sec
2018-01-03 09:54:46,338 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 85.59 sec
2018-01-03 09:54:47,375 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 89.78 sec
2018-01-03 09:54:49,435 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 98.78 sec
2018-01-03 09:54:50,465 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 100.81 sec
2018-01-03 09:54:52,531 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 110.02 sec
2018-01-03 09:54:53,560 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 112.53 sec
2018-01-03 09:54:55,622 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 117.77 sec
2018-01-03 09:54:56,656 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 120.38 sec
2018-01-03 09:54:59,750 Stage-1 map = 63%,  reduce = 3%, Cumulative CPU 129.21 sec
2018-01-03 09:55:01,810 Stage-1 map = 64%,  reduce = 3%, Cumulative CPU 131.55 sec
2018-01-03 09:55:02,840 Stage-1 map = 66%,  reduce = 3%, Cumulative CPU 134.09 sec
2018-01-03 09:55:04,898 Stage-1 map = 67%,  reduce = 3%, Cumulative CPU 154.44 sec
2018-01-03 09:55:05,932 Stage-1 map = 68%,  reduce = 6%, Cumulative CPU 157.82 sec
2018-01-03 09:55:06,961 Stage-1 map = 81%,  reduce = 6%, Cumulative CPU 159.45 sec
2018-01-03 09:55:07,993 Stage-1 map = 82%,  reduce = 6%, Cumulative CPU 162.42 sec
2018-01-03 09:55:09,025 Stage-1 map = 82%,  reduce = 11%, Cumulative CPU 162.84 sec
2018-01-03 09:55:11,080 Stage-1 map = 85%,  reduce = 11%, Cumulative CPU 165.56 sec
2018-01-03 09:55:14,170 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 167.79 sec
2018-01-03 09:55:15,202 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 187.47 sec
2018-01-03 09:55:18,292 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 191.13 sec
2018-01-03 09:55:20,350 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 195.45 sec
2018-01-03 09:55:21,378 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 196.62 sec
2018-01-03 09:55:22,406 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 199.13 sec
2018-01-03 09:55:23,435 Stage-1 map = 100%,  reduce = 72%, Cumulative CPU 208.15 sec
2018-01-03 09:55:24,466 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 211.72 sec
2018-01-03 09:55:26,520 Stage-1 map = 100%,  reduce = 90%, Cumulative CPU 215.88 sec
2018-01-03 09:55:27,548 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 218.25 sec
2018-01-03 09:55:30,631 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 226.91 sec
MapReduce Total cumulative CPU time: 3 minutes 46 seconds 910 msec
Ended Job = job_1513599404024_166901
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166909, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166909/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166909
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 09:55:45,059 Stage-2 map = 0%,  reduce = 0%
2018-01-03 09:55:52,296 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.31 sec
2018-01-03 09:55:54,361 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.95 sec
2018-01-03 09:56:02,608 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.09 sec
MapReduce Total cumulative CPU time: 16 seconds 90 msec
Ended Job = job_1513599404024_166909
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166911, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166911/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166911
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 09:56:08,637 Stage-3 map = 0%,  reduce = 0%
2018-01-03 09:56:15,860 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.39 sec
2018-01-03 09:56:28,223 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.59 sec
MapReduce Total cumulative CPU time: 8 seconds 590 msec
Ended Job = job_1513599404024_166911
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 4   Cumulative CPU: 226.91 sec   HDFS Read: 413714292 HDFS Write: 365715 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.09 sec   HDFS Read: 44374675 HDFS Write: 22657 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.59 sec   HDFS Read: 30333 HDFS Write: 2538 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 11 seconds 590 msec
OK
Time taken: 148.476 seconds, Fetched: 347 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.372 seconds
Query ID = boss_20180103095637_9a62a167-abf9-4b92-9373-7d81dc67f35e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166917, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166917/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166917
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 09:57:07,997 Stage-1 map = 0%,  reduce = 0%
2018-01-03 09:57:26,683 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 10.2 sec
2018-01-03 09:57:28,753 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 12.44 sec
2018-01-03 09:57:31,853 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 13.02 sec
2018-01-03 09:57:38,043 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 14.97 sec
2018-01-03 09:57:41,135 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 15.61 sec
2018-01-03 09:57:44,224 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 16.18 sec
2018-01-03 09:57:47,320 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 17.5 sec
2018-01-03 09:57:50,409 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 18.1 sec
2018-01-03 09:57:53,499 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 19.27 sec
2018-01-03 09:57:56,592 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 19.69 sec
2018-01-03 09:57:59,680 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 20.0 sec
2018-01-03 09:58:05,854 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 20.6 sec
2018-01-03 09:58:08,939 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 20.97 sec
2018-01-03 09:58:12,029 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 21.48 sec
2018-01-03 09:58:15,116 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 22.28 sec
2018-01-03 09:58:18,200 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 22.68 sec
2018-01-03 09:58:21,287 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 23.01 sec
2018-01-03 09:58:24,370 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 23.48 sec
2018-01-03 09:58:27,455 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 23.73 sec
2018-01-03 09:58:30,543 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 24.24 sec
2018-01-03 09:58:33,623 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 24.67 sec
2018-01-03 09:58:36,704 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 25.14 sec
2018-01-03 09:58:39,792 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 25.37 sec
2018-01-03 09:58:42,930 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 25.89 sec
2018-01-03 09:58:45,000 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 26.4 sec
2018-01-03 09:58:48,085 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 26.64 sec
2018-01-03 09:58:51,165 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 26.97 sec
2018-01-03 09:58:54,245 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 27.35 sec
2018-01-03 09:58:57,331 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 36.35 sec
2018-01-03 09:59:00,415 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 37.08 sec
2018-01-03 09:59:03,498 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 37.38 sec
2018-01-03 09:59:06,587 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 37.7 sec
2018-01-03 09:59:12,747 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 38.26 sec
2018-01-03 09:59:15,993 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 38.4 sec
2018-01-03 09:59:18,999 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 38.4 sec
2018-01-03 09:59:23,141 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 39.39 sec
2018-01-03 09:59:27,252 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 40.37 sec
2018-01-03 09:59:33,413 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 41.15 sec
2018-01-03 09:59:36,494 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 43.0 sec
2018-01-03 09:59:39,572 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 43.48 sec
2018-01-03 09:59:41,624 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 43.71 sec
2018-01-03 09:59:43,679 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 44.8 sec
2018-01-03 10:00:13,797 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 55.6 sec
MapReduce Total cumulative CPU time: 55 seconds 600 msec
Ended Job = job_1513599404024_166917
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166926, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166926/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166926
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 10:00:29,269 Stage-2 map = 0%,  reduce = 0%
2018-01-03 10:00:45,822 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 9.15 sec
2018-01-03 10:00:56,195 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 18.82 sec
2018-01-03 10:01:04,418 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 22.0 sec
2018-01-03 10:01:07,502 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 26.68 sec
MapReduce Total cumulative CPU time: 26 seconds 680 msec
Ended Job = job_1513599404024_166926
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166932, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166932/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166932
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 10:01:21,794 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:01:33,909 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.33 sec
2018-01-03 10:01:44,204 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.34 sec
MapReduce Total cumulative CPU time: 8 seconds 340 msec
Ended Job = job_1513599404024_166932
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 58.25 sec   HDFS Read: 94645784 HDFS Write: 465757 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 29.17 sec   HDFS Read: 44473875 HDFS Write: 180593 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.34 sec   HDFS Read: 188230 HDFS Write: 6626 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 35 seconds 760 msec
OK
Time taken: 309.247 seconds, Fetched: 789 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103100152_3adfe812-12f1-4a39-948c-e8a69ff1fac6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166936, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166936/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166936
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 10:02:10,920 Stage-1 map = 0%,  reduce = 0%
2018-01-03 10:02:22,286 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 8.34 sec
2018-01-03 10:02:25,384 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.4 sec
2018-01-03 10:02:28,475 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 11.58 sec
2018-01-03 10:02:31,564 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.64 sec
2018-01-03 10:02:34,655 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 13.57 sec
2018-01-03 10:02:36,713 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 14.22 sec
2018-01-03 10:02:39,795 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 14.91 sec
2018-01-03 10:02:42,886 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 15.56 sec
2018-01-03 10:02:45,969 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 16.23 sec
2018-01-03 10:02:49,054 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 16.84 sec
2018-01-03 10:02:52,141 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 17.59 sec
2018-01-03 10:02:55,226 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 18.35 sec
2018-01-03 10:02:58,311 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 19.02 sec
2018-01-03 10:03:01,396 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 19.66 sec
2018-01-03 10:03:04,476 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 20.04 sec
2018-01-03 10:03:07,557 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 20.16 sec
2018-01-03 10:03:10,641 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 20.84 sec
2018-01-03 10:03:13,721 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 21.47 sec
2018-01-03 10:03:16,806 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 23.0 sec
2018-01-03 10:03:19,889 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 24.79 sec
2018-01-03 10:03:22,973 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 25.14 sec
2018-01-03 10:03:26,068 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 27.67 sec
2018-01-03 10:03:28,124 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 28.92 sec
2018-01-03 10:03:30,178 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 30.0 sec
2018-01-03 10:03:45,823 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.85 sec
MapReduce Total cumulative CPU time: 35 seconds 850 msec
Ended Job = job_1513599404024_166936
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166953, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166953/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166953
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 10:03:59,176 Stage-2 map = 0%,  reduce = 0%
2018-01-03 10:04:13,660 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 8.6 sec
2018-01-03 10:04:24,002 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 9.29 sec
2018-01-03 10:04:27,087 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 14.46 sec
2018-01-03 10:04:29,149 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.85 sec
MapReduce Total cumulative CPU time: 20 seconds 850 msec
Ended Job = job_1513599404024_166953
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166958, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166958/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166958
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 10:04:44,119 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:04:49,283 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-03 10:04:56,491 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.03 sec
MapReduce Total cumulative CPU time: 7 seconds 30 msec
Ended Job = job_1513599404024_166958
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.85 sec   HDFS Read: 94645774 HDFS Write: 1293675 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.85 sec   HDFS Read: 45301793 HDFS Write: 168050 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.03 sec   HDFS Read: 175688 HDFS Write: 3309 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 3 seconds 730 msec
OK
Time taken: 184.61 seconds, Fetched: 505 row(s)
开始执行20171023日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.381 seconds
Query ID = boss_20180103100504_7ae80b31-bf16-4824-8527-1e3be0bea756
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166962, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166962/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166962
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 10:05:22,000 Stage-1 map = 0%,  reduce = 0%
2018-01-03 10:05:40,859 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 15.29 sec
2018-01-03 10:05:43,963 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 28.05 sec
2018-01-03 10:05:47,065 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 28.05 sec
2018-01-03 10:05:51,207 Stage-1 map = 54%,  reduce = 8%, Cumulative CPU 46.04 sec
2018-01-03 10:05:54,314 Stage-1 map = 56%,  reduce = 8%, Cumulative CPU 50.1 sec
2018-01-03 10:05:57,458 Stage-1 map = 58%,  reduce = 8%, Cumulative CPU 56.49 sec
2018-01-03 10:05:58,490 Stage-1 map = 58%,  reduce = 17%, Cumulative CPU 57.29 sec
2018-01-03 10:06:00,636 Stage-1 map = 59%,  reduce = 17%, Cumulative CPU 61.92 sec
2018-01-03 10:06:03,751 Stage-1 map = 60%,  reduce = 17%, Cumulative CPU 65.3 sec
2018-01-03 10:06:07,873 Stage-1 map = 61%,  reduce = 17%, Cumulative CPU 71.53 sec
2018-01-03 10:06:10,962 Stage-1 map = 62%,  reduce = 17%, Cumulative CPU 79.83 sec
2018-01-03 10:06:14,054 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 84.16 sec
2018-01-03 10:06:17,141 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 86.89 sec
2018-01-03 10:06:20,229 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 89.73 sec
2018-01-03 10:06:26,404 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 94.08 sec
2018-01-03 10:06:29,488 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 98.04 sec
2018-01-03 10:06:32,573 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 102.01 sec
2018-01-03 10:06:33,600 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 62.67 sec
2018-01-03 10:06:35,660 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 105.9 sec
2018-01-03 10:06:36,688 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 65.37 sec
2018-01-03 10:06:39,771 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 67.78 sec
2018-01-03 10:06:42,866 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 70.64 sec
2018-01-03 10:06:45,961 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 73.07 sec
2018-01-03 10:06:48,027 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 75.29 sec
2018-01-03 10:06:49,057 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 75.82 sec
2018-01-03 10:06:50,088 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 81.82 sec
2018-01-03 10:06:54,347 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 89.96 sec
MapReduce Total cumulative CPU time: 1 minutes 29 seconds 960 msec
Ended Job = job_1513599404024_166962
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166981, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166981/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166981
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 10:07:07,381 Stage-2 map = 0%,  reduce = 0%
2018-01-03 10:07:20,246 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 9.5 sec
2018-01-03 10:07:30,772 Stage-2 map = 83%,  reduce = 0%, Cumulative CPU 22.24 sec
2018-01-03 10:07:32,033 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 22.84 sec
2018-01-03 10:07:59,033 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 28.05 sec
2018-01-03 10:08:13,859 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 36.73 sec
MapReduce Total cumulative CPU time: 36 seconds 730 msec
Ended Job = job_1513599404024_166981
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166990, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166990/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166990
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 10:09:13,045 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:09:29,723 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.21 sec
2018-01-03 10:09:53,293 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.93 sec
MapReduce Total cumulative CPU time: 8 seconds 930 msec
Ended Job = job_1513599404024_166990
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 89.96 sec   HDFS Read: 193927077 HDFS Write: 1208461 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 38.72 sec   HDFS Read: 43018684 HDFS Write: 59189 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.93 sec   HDFS Read: 66864 HDFS Write: 2727 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 17 seconds 610 msec
OK
Time taken: 294.507 seconds, Fetched: 389 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.405 seconds
Query ID = boss_20180103101006_a7e53c24-c03f-4ae6-bda4-293afcb77d31
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_166996, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_166996/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_166996
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 10:10:40,652 Stage-1 map = 0%,  reduce = 0%
2018-01-03 10:11:41,612 Stage-1 map = 0%,  reduce = 0%, Cumulative CPU 24.93 sec
2018-01-03 10:11:48,834 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 63.19 sec
2018-01-03 10:11:53,978 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 77.95 sec
2018-01-03 10:11:55,006 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 78.93 sec
2018-01-03 10:11:59,216 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 86.67 sec
2018-01-03 10:12:08,094 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 100.54 sec
2018-01-03 10:12:09,121 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 102.83 sec
2018-01-03 10:12:12,366 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 108.3 sec
2018-01-03 10:12:14,426 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 109.39 sec
2018-01-03 10:12:15,472 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 110.64 sec
2018-01-03 10:12:30,922 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 124.61 sec
2018-01-03 10:12:46,722 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 131.22 sec
2018-01-03 10:12:50,831 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 135.08 sec
2018-01-03 10:12:57,393 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 140.83 sec
2018-01-03 10:12:58,419 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 142.13 sec
2018-01-03 10:13:06,103 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 147.02 sec
2018-01-03 10:13:11,245 Stage-1 map = 48%,  reduce = 4%, Cumulative CPU 155.11 sec
2018-01-03 10:13:12,273 Stage-1 map = 49%,  reduce = 4%, Cumulative CPU 157.28 sec
2018-01-03 10:13:15,355 Stage-1 map = 50%,  reduce = 4%, Cumulative CPU 159.9 sec
2018-01-03 10:13:21,522 Stage-1 map = 52%,  reduce = 4%, Cumulative CPU 163.93 sec
2018-01-03 10:13:24,603 Stage-1 map = 53%,  reduce = 4%, Cumulative CPU 165.41 sec
2018-01-03 10:13:27,684 Stage-1 map = 53%,  reduce = 7%, Cumulative CPU 169.85 sec
2018-01-03 10:13:33,854 Stage-1 map = 53%,  reduce = 11%, Cumulative CPU 175.1 sec
2018-01-03 10:13:40,047 Stage-1 map = 54%,  reduce = 11%, Cumulative CPU 180.22 sec
2018-01-03 10:13:41,074 Stage-1 map = 55%,  reduce = 11%, Cumulative CPU 181.66 sec
2018-01-03 10:13:49,485 Stage-1 map = 56%,  reduce = 11%, Cumulative CPU 186.98 sec
2018-01-03 10:13:56,670 Stage-1 map = 57%,  reduce = 11%, Cumulative CPU 195.14 sec
2018-01-03 10:13:59,752 Stage-1 map = 58%,  reduce = 11%, Cumulative CPU 198.02 sec
2018-01-03 10:14:04,883 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 174.59 sec
2018-01-03 10:14:07,960 Stage-1 map = 60%,  reduce = 11%, Cumulative CPU 177.75 sec
2018-01-03 10:14:11,040 Stage-1 map = 63%,  reduce = 11%, Cumulative CPU 182.09 sec
2018-01-03 10:14:14,117 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 185.35 sec
2018-01-03 10:14:22,323 Stage-1 map = 66%,  reduce = 11%, Cumulative CPU 192.05 sec
2018-01-03 10:14:25,399 Stage-1 map = 68%,  reduce = 11%, Cumulative CPU 195.17 sec
2018-01-03 10:14:28,475 Stage-1 map = 69%,  reduce = 11%, Cumulative CPU 262.8 sec
2018-01-03 10:14:30,529 Stage-1 map = 70%,  reduce = 11%, Cumulative CPU 270.08 sec
2018-01-03 10:14:31,555 Stage-1 map = 71%,  reduce = 11%, Cumulative CPU 270.72 sec
2018-01-03 10:14:34,631 Stage-1 map = 74%,  reduce = 11%, Cumulative CPU 286.08 sec
2018-01-03 10:14:36,682 Stage-1 map = 86%,  reduce = 11%, Cumulative CPU 288.66 sec
2018-01-03 10:14:37,708 Stage-1 map = 87%,  reduce = 11%, Cumulative CPU 289.44 sec
2018-01-03 10:14:39,760 Stage-1 map = 87%,  reduce = 19%, Cumulative CPU 289.51 sec
2018-01-03 10:14:40,789 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 291.2 sec
2018-01-03 10:14:42,841 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 294.01 sec
2018-01-03 10:14:43,867 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 298.57 sec
2018-01-03 10:14:44,894 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 303.31 sec
2018-01-03 10:14:45,929 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 308.68 sec
MapReduce Total cumulative CPU time: 5 minutes 8 seconds 680 msec
Ended Job = job_1513599404024_166996
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167008, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167008/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167008
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 10:15:00,083 Stage-2 map = 0%,  reduce = 0%
2018-01-03 10:15:05,244 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.15 sec
2018-01-03 10:15:07,301 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.01 sec
2018-01-03 10:15:11,411 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.49 sec
MapReduce Total cumulative CPU time: 16 seconds 490 msec
Ended Job = job_1513599404024_167008
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167011, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167011/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167011
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 10:15:23,297 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:15:32,559 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.84 sec
2018-01-03 10:15:46,944 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.54 sec
MapReduce Total cumulative CPU time: 6 seconds 540 msec
Ended Job = job_1513599404024_167011
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 308.68 sec   HDFS Read: 317513171 HDFS Write: 280703 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.49 sec   HDFS Read: 42091188 HDFS Write: 20044 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.54 sec   HDFS Read: 27720 HDFS Write: 2206 SUCCESS
Total MapReduce CPU Time Spent: 5 minutes 31 seconds 710 msec
OK
Time taken: 341.977 seconds, Fetched: 328 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103101554_9998825d-0a99-459f-be5e-e7d0dffcd909
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167021, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167021/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167021
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 10:16:06,052 Stage-1 map = 0%,  reduce = 0%
2018-01-03 10:16:38,127 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 10.48 sec
2018-01-03 10:16:41,221 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.1 sec
2018-01-03 10:16:44,310 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 15.32 sec
2018-01-03 10:16:47,403 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 16.5 sec
2018-01-03 10:16:50,490 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 17.26 sec
2018-01-03 10:16:53,577 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 18.08 sec
2018-01-03 10:16:56,669 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 18.64 sec
2018-01-03 10:16:59,759 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 19.8 sec
2018-01-03 10:17:02,845 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 20.31 sec
2018-01-03 10:17:05,933 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 20.77 sec
2018-01-03 10:17:09,017 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 21.13 sec
2018-01-03 10:17:12,102 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 21.71 sec
2018-01-03 10:17:15,187 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 22.39 sec
2018-01-03 10:17:18,269 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 23.07 sec
2018-01-03 10:17:20,328 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 23.9 sec
2018-01-03 10:17:23,415 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 24.28 sec
2018-01-03 10:17:26,498 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 24.89 sec
2018-01-03 10:17:29,578 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 25.36 sec
2018-01-03 10:17:32,659 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 25.79 sec
2018-01-03 10:17:35,740 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 26.39 sec
2018-01-03 10:17:38,821 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 27.19 sec
2018-01-03 10:17:41,905 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 27.58 sec
2018-01-03 10:17:44,986 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 28.04 sec
2018-01-03 10:17:48,065 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 28.6 sec
2018-01-03 10:17:51,148 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 29.11 sec
2018-01-03 10:17:54,228 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 29.96 sec
2018-01-03 10:17:57,308 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 31.31 sec
2018-01-03 10:17:59,366 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.75 sec
2018-01-03 10:18:12,720 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 37.97 sec
MapReduce Total cumulative CPU time: 37 seconds 970 msec
Ended Job = job_1513599404024_167021
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167037, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167037/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167037
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 10:18:34,500 Stage-2 map = 0%,  reduce = 0%
2018-01-03 10:18:41,724 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.77 sec
2018-01-03 10:18:47,906 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.4 sec
2018-01-03 10:18:54,082 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.34 sec
MapReduce Total cumulative CPU time: 16 seconds 340 msec
Ended Job = job_1513599404024_167037
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167039, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167039/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167039
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 10:19:00,745 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:19:10,014 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.08 sec
2018-01-03 10:19:26,451 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.54 sec
MapReduce Total cumulative CPU time: 5 seconds 540 msec
Ended Job = job_1513599404024_167039
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 37.97 sec   HDFS Read: 76081767 HDFS Write: 481627 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.34 sec   HDFS Read: 42291532 HDFS Write: 155574 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.54 sec   HDFS Read: 163211 HDFS Write: 6268 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 850 msec
OK
Time taken: 212.733 seconds, Fetched: 757 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103101934_1d7f8b10-7e62-43ca-bbdf-b9ef4f33806d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167050, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167050/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167050
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 10:19:44,204 Stage-1 map = 0%,  reduce = 0%
2018-01-03 10:19:55,639 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 10.0 sec
2018-01-03 10:19:58,738 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 13.69 sec
2018-01-03 10:20:01,835 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 15.37 sec
2018-01-03 10:20:04,930 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 17.08 sec
2018-01-03 10:20:08,018 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 18.48 sec
2018-01-03 10:20:11,105 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 19.77 sec
2018-01-03 10:20:14,194 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 21.26 sec
2018-01-03 10:20:17,278 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 22.46 sec
2018-01-03 10:20:20,363 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 24.02 sec
2018-01-03 10:20:23,452 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 24.92 sec
2018-01-03 10:20:26,537 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 26.11 sec
2018-01-03 10:20:29,622 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 29.23 sec
2018-01-03 10:20:36,824 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 34.57 sec
MapReduce Total cumulative CPU time: 34 seconds 570 msec
Ended Job = job_1513599404024_167050
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167064, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167064/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167064
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 10:20:43,687 Stage-2 map = 0%,  reduce = 0%
2018-01-03 10:20:51,946 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.42 sec
2018-01-03 10:20:52,979 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.59 sec
2018-01-03 10:20:58,137 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.72 sec
MapReduce Total cumulative CPU time: 18 seconds 720 msec
Ended Job = job_1513599404024_167064
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167067, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167067/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167067
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 10:21:03,774 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:21:08,947 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.37 sec
2018-01-03 10:21:16,166 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.1 sec
MapReduce Total cumulative CPU time: 6 seconds 100 msec
Ended Job = job_1513599404024_167067
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 34.57 sec   HDFS Read: 76081757 HDFS Write: 965117 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.72 sec   HDFS Read: 42775022 HDFS Write: 158193 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.1 sec   HDFS Read: 165831 HDFS Write: 3229 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 390 msec
OK
Time taken: 102.985 seconds, Fetched: 492 row(s)
开始执行20171024日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103102124_84d164dc-bdd7-4bbc-b23d-3c735f7c3595
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167071, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167071/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167071
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 10:21:39,592 Stage-1 map = 0%,  reduce = 0%
2018-01-03 10:21:49,949 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 13.45 sec
2018-01-03 10:21:53,051 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 17.35 sec
2018-01-03 10:21:55,114 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 27.27 sec
2018-01-03 10:21:56,146 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 31.15 sec
2018-01-03 10:21:59,240 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 34.44 sec
2018-01-03 10:22:02,336 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 38.1 sec
2018-01-03 10:22:05,433 Stage-1 map = 69%,  reduce = 8%, Cumulative CPU 42.12 sec
2018-01-03 10:22:06,464 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 42.71 sec
2018-01-03 10:22:08,526 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 49.14 sec
2018-01-03 10:22:11,618 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 52.25 sec
2018-01-03 10:22:14,707 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 55.88 sec
2018-01-03 10:22:17,794 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 63.78 sec
2018-01-03 10:22:20,883 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 72.46 sec
2018-01-03 10:22:23,970 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 77.18 sec
2018-01-03 10:22:25,000 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 79.12 sec
2018-01-03 10:22:27,066 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 83.54 sec
2018-01-03 10:22:28,094 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 87.56 sec
MapReduce Total cumulative CPU time: 1 minutes 27 seconds 560 msec
Ended Job = job_1513599404024_167071
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167086, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167086/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167086
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 10:22:55,982 Stage-2 map = 0%,  reduce = 0%
2018-01-03 10:23:04,257 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.66 sec
2018-01-03 10:23:05,290 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 15.33 sec
2018-01-03 10:23:29,102 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 18.71 sec
2018-01-03 10:23:44,052 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 34.2 sec
MapReduce Total cumulative CPU time: 34 seconds 200 msec
Ended Job = job_1513599404024_167086
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167094, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167094/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167094
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 10:24:29,970 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:24:54,146 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.78 sec
2018-01-03 10:25:50,173 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 6.19 sec
2018-01-03 10:26:09,092 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 15.77 sec
MapReduce Total cumulative CPU time: 15 seconds 770 msec
Ended Job = job_1513599404024_167094
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 87.56 sec   HDFS Read: 185130063 HDFS Write: 1337679 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 34.2 sec   HDFS Read: 42925576 HDFS Write: 63320 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 15.77 sec   HDFS Read: 70995 HDFS Write: 2870 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 17 seconds 530 msec
OK
Time taken: 286.636 seconds, Fetched: 409 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.392 seconds
Query ID = boss_20180103102617_0bacd090-eb33-45d1-a1e0-c397a6ef24aa
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167097, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167097/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167097
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 10:26:35,002 Stage-1 map = 0%,  reduce = 0%
2018-01-03 10:27:08,220 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 49.98 sec
2018-01-03 10:27:12,341 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 58.34 sec
2018-01-03 10:27:18,529 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 78.72 sec
2018-01-03 10:27:20,587 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 81.92 sec
2018-01-03 10:27:23,672 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 87.38 sec
2018-01-03 10:27:26,758 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 104.13 sec
2018-01-03 10:27:29,843 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 109.2 sec
2018-01-03 10:27:30,871 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 110.4 sec
2018-01-03 10:27:32,926 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 118.89 sec
2018-01-03 10:27:39,092 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 128.3 sec
2018-01-03 10:27:40,120 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 130.15 sec
2018-01-03 10:27:42,227 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 131.01 sec
2018-01-03 10:27:43,254 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 132.1 sec
2018-01-03 10:27:46,340 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 133.27 sec
2018-01-03 10:27:53,525 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 167.93 sec
2018-01-03 10:27:55,587 Stage-1 map = 47%,  reduce = 4%, Cumulative CPU 168.61 sec
2018-01-03 10:27:56,615 Stage-1 map = 48%,  reduce = 4%, Cumulative CPU 171.75 sec
2018-01-03 10:27:57,642 Stage-1 map = 48%,  reduce = 7%, Cumulative CPU 172.24 sec
2018-01-03 10:28:00,724 Stage-1 map = 49%,  reduce = 7%, Cumulative CPU 176.69 sec
2018-01-03 10:28:03,807 Stage-1 map = 50%,  reduce = 7%, Cumulative CPU 183.18 sec
2018-01-03 10:28:04,835 Stage-1 map = 50%,  reduce = 11%, Cumulative CPU 184.45 sec
2018-01-03 10:28:06,889 Stage-1 map = 52%,  reduce = 11%, Cumulative CPU 188.27 sec
2018-01-03 10:28:13,052 Stage-1 map = 55%,  reduce = 11%, Cumulative CPU 203.88 sec
2018-01-03 10:28:22,302 Stage-1 map = 56%,  reduce = 11%, Cumulative CPU 213.31 sec
2018-01-03 10:28:23,330 Stage-1 map = 57%,  reduce = 11%, Cumulative CPU 215.27 sec
2018-01-03 10:28:32,584 Stage-1 map = 58%,  reduce = 11%, Cumulative CPU 225.71 sec
2018-01-03 10:28:35,704 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 228.87 sec
2018-01-03 10:28:36,729 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 233.01 sec
2018-01-03 10:28:38,779 Stage-1 map = 62%,  reduce = 11%, Cumulative CPU 235.52 sec
2018-01-03 10:28:39,804 Stage-1 map = 63%,  reduce = 11%, Cumulative CPU 236.54 sec
2018-01-03 10:28:49,042 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 244.89 sec
2018-01-03 10:28:54,170 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 248.43 sec
2018-01-03 10:28:55,196 Stage-1 map = 66%,  reduce = 11%, Cumulative CPU 249.86 sec
2018-01-03 10:29:04,424 Stage-1 map = 67%,  reduce = 11%, Cumulative CPU 267.41 sec
2018-01-03 10:29:10,576 Stage-1 map = 68%,  reduce = 11%, Cumulative CPU 271.98 sec
2018-01-03 10:29:14,676 Stage-1 map = 70%,  reduce = 11%, Cumulative CPU 288.8 sec
2018-01-03 10:29:16,725 Stage-1 map = 71%,  reduce = 11%, Cumulative CPU 290.89 sec
2018-01-03 10:29:23,902 Stage-1 map = 72%,  reduce = 11%, Cumulative CPU 310.97 sec
2018-01-03 10:29:29,029 Stage-1 map = 84%,  reduce = 11%, Cumulative CPU 317.13 sec
2018-01-03 10:29:30,054 Stage-1 map = 84%,  reduce = 19%, Cumulative CPU 317.23 sec
2018-01-03 10:29:32,104 Stage-1 map = 84%,  reduce = 22%, Cumulative CPU 318.63 sec
2018-01-03 10:29:34,153 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 324.36 sec
2018-01-03 10:29:37,227 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 325.45 sec
2018-01-03 10:29:46,451 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 328.69 sec
2018-01-03 10:29:49,528 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 331.24 sec
2018-01-03 10:29:51,577 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 333.38 sec
2018-01-03 10:29:52,602 Stage-1 map = 100%,  reduce = 48%, Cumulative CPU 337.16 sec
2018-01-03 10:29:53,628 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 341.77 sec
2018-01-03 10:29:55,679 Stage-1 map = 100%,  reduce = 89%, Cumulative CPU 344.83 sec
2018-01-03 10:29:58,753 Stage-1 map = 100%,  reduce = 96%, Cumulative CPU 348.99 sec
2018-01-03 10:30:01,829 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 352.31 sec
MapReduce Total cumulative CPU time: 5 minutes 52 seconds 310 msec
Ended Job = job_1513599404024_167097
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167117, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167117/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167117
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 10:30:38,922 Stage-2 map = 0%,  reduce = 0%
2018-01-03 10:30:47,169 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.82 sec
2018-01-03 10:30:50,269 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.79 sec
2018-01-03 10:30:53,388 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.78 sec
MapReduce Total cumulative CPU time: 18 seconds 780 msec
Ended Job = job_1513599404024_167117
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167123, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167123/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167123
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 10:31:30,607 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:32:20,966 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 5.62 sec
2018-01-03 10:32:45,219 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 8.13 sec
2018-01-03 10:33:01,411 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 16.97 sec
MapReduce Total cumulative CPU time: 16 seconds 970 msec
Ended Job = job_1513599404024_167123
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 352.31 sec   HDFS Read: 316321580 HDFS Write: 282766 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.78 sec   HDFS Read: 41870913 HDFS Write: 21035 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 16.97 sec   HDFS Read: 28703 HDFS Write: 2234 SUCCESS
Total MapReduce CPU Time Spent: 6 minutes 28 seconds 60 msec
OK
Time taken: 405.583 seconds, Fetched: 318 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103103310_a41d520b-1264-40a4-801f-8c82843bcd0c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167136, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167136/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167136
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 10:33:35,072 Stage-1 map = 0%,  reduce = 0%
2018-01-03 10:34:09,162 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 9.58 sec
2018-01-03 10:34:15,345 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 12.21 sec
2018-01-03 10:34:22,548 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 15.26 sec
2018-01-03 10:34:25,638 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 15.8 sec
2018-01-03 10:34:31,812 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 17.95 sec
2018-01-03 10:34:43,124 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 29.01 sec
2018-01-03 10:34:46,205 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 30.24 sec
2018-01-03 10:34:49,296 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 31.26 sec
2018-01-03 10:35:09,836 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 33.53 sec
2018-01-03 10:35:19,078 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 35.05 sec
2018-01-03 10:35:28,314 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 36.02 sec
2018-01-03 10:35:34,466 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 36.38 sec
2018-01-03 10:35:46,800 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 37.69 sec
2018-01-03 10:35:57,052 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 38.13 sec
2018-01-03 10:36:09,351 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 38.95 sec
2018-01-03 10:36:12,427 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 39.11 sec
2018-01-03 10:36:19,601 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 39.76 sec
2018-01-03 10:36:28,825 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 40.52 sec
2018-01-03 10:36:38,050 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 42.82 sec
2018-01-03 10:36:45,224 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 42.82 sec
2018-01-03 10:36:55,472 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 43.03 sec
2018-01-03 10:37:01,622 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 43.38 sec
2018-01-03 10:37:07,769 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 45.63 sec
2018-01-03 10:37:18,017 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 46.6 sec
2018-01-03 10:37:21,093 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 47.17 sec
2018-01-03 10:37:31,342 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 48.9 sec
2018-01-03 10:37:34,415 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 49.19 sec
2018-01-03 10:37:40,563 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 49.82 sec
2018-01-03 10:37:43,648 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 50.06 sec
2018-01-03 10:37:47,745 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 51.73 sec
2018-01-03 10:37:53,895 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 52.25 sec
2018-01-03 10:38:03,117 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 54.16 sec
2018-01-03 10:38:09,274 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 54.7 sec
2018-01-03 10:38:13,378 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 55.51 sec
2018-01-03 10:38:19,523 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 57.27 sec
2018-01-03 10:38:23,623 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 57.55 sec
2018-01-03 10:38:29,768 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 58.71 sec
2018-01-03 10:38:38,995 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 59.24 sec
2018-01-03 10:38:42,067 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 59.36 sec
2018-01-03 10:38:45,143 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 59.71 sec
2018-01-03 10:38:51,286 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 60.21 sec
2018-01-03 10:38:54,358 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 61.14 sec
2018-01-03 10:38:58,457 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 61.57 sec
2018-01-03 10:39:01,530 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 62.22 sec
2018-01-03 10:39:09,729 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 65.37 sec
2018-01-03 10:39:12,802 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 65.72 sec
2018-01-03 10:39:15,874 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 65.86 sec
2018-01-03 10:39:28,167 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 67.33 sec
2018-01-03 10:39:38,405 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 67.82 sec
2018-01-03 10:39:49,672 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 69.06 sec
2018-01-03 10:39:52,748 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 69.25 sec
2018-01-03 10:40:06,067 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 70.62 sec
2018-01-03 10:40:28,600 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 73.22 sec
2018-01-03 10:40:34,743 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 74.05 sec
2018-01-03 10:40:43,975 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 75.48 sec
2018-01-03 10:40:53,189 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 76.11 sec
2018-01-03 10:40:59,335 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 76.42 sec
2018-01-03 10:41:15,722 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 77.09 sec
2018-01-03 10:41:21,867 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 77.51 sec
2018-01-03 10:41:24,940 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 77.6 sec
2018-01-03 10:41:31,086 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 78.16 sec
2018-01-03 10:41:34,160 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 78.63 sec
2018-01-03 10:41:35,185 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 79.55 sec
2018-01-03 10:42:10,028 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 82.75 sec
2018-01-03 10:42:19,249 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 90.9 sec
MapReduce Total cumulative CPU time: 1 minutes 30 seconds 900 msec
Ended Job = job_1513599404024_167136
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167175, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167175/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167175
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 10:43:17,753 Stage-2 map = 0%,  reduce = 0%
2018-01-03 10:44:18,638 Stage-2 map = 0%,  reduce = 0%, Cumulative CPU 6.81 sec
2018-01-03 10:44:19,668 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 12.35 sec
2018-01-03 10:44:35,929 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 24.82 sec
2018-01-03 10:44:59,352 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 30.04 sec
2018-01-03 10:45:08,990 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 34.75 sec
MapReduce Total cumulative CPU time: 34 seconds 750 msec
Ended Job = job_1513599404024_167175
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167181, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167181/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167181
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 10:45:46,972 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:46:47,737 Stage-3 map = 0%,  reduce = 0%
2018-01-03 10:47:01,060 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 7.2 sec
2018-01-03 10:47:32,838 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 12.69 sec
2018-01-03 10:47:42,061 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 18.02 sec
MapReduce Total cumulative CPU time: 18 seconds 20 msec
Ended Job = job_1513599404024_167181
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 90.9 sec   HDFS Read: 78378067 HDFS Write: 470801 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 40.0 sec   HDFS Read: 42058380 HDFS Write: 153112 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 18.02 sec   HDFS Read: 160749 HDFS Write: 6207 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 28 seconds 920 msec
OK
Time taken: 874.916 seconds, Fetched: 778 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103104751_dbe1a5a1-28c0-44f4-b7a8-a363380916ae
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167187, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167187/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167187
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 10:49:35,756 Stage-1 map = 0%,  reduce = 0%
2018-01-03 10:50:01,523 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 11.71 sec
2018-01-03 10:50:14,096 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 16.23 sec
2018-01-03 10:50:17,204 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 17.16 sec
2018-01-03 10:50:24,303 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 19.77 sec
2018-01-03 10:50:28,486 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 20.85 sec
2018-01-03 10:50:32,242 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 24.03 sec
2018-01-03 10:50:46,148 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 26.67 sec
2018-01-03 10:50:53,717 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 28.21 sec
2018-01-03 10:51:02,079 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 31.14 sec
2018-01-03 10:51:05,614 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 31.14 sec
2018-01-03 10:51:28,247 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 33.97 sec
2018-01-03 10:51:40,038 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 34.83 sec
2018-01-03 10:51:59,852 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 36.58 sec
2018-01-03 10:52:23,916 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 38.01 sec
2018-01-03 10:52:38,918 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 39.68 sec
2018-01-03 10:52:44,629 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 40.42 sec
2018-01-03 10:53:01,931 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 41.21 sec
2018-01-03 10:53:05,731 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 41.37 sec
2018-01-03 10:53:12,911 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 41.65 sec
2018-01-03 10:53:28,452 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 43.78 sec
2018-01-03 10:53:38,756 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 44.23 sec
2018-01-03 10:53:53,203 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 45.01 sec
2018-01-03 10:54:01,809 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 45.64 sec
2018-01-03 10:54:11,056 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 46.28 sec
2018-01-03 10:54:17,113 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 46.93 sec
2018-01-03 10:54:20,357 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 47.11 sec
2018-01-03 10:54:39,704 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 48.37 sec
2018-01-03 10:54:51,514 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 48.68 sec
2018-01-03 10:54:59,196 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 49.1 sec
2018-01-03 10:55:07,937 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 49.59 sec
2018-01-03 10:55:25,494 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 50.79 sec
2018-01-03 10:55:30,994 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 51.5 sec
2018-01-03 10:55:35,101 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 52.59 sec
2018-01-03 10:55:43,663 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 52.85 sec
2018-01-03 10:55:46,766 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 53.34 sec
2018-01-03 10:55:57,076 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 54.16 sec
2018-01-03 10:56:05,508 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 54.6 sec
2018-01-03 10:56:11,675 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 55.42 sec
2018-01-03 10:56:17,858 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 55.74 sec
2018-01-03 10:56:22,063 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 56.03 sec
2018-01-03 10:56:33,826 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 56.6 sec
2018-01-03 10:56:46,233 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 57.35 sec
2018-01-03 10:56:52,923 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 57.78 sec
2018-01-03 10:57:03,419 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 58.32 sec
2018-01-03 10:57:12,408 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 58.69 sec
2018-01-03 10:57:25,701 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 59.67 sec
2018-01-03 10:57:41,555 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 61.54 sec
2018-01-03 10:57:47,216 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 62.57 sec
2018-01-03 10:58:00,051 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 63.18 sec
2018-01-03 10:58:03,139 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 63.44 sec
2018-01-03 10:58:13,130 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 64.65 sec
2018-01-03 10:58:23,093 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 65.17 sec
2018-01-03 10:58:41,843 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 65.91 sec
2018-01-03 10:58:54,511 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 67.55 sec
2018-01-03 10:59:10,405 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 68.42 sec
2018-01-03 10:59:17,567 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 68.71 sec
2018-01-03 10:59:33,766 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 70.11 sec
2018-01-03 10:59:49,649 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 70.67 sec
2018-01-03 11:00:05,420 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 72.59 sec
2018-01-03 11:00:13,684 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 73.2 sec
2018-01-03 11:00:23,217 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 73.77 sec
2018-01-03 11:00:29,911 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 74.26 sec
2018-01-03 11:00:39,551 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 75.17 sec
2018-01-03 11:00:46,272 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 76.29 sec
2018-01-03 11:00:56,544 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 76.85 sec
2018-01-03 11:00:59,693 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 76.99 sec
2018-01-03 11:01:05,052 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 79.54 sec
2018-01-03 11:01:14,678 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 84.05 sec
MapReduce Total cumulative CPU time: 1 minutes 24 seconds 50 msec
Ended Job = job_1513599404024_167187
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167218, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167218/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167218
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:01:40,229 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:02:21,258 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 15.14 sec
2018-01-03 11:02:38,887 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 16.2 sec
2018-01-03 11:02:48,120 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 29.33 sec
2018-01-03 11:02:52,219 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 36.26 sec
MapReduce Total cumulative CPU time: 36 seconds 260 msec
Ended Job = job_1513599404024_167218
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167225, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167225/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167225
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:03:54,635 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:04:00,955 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-03 11:05:01,709 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-03 11:05:02,749 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 14.44 sec
2018-01-03 11:05:09,970 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 34.29 sec
MapReduce Total cumulative CPU time: 34 seconds 290 msec
Ended Job = job_1513599404024_167225
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 84.05 sec   HDFS Read: 78378057 HDFS Write: 932513 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 45.28 sec   HDFS Read: 42520092 HDFS Write: 158169 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 34.29 sec   HDFS Read: 165807 HDFS Write: 3140 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 43 seconds 620 msec
OK
Time taken: 1040.248 seconds, Fetched: 477 row(s)
开始执行20171025日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.531 seconds
Query ID = boss_20180103110519_90bff301-1b23-48ae-b71d-36784e12cf8a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167240, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167240/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167240
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 11:06:13,602 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:06:29,744 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 11.19 sec
2018-01-03 11:06:32,023 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 13.34 sec
2018-01-03 11:06:39,679 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 29.55 sec
2018-01-03 11:06:47,514 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 32.5 sec
2018-01-03 11:06:53,743 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 40.83 sec
2018-01-03 11:06:57,160 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 42.78 sec
2018-01-03 11:06:58,495 Stage-1 map = 56%,  reduce = 8%, Cumulative CPU 44.16 sec
2018-01-03 11:07:00,039 Stage-1 map = 57%,  reduce = 17%, Cumulative CPU 49.94 sec
2018-01-03 11:07:03,814 Stage-1 map = 58%,  reduce = 17%, Cumulative CPU 52.49 sec
2018-01-03 11:07:07,309 Stage-1 map = 59%,  reduce = 17%, Cumulative CPU 58.6 sec
2018-01-03 11:07:10,631 Stage-1 map = 60%,  reduce = 17%, Cumulative CPU 60.75 sec
2018-01-03 11:07:17,050 Stage-1 map = 61%,  reduce = 17%, Cumulative CPU 68.82 sec
2018-01-03 11:07:20,320 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 71.25 sec
2018-01-03 11:07:22,382 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 73.26 sec
2018-01-03 11:07:29,797 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 78.77 sec
2018-01-03 11:07:31,885 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 80.9 sec
2018-01-03 11:07:36,491 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 95.69 sec
2018-01-03 11:07:39,700 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 98.98 sec
2018-01-03 11:07:42,904 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 101.07 sec
2018-01-03 11:07:46,803 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 102.99 sec
2018-01-03 11:07:48,869 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 105.41 sec
2018-01-03 11:07:52,056 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 107.95 sec
2018-01-03 11:07:56,402 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 110.48 sec
2018-01-03 11:07:58,479 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 113.05 sec
2018-01-03 11:08:01,424 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 116.32 sec
2018-01-03 11:08:02,459 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 117.97 sec
2018-01-03 11:08:06,713 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 127.76 sec
2018-01-03 11:08:10,128 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 131.55 sec
2018-01-03 11:08:12,674 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 137.9 sec
MapReduce Total cumulative CPU time: 2 minutes 17 seconds 900 msec
Ended Job = job_1513599404024_167240
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167256, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167256/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167256
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:09:21,140 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:10:01,708 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 21.02 sec
2018-01-03 11:10:04,086 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 29.78 sec
2018-01-03 11:10:11,388 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 37.06 sec
MapReduce Total cumulative CPU time: 37 seconds 60 msec
Ended Job = job_1513599404024_167256
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167266, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167266/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167266
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:10:19,512 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:10:28,773 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.75 sec
2018-01-03 11:10:43,177 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 12.28 sec
MapReduce Total cumulative CPU time: 12 seconds 280 msec
Ended Job = job_1513599404024_167266
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 137.9 sec   HDFS Read: 185163791 HDFS Write: 1485878 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 37.06 sec   HDFS Read: 41113656 HDFS Write: 147485 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 12.28 sec   HDFS Read: 155160 HDFS Write: 3115 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 7 seconds 240 msec
OK
Time taken: 326.065 seconds, Fetched: 411 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103111051_50cbce34-7633-41e3-a248-61f207b9177b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167272, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167272/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167272
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 11:11:03,370 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:11:12,699 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 11.13 sec
2018-01-03 11:11:15,795 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 14.29 sec
2018-01-03 11:11:18,893 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 17.45 sec
2018-01-03 11:11:21,985 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 40.65 sec
2018-01-03 11:11:25,076 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 44.79 sec
2018-01-03 11:11:27,141 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 50.94 sec
2018-01-03 11:11:28,171 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 54.04 sec
2018-01-03 11:11:30,230 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 68.21 sec
2018-01-03 11:11:31,259 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 70.75 sec
2018-01-03 11:11:33,319 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 75.87 sec
2018-01-03 11:11:34,348 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 79.0 sec
2018-01-03 11:11:35,381 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 96.81 sec
2018-01-03 11:11:36,409 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 99.91 sec
2018-01-03 11:11:37,438 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 103.76 sec
2018-01-03 11:11:39,493 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 116.58 sec
2018-01-03 11:11:42,580 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 119.77 sec
2018-01-03 11:11:45,667 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 123.31 sec
2018-01-03 11:11:47,729 Stage-1 map = 100%,  reduce = 7%, Cumulative CPU 127.0 sec
2018-01-03 11:11:50,819 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 134.17 sec
2018-01-03 11:11:51,848 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 139.76 sec
2018-01-03 11:11:54,938 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 145.71 sec
MapReduce Total cumulative CPU time: 2 minutes 25 seconds 710 msec
Ended Job = job_1513599404024_167272
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167282, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167282/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167282
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:12:10,578 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:12:26,155 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 21.97 sec
2018-01-03 11:12:32,347 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 27.85 sec
MapReduce Total cumulative CPU time: 27 seconds 850 msec
Ended Job = job_1513599404024_167282
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167286, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167286/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167286
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:12:47,173 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:12:53,369 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.11 sec
2018-01-03 11:13:39,782 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 14.95 sec
2018-01-03 11:13:53,132 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 33.91 sec
MapReduce Total cumulative CPU time: 33 seconds 910 msec
Ended Job = job_1513599404024_167286
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 145.71 sec   HDFS Read: 327802780 HDFS Write: 294908 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 27.85 sec   HDFS Read: 39922948 HDFS Write: 19877 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 33.91 sec   HDFS Read: 27553 HDFS Write: 2253 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 27 seconds 470 msec
OK
Time taken: 182.215 seconds, Fetched: 314 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103111400_dbdc6e37-cc8f-422c-aa81-4110c26f0e20
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167294, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167294/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167294
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 11:14:41,210 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:14:51,873 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 6.28 sec
2018-01-03 11:14:55,201 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 8.34 sec
2018-01-03 11:14:58,005 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 8.98 sec
2018-01-03 11:15:01,210 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 9.55 sec
2018-01-03 11:15:07,500 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.89 sec
2018-01-03 11:15:10,602 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 10.96 sec
2018-01-03 11:15:13,701 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 11.16 sec
2018-01-03 11:15:16,821 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 11.78 sec
2018-01-03 11:15:19,913 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 12.88 sec
2018-01-03 11:15:23,013 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 13.43 sec
2018-01-03 11:15:26,109 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 13.78 sec
2018-01-03 11:15:29,219 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 14.28 sec
2018-01-03 11:15:32,419 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 14.82 sec
2018-01-03 11:15:34,483 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 15.26 sec
2018-01-03 11:15:41,434 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 15.88 sec
2018-01-03 11:15:44,526 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 16.24 sec
2018-01-03 11:15:47,929 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 16.58 sec
2018-01-03 11:15:51,089 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 17.3 sec
2018-01-03 11:15:55,061 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 17.3 sec
2018-01-03 11:15:58,361 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 18.72 sec
2018-01-03 11:16:08,551 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 19.37 sec
2018-01-03 11:16:20,200 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 39.77 sec
2018-01-03 11:16:38,343 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 42.09 sec
2018-01-03 11:16:40,823 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 42.25 sec
2018-01-03 11:16:53,489 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 42.5 sec
2018-01-03 11:17:05,376 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 43.37 sec
2018-01-03 11:17:17,370 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 43.62 sec
2018-01-03 11:17:24,877 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 43.79 sec
2018-01-03 11:17:39,642 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 44.08 sec
2018-01-03 11:17:42,840 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 44.2 sec
2018-01-03 11:18:18,326 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 44.44 sec
2018-01-03 11:18:21,415 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 45.3 sec
2018-01-03 11:18:28,090 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 45.7 sec
2018-01-03 11:18:31,176 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 45.78 sec
2018-01-03 11:18:50,647 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 46.65 sec
2018-01-03 11:19:00,772 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 46.91 sec
2018-01-03 11:19:07,348 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 47.09 sec
2018-01-03 11:19:17,171 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 47.24 sec
2018-01-03 11:19:28,335 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 47.57 sec
2018-01-03 11:19:50,052 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 48.34 sec
2018-01-03 11:19:53,132 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 48.46 sec
2018-01-03 11:19:59,359 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 48.7 sec
2018-01-03 11:20:03,863 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 48.92 sec
2018-01-03 11:20:06,220 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 49.6 sec
2018-01-03 11:20:09,381 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 49.9 sec
2018-01-03 11:20:20,478 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 51.71 sec
2018-01-03 11:20:31,901 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 55.71 sec
MapReduce Total cumulative CPU time: 55 seconds 710 msec
Ended Job = job_1513599404024_167294
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167318, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167318/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167318
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:20:47,769 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:20:54,970 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.32 sec
2018-01-03 11:21:05,244 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.78 sec
2018-01-03 11:21:07,299 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.69 sec
MapReduce Total cumulative CPU time: 16 seconds 690 msec
Ended Job = job_1513599404024_167318
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167321, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167321/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167321
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:21:28,205 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:21:41,660 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.68 sec
2018-01-03 11:21:56,076 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 10.78 sec
MapReduce Total cumulative CPU time: 10 seconds 780 msec
Ended Job = job_1513599404024_167321
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 55.71 sec   HDFS Read: 74257408 HDFS Write: 495689 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.69 sec   HDFS Read: 40123149 HDFS Write: 169163 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 10.78 sec   HDFS Read: 176800 HDFS Write: 6252 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 23 seconds 180 msec
OK
Time taken: 476.284 seconds, Fetched: 782 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103112212_0a59cf82-167f-4c3b-b06d-39b5671db21d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167327, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167327/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167327
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 11:22:24,961 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:22:36,356 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 9.72 sec
2018-01-03 11:22:40,518 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.27 sec
2018-01-03 11:22:44,703 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 14.86 sec
2018-01-03 11:22:47,891 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 17.13 sec
2018-01-03 11:22:51,114 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 17.86 sec
2018-01-03 11:22:54,218 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 18.15 sec
2018-01-03 11:23:00,395 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 19.07 sec
2018-01-03 11:23:03,481 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 20.02 sec
2018-01-03 11:23:06,572 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 21.27 sec
2018-01-03 11:23:09,659 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 21.51 sec
2018-01-03 11:23:12,746 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 21.96 sec
2018-01-03 11:23:14,809 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 22.51 sec
2018-01-03 11:23:17,898 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 22.87 sec
2018-01-03 11:23:20,986 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 23.71 sec
2018-01-03 11:23:24,072 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 24.09 sec
2018-01-03 11:23:27,158 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 24.59 sec
2018-01-03 11:23:30,241 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 25.15 sec
2018-01-03 11:23:33,326 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 35.74 sec
2018-01-03 11:23:36,413 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 36.35 sec
2018-01-03 11:23:39,498 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 37.27 sec
2018-01-03 11:23:42,589 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 37.77 sec
2018-01-03 11:23:45,674 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 39.18 sec
2018-01-03 11:23:48,753 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 39.69 sec
2018-01-03 11:23:51,838 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 40.17 sec
2018-01-03 11:23:54,920 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 41.04 sec
2018-01-03 11:23:57,999 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 41.64 sec
2018-01-03 11:24:01,084 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 42.27 sec
2018-01-03 11:24:04,163 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 44.94 sec
2018-01-03 11:24:06,216 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 46.68 sec
2018-01-03 11:24:12,513 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 51.37 sec
MapReduce Total cumulative CPU time: 51 seconds 370 msec
Ended Job = job_1513599404024_167327
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167332, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167332/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167332
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:24:32,855 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:24:39,530 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.56 sec
2018-01-03 11:24:41,587 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.68 sec
2018-01-03 11:24:47,772 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.64 sec
MapReduce Total cumulative CPU time: 17 seconds 640 msec
Ended Job = job_1513599404024_167332
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167334, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167334/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167334
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:24:59,780 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:25:05,064 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.51 sec
2018-01-03 11:25:16,462 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.1 sec
MapReduce Total cumulative CPU time: 8 seconds 100 msec
Ended Job = job_1513599404024_167334
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 51.37 sec   HDFS Read: 74257398 HDFS Write: 827266 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.64 sec   HDFS Read: 40454726 HDFS Write: 124707 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.1 sec   HDFS Read: 132345 HDFS Write: 3492 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 17 seconds 110 msec
OK
Time taken: 185.404 seconds, Fetched: 506 row(s)
开始执行20171026日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.372 seconds
Query ID = boss_20180103112524_4b1c4ef0-acd7-4383-b68b-2a0cbe68bfc5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167338, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167338/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167338
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 11:25:38,980 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:25:49,362 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 12.62 sec
2018-01-03 11:25:55,570 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 23.43 sec
2018-01-03 11:25:58,668 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 26.49 sec
2018-01-03 11:26:00,743 Stage-1 map = 54%,  reduce = 8%, Cumulative CPU 27.11 sec
2018-01-03 11:26:01,776 Stage-1 map = 56%,  reduce = 8%, Cumulative CPU 30.36 sec
2018-01-03 11:26:04,872 Stage-1 map = 59%,  reduce = 8%, Cumulative CPU 33.02 sec
2018-01-03 11:26:05,903 Stage-1 map = 59%,  reduce = 17%, Cumulative CPU 33.61 sec
2018-01-03 11:26:07,966 Stage-1 map = 60%,  reduce = 17%, Cumulative CPU 36.08 sec
2018-01-03 11:26:11,065 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 39.14 sec
2018-01-03 11:26:14,158 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 42.0 sec
2018-01-03 11:26:17,257 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 44.76 sec
2018-01-03 11:26:20,352 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 48.19 sec
2018-01-03 11:26:23,466 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 51.0 sec
2018-01-03 11:26:25,526 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 53.49 sec
2018-01-03 11:26:28,614 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 56.53 sec
2018-01-03 11:26:31,705 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 60.32 sec
2018-01-03 11:26:34,795 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 62.16 sec
2018-01-03 11:26:37,879 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 64.75 sec
2018-01-03 11:26:39,938 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 66.98 sec
2018-01-03 11:26:41,619 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 70.29 sec
2018-01-03 11:26:44,143 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 78.47 sec
MapReduce Total cumulative CPU time: 1 minutes 18 seconds 470 msec
Ended Job = job_1513599404024_167338
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167347, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167347/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167347
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:27:31,830 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:27:38,173 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.28 sec
2018-01-03 11:27:46,969 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.57 sec
MapReduce Total cumulative CPU time: 16 seconds 570 msec
Ended Job = job_1513599404024_167347
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167359, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167359/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167359
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:28:02,792 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:28:10,046 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.76 sec
2018-01-03 11:28:16,219 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.47 sec
MapReduce Total cumulative CPU time: 6 seconds 470 msec
Ended Job = job_1513599404024_167359
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 78.47 sec   HDFS Read: 184954337 HDFS Write: 1625832 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.57 sec   HDFS Read: 43567384 HDFS Write: 160048 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.47 sec   HDFS Read: 167723 HDFS Write: 3152 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 41 seconds 510 msec
OK
Time taken: 173.81 seconds, Fetched: 416 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.395 seconds
Query ID = boss_20180103112825_6d8a28d9-122c-4788-a497-7cf3b6605e6e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167363, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167363/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167363
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 11:28:35,996 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:28:45,447 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.59 sec
2018-01-03 11:28:48,758 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 16.63 sec
2018-01-03 11:28:51,219 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 16.63 sec
2018-01-03 11:28:52,254 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 49.47 sec
2018-01-03 11:28:53,286 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 59.93 sec
2018-01-03 11:28:55,352 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 71.5 sec
2018-01-03 11:28:56,386 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 80.19 sec
2018-01-03 11:28:58,461 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 90.35 sec
2018-01-03 11:29:00,525 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 107.34 sec
2018-01-03 11:29:01,557 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 110.42 sec
2018-01-03 11:29:02,640 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 129.93 sec
2018-01-03 11:29:03,670 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 133.02 sec
2018-01-03 11:29:04,703 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 137.49 sec
2018-01-03 11:29:05,738 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 141.53 sec
2018-01-03 11:29:10,395 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 152.24 sec
2018-01-03 11:29:12,644 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 158.55 sec
2018-01-03 11:29:15,738 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 160.48 sec
2018-01-03 11:29:20,214 Stage-1 map = 82%,  reduce = 7%, Cumulative CPU 161.2 sec
2018-01-03 11:29:21,258 Stage-1 map = 82%,  reduce = 15%, Cumulative CPU 171.59 sec
2018-01-03 11:29:24,481 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 184.85 sec
2018-01-03 11:29:28,104 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 194.29 sec
2018-01-03 11:29:29,378 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 197.19 sec
2018-01-03 11:29:30,408 Stage-1 map = 100%,  reduce = 52%, Cumulative CPU 198.56 sec
2018-01-03 11:29:31,438 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 213.51 sec
MapReduce Total cumulative CPU time: 3 minutes 33 seconds 510 msec
Ended Job = job_1513599404024_167363
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167370, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167370/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167370
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:29:48,702 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:29:54,895 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.74 sec
2018-01-03 11:29:57,988 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.38 sec
2018-01-03 11:30:10,346 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.04 sec
MapReduce Total cumulative CPU time: 20 seconds 40 msec
Ended Job = job_1513599404024_167370
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167373, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167373/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167373
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:30:17,310 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:30:22,463 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.69 sec
2018-01-03 11:30:33,772 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.33 sec
MapReduce Total cumulative CPU time: 7 seconds 330 msec
Ended Job = job_1513599404024_167373
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 213.51 sec   HDFS Read: 316625344 HDFS Write: 275879 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.04 sec   HDFS Read: 42217687 HDFS Write: 20150 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.33 sec   HDFS Read: 27822 HDFS Write: 2341 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 0 seconds 880 msec
OK
Time taken: 129.792 seconds, Fetched: 321 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.366 seconds
Query ID = boss_20180103113041_4744764b-dae0-4825-8f9b-b53236455eda
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167379, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167379/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167379
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 11:30:53,151 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:31:08,750 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 9.72 sec
2018-01-03 11:31:11,849 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.09 sec
2018-01-03 11:31:14,948 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 14.31 sec
2018-01-03 11:31:21,133 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 18.82 sec
2018-01-03 11:31:24,228 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 20.8 sec
2018-01-03 11:31:27,320 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 23.86 sec
2018-01-03 11:31:30,408 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 24.86 sec
2018-01-03 11:31:33,498 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 25.89 sec
2018-01-03 11:31:36,586 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 26.72 sec
2018-01-03 11:31:39,676 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 27.26 sec
2018-01-03 11:31:42,766 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 28.05 sec
2018-01-03 11:31:45,852 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 28.82 sec
2018-01-03 11:31:48,939 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 29.42 sec
2018-01-03 11:31:52,025 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 30.19 sec
2018-01-03 11:31:55,110 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 30.71 sec
2018-01-03 11:31:58,195 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 31.69 sec
2018-01-03 11:32:01,282 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 32.35 sec
2018-01-03 11:32:04,366 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 32.74 sec
2018-01-03 11:32:07,448 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 40.85 sec
2018-01-03 11:32:10,530 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 41.51 sec
2018-01-03 11:32:13,615 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 42.23 sec
2018-01-03 11:32:16,695 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 42.62 sec
2018-01-03 11:32:19,776 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 42.96 sec
2018-01-03 11:32:22,862 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 45.76 sec
2018-01-03 11:32:24,915 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 48.25 sec
2018-01-03 11:32:30,063 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 52.14 sec
MapReduce Total cumulative CPU time: 52 seconds 140 msec
Ended Job = job_1513599404024_167379
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167389, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167389/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167389
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:32:44,878 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:32:58,273 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 14.44 sec
2018-01-03 11:33:02,392 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 28.91 sec
2018-01-03 11:33:08,575 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 35.42 sec
MapReduce Total cumulative CPU time: 35 seconds 420 msec
Ended Job = job_1513599404024_167389
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167393, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167393/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167393
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:33:14,318 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:33:19,468 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.49 sec
2018-01-03 11:33:26,667 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.4 sec
MapReduce Total cumulative CPU time: 7 seconds 400 msec
Ended Job = job_1513599404024_167393
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 52.14 sec   HDFS Read: 74397511 HDFS Write: 493033 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 35.42 sec   HDFS Read: 42434263 HDFS Write: 172099 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.4 sec   HDFS Read: 179732 HDFS Write: 6305 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 34 seconds 960 msec
OK
Time taken: 166.395 seconds, Fetched: 781 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103113334_c1636fda-39a3-4839-aa66-98eda18237d9
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167397, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167397/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167397
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 11:34:00,247 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:34:28,663 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 10.96 sec
2018-01-03 11:34:31,766 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.65 sec
2018-01-03 11:34:34,857 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 14.07 sec
2018-01-03 11:34:37,943 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 16.63 sec
2018-01-03 11:34:41,038 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 17.66 sec
2018-01-03 11:34:44,123 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 18.48 sec
2018-01-03 11:34:47,209 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 19.07 sec
2018-01-03 11:34:50,296 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 19.53 sec
2018-01-03 11:34:53,379 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 20.42 sec
2018-01-03 11:34:56,463 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 21.1 sec
2018-01-03 11:34:59,549 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 23.2 sec
2018-01-03 11:35:02,631 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 23.94 sec
2018-01-03 11:35:05,713 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 29.19 sec
2018-01-03 11:35:08,796 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 29.37 sec
2018-01-03 11:35:11,878 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 30.01 sec
2018-01-03 11:35:14,966 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 30.35 sec
2018-01-03 11:35:18,048 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 31.64 sec
2018-01-03 11:35:21,128 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 32.07 sec
2018-01-03 11:35:27,290 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 32.94 sec
2018-01-03 11:35:30,372 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 33.45 sec
2018-01-03 11:35:33,452 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 36.41 sec
2018-01-03 11:35:34,480 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 37.62 sec
2018-01-03 11:35:50,910 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 45.41 sec
MapReduce Total cumulative CPU time: 45 seconds 410 msec
Ended Job = job_1513599404024_167397
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167411, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167411/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167411
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:36:10,916 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:36:20,181 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.19 sec
2018-01-03 11:36:23,265 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.42 sec
2018-01-03 11:36:41,765 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 24.05 sec
MapReduce Total cumulative CPU time: 24 seconds 50 msec
Ended Job = job_1513599404024_167411
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167418, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167418/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167418
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:36:59,591 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:37:12,202 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.33 sec
2018-01-03 11:37:25,136 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.47 sec
MapReduce Total cumulative CPU time: 7 seconds 470 msec
Ended Job = job_1513599404024_167418
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 45.41 sec   HDFS Read: 74397502 HDFS Write: 766862 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 25.86 sec   HDFS Read: 42708096 HDFS Write: 111219 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.47 sec   HDFS Read: 118857 HDFS Write: 3204 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 18 seconds 740 msec
OK
Time taken: 231.602 seconds, Fetched: 462 row(s)
开始执行20171027日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103113733_7730f209-56c5-4b0d-85ee-19e303d13301
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167421, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167421/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167421
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 11:37:44,618 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:37:58,133 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 11.11 sec
2018-01-03 11:38:00,308 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 22.02 sec
2018-01-03 11:38:01,345 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 24.9 sec
2018-01-03 11:38:02,382 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 27.6 sec
2018-01-03 11:38:04,448 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 30.41 sec
2018-01-03 11:38:05,480 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 33.66 sec
2018-01-03 11:38:07,552 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 36.44 sec
2018-01-03 11:38:08,589 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 39.98 sec
2018-01-03 11:38:10,657 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 43.07 sec
2018-01-03 11:38:12,722 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 76.46 sec
2018-01-03 11:38:13,751 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 81.21 sec
2018-01-03 11:38:16,880 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 83.83 sec
2018-01-03 11:38:19,984 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 86.54 sec
2018-01-03 11:38:22,044 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 89.37 sec
2018-01-03 11:38:25,143 Stage-1 map = 71%,  reduce = 8%, Cumulative CPU 93.58 sec
2018-01-03 11:38:28,239 Stage-1 map = 73%,  reduce = 8%, Cumulative CPU 96.3 sec
2018-01-03 11:38:31,111 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 99.74 sec
2018-01-03 11:38:34,201 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 102.81 sec
2018-01-03 11:38:37,294 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 105.73 sec
2018-01-03 11:38:40,390 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 108.46 sec
2018-01-03 11:38:42,456 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 110.12 sec
2018-01-03 11:38:43,488 Stage-1 map = 100%,  reduce = 57%, Cumulative CPU 111.17 sec
2018-01-03 11:38:44,550 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 122.05 sec
MapReduce Total cumulative CPU time: 2 minutes 2 seconds 50 msec
Ended Job = job_1513599404024_167421
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167427, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167427/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167427
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:38:57,955 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:39:03,146 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.66 sec
2018-01-03 11:39:05,211 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.45 sec
2018-01-03 11:39:15,510 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 20.41 sec
2018-01-03 11:39:20,653 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 27.92 sec
MapReduce Total cumulative CPU time: 27 seconds 920 msec
Ended Job = job_1513599404024_167427
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167429, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167429/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167429
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:39:34,548 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:39:40,750 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.75 sec
2018-01-03 11:39:50,022 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.22 sec
MapReduce Total cumulative CPU time: 8 seconds 220 msec
Ended Job = job_1513599404024_167429
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 122.05 sec   HDFS Read: 231758471 HDFS Write: 1722290 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 27.92 sec   HDFS Read: 43819372 HDFS Write: 173397 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.22 sec   HDFS Read: 181072 HDFS Write: 3006 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 38 seconds 190 msec
OK
Time taken: 137.851 seconds, Fetched: 404 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.39 seconds
Query ID = boss_20180103113957_ffefc2df-52f2-4aa7-b299-42f611a112fe
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167432, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167432/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167432
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 11:40:06,936 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:40:17,290 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 11.46 sec
2018-01-03 11:40:18,322 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 24.11 sec
2018-01-03 11:40:20,389 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 27.41 sec
2018-01-03 11:40:22,453 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 70.67 sec
2018-01-03 11:40:25,551 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 81.52 sec
2018-01-03 11:40:28,642 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 87.58 sec
2018-01-03 11:40:29,676 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 99.89 sec
2018-01-03 11:40:31,737 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 118.26 sec
2018-01-03 11:40:34,826 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 124.62 sec
2018-01-03 11:40:37,915 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 131.21 sec
2018-01-03 11:40:41,007 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 143.27 sec
2018-01-03 11:40:43,071 Stage-1 map = 63%,  reduce = 11%, Cumulative CPU 148.47 sec
2018-01-03 11:40:44,102 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 151.15 sec
2018-01-03 11:40:46,163 Stage-1 map = 68%,  reduce = 11%, Cumulative CPU 154.67 sec
2018-01-03 11:40:48,251 Stage-1 map = 82%,  reduce = 15%, Cumulative CPU 158.9 sec
2018-01-03 11:40:49,287 Stage-1 map = 83%,  reduce = 19%, Cumulative CPU 161.88 sec
2018-01-03 11:40:51,346 Stage-1 map = 83%,  reduce = 22%, Cumulative CPU 162.87 sec
2018-01-03 11:40:52,376 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 165.45 sec
2018-01-03 11:40:55,468 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 169.77 sec
2018-01-03 11:41:00,615 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 193.06 sec
2018-01-03 11:41:01,647 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 198.53 sec
2018-01-03 11:41:02,675 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 209.02 sec
MapReduce Total cumulative CPU time: 3 minutes 29 seconds 20 msec
Ended Job = job_1513599404024_167432
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167441, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167441/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167441
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:41:25,368 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:41:58,346 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 17.99 sec
2018-01-03 11:42:01,744 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 23.43 sec
2018-01-03 11:42:25,257 Stage-2 map = 100%,  reduce = 79%, Cumulative CPU 29.89 sec
2018-01-03 11:42:28,807 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 33.76 sec
MapReduce Total cumulative CPU time: 33 seconds 760 msec
Ended Job = job_1513599404024_167441
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167446, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167446/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167446
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:42:43,724 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:42:49,927 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.11 sec
2018-01-03 11:43:11,554 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 7.54 sec
2018-01-03 11:43:15,668 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 12.66 sec
MapReduce Total cumulative CPU time: 12 seconds 660 msec
Ended Job = job_1513599404024_167446
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 209.02 sec   HDFS Read: 342046291 HDFS Write: 306106 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 33.76 sec   HDFS Read: 42403450 HDFS Write: 20574 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 12.66 sec   HDFS Read: 28250 HDFS Write: 2286 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 15 seconds 440 msec
OK
Time taken: 198.945 seconds, Fetched: 320 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103114331_963fe348-531f-4b89-b02e-6757fc0e3ebf
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167451, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167451/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167451
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 11:44:09,768 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:44:31,486 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 11.34 sec
2018-01-03 11:44:34,668 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 13.52 sec
2018-01-03 11:44:37,763 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 15.48 sec
2018-01-03 11:44:40,869 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 16.7 sec
2018-01-03 11:44:43,958 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 17.97 sec
2018-01-03 11:44:47,047 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 19.02 sec
2018-01-03 11:44:50,137 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 19.75 sec
2018-01-03 11:44:53,226 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 20.45 sec
2018-01-03 11:44:56,316 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 21.27 sec
2018-01-03 11:44:59,414 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 22.11 sec
2018-01-03 11:45:02,500 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 22.57 sec
2018-01-03 11:45:05,588 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 23.44 sec
2018-01-03 11:45:08,678 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 24.14 sec
2018-01-03 11:45:11,763 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 24.82 sec
2018-01-03 11:45:14,849 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 25.45 sec
2018-01-03 11:45:17,937 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 26.38 sec
2018-01-03 11:45:21,021 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 27.01 sec
2018-01-03 11:45:24,106 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 27.33 sec
2018-01-03 11:45:27,192 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 27.86 sec
2018-01-03 11:45:30,275 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 28.69 sec
2018-01-03 11:45:33,357 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 30.53 sec
2018-01-03 11:45:36,441 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 31.27 sec
2018-01-03 11:45:38,498 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.6 sec
2018-01-03 11:45:43,640 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 36.63 sec
MapReduce Total cumulative CPU time: 36 seconds 630 msec
Ended Job = job_1513599404024_167451
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167459, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167459/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167459
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:45:49,333 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:45:54,485 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.32 sec
2018-01-03 11:45:56,545 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.75 sec
2018-01-03 11:46:02,716 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.3 sec
MapReduce Total cumulative CPU time: 15 seconds 300 msec
Ended Job = job_1513599404024_167459
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167461, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167461/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167461
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:46:11,453 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:46:16,618 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.3 sec
2018-01-03 11:46:23,820 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.29 sec
MapReduce Total cumulative CPU time: 6 seconds 290 msec
Ended Job = job_1513599404024_167461
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 36.63 sec   HDFS Read: 77623675 HDFS Write: 501045 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.3 sec   HDFS Read: 42597809 HDFS Write: 169646 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.29 sec   HDFS Read: 177283 HDFS Write: 6279 SUCCESS
Total MapReduce CPU Time Spent: 58 seconds 220 msec
OK
Time taken: 173.404 seconds, Fetched: 772 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103114631_37777e03-2a67-4d5c-9257-d9121177fae0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167465, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167465/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167465
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 11:46:42,696 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:46:52,037 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 8.94 sec
2018-01-03 11:46:55,142 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 10.5 sec
2018-01-03 11:46:58,239 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 11.73 sec
2018-01-03 11:47:01,336 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 13.06 sec
2018-01-03 11:47:04,451 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 14.54 sec
2018-01-03 11:47:07,544 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 15.57 sec
2018-01-03 11:47:10,635 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 16.62 sec
2018-01-03 11:47:13,728 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 17.94 sec
2018-01-03 11:47:16,816 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 19.05 sec
2018-01-03 11:47:19,904 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 21.2 sec
2018-01-03 11:47:20,933 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 22.64 sec
2018-01-03 11:47:48,713 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 33.44 sec
2018-01-03 11:47:49,746 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.42 sec
MapReduce Total cumulative CPU time: 35 seconds 420 msec
Ended Job = job_1513599404024_167465
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167469, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167469/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167469
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:47:58,475 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:48:03,652 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.11 sec
2018-01-03 11:48:05,716 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.22 sec
2018-01-03 11:48:13,964 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.04 sec
MapReduce Total cumulative CPU time: 16 seconds 40 msec
Ended Job = job_1513599404024_167469
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167472, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167472/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167472
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:48:19,632 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:48:28,981 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.48 sec
2018-01-03 11:48:35,167 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.99 sec
MapReduce Total cumulative CPU time: 7 seconds 990 msec
Ended Job = job_1513599404024_167472
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.42 sec   HDFS Read: 77623665 HDFS Write: 811446 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.04 sec   HDFS Read: 42908210 HDFS Write: 116542 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.99 sec   HDFS Read: 124180 HDFS Write: 3165 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 450 msec
OK
Time taken: 124.612 seconds, Fetched: 473 row(s)
开始执行20171028日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.366 seconds
Query ID = boss_20180103114843_67bc37bb-b5b4-4607-97a4-a165bbc81168
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167477, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167477/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167477
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 11:48:52,911 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:49:03,294 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 12.21 sec
2018-01-03 11:49:04,331 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 25.11 sec
2018-01-03 11:49:06,405 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 28.98 sec
2018-01-03 11:49:07,441 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 32.7 sec
2018-01-03 11:49:09,508 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 36.09 sec
2018-01-03 11:49:10,541 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 39.54 sec
2018-01-03 11:49:11,575 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 43.23 sec
2018-01-03 11:49:13,638 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 46.53 sec
2018-01-03 11:49:16,736 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 49.77 sec
2018-01-03 11:49:19,830 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 52.79 sec
2018-01-03 11:49:21,898 Stage-1 map = 69%,  reduce = 8%, Cumulative CPU 56.67 sec
2018-01-03 11:49:22,930 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 57.24 sec
2018-01-03 11:49:24,997 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 60.73 sec
2018-01-03 11:49:28,090 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 64.04 sec
2018-01-03 11:49:31,183 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 67.36 sec
2018-01-03 11:49:34,279 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 70.32 sec
2018-01-03 11:49:37,368 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 72.82 sec
2018-01-03 11:49:40,458 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 77.02 sec
2018-01-03 11:49:42,518 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 77.85 sec
2018-01-03 11:49:43,547 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 89.07 sec
MapReduce Total cumulative CPU time: 1 minutes 29 seconds 70 msec
Ended Job = job_1513599404024_167477
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167483, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167483/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167483
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:50:03,345 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:50:09,551 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.67 sec
2018-01-03 11:50:18,852 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.68 sec
MapReduce Total cumulative CPU time: 18 seconds 680 msec
Ended Job = job_1513599404024_167483
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167487, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167487/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167487
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:50:25,569 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:50:30,746 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec
2018-01-03 11:50:42,076 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.25 sec
MapReduce Total cumulative CPU time: 7 seconds 250 msec
Ended Job = job_1513599404024_167487
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 89.07 sec   HDFS Read: 250002320 HDFS Write: 1814928 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.68 sec   HDFS Read: 46844076 HDFS Write: 203740 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.25 sec   HDFS Read: 211415 HDFS Write: 3150 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 55 seconds 0 msec
OK
Time taken: 119.627 seconds, Fetched: 399 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103115050_c3978cdd-863b-4ec5-808d-eeae19d5af0d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167490, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167490/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167490
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 4
2018-01-03 11:50:59,263 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:51:09,678 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 11.62 sec
2018-01-03 11:51:10,711 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 22.88 sec
2018-01-03 11:51:12,778 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 26.35 sec
2018-01-03 11:51:13,808 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 29.6 sec
2018-01-03 11:51:15,871 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 44.93 sec
2018-01-03 11:51:16,909 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 48.51 sec
2018-01-03 11:51:18,972 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 59.92 sec
2018-01-03 11:51:22,069 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 70.12 sec
2018-01-03 11:51:24,130 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 73.41 sec
2018-01-03 11:51:25,160 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 79.44 sec
2018-01-03 11:51:27,219 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 82.66 sec
2018-01-03 11:51:28,255 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 88.66 sec
2018-01-03 11:51:30,314 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 91.63 sec
2018-01-03 11:51:31,345 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 97.25 sec
2018-01-03 11:51:33,406 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 103.45 sec
2018-01-03 11:51:34,439 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 106.49 sec
2018-01-03 11:51:36,496 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 109.53 sec
2018-01-03 11:51:37,525 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 112.71 sec
2018-01-03 11:51:39,582 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 116.15 sec
2018-01-03 11:51:40,611 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 119.24 sec
2018-01-03 11:51:41,642 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 121.23 sec
2018-01-03 11:51:42,669 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 124.33 sec
2018-01-03 11:51:43,703 Stage-1 map = 86%,  reduce = 6%, Cumulative CPU 124.81 sec
2018-01-03 11:51:44,734 Stage-1 map = 86%,  reduce = 11%, Cumulative CPU 125.73 sec
2018-01-03 11:51:45,763 Stage-1 map = 88%,  reduce = 17%, Cumulative CPU 129.54 sec
2018-01-03 11:51:46,793 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 131.15 sec
2018-01-03 11:51:47,821 Stage-1 map = 100%,  reduce = 44%, Cumulative CPU 135.05 sec
2018-01-03 11:51:48,953 Stage-1 map = 100%,  reduce = 75%, Cumulative CPU 143.48 sec
2018-01-03 11:51:52,041 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 150.97 sec
MapReduce Total cumulative CPU time: 2 minutes 30 seconds 970 msec
Ended Job = job_1513599404024_167490
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167492, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167492/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167492
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:52:05,972 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:52:19,392 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.98 sec
2018-01-03 11:52:24,547 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.19 sec
2018-01-03 11:52:25,578 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.89 sec
MapReduce Total cumulative CPU time: 15 seconds 890 msec
Ended Job = job_1513599404024_167492
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167494, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167494/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167494
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:52:41,327 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:52:45,540 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.34 sec
2018-01-03 11:52:51,722 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.48 sec
MapReduce Total cumulative CPU time: 5 seconds 480 msec
Ended Job = job_1513599404024_167494
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 4   Cumulative CPU: 150.97 sec   HDFS Read: 414323188 HDFS Write: 351792 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.89 sec   HDFS Read: 45381464 HDFS Write: 21771 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.48 sec   HDFS Read: 29447 HDFS Write: 2372 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 52 seconds 340 msec
OK
Time taken: 122.459 seconds, Fetched: 344 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.345 seconds
Query ID = boss_20180103115259_06384839-f3bd-49f1-94e5-141acb3ac220
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167497, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167497/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167497
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 11:53:16,582 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:53:26,952 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 8.54 sec
2018-01-03 11:53:30,055 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 10.17 sec
2018-01-03 11:53:32,116 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 11.07 sec
2018-01-03 11:53:35,206 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 11.72 sec
2018-01-03 11:53:38,299 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 12.2 sec
2018-01-03 11:53:41,389 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 12.93 sec
2018-01-03 11:53:44,477 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 13.39 sec
2018-01-03 11:53:47,569 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 13.93 sec
2018-01-03 11:53:50,657 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 14.6 sec
2018-01-03 11:53:53,755 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 15.24 sec
2018-01-03 11:53:56,851 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 15.73 sec
2018-01-03 11:53:59,943 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 16.52 sec
2018-01-03 11:54:03,028 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 16.93 sec
2018-01-03 11:54:06,122 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 17.58 sec
2018-01-03 11:54:09,206 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 18.19 sec
2018-01-03 11:54:12,288 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 19.75 sec
2018-01-03 11:54:14,344 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 21.08 sec
2018-01-03 11:54:19,489 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 25.31 sec
MapReduce Total cumulative CPU time: 25 seconds 310 msec
Ended Job = job_1513599404024_167497
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167506, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167506/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167506
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:54:25,405 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:54:31,607 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.96 sec
2018-01-03 11:54:33,672 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.53 sec
2018-01-03 11:54:42,953 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 22.44 sec
MapReduce Total cumulative CPU time: 22 seconds 440 msec
Ended Job = job_1513599404024_167506
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167507, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167507/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167507
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:54:50,239 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:54:56,418 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.66 sec
2018-01-03 11:55:01,562 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.78 sec
MapReduce Total cumulative CPU time: 6 seconds 780 msec
Ended Job = job_1513599404024_167507
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 25.31 sec   HDFS Read: 86024481 HDFS Write: 538434 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 22.44 sec   HDFS Read: 45567264 HDFS Write: 194396 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.78 sec   HDFS Read: 202033 HDFS Write: 6332 SUCCESS
Total MapReduce CPU Time Spent: 54 seconds 530 msec
OK
Time taken: 123.126 seconds, Fetched: 754 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103115509_adae2d4f-8e1f-4765-aaa5-0ae0ab2174b5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167509, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167509/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167509
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 11:55:20,416 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:55:30,791 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.4 sec
2018-01-03 11:55:33,899 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 12.35 sec
2018-01-03 11:55:37,003 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 15.03 sec
2018-01-03 11:55:40,101 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 17.02 sec
2018-01-03 11:55:43,197 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 18.35 sec
2018-01-03 11:55:46,291 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 20.36 sec
2018-01-03 11:55:49,386 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 21.74 sec
2018-01-03 11:55:52,483 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 23.26 sec
2018-01-03 11:55:55,572 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 24.25 sec
2018-01-03 11:55:58,661 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 25.5 sec
2018-01-03 11:56:00,724 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 28.14 sec
2018-01-03 11:56:07,941 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.66 sec
MapReduce Total cumulative CPU time: 32 seconds 660 msec
Ended Job = job_1513599404024_167509
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167512, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167512/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167512
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:56:16,490 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:56:22,796 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.69 sec
2018-01-03 11:56:30,009 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.11 sec
2018-01-03 11:56:33,097 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.0 sec
MapReduce Total cumulative CPU time: 16 seconds 0 msec
Ended Job = job_1513599404024_167512
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167514, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167514/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167514
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:56:40,812 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:56:52,134 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.4 sec
2018-01-03 11:56:59,337 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.34 sec
MapReduce Total cumulative CPU time: 6 seconds 340 msec
Ended Job = job_1513599404024_167514
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 32.66 sec   HDFS Read: 86024471 HDFS Write: 886845 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.0 sec   HDFS Read: 45915675 HDFS Write: 119396 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.34 sec   HDFS Read: 127034 HDFS Write: 2963 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 0 msec
OK
Time taken: 111.072 seconds, Fetched: 436 row(s)
开始执行20171029日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103115707_a5b888fe-eb0f-44df-845c-c722872292c8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167517, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167517/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167517
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 11:57:19,304 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:57:29,664 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 12.79 sec
2018-01-03 11:57:32,766 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 16.45 sec
2018-01-03 11:57:35,861 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 19.74 sec
2018-01-03 11:57:38,954 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 23.43 sec
2018-01-03 11:57:42,048 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 26.28 sec
2018-01-03 11:57:44,111 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 40.09 sec
2018-01-03 11:57:45,142 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 42.58 sec
2018-01-03 11:57:47,200 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 46.52 sec
2018-01-03 11:57:48,231 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 48.14 sec
2018-01-03 11:57:50,289 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 52.0 sec
2018-01-03 11:57:51,323 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 54.79 sec
2018-01-03 11:57:52,352 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 58.48 sec
2018-01-03 11:57:54,417 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 62.54 sec
2018-01-03 11:57:55,448 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 65.76 sec
2018-01-03 11:57:57,509 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 68.85 sec
2018-01-03 11:58:00,600 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 71.71 sec
2018-01-03 11:58:03,687 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 74.49 sec
2018-01-03 11:58:05,750 Stage-1 map = 79%,  reduce = 8%, Cumulative CPU 75.05 sec
2018-01-03 11:58:06,780 Stage-1 map = 81%,  reduce = 8%, Cumulative CPU 77.96 sec
2018-01-03 11:58:07,809 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 80.54 sec
2018-01-03 11:58:09,870 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 84.13 sec
2018-01-03 11:58:10,899 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 89.19 sec
MapReduce Total cumulative CPU time: 1 minutes 29 seconds 190 msec
Ended Job = job_1513599404024_167517
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167519, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167519/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167519
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 11:58:18,609 Stage-2 map = 0%,  reduce = 0%
2018-01-03 11:58:26,858 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.48 sec
2018-01-03 11:58:32,009 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.09 sec
2018-01-03 11:58:36,124 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.18 sec
MapReduce Total cumulative CPU time: 19 seconds 180 msec
Ended Job = job_1513599404024_167519
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167522, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167522/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167522
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 11:58:42,758 Stage-3 map = 0%,  reduce = 0%
2018-01-03 11:58:46,892 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.01 sec
2018-01-03 11:58:53,068 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.89 sec
MapReduce Total cumulative CPU time: 5 seconds 890 msec
Ended Job = job_1513599404024_167522
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 89.19 sec   HDFS Read: 249311452 HDFS Write: 1840684 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.18 sec   HDFS Read: 47112768 HDFS Write: 209080 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.89 sec   HDFS Read: 216755 HDFS Write: 3069 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 54 seconds 260 msec
OK
Time taken: 106.78 seconds, Fetched: 399 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.428 seconds
Query ID = boss_20180103115901_35abb4a2-3474-4a5e-a771-d0dd3c412acd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167524, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167524/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167524
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 4
2018-01-03 11:59:12,999 Stage-1 map = 0%,  reduce = 0%
2018-01-03 11:59:23,731 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 22.97 sec
2018-01-03 11:59:26,833 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 31.07 sec
2018-01-03 11:59:29,932 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 38.43 sec
2018-01-03 11:59:33,023 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 45.66 sec
2018-01-03 11:59:36,116 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 51.72 sec
2018-01-03 11:59:39,206 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 57.71 sec
2018-01-03 11:59:42,296 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 66.31 sec
2018-01-03 11:59:45,387 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 72.28 sec
2018-01-03 11:59:46,416 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 74.68 sec
2018-01-03 11:59:48,476 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 77.79 sec
2018-01-03 11:59:50,533 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 90.29 sec
2018-01-03 11:59:51,562 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 93.39 sec
2018-01-03 11:59:53,621 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 100.54 sec
2018-01-03 11:59:56,714 Stage-1 map = 77%,  reduce = 6%, Cumulative CPU 104.4 sec
2018-01-03 11:59:57,744 Stage-1 map = 77%,  reduce = 11%, Cumulative CPU 105.05 sec
2018-01-03 11:59:59,803 Stage-1 map = 79%,  reduce = 11%, Cumulative CPU 108.77 sec
2018-01-03 12:00:02,890 Stage-1 map = 83%,  reduce = 11%, Cumulative CPU 112.06 sec
2018-01-03 12:00:05,983 Stage-1 map = 86%,  reduce = 11%, Cumulative CPU 115.43 sec
2018-01-03 12:00:07,011 Stage-1 map = 86%,  reduce = 17%, Cumulative CPU 116.1 sec
2018-01-03 12:00:08,040 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 116.71 sec
2018-01-03 12:00:09,068 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 121.14 sec
2018-01-03 12:00:10,096 Stage-1 map = 100%,  reduce = 64%, Cumulative CPU 127.58 sec
2018-01-03 12:00:11,124 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 130.98 sec
2018-01-03 12:00:12,152 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 137.02 sec
MapReduce Total cumulative CPU time: 2 minutes 17 seconds 20 msec
Ended Job = job_1513599404024_167524
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167528, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167528/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167528
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:00:21,973 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:00:38,433 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.14 sec
2018-01-03 12:00:42,547 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 15.13 sec
2018-01-03 12:00:46,660 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.96 sec
MapReduce Total cumulative CPU time: 20 seconds 960 msec
Ended Job = job_1513599404024_167528
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167531, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167531/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167531
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:00:55,750 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:01:01,029 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.63 sec
2018-01-03 12:01:08,233 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.08 sec
MapReduce Total cumulative CPU time: 7 seconds 80 msec
Ended Job = job_1513599404024_167531
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 4   Cumulative CPU: 137.02 sec   HDFS Read: 405268658 HDFS Write: 350167 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.96 sec   HDFS Read: 45622775 HDFS Write: 21654 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.08 sec   HDFS Read: 29330 HDFS Write: 2346 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 45 seconds 60 msec
OK
Time taken: 128.183 seconds, Fetched: 330 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.397 seconds
Query ID = boss_20180103120116_6d005f19-8ca6-48dd-a018-567b535c838b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167534, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167534/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167534
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:01:27,723 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:01:38,229 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 10.12 sec
2018-01-03 12:01:41,330 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 13.48 sec
2018-01-03 12:01:44,423 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 15.5 sec
2018-01-03 12:01:47,514 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 16.93 sec
2018-01-03 12:01:50,607 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 17.84 sec
2018-01-03 12:01:53,695 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 18.32 sec
2018-01-03 12:01:56,783 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 18.9 sec
2018-01-03 12:01:59,873 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 19.27 sec
2018-01-03 12:02:02,959 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 19.75 sec
2018-01-03 12:02:06,044 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 20.34 sec
2018-01-03 12:02:09,133 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 20.86 sec
2018-01-03 12:02:12,215 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 21.63 sec
2018-01-03 12:02:15,301 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 22.11 sec
2018-01-03 12:02:18,389 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 22.44 sec
2018-01-03 12:02:21,472 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 22.69 sec
2018-01-03 12:02:24,553 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 23.25 sec
2018-01-03 12:02:27,637 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 24.1 sec
2018-01-03 12:02:30,718 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 24.46 sec
2018-01-03 12:02:33,800 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 24.88 sec
2018-01-03 12:02:35,858 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 25.14 sec
2018-01-03 12:02:38,941 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 25.53 sec
2018-01-03 12:02:42,021 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 27.21 sec
2018-01-03 12:02:44,079 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 28.66 sec
2018-01-03 12:02:51,272 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 33.06 sec
MapReduce Total cumulative CPU time: 33 seconds 60 msec
Ended Job = job_1513599404024_167534
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167546, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167546/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167546
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:02:56,977 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:03:04,177 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.46 sec
2018-01-03 12:03:14,454 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.9 sec
2018-01-03 12:03:16,510 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 13.55 sec
2018-01-03 12:03:17,537 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.58 sec
MapReduce Total cumulative CPU time: 16 seconds 580 msec
Ended Job = job_1513599404024_167546
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167551, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167551/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167551
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:03:39,177 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:03:52,535 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.63 sec
2018-01-03 12:04:06,931 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.77 sec
MapReduce Total cumulative CPU time: 7 seconds 770 msec
Ended Job = job_1513599404024_167551
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 33.06 sec   HDFS Read: 91274327 HDFS Write: 536853 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.58 sec   HDFS Read: 45808619 HDFS Write: 205593 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.77 sec   HDFS Read: 213230 HDFS Write: 6920 SUCCESS
Total MapReduce CPU Time Spent: 57 seconds 410 msec
OK
Time taken: 171.57 seconds, Fetched: 841 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103120414_fba591df-4f1d-464c-997e-908c62f0eb33
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167560, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167560/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167560
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:04:24,738 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:04:40,239 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 9.9 sec
2018-01-03 12:04:43,331 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 12.21 sec
2018-01-03 12:04:46,425 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 14.11 sec
2018-01-03 12:04:49,513 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 15.02 sec
2018-01-03 12:04:52,598 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 15.67 sec
2018-01-03 12:04:54,656 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 16.97 sec
2018-01-03 12:04:57,743 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 18.95 sec
2018-01-03 12:05:00,826 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 19.83 sec
2018-01-03 12:05:03,921 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 21.24 sec
2018-01-03 12:05:07,007 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 22.28 sec
2018-01-03 12:05:10,089 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 24.11 sec
2018-01-03 12:05:11,117 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.58 sec
2018-01-03 12:05:17,290 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 32.09 sec
MapReduce Total cumulative CPU time: 32 seconds 90 msec
Ended Job = job_1513599404024_167560
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167571, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167571/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167571
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:05:32,087 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:05:39,318 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.55 sec
2018-01-03 12:05:41,384 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.26 sec
2018-01-03 12:05:44,477 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.68 sec
MapReduce Total cumulative CPU time: 15 seconds 680 msec
Ended Job = job_1513599404024_167571
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167574, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167574/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167574
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:06:15,251 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:06:21,526 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.58 sec
2018-01-03 12:06:34,923 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.16 sec
MapReduce Total cumulative CPU time: 7 seconds 160 msec
Ended Job = job_1513599404024_167574
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 32.09 sec   HDFS Read: 91274317 HDFS Write: 867255 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.68 sec   HDFS Read: 46139021 HDFS Write: 121063 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.16 sec   HDFS Read: 128701 HDFS Write: 3001 SUCCESS
Total MapReduce CPU Time Spent: 54 seconds 930 msec
OK
Time taken: 142.295 seconds, Fetched: 438 row(s)
开始执行20171030日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103120643_94e0106c-2123-42b8-b3df-b47e326f67a9
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167584, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167584/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167584
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 12:06:53,187 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:07:03,563 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 11.29 sec
2018-01-03 12:07:04,601 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 23.25 sec
2018-01-03 12:07:06,676 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 30.0 sec
2018-01-03 12:07:09,779 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 33.19 sec
2018-01-03 12:07:12,875 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 36.45 sec
2018-01-03 12:07:15,975 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 39.19 sec
2018-01-03 12:07:18,044 Stage-1 map = 64%,  reduce = 8%, Cumulative CPU 39.82 sec
2018-01-03 12:07:19,076 Stage-1 map = 67%,  reduce = 8%, Cumulative CPU 43.09 sec
2018-01-03 12:07:22,171 Stage-1 map = 70%,  reduce = 8%, Cumulative CPU 47.23 sec
2018-01-03 12:07:25,267 Stage-1 map = 73%,  reduce = 8%, Cumulative CPU 50.27 sec
2018-01-03 12:07:28,357 Stage-1 map = 76%,  reduce = 8%, Cumulative CPU 53.35 sec
2018-01-03 12:07:31,447 Stage-1 map = 79%,  reduce = 8%, Cumulative CPU 56.39 sec
2018-01-03 12:07:33,507 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 57.13 sec
2018-01-03 12:07:34,541 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 60.11 sec
2018-01-03 12:07:35,571 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 62.54 sec
2018-01-03 12:07:39,690 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 75.31 sec
MapReduce Total cumulative CPU time: 1 minutes 15 seconds 310 msec
Ended Job = job_1513599404024_167584
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167593, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167593/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167593
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:07:45,413 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:07:56,775 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 10.97 sec
2018-01-03 12:08:08,104 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 11.65 sec
2018-01-03 12:08:13,249 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 17.21 sec
2018-01-03 12:08:14,277 Stage-2 map = 100%,  reduce = 33%, Cumulative CPU 17.34 sec
2018-01-03 12:08:15,305 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.38 sec
MapReduce Total cumulative CPU time: 23 seconds 380 msec
Ended Job = job_1513599404024_167593
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167599, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167599/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167599
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:08:21,966 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:08:27,439 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.42 sec
2018-01-03 12:08:37,746 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.27 sec
MapReduce Total cumulative CPU time: 9 seconds 270 msec
Ended Job = job_1513599404024_167599
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 75.31 sec   HDFS Read: 191172597 HDFS Write: 1567288 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.38 sec   HDFS Read: 42540947 HDFS Write: 140214 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.27 sec   HDFS Read: 147889 HDFS Write: 2774 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 47 seconds 960 msec
OK
Time taken: 114.846 seconds, Fetched: 370 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.393 seconds
Query ID = boss_20180103120845_4e446377-f053-4405-a8a7-97aedb0d8aaf
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167604, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167604/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167604
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 12:08:54,618 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:09:05,007 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 11.96 sec
2018-01-03 12:09:09,155 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 26.33 sec
2018-01-03 12:09:12,259 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 30.55 sec
2018-01-03 12:09:15,373 Stage-1 map = 39%,  reduce = 4%, Cumulative CPU 34.21 sec
2018-01-03 12:09:18,475 Stage-1 map = 41%,  reduce = 4%, Cumulative CPU 37.17 sec
2018-01-03 12:09:21,570 Stage-1 map = 43%,  reduce = 4%, Cumulative CPU 40.38 sec
2018-01-03 12:09:23,631 Stage-1 map = 47%,  reduce = 7%, Cumulative CPU 52.79 sec
2018-01-03 12:09:24,664 Stage-1 map = 50%,  reduce = 11%, Cumulative CPU 57.19 sec
2018-01-03 12:09:26,731 Stage-1 map = 53%,  reduce = 11%, Cumulative CPU 60.9 sec
2018-01-03 12:09:27,763 Stage-1 map = 54%,  reduce = 11%, Cumulative CPU 63.76 sec
2018-01-03 12:09:29,825 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 70.4 sec
2018-01-03 12:09:32,918 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 77.24 sec
2018-01-03 12:09:36,018 Stage-1 map = 70%,  reduce = 11%, Cumulative CPU 83.71 sec
2018-01-03 12:09:39,111 Stage-1 map = 73%,  reduce = 11%, Cumulative CPU 90.35 sec
2018-01-03 12:09:40,144 Stage-1 map = 85%,  reduce = 11%, Cumulative CPU 93.14 sec
2018-01-03 12:09:41,179 Stage-1 map = 100%,  reduce = 11%, Cumulative CPU 96.77 sec
2018-01-03 12:09:42,213 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 102.01 sec
2018-01-03 12:09:43,242 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 110.97 sec
MapReduce Total cumulative CPU time: 1 minutes 50 seconds 970 msec
Ended Job = job_1513599404024_167604
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167613, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167613/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167613
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:09:50,401 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:09:56,594 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.43 sec
2018-01-03 12:09:57,624 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.37 sec
2018-01-03 12:10:02,771 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.94 sec
MapReduce Total cumulative CPU time: 14 seconds 940 msec
Ended Job = job_1513599404024_167613
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167615, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167615/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167615
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:10:17,487 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:10:24,719 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec
2018-01-03 12:10:30,907 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.71 sec
MapReduce Total cumulative CPU time: 5 seconds 710 msec
Ended Job = job_1513599404024_167615
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 110.97 sec   HDFS Read: 303537479 HDFS Write: 286044 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.94 sec   HDFS Read: 41259965 HDFS Write: 19842 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.71 sec   HDFS Read: 27518 HDFS Write: 2203 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 11 seconds 620 msec
OK
Time taken: 106.419 seconds, Fetched: 314 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103121038_e5d65573-f3db-44bc-89d8-d8fc48992b0b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167617, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167617/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167617
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:10:48,620 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:10:58,991 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 9.0 sec
2018-01-03 12:11:02,096 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.45 sec
2018-01-03 12:11:05,196 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 12.36 sec
2018-01-03 12:11:08,291 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 13.49 sec
2018-01-03 12:11:11,389 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 14.29 sec
2018-01-03 12:11:14,482 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 14.79 sec
2018-01-03 12:11:17,571 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 15.47 sec
2018-01-03 12:11:20,666 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 16.09 sec
2018-01-03 12:11:23,757 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 16.87 sec
2018-01-03 12:11:25,818 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 17.68 sec
2018-01-03 12:11:28,911 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 18.39 sec
2018-01-03 12:11:31,998 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 18.79 sec
2018-01-03 12:11:35,087 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 19.76 sec
2018-01-03 12:11:38,177 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 20.12 sec
2018-01-03 12:11:41,264 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 20.58 sec
2018-01-03 12:11:44,349 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 21.72 sec
2018-01-03 12:11:47,438 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 22.06 sec
2018-01-03 12:11:50,523 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 24.18 sec
2018-01-03 12:11:53,608 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.4 sec
2018-01-03 12:11:58,756 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.46 sec
MapReduce Total cumulative CPU time: 30 seconds 460 msec
Ended Job = job_1513599404024_167617
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167620, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167620/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167620
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:12:06,580 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:12:13,336 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.59 sec
2018-01-03 12:12:24,657 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 13.08 sec
2018-01-03 12:12:26,715 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.75 sec
MapReduce Total cumulative CPU time: 18 seconds 750 msec
Ended Job = job_1513599404024_167620
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167623, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167623/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167623
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:12:43,382 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:12:54,718 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.44 sec
2018-01-03 12:12:59,894 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.38 sec
MapReduce Total cumulative CPU time: 6 seconds 380 msec
Ended Job = job_1513599404024_167623
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.46 sec   HDFS Read: 78458346 HDFS Write: 572687 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.75 sec   HDFS Read: 41546028 HDFS Write: 170794 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.38 sec   HDFS Read: 178431 HDFS Write: 6164 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 590 msec
OK
Time taken: 142.313 seconds, Fetched: 735 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.38 seconds
Query ID = boss_20180103121315_05611d24-1e4e-496c-8e0b-d153a74699ca
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167625, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167625/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167625
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:13:26,409 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:13:36,751 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 14.65 sec
2018-01-03 12:13:39,848 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 17.48 sec
2018-01-03 12:13:42,938 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 31.63 sec
2018-01-03 12:13:46,024 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 32.6 sec
2018-01-03 12:13:49,114 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 33.52 sec
2018-01-03 12:13:51,171 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 34.22 sec
2018-01-03 12:13:54,256 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 35.27 sec
2018-01-03 12:13:57,343 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 36.59 sec
2018-01-03 12:14:00,429 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 37.16 sec
2018-01-03 12:14:03,513 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 38.53 sec
2018-01-03 12:14:06,599 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 39.14 sec
2018-01-03 12:14:09,691 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 40.64 sec
2018-01-03 12:14:11,748 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 41.97 sec
2018-01-03 12:14:18,947 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 46.77 sec
MapReduce Total cumulative CPU time: 46 seconds 770 msec
Ended Job = job_1513599404024_167625
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167629, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167629/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167629
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:14:32,608 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:14:36,728 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.25 sec
2018-01-03 12:14:37,758 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.64 sec
2018-01-03 12:14:42,904 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.19 sec
MapReduce Total cumulative CPU time: 15 seconds 190 msec
Ended Job = job_1513599404024_167629
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167631, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167631/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167631
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:14:48,517 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:14:54,692 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.66 sec
2018-01-03 12:15:00,861 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.28 sec
MapReduce Total cumulative CPU time: 6 seconds 280 msec
Ended Job = job_1513599404024_167631
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 46.77 sec   HDFS Read: 78458336 HDFS Write: 877132 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.19 sec   HDFS Read: 41850473 HDFS Write: 143608 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.28 sec   HDFS Read: 151246 HDFS Write: 3451 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 8 seconds 240 msec
OK
Time taken: 106.159 seconds, Fetched: 518 row(s)
开始执行20171031日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.374 seconds
Query ID = boss_20180103121509_5821e00d-d656-417b-b00e-dd3c9b915c3b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167632, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167632/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167632
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 12:15:32,803 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:15:43,148 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.9 sec
2018-01-03 12:15:44,180 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 40.62 sec
2018-01-03 12:15:46,247 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 44.94 sec
2018-01-03 12:15:47,278 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 56.56 sec
2018-01-03 12:15:48,310 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 58.81 sec
2018-01-03 12:15:49,341 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 62.23 sec
2018-01-03 12:15:52,436 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 65.57 sec
2018-01-03 12:15:55,532 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 68.57 sec
2018-01-03 12:15:58,627 Stage-1 map = 70%,  reduce = 8%, Cumulative CPU 72.07 sec
2018-01-03 12:16:00,687 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 73.17 sec
2018-01-03 12:16:01,718 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 77.27 sec
2018-01-03 12:16:04,816 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 80.44 sec
2018-01-03 12:16:07,904 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 83.67 sec
2018-01-03 12:16:10,990 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 86.93 sec
2018-01-03 12:16:13,051 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 89.46 sec
2018-01-03 12:16:14,081 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 93.09 sec
2018-01-03 12:16:16,287 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 99.75 sec
MapReduce Total cumulative CPU time: 1 minutes 39 seconds 750 msec
Ended Job = job_1513599404024_167632
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167636, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167636/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167636
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:16:31,821 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:16:36,972 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.78 sec
2018-01-03 12:16:38,003 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.18 sec
2018-01-03 12:16:44,180 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.73 sec
MapReduce Total cumulative CPU time: 19 seconds 730 msec
Ended Job = job_1513599404024_167636
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167640, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167640/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167640
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:16:49,795 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:16:53,916 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec
2018-01-03 12:17:00,096 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.48 sec
MapReduce Total cumulative CPU time: 5 seconds 480 msec
Ended Job = job_1513599404024_167640
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 99.75 sec   HDFS Read: 186384618 HDFS Write: 1584266 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.73 sec   HDFS Read: 44652996 HDFS Write: 137760 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.48 sec   HDFS Read: 145435 HDFS Write: 2961 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 4 seconds 960 msec
OK
Time taken: 111.959 seconds, Fetched: 376 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.39 seconds
Query ID = boss_20180103121708_eefa1e7c-b43b-4511-bd75-498cd2e04480
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167648, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167648/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167648
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 12:17:17,345 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:17:24,602 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 10.72 sec
2018-01-03 12:17:26,668 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 22.68 sec
2018-01-03 12:17:29,762 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 26.26 sec
2018-01-03 12:17:32,860 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 29.46 sec
2018-01-03 12:17:34,922 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 42.09 sec
2018-01-03 12:17:35,960 Stage-1 map = 52%,  reduce = 7%, Cumulative CPU 46.48 sec
2018-01-03 12:17:38,022 Stage-1 map = 55%,  reduce = 11%, Cumulative CPU 50.72 sec
2018-01-03 12:17:39,052 Stage-1 map = 58%,  reduce = 11%, Cumulative CPU 54.07 sec
2018-01-03 12:17:41,115 Stage-1 map = 62%,  reduce = 11%, Cumulative CPU 57.53 sec
2018-01-03 12:17:42,145 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 60.98 sec
2018-01-03 12:17:44,204 Stage-1 map = 81%,  reduce = 11%, Cumulative CPU 67.52 sec
2018-01-03 12:17:45,234 Stage-1 map = 81%,  reduce = 19%, Cumulative CPU 67.85 sec
2018-01-03 12:17:47,292 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 71.33 sec
2018-01-03 12:17:50,382 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 76.48 sec
2018-01-03 12:17:51,411 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 81.11 sec
2018-01-03 12:17:52,440 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 84.23 sec
2018-01-03 12:17:53,470 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 89.4 sec
MapReduce Total cumulative CPU time: 1 minutes 29 seconds 400 msec
Ended Job = job_1513599404024_167648
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167654, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167654/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167654
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:18:00,180 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:18:05,334 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.16 sec
2018-01-03 12:18:12,544 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.01 sec
2018-01-03 12:18:18,716 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.81 sec
MapReduce Total cumulative CPU time: 12 seconds 810 msec
Ended Job = job_1513599404024_167654
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167657, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167657/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167657
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:18:24,381 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:18:29,548 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.34 sec
2018-01-03 12:18:35,745 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.62 sec
MapReduce Total cumulative CPU time: 4 seconds 620 msec
Ended Job = job_1513599404024_167657
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 89.4 sec   HDFS Read: 295863727 HDFS Write: 301891 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.81 sec   HDFS Read: 43370883 HDFS Write: 19061 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.62 sec   HDFS Read: 26737 HDFS Write: 2141 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 46 seconds 830 msec
OK
Time taken: 88.367 seconds, Fetched: 299 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103121843_b972975d-66e9-4e0c-a937-2dd16b0f77b7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167662, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167662/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167662
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:18:54,929 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:19:13,528 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 8.9 sec
2018-01-03 12:19:16,620 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 11.19 sec
2018-01-03 12:19:19,708 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 12.37 sec
2018-01-03 12:19:21,766 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 13.12 sec
2018-01-03 12:19:24,852 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 13.65 sec
2018-01-03 12:19:27,942 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 14.21 sec
2018-01-03 12:19:31,026 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 14.64 sec
2018-01-03 12:19:34,112 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 15.16 sec
2018-01-03 12:19:37,199 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 15.63 sec
2018-01-03 12:19:40,283 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 16.29 sec
2018-01-03 12:19:43,366 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 16.77 sec
2018-01-03 12:19:46,451 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 17.28 sec
2018-01-03 12:19:49,532 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 17.62 sec
2018-01-03 12:19:52,612 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 18.16 sec
2018-01-03 12:19:55,695 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 18.58 sec
2018-01-03 12:19:58,775 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 18.9 sec
2018-01-03 12:20:01,854 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 19.68 sec
2018-01-03 12:20:04,942 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 20.04 sec
2018-01-03 12:20:08,021 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 20.57 sec
2018-01-03 12:20:10,073 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 22.67 sec
2018-01-03 12:20:13,154 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 23.46 sec
2018-01-03 12:20:16,235 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 25.68 sec
2018-01-03 12:20:19,314 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 26.11 sec
2018-01-03 12:20:20,341 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 26.85 sec
2018-01-03 12:20:25,480 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.9 sec
MapReduce Total cumulative CPU time: 30 seconds 900 msec
Ended Job = job_1513599404024_167662
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167674, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167674/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167674
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:20:31,181 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:20:36,326 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.22 sec
2018-01-03 12:20:39,417 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.21 sec
2018-01-03 12:20:43,530 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.5 sec
MapReduce Total cumulative CPU time: 18 seconds 500 msec
Ended Job = job_1513599404024_167674
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167677, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167677/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167677
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:20:50,202 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:20:54,340 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.95 sec
2018-01-03 12:21:17,057 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.43 sec
MapReduce Total cumulative CPU time: 7 seconds 430 msec
Ended Job = job_1513599404024_167677
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.9 sec   HDFS Read: 73873777 HDFS Write: 525862 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.5 sec   HDFS Read: 43594274 HDFS Write: 163888 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.43 sec   HDFS Read: 171525 HDFS Write: 6118 SUCCESS
Total MapReduce CPU Time Spent: 56 seconds 830 msec
OK
Time taken: 154.604 seconds, Fetched: 753 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.35 seconds
Query ID = boss_20180103122124_3697e184-d2d2-4694-aced-2679335460c7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167682, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167682/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167682
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:21:34,751 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:21:46,135 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 10.67 sec
2018-01-03 12:21:49,233 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 13.94 sec
2018-01-03 12:21:52,326 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 15.34 sec
2018-01-03 12:21:55,422 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 16.51 sec
2018-01-03 12:21:58,520 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 17.22 sec
2018-01-03 12:22:01,607 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 17.99 sec
2018-01-03 12:22:03,665 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 19.23 sec
2018-01-03 12:22:06,767 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 20.99 sec
2018-01-03 12:22:09,853 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 21.84 sec
2018-01-03 12:22:12,939 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 23.31 sec
2018-01-03 12:22:16,028 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 24.94 sec
2018-01-03 12:22:19,111 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 26.83 sec
2018-01-03 12:22:22,200 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 30.63 sec
2018-01-03 12:22:27,344 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 35.11 sec
MapReduce Total cumulative CPU time: 35 seconds 110 msec
Ended Job = job_1513599404024_167682
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167688, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167688/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167688
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:22:34,039 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:22:47,421 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.19 sec
2018-01-03 12:22:55,649 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.62 sec
2018-01-03 12:22:57,709 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.82 sec
MapReduce Total cumulative CPU time: 16 seconds 820 msec
Ended Job = job_1513599404024_167688
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167694, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167694/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167694
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:23:11,339 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:23:16,510 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.25 sec
2018-01-03 12:23:30,937 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.09 sec
MapReduce Total cumulative CPU time: 6 seconds 90 msec
Ended Job = job_1513599404024_167694
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 35.11 sec   HDFS Read: 73873767 HDFS Write: 796694 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.82 sec   HDFS Read: 43865106 HDFS Write: 143580 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.09 sec   HDFS Read: 151218 HDFS Write: 3358 SUCCESS
Total MapReduce CPU Time Spent: 58 seconds 20 msec
OK
Time taken: 127.196 seconds, Fetched: 455 row(s)
开始执行20171101日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.371 seconds
Query ID = boss_20180103122346_812e0234-7e80-4018-87cd-6e89b01e1d17
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167698, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167698/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167698
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 12:24:28,563 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:24:41,294 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 23.06 sec
2018-01-03 12:24:42,353 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 24.1 sec
2018-01-03 12:24:44,480 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 29.36 sec
2018-01-03 12:24:47,632 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 33.15 sec
2018-01-03 12:24:50,776 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 36.57 sec
2018-01-03 12:24:52,907 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 39.63 sec
2018-01-03 12:24:53,965 Stage-1 map = 65%,  reduce = 8%, Cumulative CPU 40.32 sec
2018-01-03 12:24:56,063 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 43.4 sec
2018-01-03 12:24:59,202 Stage-1 map = 71%,  reduce = 8%, Cumulative CPU 46.62 sec
2018-01-03 12:25:01,301 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 47.2 sec
2018-01-03 12:25:02,348 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 51.16 sec
2018-01-03 12:25:04,558 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 42.03 sec
2018-01-03 12:25:05,601 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 54.47 sec
2018-01-03 12:25:07,688 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 45.51 sec
2018-01-03 12:25:10,819 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 49.21 sec
2018-01-03 12:25:11,865 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 58.47 sec
MapReduce Total cumulative CPU time: 58 seconds 470 msec
Ended Job = job_1513599404024_167698
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167703, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167703/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167703
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:25:20,674 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:25:32,009 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.77 sec
2018-01-03 12:25:35,099 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.82 sec
2018-01-03 12:25:39,219 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.31 sec
MapReduce Total cumulative CPU time: 18 seconds 310 msec
Ended Job = job_1513599404024_167703
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167705, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167705/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167705
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:25:44,845 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:25:51,028 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.51 sec
2018-01-03 12:26:04,397 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.14 sec
MapReduce Total cumulative CPU time: 8 seconds 140 msec
Ended Job = job_1513599404024_167705
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 58.47 sec   HDFS Read: 180832644 HDFS Write: 1603461 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.31 sec   HDFS Read: 61078803 HDFS Write: 148927 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.14 sec   HDFS Read: 156602 HDFS Write: 2872 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 24 seconds 920 msec
OK
Time taken: 138.52 seconds, Fetched: 383 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.385 seconds
Query ID = boss_20180103122612_68652f82-b74f-44ea-a6a7-759e5176aaa0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167707, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167707/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167707
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 12:26:29,494 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:26:38,841 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.39 sec
2018-01-03 12:26:39,886 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 35.14 sec
2018-01-03 12:26:41,995 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 39.44 sec
2018-01-03 12:26:43,033 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 43.39 sec
2018-01-03 12:26:45,100 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 46.59 sec
2018-01-03 12:26:46,133 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 50.17 sec
2018-01-03 12:26:48,199 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 53.46 sec
2018-01-03 12:26:49,231 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 56.67 sec
2018-01-03 12:26:50,269 Stage-1 map = 55%,  reduce = 7%, Cumulative CPU 57.59 sec
2018-01-03 12:26:51,301 Stage-1 map = 57%,  reduce = 11%, Cumulative CPU 61.6 sec
2018-01-03 12:26:52,337 Stage-1 map = 60%,  reduce = 11%, Cumulative CPU 64.67 sec
2018-01-03 12:26:54,401 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 68.34 sec
2018-01-03 12:26:55,434 Stage-1 map = 77%,  reduce = 11%, Cumulative CPU 72.37 sec
2018-01-03 12:26:56,467 Stage-1 map = 77%,  reduce = 19%, Cumulative CPU 72.5 sec
2018-01-03 12:26:57,500 Stage-1 map = 77%,  reduce = 22%, Cumulative CPU 72.56 sec
2018-01-03 12:26:58,533 Stage-1 map = 80%,  reduce = 22%, Cumulative CPU 75.55 sec
2018-01-03 12:27:01,634 Stage-1 map = 82%,  reduce = 22%, Cumulative CPU 78.87 sec
2018-01-03 12:27:02,665 Stage-1 map = 84%,  reduce = 22%, Cumulative CPU 70.96 sec
2018-01-03 12:27:05,757 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 74.85 sec
2018-01-03 12:27:06,788 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 77.22 sec
2018-01-03 12:27:07,821 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 84.18 sec
2018-01-03 12:27:08,851 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 88.56 sec
MapReduce Total cumulative CPU time: 1 minutes 28 seconds 560 msec
Ended Job = job_1513599404024_167707
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167714, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167714/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167714
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:27:16,667 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:27:21,837 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.36 sec
2018-01-03 12:27:28,015 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.23 sec
MapReduce Total cumulative CPU time: 13 seconds 230 msec
Ended Job = job_1513599404024_167714
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167717, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167717/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167717
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:27:33,627 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:27:45,976 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.3 sec
2018-01-03 12:27:51,120 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.37 sec
MapReduce Total cumulative CPU time: 4 seconds 370 msec
Ended Job = job_1513599404024_167717
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 88.56 sec   HDFS Read: 296875313 HDFS Write: 324997 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.23 sec   HDFS Read: 59800601 HDFS Write: 20821 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.37 sec   HDFS Read: 28497 HDFS Write: 2278 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 46 seconds 160 msec
OK
Time taken: 99.989 seconds, Fetched: 325 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.351 seconds
Query ID = boss_20180103122758_0f4c449f-c72a-4974-9c08-3d88725d3a71
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167720, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167720/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167720
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:28:09,043 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:28:42,080 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.11 sec
2018-01-03 12:28:45,175 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 13.39 sec
2018-01-03 12:28:48,269 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 14.81 sec
2018-01-03 12:28:51,366 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 16.3 sec
2018-01-03 12:28:54,456 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 17.15 sec
2018-01-03 12:28:57,547 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 18.25 sec
2018-01-03 12:29:00,639 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 20.19 sec
2018-01-03 12:29:02,698 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 21.45 sec
2018-01-03 12:29:05,787 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 22.72 sec
2018-01-03 12:29:08,879 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 23.59 sec
2018-01-03 12:29:11,965 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 24.4 sec
2018-01-03 12:29:15,051 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 25.49 sec
2018-01-03 12:29:18,138 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 26.12 sec
2018-01-03 12:29:21,219 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 26.82 sec
2018-01-03 12:29:24,304 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 27.93 sec
2018-01-03 12:29:27,392 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 29.69 sec
2018-01-03 12:29:30,475 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 30.43 sec
2018-01-03 12:29:31,503 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 31.86 sec
2018-01-03 12:29:45,898 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 37.17 sec
MapReduce Total cumulative CPU time: 37 seconds 170 msec
Ended Job = job_1513599404024_167720
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167732, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167732/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167732
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:29:51,684 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:29:56,828 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.89 sec
2018-01-03 12:29:59,915 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.14 sec
2018-01-03 12:30:11,209 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.42 sec
MapReduce Total cumulative CPU time: 18 seconds 420 msec
Ended Job = job_1513599404024_167732
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167734, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167734/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167734
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:30:16,798 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:30:21,941 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.51 sec
2018-01-03 12:30:35,291 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.16 sec
MapReduce Total cumulative CPU time: 6 seconds 160 msec
Ended Job = job_1513599404024_167734
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 37.17 sec   HDFS Read: 81766104 HDFS Write: 549727 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.42 sec   HDFS Read: 60024747 HDFS Write: 172199 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.16 sec   HDFS Read: 179832 HDFS Write: 5890 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 750 msec
OK
Time taken: 157.465 seconds, Fetched: 722 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.349 seconds
Query ID = boss_20180103123043_75842db7-0b00-4aae-bd09-7ff31a666a03
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167739, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167739/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167739
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:30:58,999 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:31:09,355 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 10.73 sec
2018-01-03 12:31:12,454 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 13.09 sec
2018-01-03 12:31:15,546 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 14.28 sec
2018-01-03 12:31:18,637 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 15.05 sec
2018-01-03 12:31:21,728 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 15.78 sec
2018-01-03 12:31:24,818 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 17.18 sec
2018-01-03 12:31:27,906 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 18.37 sec
2018-01-03 12:31:31,004 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 20.37 sec
2018-01-03 12:31:34,089 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 21.45 sec
2018-01-03 12:31:37,173 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 22.66 sec
2018-01-03 12:31:40,261 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.81 sec
2018-01-03 12:31:45,403 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.34 sec
MapReduce Total cumulative CPU time: 30 seconds 340 msec
Ended Job = job_1513599404024_167739
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167750, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167750/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167750
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:32:10,161 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:32:16,431 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.99 sec
2018-01-03 12:32:18,489 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.34 sec
2018-01-03 12:32:24,662 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.76 sec
MapReduce Total cumulative CPU time: 17 seconds 760 msec
Ended Job = job_1513599404024_167750
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167755, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167755/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167755
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:32:31,330 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:32:35,562 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.78 sec
2018-01-03 12:32:46,892 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.74 sec
MapReduce Total cumulative CPU time: 5 seconds 740 msec
Ended Job = job_1513599404024_167755
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.34 sec   HDFS Read: 81766095 HDFS Write: 864038 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.76 sec   HDFS Read: 60339062 HDFS Write: 144265 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.74 sec   HDFS Read: 151903 HDFS Write: 3181 SUCCESS
Total MapReduce CPU Time Spent: 53 seconds 840 msec
OK
Time taken: 124.911 seconds, Fetched: 482 row(s)
开始执行20171102日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103123254_b12f0352-2c77-4b59-810d-8455f06f1d72
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167760, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167760/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167760
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 12:33:04,170 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:33:15,576 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 11.97 sec
2018-01-03 12:33:18,683 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 15.34 sec
2018-01-03 12:33:21,784 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 19.31 sec
2018-01-03 12:33:23,848 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 22.65 sec
2018-01-03 12:33:26,947 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 25.67 sec
2018-01-03 12:33:30,041 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 28.7 sec
2018-01-03 12:33:33,134 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 31.73 sec
2018-01-03 12:33:36,232 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 34.54 sec
2018-01-03 12:33:39,323 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 38.38 sec
2018-01-03 12:33:42,417 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 41.63 sec
2018-01-03 12:33:45,512 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 62.53 sec
2018-01-03 12:33:48,599 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 65.55 sec
2018-01-03 12:33:50,661 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 67.67 sec
2018-01-03 12:34:00,978 Stage-1 map = 50%,  reduce = 8%, Cumulative CPU 113.22 sec
2018-01-03 12:34:02,010 Stage-1 map = 50%,  reduce = 17%, Cumulative CPU 113.81 sec
2018-01-03 12:34:08,189 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 70.08 sec
2018-01-03 12:34:09,219 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 71.14 sec
2018-01-03 12:34:10,249 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 75.47 sec
2018-01-03 12:34:11,282 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 79.71 sec
MapReduce Total cumulative CPU time: 1 minutes 19 seconds 710 msec
Ended Job = job_1513599404024_167760
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167767, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167767/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167767
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:34:16,960 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:34:22,118 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.05 sec
2018-01-03 12:34:23,149 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.12 sec
2018-01-03 12:34:28,300 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.01 sec
MapReduce Total cumulative CPU time: 20 seconds 10 msec
Ended Job = job_1513599404024_167767
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167768, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167768/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167768
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:35:26,099 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:35:41,514 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.21 sec
2018-01-03 12:35:57,973 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 11.45 sec
MapReduce Total cumulative CPU time: 11 seconds 450 msec
Ended Job = job_1513599404024_167768
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 79.71 sec   HDFS Read: 181451642 HDFS Write: 1456752 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.01 sec   HDFS Read: 41226166 HDFS Write: 135609 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 11.89 sec   HDFS Read: 143284 HDFS Write: 2857 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 51 seconds 610 msec
OK
Time taken: 185.18 seconds, Fetched: 380 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.398 seconds
Query ID = boss_20180103123606_0d6d14ca-b7d9-4ea3-b9d3-1fe625102d82
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167774, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167774/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167774
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 12:36:19,117 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:36:26,432 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 8.08 sec
2018-01-03 12:36:30,577 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 20.02 sec
2018-01-03 12:36:33,693 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 25.13 sec
2018-01-03 12:36:36,794 Stage-1 map = 39%,  reduce = 4%, Cumulative CPU 28.66 sec
2018-01-03 12:36:39,888 Stage-1 map = 41%,  reduce = 4%, Cumulative CPU 43.02 sec
2018-01-03 12:36:42,983 Stage-1 map = 43%,  reduce = 4%, Cumulative CPU 51.47 sec
2018-01-03 12:36:45,044 Stage-1 map = 43%,  reduce = 7%, Cumulative CPU 52.16 sec
2018-01-03 12:36:46,075 Stage-1 map = 46%,  reduce = 7%, Cumulative CPU 66.41 sec
2018-01-03 12:36:47,106 Stage-1 map = 46%,  reduce = 11%, Cumulative CPU 66.91 sec
2018-01-03 12:36:49,178 Stage-1 map = 49%,  reduce = 11%, Cumulative CPU 81.72 sec
2018-01-03 12:36:51,415 Stage-1 map = 51%,  reduce = 11%, Cumulative CPU 84.99 sec
2018-01-03 12:36:52,474 Stage-1 map = 52%,  reduce = 11%, Cumulative CPU 91.68 sec
2018-01-03 12:36:54,637 Stage-1 map = 54%,  reduce = 11%, Cumulative CPU 95.07 sec
2018-01-03 12:36:55,670 Stage-1 map = 56%,  reduce = 11%, Cumulative CPU 102.98 sec
2018-01-03 12:36:57,732 Stage-1 map = 57%,  reduce = 11%, Cumulative CPU 105.72 sec
2018-01-03 12:36:58,763 Stage-1 map = 58%,  reduce = 11%, Cumulative CPU 107.95 sec
2018-01-03 12:37:01,853 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 117.57 sec
2018-01-03 12:37:03,921 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 119.48 sec
2018-01-03 12:37:07,009 Stage-1 map = 62%,  reduce = 11%, Cumulative CPU 136.95 sec
2018-01-03 12:37:08,039 Stage-1 map = 77%,  reduce = 15%, Cumulative CPU 141.52 sec
2018-01-03 12:37:10,100 Stage-1 map = 77%,  reduce = 19%, Cumulative CPU 144.01 sec
2018-01-03 12:37:11,129 Stage-1 map = 77%,  reduce = 22%, Cumulative CPU 144.9 sec
2018-01-03 12:37:15,245 Stage-1 map = 78%,  reduce = 22%, Cumulative CPU 158.02 sec
2018-01-03 12:37:18,327 Stage-1 map = 80%,  reduce = 22%, Cumulative CPU 160.91 sec
2018-01-03 12:37:21,413 Stage-1 map = 82%,  reduce = 22%, Cumulative CPU 164.0 sec
2018-01-03 12:37:24,497 Stage-1 map = 84%,  reduce = 22%, Cumulative CPU 166.92 sec
2018-01-03 12:37:27,579 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 169.44 sec
2018-01-03 12:37:29,637 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 110.91 sec
2018-01-03 12:37:30,665 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 171.98 sec
2018-01-03 12:37:31,692 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 175.1 sec
2018-01-03 12:37:32,719 Stage-1 map = 100%,  reduce = 48%, Cumulative CPU 179.21 sec
2018-01-03 12:37:33,747 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 188.78 sec
MapReduce Total cumulative CPU time: 3 minutes 8 seconds 780 msec
Ended Job = job_1513599404024_167774
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167776, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167776/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167776
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:37:41,528 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:37:47,726 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.14 sec
2018-01-03 12:37:48,759 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.38 sec
2018-01-03 12:37:52,878 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.43 sec
MapReduce Total cumulative CPU time: 14 seconds 430 msec
Ended Job = job_1513599404024_167776
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167777, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167777/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167777
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:38:14,581 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:38:19,724 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.66 sec
2018-01-03 12:38:25,890 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.02 sec
MapReduce Total cumulative CPU time: 5 seconds 20 msec
Ended Job = job_1513599404024_167777
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 188.78 sec   HDFS Read: 293719097 HDFS Write: 282812 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.43 sec   HDFS Read: 40052482 HDFS Write: 20050 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.02 sec   HDFS Read: 27722 HDFS Write: 2172 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 28 seconds 230 msec
OK
Time taken: 140.115 seconds, Fetched: 305 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103123841_9da73614-3305-4104-bd41-f4d735b6f2b7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167781, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167781/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167781
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:38:52,430 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:39:02,803 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 10.37 sec
2018-01-03 12:39:05,905 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 14.13 sec
2018-01-03 12:39:08,997 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 14.93 sec
2018-01-03 12:39:12,120 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 15.71 sec
2018-01-03 12:39:14,183 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 16.31 sec
2018-01-03 12:39:17,279 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 17.17 sec
2018-01-03 12:39:20,367 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 18.01 sec
2018-01-03 12:39:23,457 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 18.56 sec
2018-01-03 12:39:26,542 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 19.06 sec
2018-01-03 12:39:29,627 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 20.38 sec
2018-01-03 12:39:32,717 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 21.15 sec
2018-01-03 12:39:33,747 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 22.39 sec
2018-01-03 12:39:38,893 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 26.89 sec
MapReduce Total cumulative CPU time: 26 seconds 890 msec
Ended Job = job_1513599404024_167781
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167784, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167784/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167784
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:39:46,606 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:39:52,845 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.55 sec
2018-01-03 12:40:01,089 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.72 sec
2018-01-03 12:40:02,120 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.08 sec
MapReduce Total cumulative CPU time: 17 seconds 80 msec
Ended Job = job_1513599404024_167784
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167786, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167786/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167786
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:40:09,756 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:40:14,919 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec
2018-01-03 12:40:21,098 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.92 sec
MapReduce Total cumulative CPU time: 5 seconds 920 msec
Ended Job = job_1513599404024_167786
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 26.89 sec   HDFS Read: 40383005 HDFS Write: 499090 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.08 sec   HDFS Read: 40268186 HDFS Write: 156086 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.92 sec   HDFS Read: 163723 HDFS Write: 5722 SUCCESS
Total MapReduce CPU Time Spent: 49 seconds 890 msec
OK
Time taken: 101.556 seconds, Fetched: 657 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103124029_fc6376ba-00f9-4e45-afaa-d7f8ba0d14b5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167796, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167796/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167796
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:41:13,210 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:42:13,887 Stage-1 map = 0%,  reduce = 0%, Cumulative CPU 8.95 sec
2018-01-03 12:42:14,918 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 17.62 sec
2018-01-03 12:42:20,069 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 19.53 sec
2018-01-03 12:42:23,155 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 21.98 sec
2018-01-03 12:42:26,244 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 24.73 sec
2018-01-03 12:42:29,331 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 26.6 sec
2018-01-03 12:42:32,418 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 28.49 sec
2018-01-03 12:42:35,505 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 31.11 sec
2018-01-03 12:42:38,589 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 33.94 sec
2018-01-03 12:42:41,672 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 35.42 sec
2018-01-03 12:42:44,758 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 37.48 sec
2018-01-03 12:42:45,786 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 39.24 sec
2018-01-03 12:42:51,955 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 44.16 sec
MapReduce Total cumulative CPU time: 44 seconds 160 msec
Ended Job = job_1513599404024_167796
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167801, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167801/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167801
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:42:58,021 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:43:04,209 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.15 sec
2018-01-03 12:43:08,337 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.65 sec
2018-01-03 12:43:09,367 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.89 sec
MapReduce Total cumulative CPU time: 14 seconds 890 msec
Ended Job = job_1513599404024_167801
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167803, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167803/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167803
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:43:14,991 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:43:23,213 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.16 sec
2018-01-03 12:43:28,379 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.41 sec
MapReduce Total cumulative CPU time: 7 seconds 410 msec
Ended Job = job_1513599404024_167803
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 44.16 sec   HDFS Read: 40382995 HDFS Write: 818563 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.89 sec   HDFS Read: 40587659 HDFS Write: 140963 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.41 sec   HDFS Read: 148601 HDFS Write: 3228 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 6 seconds 460 msec
OK
Time taken: 180.569 seconds, Fetched: 488 row(s)
开始执行20171103日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.365 seconds
Query ID = boss_20180103124337_c58fdc35-fa99-4ab4-814a-9326e19e83bd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167805, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167805/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167805
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 12:43:48,496 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:43:58,961 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 11.27 sec
2018-01-03 12:44:02,062 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 15.52 sec
2018-01-03 12:44:05,162 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 19.14 sec
2018-01-03 12:44:08,255 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 22.5 sec
2018-01-03 12:44:11,349 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 25.47 sec
2018-01-03 12:44:14,440 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 29.03 sec
2018-01-03 12:44:17,529 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 32.01 sec
2018-01-03 12:44:20,623 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 35.03 sec
2018-01-03 12:44:22,683 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 48.9 sec
2018-01-03 12:44:23,714 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 52.55 sec
2018-01-03 12:44:24,743 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 56.52 sec
2018-01-03 12:44:26,804 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 59.88 sec
2018-01-03 12:44:29,910 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 62.69 sec
2018-01-03 12:44:32,995 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 65.52 sec
2018-01-03 12:44:36,086 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 70.66 sec
2018-01-03 12:44:37,115 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 80.68 sec
MapReduce Total cumulative CPU time: 1 minutes 20 seconds 680 msec
Ended Job = job_1513599404024_167805
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167809, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167809/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167809
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:44:44,894 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:44:50,152 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.68 sec
2018-01-03 12:44:51,185 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.21 sec
2018-01-03 12:45:00,459 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.21 sec
MapReduce Total cumulative CPU time: 18 seconds 210 msec
Ended Job = job_1513599404024_167809
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167810, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167810/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167810
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:45:14,097 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:45:19,247 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.31 sec
2018-01-03 12:45:25,432 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.87 sec
MapReduce Total cumulative CPU time: 6 seconds 870 msec
Ended Job = job_1513599404024_167810
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 80.68 sec   HDFS Read: 200341551 HDFS Write: 1671353 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.21 sec   HDFS Read: 44428759 HDFS Write: 160079 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.87 sec   HDFS Read: 167754 HDFS Write: 3205 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 45 seconds 760 msec
OK
Time taken: 109.166 seconds, Fetched: 406 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.386 seconds
Query ID = boss_20180103124533_6b9536d3-6aff-4e78-9dfa-6b1feaf4875e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167812, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167812/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167812
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 12:45:47,361 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:45:58,749 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 30.85 sec
2018-01-03 12:45:59,783 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 44.15 sec
2018-01-03 12:46:01,850 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 55.0 sec
2018-01-03 12:46:02,882 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 66.92 sec
2018-01-03 12:46:04,952 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 78.59 sec
2018-01-03 12:46:08,125 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 90.03 sec
2018-01-03 12:46:11,226 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 96.18 sec
2018-01-03 12:46:14,316 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 103.07 sec
2018-01-03 12:46:15,351 Stage-1 map = 58%,  reduce = 4%, Cumulative CPU 103.56 sec
2018-01-03 12:46:17,413 Stage-1 map = 62%,  reduce = 7%, Cumulative CPU 110.59 sec
2018-01-03 12:46:20,508 Stage-1 map = 67%,  reduce = 7%, Cumulative CPU 117.71 sec
2018-01-03 12:46:23,600 Stage-1 map = 72%,  reduce = 7%, Cumulative CPU 124.27 sec
2018-01-03 12:46:24,636 Stage-1 map = 84%,  reduce = 7%, Cumulative CPU 126.51 sec
2018-01-03 12:46:25,676 Stage-1 map = 84%,  reduce = 15%, Cumulative CPU 127.29 sec
2018-01-03 12:46:26,714 Stage-1 map = 86%,  reduce = 19%, Cumulative CPU 130.23 sec
2018-01-03 12:46:27,759 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 130.29 sec
2018-01-03 12:46:28,826 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 133.34 sec
2018-01-03 12:46:29,860 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 135.2 sec
2018-01-03 12:46:30,894 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 143.27 sec
2018-01-03 12:46:31,951 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 147.12 sec
MapReduce Total cumulative CPU time: 2 minutes 27 seconds 120 msec
Ended Job = job_1513599404024_167812
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167817, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167817/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167817
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:46:38,761 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:46:43,913 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.44 sec
2018-01-03 12:46:47,016 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.62 sec
2018-01-03 12:46:57,304 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 10.62 sec
MapReduce Total cumulative CPU time: 10 seconds 620 msec
Ended Job = job_1513599404024_167817
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167818, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167818/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167818
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:47:10,099 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:47:14,230 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.33 sec
2018-01-03 12:47:20,410 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.69 sec
MapReduce Total cumulative CPU time: 4 seconds 690 msec
Ended Job = job_1513599404024_167818
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 147.12 sec   HDFS Read: 326106210 HDFS Write: 294621 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.12 sec   HDFS Read: 43052289 HDFS Write: 19728 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.69 sec   HDFS Read: 27404 HDFS Write: 2285 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 46 seconds 930 msec
OK
Time taken: 108.165 seconds, Fetched: 313 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.348 seconds
Query ID = boss_20180103124728_8909eea8-c0bb-4420-bb18-36be4f935612
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167819, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167819/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167819
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:47:45,631 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:47:56,006 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 10.22 sec
2018-01-03 12:47:57,041 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 11.6 sec
2018-01-03 12:48:03,249 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 15.39 sec
MapReduce Total cumulative CPU time: 15 seconds 390 msec
Ended Job = job_1513599404024_167819
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167821, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167821/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167821
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:48:09,108 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:48:14,287 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.79 sec
2018-01-03 12:48:15,322 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.63 sec
2018-01-03 12:48:28,734 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.73 sec
MapReduce Total cumulative CPU time: 13 seconds 730 msec
Ended Job = job_1513599404024_167821
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167823, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167823/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167823
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:48:34,412 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:48:39,562 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.97 sec
2018-01-03 12:48:52,935 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.67 sec
MapReduce Total cumulative CPU time: 5 seconds 670 msec
Ended Job = job_1513599404024_167823
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 15.39 sec   HDFS Read: 12748559 HDFS Write: 710138 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.73 sec   HDFS Read: 43467226 HDFS Write: 205985 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.67 sec   HDFS Read: 213622 HDFS Write: 5532 SUCCESS
Total MapReduce CPU Time Spent: 34 seconds 790 msec
OK
Time taken: 85.827 seconds, Fetched: 642 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103124900_c285d2ca-6f48-44c2-bbc0-b387bc4a4424
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167825, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167825/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167825
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:49:10,358 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:49:20,741 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 10.64 sec
2018-01-03 12:49:22,815 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.45 sec
2018-01-03 12:49:36,233 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.57 sec
MapReduce Total cumulative CPU time: 17 seconds 570 msec
Ended Job = job_1513599404024_167825
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167827, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167827/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167827
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:49:42,974 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:49:49,166 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.13 sec
2018-01-03 12:49:56,378 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.44 sec
2018-01-03 12:49:57,407 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.89 sec
MapReduce Total cumulative CPU time: 14 seconds 890 msec
Ended Job = job_1513599404024_167827
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167828, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167828/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167828
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:50:12,310 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:50:37,990 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.8 sec
2018-01-03 12:50:45,178 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.39 sec
MapReduce Total cumulative CPU time: 5 seconds 390 msec
Ended Job = job_1513599404024_167828
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.57 sec   HDFS Read: 12748549 HDFS Write: 844489 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.89 sec   HDFS Read: 43601577 HDFS Write: 128714 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.39 sec   HDFS Read: 136352 HDFS Write: 3207 SUCCESS
Total MapReduce CPU Time Spent: 37 seconds 850 msec
OK
Time taken: 105.544 seconds, Fetched: 497 row(s)
开始执行20171104日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103125053_37591af6-a9c4-4666-bc20-8f06aef7e88d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167831, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167831/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167831
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 12:51:02,118 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:51:11,435 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 11.78 sec
2018-01-03 12:51:14,532 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 15.67 sec
2018-01-03 12:51:17,626 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 31.19 sec
2018-01-03 12:51:20,716 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 34.86 sec
2018-01-03 12:51:22,777 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 38.06 sec
2018-01-03 12:51:25,869 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 41.19 sec
2018-01-03 12:51:27,934 Stage-1 map = 62%,  reduce = 17%, Cumulative CPU 42.08 sec
2018-01-03 12:51:28,964 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 45.42 sec
2018-01-03 12:51:32,053 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 48.72 sec
2018-01-03 12:51:35,142 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 51.91 sec
2018-01-03 12:51:38,228 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 55.39 sec
2018-01-03 12:51:41,314 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 59.9 sec
2018-01-03 12:51:42,342 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 51.77 sec
2018-01-03 12:51:44,401 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 62.94 sec
2018-01-03 12:51:45,430 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 55.17 sec
2018-01-03 12:51:46,457 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 56.36 sec
2018-01-03 12:51:47,486 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 64.94 sec
MapReduce Total cumulative CPU time: 1 minutes 4 seconds 940 msec
Ended Job = job_1513599404024_167831
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167833, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167833/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167833
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:51:53,223 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:51:58,399 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.17 sec
2018-01-03 12:52:06,651 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.98 sec
2018-01-03 12:52:12,837 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.81 sec
MapReduce Total cumulative CPU time: 16 seconds 810 msec
Ended Job = job_1513599404024_167833
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167836, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167836/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167836
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:52:19,497 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:52:24,658 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.03 sec
2018-01-03 12:52:29,807 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.91 sec
MapReduce Total cumulative CPU time: 5 seconds 910 msec
Ended Job = job_1513599404024_167836
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 64.94 sec   HDFS Read: 237950308 HDFS Write: 1767340 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.81 sec   HDFS Read: 45952804 HDFS Write: 165245 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.91 sec   HDFS Read: 172916 HDFS Write: 3069 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 27 seconds 660 msec
OK
Time taken: 97.633 seconds, Fetched: 407 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.406 seconds
Query ID = boss_20180103125237_6ef16e43-387e-4dd1-b313-808f4c154db5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167838, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167838/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167838
Hadoop job information for Stage-1: number of mappers: 4; number of reducers: 4
2018-01-03 12:52:46,551 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:52:55,879 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 24.62 sec
2018-01-03 12:52:56,912 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 37.15 sec
2018-01-03 12:52:58,975 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 41.0 sec
2018-01-03 12:53:00,010 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 44.23 sec
2018-01-03 12:53:02,071 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 47.43 sec
2018-01-03 12:53:03,102 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 53.07 sec
2018-01-03 12:53:04,133 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 65.24 sec
2018-01-03 12:53:06,193 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 68.26 sec
2018-01-03 12:53:07,228 Stage-1 map = 61%,  reduce = 4%, Cumulative CPU 72.79 sec
2018-01-03 12:53:08,259 Stage-1 map = 61%,  reduce = 8%, Cumulative CPU 73.49 sec
2018-01-03 12:53:09,293 Stage-1 map = 62%,  reduce = 13%, Cumulative CPU 77.2 sec
2018-01-03 12:53:10,324 Stage-1 map = 65%,  reduce = 13%, Cumulative CPU 80.04 sec
2018-01-03 12:53:12,384 Stage-1 map = 66%,  reduce = 13%, Cumulative CPU 83.24 sec
2018-01-03 12:53:13,414 Stage-1 map = 68%,  reduce = 13%, Cumulative CPU 85.55 sec
2018-01-03 12:53:15,473 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 89.03 sec
2018-01-03 12:53:16,503 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 92.69 sec
2018-01-03 12:53:18,563 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 96.28 sec
2018-01-03 12:53:19,592 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 99.48 sec
2018-01-03 12:53:21,649 Stage-1 map = 89%,  reduce = 17%, Cumulative CPU 105.7 sec
2018-01-03 12:53:22,678 Stage-1 map = 89%,  reduce = 21%, Cumulative CPU 105.83 sec
2018-01-03 12:53:23,707 Stage-1 map = 91%,  reduce = 21%, Cumulative CPU 109.17 sec
2018-01-03 12:53:24,735 Stage-1 map = 91%,  reduce = 25%, Cumulative CPU 109.34 sec
2018-01-03 12:53:25,764 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 112.08 sec
2018-01-03 12:53:26,792 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 118.83 sec
2018-01-03 12:53:27,824 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 126.7 sec
MapReduce Total cumulative CPU time: 2 minutes 6 seconds 700 msec
Ended Job = job_1513599404024_167838
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167840, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167840/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167840
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:53:33,763 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:53:38,943 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.87 sec
2018-01-03 12:53:46,168 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.69 sec
MapReduce Total cumulative CPU time: 13 seconds 690 msec
Ended Job = job_1513599404024_167840
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167842, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167842/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167842
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:53:52,827 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:53:57,990 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.64 sec
2018-01-03 12:54:12,388 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.49 sec
MapReduce Total cumulative CPU time: 5 seconds 490 msec
Ended Job = job_1513599404024_167842
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 4  Reduce: 4   Cumulative CPU: 126.7 sec   HDFS Read: 399341313 HDFS Write: 350708 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.69 sec   HDFS Read: 44536701 HDFS Write: 21532 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.49 sec   HDFS Read: 29208 HDFS Write: 2264 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 25 seconds 880 msec
OK
Time taken: 95.773 seconds, Fetched: 322 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103125420_5e1c3d40-8d0b-4f03-9ff7-7147adf3df10
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167844, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167844/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167844
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:54:28,621 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:54:40,007 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 9.92 sec
2018-01-03 12:54:42,071 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 11.48 sec
2018-01-03 12:54:45,162 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.52 sec
2018-01-03 12:54:51,347 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.38 sec
MapReduce Total cumulative CPU time: 17 seconds 380 msec
Ended Job = job_1513599404024_167844
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167846, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167846/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167846
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:54:57,073 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:55:02,246 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.09 sec
2018-01-03 12:55:10,506 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.86 sec
2018-01-03 12:55:12,570 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.29 sec
MapReduce Total cumulative CPU time: 14 seconds 290 msec
Ended Job = job_1513599404024_167846
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167848, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167848/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167848
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:55:19,231 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:55:52,132 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.91 sec
2018-01-03 12:55:58,299 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.56 sec
MapReduce Total cumulative CPU time: 5 seconds 560 msec
Ended Job = job_1513599404024_167848
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.38 sec   HDFS Read: 14178571 HDFS Write: 740180 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.29 sec   HDFS Read: 44925331 HDFS Write: 236951 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.56 sec   HDFS Read: 244588 HDFS Write: 6213 SUCCESS
Total MapReduce CPU Time Spent: 37 seconds 230 msec
OK
Time taken: 99.243 seconds, Fetched: 712 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103125606_635ee200-6dbd-4739-9953-abe6d5f61475
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167852, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167852/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167852
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 12:56:38,214 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:56:48,589 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 11.84 sec
2018-01-03 12:56:51,695 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.36 sec
2018-01-03 12:56:56,864 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.83 sec
MapReduce Total cumulative CPU time: 19 seconds 830 msec
Ended Job = job_1513599404024_167852
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167856, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167856/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167856
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:57:02,675 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:57:07,833 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.79 sec
2018-01-03 12:57:22,273 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.23 sec
2018-01-03 12:57:24,333 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.71 sec
MapReduce Total cumulative CPU time: 16 seconds 710 msec
Ended Job = job_1513599404024_167856
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167858, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167858/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167858
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:57:45,014 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:57:56,368 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.31 sec
2018-01-03 12:58:02,551 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.09 sec
MapReduce Total cumulative CPU time: 7 seconds 90 msec
Ended Job = job_1513599404024_167858
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.83 sec   HDFS Read: 14178561 HDFS Write: 949880 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.71 sec   HDFS Read: 45135031 HDFS Write: 146711 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.09 sec   HDFS Read: 154349 HDFS Write: 3397 SUCCESS
Total MapReduce CPU Time Spent: 43 seconds 630 msec
OK
Time taken: 118.109 seconds, Fetched: 437 row(s)
开始执行20171105日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.365 seconds
Query ID = boss_20180103125811_c517911c-daf3-49bb-9587-3bb082edb90b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167861, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167861/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167861
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 12:58:20,582 Stage-1 map = 0%,  reduce = 0%
2018-01-03 12:58:30,951 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.26 sec
2018-01-03 12:58:34,056 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 16.29 sec
2018-01-03 12:58:37,154 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 19.56 sec
2018-01-03 12:58:40,250 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 22.86 sec
2018-01-03 12:58:41,281 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 36.89 sec
2018-01-03 12:58:43,348 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 40.1 sec
2018-01-03 12:58:44,380 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 44.48 sec
2018-01-03 12:58:46,443 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 47.59 sec
2018-01-03 12:58:47,474 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 51.22 sec
2018-01-03 12:58:48,507 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 54.18 sec
2018-01-03 12:58:49,539 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 57.34 sec
2018-01-03 12:58:52,637 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 61.05 sec
2018-01-03 12:58:55,729 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 64.12 sec
2018-01-03 12:58:58,822 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 67.3 sec
2018-01-03 12:58:59,859 Stage-1 map = 80%,  reduce = 8%, Cumulative CPU 67.78 sec
2018-01-03 12:59:01,927 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 71.68 sec
2018-01-03 12:59:02,958 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 80.26 sec
MapReduce Total cumulative CPU time: 1 minutes 20 seconds 260 msec
Ended Job = job_1513599404024_167861
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167863, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167863/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167863
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 12:59:12,707 Stage-2 map = 0%,  reduce = 0%
2018-01-03 12:59:17,878 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.56 sec
2018-01-03 12:59:26,131 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.14 sec
2018-01-03 12:59:28,194 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.86 sec
MapReduce Total cumulative CPU time: 14 seconds 860 msec
Ended Job = job_1513599404024_167863
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167864, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167864/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167864
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 12:59:34,861 Stage-3 map = 0%,  reduce = 0%
2018-01-03 12:59:38,991 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.93 sec
2018-01-03 12:59:45,180 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.48 sec
MapReduce Total cumulative CPU time: 5 seconds 480 msec
Ended Job = job_1513599404024_167864
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 80.26 sec   HDFS Read: 230136383 HDFS Write: 1770684 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.86 sec   HDFS Read: 44915408 HDFS Write: 162567 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.48 sec   HDFS Read: 170242 HDFS Write: 3022 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 40 seconds 600 msec
OK
Time taken: 95.708 seconds, Fetched: 392 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.382 seconds
Query ID = boss_20180103125953_c0f62e30-a049-4578-b99b-03619c04dfc6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167865, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167865/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167865
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 4
2018-01-03 13:00:03,880 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:00:14,239 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 23.97 sec
2018-01-03 13:00:17,339 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 31.17 sec
2018-01-03 13:00:20,432 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 41.15 sec
2018-01-03 13:00:21,463 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 54.41 sec
2018-01-03 13:00:23,524 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 64.38 sec
2018-01-03 13:00:26,618 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 73.82 sec
2018-01-03 13:00:29,716 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 82.67 sec
2018-01-03 13:00:32,813 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 90.37 sec
2018-01-03 13:00:35,905 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 98.67 sec
2018-01-03 13:00:36,934 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 100.74 sec
2018-01-03 13:00:38,998 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 106.51 sec
2018-01-03 13:00:42,087 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 112.3 sec
2018-01-03 13:00:43,118 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 114.18 sec
2018-01-03 13:00:44,160 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 117.04 sec
2018-01-03 13:00:45,203 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 124.9 sec
2018-01-03 13:00:47,262 Stage-1 map = 100%,  reduce = 75%, Cumulative CPU 128.28 sec
2018-01-03 13:00:51,385 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 133.01 sec
MapReduce Total cumulative CPU time: 2 minutes 13 seconds 10 msec
Ended Job = job_1513599404024_167865
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167873, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167873/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167873
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:01:00,444 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:01:04,720 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.71 sec
2018-01-03 13:01:05,761 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.98 sec
2018-01-03 13:01:11,941 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.35 sec
MapReduce Total cumulative CPU time: 16 seconds 350 msec
Ended Job = job_1513599404024_167873
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167875, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167875/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167875
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:01:17,631 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:01:31,030 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.51 sec
2018-01-03 13:01:45,446 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.24 sec
MapReduce Total cumulative CPU time: 6 seconds 240 msec
Ended Job = job_1513599404024_167875
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 4   Cumulative CPU: 133.01 sec   HDFS Read: 391446942 HDFS Write: 335596 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.35 sec   HDFS Read: 43480844 HDFS Write: 20203 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.24 sec   HDFS Read: 27879 HDFS Write: 2226 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 35 seconds 600 msec
OK
Time taken: 112.541 seconds, Fetched: 316 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.351 seconds
Query ID = boss_20180103130201_67c6cc91-18bc-4aa3-9bfd-738d3c1ac66d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167880, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167880/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167880
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:02:10,760 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:02:22,183 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 10.35 sec
2018-01-03 13:02:25,296 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.62 sec
2018-01-03 13:02:37,685 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.69 sec
MapReduce Total cumulative CPU time: 18 seconds 690 msec
Ended Job = job_1513599404024_167880
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167882, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167882/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167882
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:02:44,452 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:02:49,624 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.76 sec
2018-01-03 13:02:57,869 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.99 sec
2018-01-03 13:02:59,931 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.39 sec
MapReduce Total cumulative CPU time: 16 seconds 390 msec
Ended Job = job_1513599404024_167882
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167885, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167885/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167885
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:03:05,541 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:03:17,888 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.39 sec
2018-01-03 13:03:25,088 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.23 sec
MapReduce Total cumulative CPU time: 7 seconds 230 msec
Ended Job = job_1513599404024_167885
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.69 sec   HDFS Read: 13514563 HDFS Write: 690343 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.39 sec   HDFS Read: 43834749 HDFS Write: 241610 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.23 sec   HDFS Read: 249247 HDFS Write: 6428 SUCCESS
Total MapReduce CPU Time Spent: 42 seconds 310 msec
OK
Time taken: 84.944 seconds, Fetched: 746 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103130332_4e033b68-d621-40a8-be57-ee2f59ff9030
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167888, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167888/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167888
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:03:45,832 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:03:56,194 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 13.18 sec
2018-01-03 13:03:59,298 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 18.35 sec
2018-01-03 13:04:04,464 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 22.64 sec
MapReduce Total cumulative CPU time: 22 seconds 640 msec
Ended Job = job_1513599404024_167888
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167892, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167892/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167892
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:04:18,209 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:04:25,424 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.39 sec
2018-01-03 13:04:30,569 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.18 sec
2018-01-03 13:04:31,599 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.52 sec
MapReduce Total cumulative CPU time: 17 seconds 520 msec
Ended Job = job_1513599404024_167892
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167894, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167894/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167894
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:04:41,389 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:04:45,528 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.01 sec
2018-01-03 13:04:52,835 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.11 sec
MapReduce Total cumulative CPU time: 6 seconds 110 msec
Ended Job = job_1513599404024_167894
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 22.64 sec   HDFS Read: 13514553 HDFS Write: 961250 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.52 sec   HDFS Read: 44105656 HDFS Write: 149762 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.11 sec   HDFS Read: 157400 HDFS Write: 3139 SUCCESS
Total MapReduce CPU Time Spent: 46 seconds 270 msec
OK
Time taken: 82.065 seconds, Fetched: 450 row(s)
开始执行20171106日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.474 seconds
Query ID = boss_20180103130501_45ba49af-893c-4c58-913a-2289e6cf7f94
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167897, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167897/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167897
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 13:05:20,318 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:05:31,722 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 14.08 sec
2018-01-03 13:05:34,822 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 30.96 sec
2018-01-03 13:05:35,855 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 37.23 sec
2018-01-03 13:05:37,934 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 40.6 sec
2018-01-03 13:05:41,028 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 44.16 sec
2018-01-03 13:05:44,150 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 64.37 sec
2018-01-03 13:05:47,279 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 73.1 sec
2018-01-03 13:05:50,895 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 76.41 sec
2018-01-03 13:05:52,987 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 80.44 sec
2018-01-03 13:05:55,056 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 81.15 sec
2018-01-03 13:05:56,088 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 85.4 sec
2018-01-03 13:05:59,175 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 96.92 sec
2018-01-03 13:06:03,297 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 111.41 sec
2018-01-03 13:06:06,405 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 114.58 sec
2018-01-03 13:06:10,001 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 117.66 sec
2018-01-03 13:06:11,033 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 119.45 sec
2018-01-03 13:06:12,664 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 125.29 sec
MapReduce Total cumulative CPU time: 2 minutes 5 seconds 290 msec
Ended Job = job_1513599404024_167897
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167903, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167903/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167903
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:06:35,008 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:06:40,170 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.82 sec
2018-01-03 13:06:42,233 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.05 sec
2018-01-03 13:06:46,363 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.22 sec
MapReduce Total cumulative CPU time: 18 seconds 220 msec
Ended Job = job_1513599404024_167903
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167906, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167906/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167906
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:06:52,093 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:06:58,309 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.76 sec
2018-01-03 13:07:04,494 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.91 sec
MapReduce Total cumulative CPU time: 8 seconds 910 msec
Ended Job = job_1513599404024_167906
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 131.09 sec   HDFS Read: 178284968 HDFS Write: 1698223 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.22 sec   HDFS Read: 45108854 HDFS Write: 237237 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.91 sec   HDFS Read: 244912 HDFS Write: 2995 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 38 seconds 220 msec
OK
Time taken: 123.576 seconds, Fetched: 377 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.389 seconds
Query ID = boss_20180103130712_d1abd092-dd36-4a40-a9ec-70ed8eb963da
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167911, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167911/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167911
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 13:07:22,389 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:07:32,735 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 24.81 sec
2018-01-03 13:07:35,836 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 28.26 sec
2018-01-03 13:07:38,930 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 32.52 sec
2018-01-03 13:07:42,020 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 35.67 sec
2018-01-03 13:07:43,058 Stage-1 map = 43%,  reduce = 4%, Cumulative CPU 36.15 sec
2018-01-03 13:07:44,091 Stage-1 map = 43%,  reduce = 11%, Cumulative CPU 37.46 sec
2018-01-03 13:07:45,125 Stage-1 map = 45%,  reduce = 11%, Cumulative CPU 40.62 sec
2018-01-03 13:07:46,166 Stage-1 map = 51%,  reduce = 11%, Cumulative CPU 52.43 sec
2018-01-03 13:07:48,225 Stage-1 map = 53%,  reduce = 11%, Cumulative CPU 55.66 sec
2018-01-03 13:07:49,255 Stage-1 map = 56%,  reduce = 11%, Cumulative CPU 58.96 sec
2018-01-03 13:07:51,313 Stage-1 map = 58%,  reduce = 11%, Cumulative CPU 62.05 sec
2018-01-03 13:07:52,342 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 65.48 sec
2018-01-03 13:07:54,403 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 68.6 sec
2018-01-03 13:07:55,433 Stage-1 map = 68%,  reduce = 11%, Cumulative CPU 72.29 sec
2018-01-03 13:07:57,490 Stage-1 map = 70%,  reduce = 11%, Cumulative CPU 75.55 sec
2018-01-03 13:07:58,520 Stage-1 map = 85%,  reduce = 19%, Cumulative CPU 80.85 sec
2018-01-03 13:07:59,550 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 80.88 sec
2018-01-03 13:08:01,609 Stage-1 map = 100%,  reduce = 27%, Cumulative CPU 84.82 sec
2018-01-03 13:08:02,642 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 91.17 sec
2018-01-03 13:08:04,699 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 96.69 sec
MapReduce Total cumulative CPU time: 1 minutes 36 seconds 690 msec
Ended Job = job_1513599404024_167911
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167916, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167916/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167916
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:08:10,360 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:08:15,583 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.48 sec
2018-01-03 13:08:22,784 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.29 sec
2018-01-03 13:08:24,843 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.7 sec
MapReduce Total cumulative CPU time: 13 seconds 700 msec
Ended Job = job_1513599404024_167916
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167919, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167919/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167919
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:08:30,544 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:08:49,067 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.41 sec
2018-01-03 13:08:56,274 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.0 sec
MapReduce Total cumulative CPU time: 5 seconds 0 msec
Ended Job = job_1513599404024_167919
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 96.69 sec   HDFS Read: 302688221 HDFS Write: 265692 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.7 sec   HDFS Read: 43676585 HDFS Write: 19628 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.0 sec   HDFS Read: 27304 HDFS Write: 2083 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 55 seconds 390 msec
OK
Time taken: 105.072 seconds, Fetched: 300 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.417 seconds
Query ID = boss_20180103130904_5a24aa88-e00d-495c-a462-7d880c7a6994
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167923, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167923/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167923
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:09:23,266 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:09:35,707 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 11.34 sec
2018-01-03 13:09:38,808 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.88 sec
2018-01-03 13:09:43,978 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.89 sec
MapReduce Total cumulative CPU time: 19 seconds 890 msec
Ended Job = job_1513599404024_167923
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167928, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167928/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167928
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:09:50,699 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:09:55,855 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.37 sec
2018-01-03 13:09:56,885 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.17 sec
2018-01-03 13:10:05,127 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.49 sec
MapReduce Total cumulative CPU time: 15 seconds 490 msec
Ended Job = job_1513599404024_167928
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167930, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167930/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167930
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:10:13,826 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:10:20,085 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.79 sec
2018-01-03 13:10:25,307 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.24 sec
MapReduce Total cumulative CPU time: 7 seconds 240 msec
Ended Job = job_1513599404024_167930
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.89 sec   HDFS Read: 12123440 HDFS Write: 479885 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.49 sec   HDFS Read: 43890198 HDFS Write: 181105 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.24 sec   HDFS Read: 188742 HDFS Write: 6077 SUCCESS
Total MapReduce CPU Time Spent: 42 seconds 620 msec
OK
Time taken: 83.331 seconds, Fetched: 764 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.362 seconds
Query ID = boss_20180103131034_dfa1db99-3c29-4d5f-af0a-7066b9ad543f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167932, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167932/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167932
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:10:45,850 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:10:55,179 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.04 sec
2018-01-03 13:11:04,474 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.4 sec
MapReduce Total cumulative CPU time: 18 seconds 400 msec
Ended Job = job_1513599404024_167932
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167933, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167933/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167933
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:11:10,407 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:11:16,624 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.85 sec
2018-01-03 13:11:23,858 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.83 sec
2018-01-03 13:11:25,922 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.55 sec
MapReduce Total cumulative CPU time: 17 seconds 550 msec
Ended Job = job_1513599404024_167933
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167935, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167935/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167935
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:11:34,693 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:11:38,825 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.66 sec
2018-01-03 13:11:45,009 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.34 sec
MapReduce Total cumulative CPU time: 5 seconds 340 msec
Ended Job = job_1513599404024_167935
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.4 sec   HDFS Read: 12123430 HDFS Write: 888392 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.55 sec   HDFS Read: 44298705 HDFS Write: 136101 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.34 sec   HDFS Read: 143739 HDFS Write: 3454 SUCCESS
Total MapReduce CPU Time Spent: 41 seconds 290 msec
OK
Time taken: 71.847 seconds, Fetched: 431 row(s)
开始执行20171107日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.367 seconds
Query ID = boss_20180103131152_89394d67-a1a7-424a-8cbb-1e7b18c8a993
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167938, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167938/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167938
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 13:12:02,882 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:12:12,235 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 13.49 sec
2018-01-03 13:12:13,268 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 30.2 sec
2018-01-03 13:12:16,377 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 35.26 sec
2018-01-03 13:12:18,440 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 39.0 sec
2018-01-03 13:12:21,533 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 41.9 sec
2018-01-03 13:12:24,634 Stage-1 map = 63%,  reduce = 8%, Cumulative CPU 45.65 sec
2018-01-03 13:12:27,728 Stage-1 map = 65%,  reduce = 8%, Cumulative CPU 49.46 sec
2018-01-03 13:12:30,818 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 53.24 sec
2018-01-03 13:12:33,911 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 57.3 sec
2018-01-03 13:12:36,999 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 60.65 sec
2018-01-03 13:12:40,087 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 64.53 sec
2018-01-03 13:12:43,174 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 67.98 sec
2018-01-03 13:12:46,263 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 71.35 sec
2018-01-03 13:12:48,320 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 74.12 sec
2018-01-03 13:12:49,350 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 75.72 sec
2018-01-03 13:12:50,378 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 80.42 sec
2018-01-03 13:12:52,436 Stage-1 map = 100%,  reduce = 84%, Cumulative CPU 84.42 sec
2018-01-03 13:12:54,493 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 87.51 sec
MapReduce Total cumulative CPU time: 1 minutes 27 seconds 510 msec
Ended Job = job_1513599404024_167938
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167940, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167940/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167940
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:13:01,212 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:13:09,495 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.53 sec
2018-01-03 13:13:10,526 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.07 sec
2018-01-03 13:13:19,850 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.07 sec
MapReduce Total cumulative CPU time: 23 seconds 70 msec
Ended Job = job_1513599404024_167940
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167943, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167943/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167943
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:13:42,636 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:13:53,982 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.81 sec
2018-01-03 13:13:59,138 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.84 sec
MapReduce Total cumulative CPU time: 6 seconds 840 msec
Ended Job = job_1513599404024_167943
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 87.51 sec   HDFS Read: 180373665 HDFS Write: 1732602 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.07 sec   HDFS Read: 46040857 HDFS Write: 231341 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.84 sec   HDFS Read: 239016 HDFS Write: 2868 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 57 seconds 420 msec
OK
Time taken: 127.249 seconds, Fetched: 366 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.415 seconds
Query ID = boss_20180103131407_82dec071-539d-4912-8957-3bf4681c30af
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167945, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167945/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167945
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 13:14:19,828 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:14:29,154 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 24.98 sec
2018-01-03 13:14:30,190 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 36.16 sec
2018-01-03 13:14:32,257 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 42.11 sec
2018-01-03 13:14:33,293 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 45.94 sec
2018-01-03 13:14:35,357 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 49.29 sec
2018-01-03 13:14:36,389 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 52.61 sec
2018-01-03 13:14:38,450 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 56.37 sec
2018-01-03 13:14:39,481 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 59.53 sec
2018-01-03 13:14:41,541 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 63.57 sec
2018-01-03 13:14:42,576 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 66.69 sec
2018-01-03 13:14:44,635 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 70.25 sec
2018-01-03 13:14:45,666 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 73.29 sec
2018-01-03 13:14:47,730 Stage-1 map = 79%,  reduce = 7%, Cumulative CPU 73.79 sec
2018-01-03 13:14:48,761 Stage-1 map = 82%,  reduce = 7%, Cumulative CPU 76.81 sec
2018-01-03 13:14:50,824 Stage-1 map = 84%,  reduce = 7%, Cumulative CPU 80.13 sec
2018-01-03 13:14:53,915 Stage-1 map = 86%,  reduce = 7%, Cumulative CPU 83.19 sec
2018-01-03 13:14:54,945 Stage-1 map = 86%,  reduce = 15%, Cumulative CPU 83.73 sec
2018-01-03 13:14:55,976 Stage-1 map = 88%,  reduce = 15%, Cumulative CPU 76.96 sec
2018-01-03 13:14:57,006 Stage-1 map = 100%,  reduce = 15%, Cumulative CPU 78.46 sec
2018-01-03 13:14:58,035 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 86.59 sec
2018-01-03 13:14:59,065 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 91.12 sec
MapReduce Total cumulative CPU time: 1 minutes 31 seconds 120 msec
Ended Job = job_1513599404024_167945
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167951, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167951/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167951
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:15:12,791 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:15:18,976 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.32 sec
2018-01-03 13:15:28,250 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.72 sec
MapReduce Total cumulative CPU time: 17 seconds 720 msec
Ended Job = job_1513599404024_167951
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167954, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167954/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167954
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:15:57,048 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:16:02,223 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.48 sec
2018-01-03 13:16:07,380 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.8 sec
MapReduce Total cumulative CPU time: 4 seconds 800 msec
Ended Job = job_1513599404024_167954
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 91.12 sec   HDFS Read: 315288183 HDFS Write: 272086 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.72 sec   HDFS Read: 44580603 HDFS Write: 20004 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.8 sec   HDFS Read: 27680 HDFS Write: 2060 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 53 seconds 640 msec
OK
Time taken: 121.275 seconds, Fetched: 286 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103131615_92c62503-f64c-4c0a-be2f-2dafab9b3bca
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167959, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167959/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167959
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:16:26,962 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:16:37,323 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 13.05 sec
2018-01-03 13:16:38,357 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.37 sec
2018-01-03 13:16:43,525 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.13 sec
MapReduce Total cumulative CPU time: 19 seconds 130 msec
Ended Job = job_1513599404024_167959
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167963, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167963/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167963
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:16:49,548 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:16:54,716 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.4 sec
2018-01-03 13:17:00,904 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.66 sec
MapReduce Total cumulative CPU time: 13 seconds 660 msec
Ended Job = job_1513599404024_167963
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167965, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167965/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167965
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:17:22,541 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:17:26,666 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.79 sec
2018-01-03 13:17:34,907 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.32 sec
MapReduce Total cumulative CPU time: 6 seconds 320 msec
Ended Job = job_1513599404024_167965
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.13 sec   HDFS Read: 11927729 HDFS Write: 409791 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.66 sec   HDFS Read: 44717728 HDFS Write: 155120 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.32 sec   HDFS Read: 162757 HDFS Write: 5441 SUCCESS
Total MapReduce CPU Time Spent: 39 seconds 110 msec
OK
Time taken: 80.809 seconds, Fetched: 657 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103131742_e93084c5-57ef-4b19-b383-17eb0e004da1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167968, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167968/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167968
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:17:52,668 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:18:03,067 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 11.55 sec
2018-01-03 13:18:05,133 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.55 sec
2018-01-03 13:18:19,555 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.2 sec
MapReduce Total cumulative CPU time: 21 seconds 200 msec
Ended Job = job_1513599404024_167968
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167970, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167970/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167970
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:18:27,278 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:18:32,585 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.65 sec
2018-01-03 13:18:34,647 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.35 sec
2018-01-03 13:18:40,889 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.91 sec
MapReduce Total cumulative CPU time: 16 seconds 910 msec
Ended Job = job_1513599404024_167970
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167971, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167971/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167971
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:18:47,722 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:18:54,952 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.87 sec
2018-01-03 13:19:01,146 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.48 sec
MapReduce Total cumulative CPU time: 6 seconds 480 msec
Ended Job = job_1513599404024_167971
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.2 sec   HDFS Read: 11927719 HDFS Write: 938293 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.91 sec   HDFS Read: 45246230 HDFS Write: 139111 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.48 sec   HDFS Read: 146749 HDFS Write: 2814 SUCCESS
Total MapReduce CPU Time Spent: 44 seconds 590 msec
OK
Time taken: 79.551 seconds, Fetched: 422 row(s)
开始执行20171108日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103131909_55d4be94-fbcb-419a-92b7-bb733dc3a02a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167974, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167974/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167974
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 13:19:18,393 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:19:28,772 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.32 sec
2018-01-03 13:19:31,881 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 16.2 sec
2018-01-03 13:19:33,951 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 19.67 sec
2018-01-03 13:19:37,047 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 23.53 sec
2018-01-03 13:19:40,148 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 27.73 sec
2018-01-03 13:19:42,219 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 37.73 sec
2018-01-03 13:19:43,254 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 41.04 sec
2018-01-03 13:19:46,369 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 44.28 sec
2018-01-03 13:19:47,412 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 45.68 sec
2018-01-03 13:19:48,446 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 51.25 sec
2018-01-03 13:19:49,483 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 55.51 sec
MapReduce Total cumulative CPU time: 55 seconds 510 msec
Ended Job = job_1513599404024_167974
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167976, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167976/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167976
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:19:55,266 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:20:07,686 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.32 sec
2018-01-03 13:20:08,721 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.62 sec
2018-01-03 13:20:13,882 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.59 sec
MapReduce Total cumulative CPU time: 18 seconds 590 msec
Ended Job = job_1513599404024_167976
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167978, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167978/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167978
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:20:20,614 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:20:25,774 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.85 sec
2018-01-03 13:20:31,954 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.54 sec
MapReduce Total cumulative CPU time: 5 seconds 540 msec
Ended Job = job_1513599404024_167978
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 55.51 sec   HDFS Read: 174573587 HDFS Write: 1677311 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.59 sec   HDFS Read: 47082487 HDFS Write: 215026 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.54 sec   HDFS Read: 222701 HDFS Write: 2819 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 19 seconds 640 msec
OK
Time taken: 83.874 seconds, Fetched: 375 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.391 seconds
Query ID = boss_20180103132039_34b82a43-ae3d-4c84-a750-320a69835ecc
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167980, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167980/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167980
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 13:20:48,660 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:20:59,004 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 11.12 sec
2018-01-03 13:21:02,104 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 25.53 sec
2018-01-03 13:21:03,136 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 29.2 sec
2018-01-03 13:21:04,169 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 42.4 sec
2018-01-03 13:21:05,201 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 45.58 sec
2018-01-03 13:21:07,262 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 50.92 sec
2018-01-03 13:21:08,292 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 56.09 sec
2018-01-03 13:21:11,383 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 67.63 sec
2018-01-03 13:21:12,412 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 69.41 sec
2018-01-03 13:21:14,471 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 75.68 sec
2018-01-03 13:21:17,556 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 81.68 sec
2018-01-03 13:21:20,644 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 86.95 sec
2018-01-03 13:21:22,706 Stage-1 map = 62%,  reduce = 11%, Cumulative CPU 88.59 sec
2018-01-03 13:21:23,736 Stage-1 map = 67%,  reduce = 11%, Cumulative CPU 94.81 sec
2018-01-03 13:21:26,822 Stage-1 map = 70%,  reduce = 11%, Cumulative CPU 101.27 sec
2018-01-03 13:21:28,884 Stage-1 map = 73%,  reduce = 11%, Cumulative CPU 104.55 sec
2018-01-03 13:21:29,919 Stage-1 map = 86%,  reduce = 11%, Cumulative CPU 108.65 sec
2018-01-03 13:21:30,951 Stage-1 map = 86%,  reduce = 15%, Cumulative CPU 108.79 sec
2018-01-03 13:21:31,982 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 108.94 sec
2018-01-03 13:21:33,010 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 112.71 sec
2018-01-03 13:21:34,041 Stage-1 map = 100%,  reduce = 48%, Cumulative CPU 116.3 sec
2018-01-03 13:21:35,070 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 123.28 sec
MapReduce Total cumulative CPU time: 2 minutes 3 seconds 280 msec
Ended Job = job_1513599404024_167980
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167983, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167983/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167983
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:21:40,943 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:21:46,100 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.65 sec
2018-01-03 13:21:48,162 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.62 sec
2018-01-03 13:21:51,247 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.99 sec
MapReduce Total cumulative CPU time: 13 seconds 990 msec
Ended Job = job_1513599404024_167983
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167985, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167985/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167985
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:22:00,916 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:22:07,106 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.24 sec
2018-01-03 13:22:13,298 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.26 sec
MapReduce Total cumulative CPU time: 6 seconds 260 msec
Ended Job = job_1513599404024_167985
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 123.28 sec   HDFS Read: 304380307 HDFS Write: 263290 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.99 sec   HDFS Read: 45668728 HDFS Write: 19908 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.26 sec   HDFS Read: 27584 HDFS Write: 2023 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 23 seconds 530 msec
OK
Time taken: 94.587 seconds, Fetched: 292 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103132221_6aa66693-074e-4ca8-b84c-7ee8e3563d64
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167989, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167989/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167989
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:22:34,682 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:22:48,153 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 11.57 sec
2018-01-03 13:22:51,261 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 14.39 sec
2018-01-03 13:22:52,294 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.1 sec
2018-01-03 13:22:57,463 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.03 sec
MapReduce Total cumulative CPU time: 20 seconds 30 msec
Ended Job = job_1513599404024_167989
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167990, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167990/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167990
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:23:05,232 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:23:10,393 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.09 sec
2018-01-03 13:23:12,457 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.66 sec
2018-01-03 13:23:17,609 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.94 sec
MapReduce Total cumulative CPU time: 14 seconds 940 msec
Ended Job = job_1513599404024_167990
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167991, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167991/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167991
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:23:34,297 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:23:38,499 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.41 sec
2018-01-03 13:23:44,698 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.31 sec
MapReduce Total cumulative CPU time: 6 seconds 310 msec
Ended Job = job_1513599404024_167991
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.03 sec   HDFS Read: 12185528 HDFS Write: 636720 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.94 sec   HDFS Read: 46041578 HDFS Write: 265279 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.31 sec   HDFS Read: 272916 HDFS Write: 6049 SUCCESS
Total MapReduce CPU Time Spent: 41 seconds 280 msec
OK
Time taken: 85.748 seconds, Fetched: 721 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103132353_c3717d9b-6cca-4ec5-86bd-a75589b9ef5c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167994, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167994/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167994
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:24:03,067 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:24:13,428 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 10.48 sec
2018-01-03 13:24:14,462 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.03 sec
2018-01-03 13:24:20,668 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.09 sec
MapReduce Total cumulative CPU time: 20 seconds 90 msec
Ended Job = job_1513599404024_167994
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167996, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167996/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167996
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:24:40,439 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:24:46,631 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.38 sec
2018-01-03 13:24:49,722 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.64 sec
2018-01-03 13:24:52,816 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.03 sec
MapReduce Total cumulative CPU time: 18 seconds 30 msec
Ended Job = job_1513599404024_167996
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_167997, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_167997/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_167997
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:25:00,592 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:25:05,853 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.35 sec
2018-01-03 13:25:11,012 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.8 sec
MapReduce Total cumulative CPU time: 6 seconds 800 msec
Ended Job = job_1513599404024_167997
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.09 sec   HDFS Read: 12185518 HDFS Write: 833281 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.03 sec   HDFS Read: 46238139 HDFS Write: 143384 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.8 sec   HDFS Read: 151022 HDFS Write: 2896 SUCCESS
Total MapReduce CPU Time Spent: 44 seconds 920 msec
OK
Time taken: 78.587 seconds, Fetched: 435 row(s)
开始执行20171109日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103132519_b5f8532b-5d11-45b2-a3bc-8c4e97735e0e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168000, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168000/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168000
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 13:25:28,956 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:25:38,333 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 13.2 sec
2018-01-03 13:25:46,635 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 27.18 sec
2018-01-03 13:25:49,734 Stage-1 map = 57%,  reduce = 8%, Cumulative CPU 31.98 sec
2018-01-03 13:25:52,852 Stage-1 map = 60%,  reduce = 8%, Cumulative CPU 35.76 sec
2018-01-03 13:25:53,903 Stage-1 map = 60%,  reduce = 17%, Cumulative CPU 36.5 sec
2018-01-03 13:25:55,973 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 40.28 sec
2018-01-03 13:25:59,068 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 44.04 sec
2018-01-03 13:26:02,164 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 47.6 sec
2018-01-03 13:26:05,283 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 52.18 sec
2018-01-03 13:26:08,375 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 56.04 sec
2018-01-03 13:26:11,472 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 59.21 sec
2018-01-03 13:26:14,563 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 62.37 sec
2018-01-03 13:26:16,626 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 65.46 sec
2018-01-03 13:26:18,687 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 66.78 sec
2018-01-03 13:26:19,721 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 76.41 sec
MapReduce Total cumulative CPU time: 1 minutes 16 seconds 410 msec
Ended Job = job_1513599404024_168000
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168004, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168004/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168004
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:26:25,676 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:26:31,895 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.01 sec
2018-01-03 13:26:37,058 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 14.12 sec
2018-01-03 13:26:45,296 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.09 sec
MapReduce Total cumulative CPU time: 23 seconds 90 msec
Ended Job = job_1513599404024_168004
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168010, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168010/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168010
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:26:50,930 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:26:55,054 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.19 sec
2018-01-03 13:27:03,282 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.3 sec
MapReduce Total cumulative CPU time: 7 seconds 300 msec
Ended Job = job_1513599404024_168010
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 76.41 sec   HDFS Read: 178513707 HDFS Write: 1633159 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.09 sec   HDFS Read: 46672197 HDFS Write: 203789 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.3 sec   HDFS Read: 211464 HDFS Write: 2871 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 46 seconds 800 msec
OK
Time taken: 105.332 seconds, Fetched: 371 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.388 seconds
Query ID = boss_20180103132711_7a2775b5-d1c6-4d31-b0fd-9e6164230386
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168012, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168012/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168012
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 13:27:22,542 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:27:32,904 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.64 sec
2018-01-03 13:27:36,005 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 16.53 sec
2018-01-03 13:27:38,069 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 19.24 sec
2018-01-03 13:27:41,164 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 35.56 sec
2018-01-03 13:27:44,257 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 42.8 sec
2018-01-03 13:27:45,292 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 53.49 sec
2018-01-03 13:27:47,356 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 60.54 sec
2018-01-03 13:27:48,387 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 62.2 sec
2018-01-03 13:27:50,447 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 65.7 sec
2018-01-03 13:27:53,539 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 69.16 sec
2018-01-03 13:27:55,606 Stage-1 map = 80%,  reduce = 15%, Cumulative CPU 70.31 sec
2018-01-03 13:27:56,637 Stage-1 map = 82%,  reduce = 22%, Cumulative CPU 74.3 sec
2018-01-03 13:27:59,725 Stage-1 map = 84%,  reduce = 22%, Cumulative CPU 77.67 sec
2018-01-03 13:28:02,814 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 82.12 sec
2018-01-03 13:28:05,904 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 86.77 sec
2018-01-03 13:28:06,935 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 95.77 sec
2018-01-03 13:28:07,967 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 99.35 sec
MapReduce Total cumulative CPU time: 1 minutes 39 seconds 350 msec
Ended Job = job_1513599404024_168012
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168018, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168018/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168018
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:28:13,932 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:28:22,203 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.37 sec
2018-01-03 13:28:23,239 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.44 sec
2018-01-03 13:28:27,367 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.02 sec
MapReduce Total cumulative CPU time: 16 seconds 20 msec
Ended Job = job_1513599404024_168018
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168021, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168021/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168021
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:28:49,060 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:29:02,432 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.75 sec
2018-01-03 13:29:07,573 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.72 sec
MapReduce Total cumulative CPU time: 4 seconds 720 msec
Ended Job = job_1513599404024_168021
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 99.35 sec   HDFS Read: 298424659 HDFS Write: 268555 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.02 sec   HDFS Read: 45307855 HDFS Write: 21210 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.72 sec   HDFS Read: 28886 HDFS Write: 2093 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 0 seconds 90 msec
OK
Time taken: 117.596 seconds, Fetched: 297 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.346 seconds
Query ID = boss_20180103132915_bc91a5b6-011f-4d9c-b8ce-3abc8c5e29e5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168025, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168025/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168025
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:29:24,927 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:29:36,335 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 9.98 sec
2018-01-03 13:29:39,440 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 11.74 sec
2018-01-03 13:29:42,539 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.8 sec
2018-01-03 13:29:48,739 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.67 sec
MapReduce Total cumulative CPU time: 18 seconds 670 msec
Ended Job = job_1513599404024_168025
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168028, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168028/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168028
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:30:02,476 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:30:07,636 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.0 sec
2018-01-03 13:30:15,868 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.17 sec
2018-01-03 13:30:22,041 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.18 sec
MapReduce Total cumulative CPU time: 15 seconds 180 msec
Ended Job = job_1513599404024_168028
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168033, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168033/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168033
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:30:36,776 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:30:50,186 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.94 sec
2018-01-03 13:30:55,341 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.85 sec
MapReduce Total cumulative CPU time: 5 seconds 850 msec
Ended Job = job_1513599404024_168033
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.67 sec   HDFS Read: 12196286 HDFS Write: 595536 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.18 sec   HDFS Read: 45634256 HDFS Write: 246941 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.85 sec   HDFS Read: 254578 HDFS Write: 6264 SUCCESS
Total MapReduce CPU Time Spent: 39 seconds 700 msec
OK
Time taken: 101.108 seconds, Fetched: 767 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103133103_39dd3a5c-3f76-4174-97d9-1abd4b4d73e6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168037, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168037/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168037
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:31:12,638 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:31:21,949 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 12.68 sec
2018-01-03 13:31:24,014 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.52 sec
2018-01-03 13:31:37,409 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.78 sec
MapReduce Total cumulative CPU time: 21 seconds 780 msec
Ended Job = job_1513599404024_168037
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168042, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168042/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168042
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:31:44,436 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:31:49,602 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.3 sec
2018-01-03 13:31:50,637 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.18 sec
2018-01-03 13:31:55,790 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.01 sec
MapReduce Total cumulative CPU time: 15 seconds 10 msec
Ended Job = job_1513599404024_168042
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168044, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168044/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168044
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:32:01,427 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:32:06,578 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.38 sec
2018-01-03 13:32:12,764 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.03 sec
MapReduce Total cumulative CPU time: 7 seconds 30 msec
Ended Job = job_1513599404024_168044
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.78 sec   HDFS Read: 12196276 HDFS Write: 784847 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.01 sec   HDFS Read: 45823567 HDFS Write: 144413 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.03 sec   HDFS Read: 152051 HDFS Write: 3274 SUCCESS
Total MapReduce CPU Time Spent: 43 seconds 820 msec
OK
Time taken: 70.734 seconds, Fetched: 444 row(s)
开始执行20171110日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.389 seconds
Query ID = boss_20180103133221_060ca5fd-5fac-443c-a86e-2d00ae90b449
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168048, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168048/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168048
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 13:32:33,818 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:32:43,152 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 11.61 sec
2018-01-03 13:32:44,186 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 23.62 sec
2018-01-03 13:32:47,290 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 27.33 sec
2018-01-03 13:32:50,389 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 30.47 sec
2018-01-03 13:32:53,482 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 33.1 sec
2018-01-03 13:32:54,521 Stage-1 map = 57%,  reduce = 17%, Cumulative CPU 34.27 sec
2018-01-03 13:32:56,588 Stage-1 map = 60%,  reduce = 17%, Cumulative CPU 37.27 sec
2018-01-03 13:32:59,681 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 41.53 sec
2018-01-03 13:33:02,774 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 44.83 sec
2018-01-03 13:33:05,870 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 47.93 sec
2018-01-03 13:33:08,961 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 51.01 sec
2018-01-03 13:33:12,086 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 54.22 sec
2018-01-03 13:33:15,183 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 58.31 sec
2018-01-03 13:33:18,268 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 61.44 sec
2018-01-03 13:33:21,354 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 65.0 sec
2018-01-03 13:33:24,444 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 68.03 sec
2018-01-03 13:33:25,477 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 69.21 sec
2018-01-03 13:33:27,533 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 77.95 sec
MapReduce Total cumulative CPU time: 1 minutes 17 seconds 950 msec
Ended Job = job_1513599404024_168048
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168052, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168052/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168052
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:33:34,241 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:33:43,635 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.87 sec
2018-01-03 13:33:47,765 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.39 sec
2018-01-03 13:33:54,978 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.09 sec
MapReduce Total cumulative CPU time: 23 seconds 90 msec
Ended Job = job_1513599404024_168052
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168053, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168053/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168053
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:34:08,736 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:34:12,858 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.04 sec
2018-01-03 13:34:21,082 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.19 sec
MapReduce Total cumulative CPU time: 6 seconds 190 msec
Ended Job = job_1513599404024_168053
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 77.95 sec   HDFS Read: 193759054 HDFS Write: 1644857 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.09 sec   HDFS Read: 46977578 HDFS Write: 192945 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.19 sec   HDFS Read: 200620 HDFS Write: 2953 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 47 seconds 230 msec
OK
Time taken: 121.124 seconds, Fetched: 390 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.392 seconds
Query ID = boss_20180103133428_868d81a9-6b7f-48ca-a358-08d56c004bee
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168056, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168056/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168056
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 13:34:37,774 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:34:48,132 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.41 sec
2018-01-03 13:34:51,230 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 16.29 sec
2018-01-03 13:34:54,324 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 30.81 sec
2018-01-03 13:34:55,356 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 55.58 sec
2018-01-03 13:34:56,387 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 56.59 sec
2018-01-03 13:34:57,418 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 59.95 sec
2018-01-03 13:34:58,449 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 63.51 sec
2018-01-03 13:35:00,514 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 66.61 sec
2018-01-03 13:35:03,602 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 72.84 sec
2018-01-03 13:35:05,661 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 88.11 sec
2018-01-03 13:35:06,695 Stage-1 map = 54%,  reduce = 4%, Cumulative CPU 88.81 sec
2018-01-03 13:35:07,725 Stage-1 map = 56%,  reduce = 11%, Cumulative CPU 93.26 sec
2018-01-03 13:35:08,755 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 96.64 sec
2018-01-03 13:35:10,817 Stage-1 map = 60%,  reduce = 11%, Cumulative CPU 106.98 sec
2018-01-03 13:35:11,848 Stage-1 map = 73%,  reduce = 11%, Cumulative CPU 110.58 sec
2018-01-03 13:35:12,876 Stage-1 map = 74%,  reduce = 19%, Cumulative CPU 124.19 sec
2018-01-03 13:35:13,905 Stage-1 map = 74%,  reduce = 22%, Cumulative CPU 124.37 sec
2018-01-03 13:35:18,018 Stage-1 map = 75%,  reduce = 22%, Cumulative CPU 80.51 sec
2018-01-03 13:35:21,106 Stage-1 map = 77%,  reduce = 22%, Cumulative CPU 83.29 sec
2018-01-03 13:35:23,163 Stage-1 map = 78%,  reduce = 22%, Cumulative CPU 167.09 sec
2018-01-03 13:35:24,192 Stage-1 map = 79%,  reduce = 22%, Cumulative CPU 86.17 sec
2018-01-03 13:35:27,276 Stage-1 map = 81%,  reduce = 22%, Cumulative CPU 89.3 sec
2018-01-03 13:35:30,363 Stage-1 map = 83%,  reduce = 22%, Cumulative CPU 91.93 sec
2018-01-03 13:35:33,448 Stage-1 map = 84%,  reduce = 22%, Cumulative CPU 93.85 sec
2018-01-03 13:35:36,534 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 96.03 sec
2018-01-03 13:35:39,623 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 99.7 sec
2018-01-03 13:35:40,651 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 101.76 sec
2018-01-03 13:35:41,681 Stage-1 map = 100%,  reduce = 37%, Cumulative CPU 102.2 sec
2018-01-03 13:35:42,709 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 114.05 sec
MapReduce Total cumulative CPU time: 1 minutes 54 seconds 50 msec
Ended Job = job_1513599404024_168056
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168060, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168060/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168060
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:35:56,561 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:36:00,698 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.86 sec
2018-01-03 13:36:05,859 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.65 sec
2018-01-03 13:36:07,923 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.32 sec
MapReduce Total cumulative CPU time: 15 seconds 320 msec
Ended Job = job_1513599404024_168060
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168062, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168062/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168062
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:36:16,593 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:36:21,075 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.28 sec
2018-01-03 13:36:27,265 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.38 sec
MapReduce Total cumulative CPU time: 4 seconds 380 msec
Ended Job = job_1513599404024_168062
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 114.05 sec   HDFS Read: 304416881 HDFS Write: 276393 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.32 sec   HDFS Read: 45609376 HDFS Write: 20159 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.38 sec   HDFS Read: 27835 HDFS Write: 2031 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 13 seconds 750 msec
OK
Time taken: 119.483 seconds, Fetched: 290 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103133634_cdd3aeb7-b1df-4d60-b98e-75e57fc91c7f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168066, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168066/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168066
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:36:45,675 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:36:58,096 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 10.38 sec
2018-01-03 13:37:01,191 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 12.22 sec
2018-01-03 13:37:04,284 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.45 sec
2018-01-03 13:37:09,445 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.38 sec
MapReduce Total cumulative CPU time: 19 seconds 380 msec
Ended Job = job_1513599404024_168066
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168072, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168072/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168072
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:37:29,251 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:37:34,424 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.67 sec
2018-01-03 13:37:43,697 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.22 sec
2018-01-03 13:37:50,916 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.75 sec
MapReduce Total cumulative CPU time: 16 seconds 750 msec
Ended Job = job_1513599404024_168072
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168076, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168076/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168076
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:37:56,797 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:38:01,960 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec
2018-01-03 13:38:07,115 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.55 sec
MapReduce Total cumulative CPU time: 7 seconds 550 msec
Ended Job = job_1513599404024_168076
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.38 sec   HDFS Read: 14715862 HDFS Write: 725054 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.75 sec   HDFS Read: 46057457 HDFS Write: 253268 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.55 sec   HDFS Read: 260905 HDFS Write: 7208 SUCCESS
Total MapReduce CPU Time Spent: 43 seconds 680 msec
OK
Time taken: 94.208 seconds, Fetched: 906 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.351 seconds
Query ID = boss_20180103133815_0bea2a95-d138-41e2-a8bc-17027aded3f8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168077, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168077/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168077
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:38:25,473 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:38:41,996 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 13.95 sec
2018-01-03 13:38:45,088 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 18.9 sec
2018-01-03 13:38:46,124 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 18.9 sec
2018-01-03 13:38:52,303 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 26.4 sec
MapReduce Total cumulative CPU time: 26 seconds 400 msec
Ended Job = job_1513599404024_168077
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168081, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168081/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168081
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:39:06,014 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:39:11,181 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.43 sec
2018-01-03 13:39:17,362 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.93 sec
MapReduce Total cumulative CPU time: 16 seconds 930 msec
Ended Job = job_1513599404024_168081
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168084, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168084/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168084
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:39:33,232 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:39:37,374 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.86 sec
2018-01-03 13:39:45,611 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.99 sec
MapReduce Total cumulative CPU time: 5 seconds 990 msec
Ended Job = job_1513599404024_168084
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 26.4 sec   HDFS Read: 14715852 HDFS Write: 948672 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.93 sec   HDFS Read: 46281075 HDFS Write: 135443 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.99 sec   HDFS Read: 143081 HDFS Write: 3037 SUCCESS
Total MapReduce CPU Time Spent: 49 seconds 320 msec
OK
Time taken: 90.789 seconds, Fetched: 470 row(s)
开始执行20171111日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103133953_e48e838a-3c9f-43b8-ad56-7d2351a86e98
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168086, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168086/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168086
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 13:40:02,712 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:40:13,113 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 12.63 sec
2018-01-03 13:40:14,149 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 24.57 sec
2018-01-03 13:40:16,231 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 28.46 sec
2018-01-03 13:40:17,272 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 34.35 sec
2018-01-03 13:40:20,406 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 37.44 sec
2018-01-03 13:40:23,506 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 40.63 sec
2018-01-03 13:40:26,609 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 43.23 sec
2018-01-03 13:40:28,683 Stage-1 map = 62%,  reduce = 8%, Cumulative CPU 43.98 sec
2018-01-03 13:40:29,714 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 47.8 sec
2018-01-03 13:40:32,818 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 50.93 sec
2018-01-03 13:40:35,919 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 54.14 sec
2018-01-03 13:40:39,110 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 57.3 sec
2018-01-03 13:40:42,208 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 59.01 sec
2018-01-03 13:40:45,304 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 61.44 sec
2018-01-03 13:40:48,404 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 63.13 sec
2018-01-03 13:40:50,852 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 63.24 sec
2018-01-03 13:40:53,960 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 68.79 sec
2018-01-03 13:40:57,275 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 71.53 sec
2018-01-03 13:40:58,675 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 72.42 sec
2018-01-03 13:41:00,889 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 74.0 sec
2018-01-03 13:41:02,187 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 78.39 sec
2018-01-03 13:41:03,233 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 83.31 sec
MapReduce Total cumulative CPU time: 1 minutes 23 seconds 310 msec
Ended Job = job_1513599404024_168086
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168097, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168097/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168097
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:41:21,157 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:41:28,474 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.03 sec
2018-01-03 13:41:39,832 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.79 sec
2018-01-03 13:42:09,434 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 24.79 sec
2018-01-03 13:42:15,910 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 31.63 sec
MapReduce Total cumulative CPU time: 31 seconds 630 msec
Ended Job = job_1513599404024_168097
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168100, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168100/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168100
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:42:29,485 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:42:41,824 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.68 sec
2018-01-03 13:42:46,962 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.46 sec
MapReduce Total cumulative CPU time: 6 seconds 460 msec
Ended Job = job_1513599404024_168100
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 83.31 sec   HDFS Read: 224406531 HDFS Write: 1808638 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 31.63 sec   HDFS Read: 50215140 HDFS Write: 245158 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.46 sec   HDFS Read: 252833 HDFS Write: 3157 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 1 seconds 400 msec
OK
Time taken: 174.461 seconds, Fetched: 405 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.384 seconds
Query ID = boss_20180103134254_6f15a442-679c-4cb5-8c91-294699a4ebfa
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168102, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168102/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168102
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 13:43:11,828 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:43:22,209 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.98 sec
2018-01-03 13:43:25,314 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 15.57 sec
2018-01-03 13:43:27,382 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 17.71 sec
2018-01-03 13:43:30,480 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 47.76 sec
2018-01-03 13:43:33,577 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 60.26 sec
2018-01-03 13:43:35,645 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 63.67 sec
2018-01-03 13:43:36,677 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 72.89 sec
2018-01-03 13:43:38,738 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 76.24 sec
2018-01-03 13:43:39,772 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 82.89 sec
2018-01-03 13:43:40,810 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 84.96 sec
2018-01-03 13:43:41,841 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 88.14 sec
2018-01-03 13:43:42,871 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 91.95 sec
2018-01-03 13:43:44,937 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 95.09 sec
2018-01-03 13:43:48,026 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 98.45 sec
2018-01-03 13:43:50,090 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 101.01 sec
2018-01-03 13:43:51,123 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 107.09 sec
2018-01-03 13:43:52,154 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 117.92 sec
MapReduce Total cumulative CPU time: 1 minutes 57 seconds 920 msec
Ended Job = job_1513599404024_168102
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168105, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168105/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168105
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:44:04,905 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:44:11,110 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.39 sec
2018-01-03 13:44:31,702 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.09 sec
MapReduce Total cumulative CPU time: 17 seconds 90 msec
Ended Job = job_1513599404024_168105
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168108, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168108/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168108
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:44:39,472 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:44:47,824 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.27 sec
2018-01-03 13:44:55,030 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.35 sec
MapReduce Total cumulative CPU time: 6 seconds 350 msec
Ended Job = job_1513599404024_168108
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 117.92 sec   HDFS Read: 352835882 HDFS Write: 313538 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.09 sec   HDFS Read: 48720302 HDFS Write: 20471 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.35 sec   HDFS Read: 28147 HDFS Write: 2279 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 21 seconds 360 msec
OK
Time taken: 121.367 seconds, Fetched: 316 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103134510_747b5289-2eac-4c99-bcf2-994a87bb7393
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168110, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168110/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168110
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:45:20,369 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:45:30,708 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 15.06 sec
2018-01-03 13:45:33,807 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 17.33 sec
2018-01-03 13:45:36,898 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 22.19 sec
2018-01-03 13:45:51,331 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 27.6 sec
MapReduce Total cumulative CPU time: 27 seconds 600 msec
Ended Job = job_1513599404024_168110
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168113, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168113/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168113
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:45:58,087 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:46:02,216 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.43 sec
2018-01-03 13:46:12,517 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.15 sec
2018-01-03 13:46:13,547 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.98 sec
MapReduce Total cumulative CPU time: 17 seconds 980 msec
Ended Job = job_1513599404024_168113
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168115, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168115/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168115
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:46:24,561 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:46:36,968 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.89 sec
2018-01-03 13:46:43,148 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.21 sec
MapReduce Total cumulative CPU time: 7 seconds 210 msec
Ended Job = job_1513599404024_168115
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 27.6 sec   HDFS Read: 17932664 HDFS Write: 791835 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.98 sec   HDFS Read: 49198019 HDFS Write: 280104 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.21 sec   HDFS Read: 287741 HDFS Write: 6815 SUCCESS
Total MapReduce CPU Time Spent: 52 seconds 790 msec
OK
Time taken: 93.465 seconds, Fetched: 846 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103134650_dc16caf1-fc80-46ca-ab60-5056484a71b7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168119, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168119/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168119
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:47:00,507 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:47:12,929 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 11.69 sec
2018-01-03 13:47:16,023 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 15.16 sec
2018-01-03 13:47:19,122 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 17.81 sec
2018-01-03 13:47:21,190 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 19.79 sec
2018-01-03 13:47:28,411 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 24.4 sec
MapReduce Total cumulative CPU time: 24 seconds 400 msec
Ended Job = job_1513599404024_168119
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168121, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168121/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168121
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:47:37,273 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:47:42,454 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.48 sec
2018-01-03 13:47:43,498 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.5 sec
2018-01-03 13:47:56,945 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.65 sec
MapReduce Total cumulative CPU time: 16 seconds 650 msec
Ended Job = job_1513599404024_168121
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168123, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168123/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168123
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:48:12,703 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:48:17,906 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.76 sec
2018-01-03 13:48:24,099 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.42 sec
MapReduce Total cumulative CPU time: 5 seconds 420 msec
Ended Job = job_1513599404024_168123
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 24.4 sec   HDFS Read: 17932654 HDFS Write: 1164537 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.65 sec   HDFS Read: 49570721 HDFS Write: 150229 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.42 sec   HDFS Read: 157867 HDFS Write: 3204 SUCCESS
Total MapReduce CPU Time Spent: 46 seconds 470 msec
OK
Time taken: 94.199 seconds, Fetched: 498 row(s)
开始执行20171112日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103134832_27775131-a323-4c0c-b6a4-7347562fa839
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168126, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168126/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168126
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 13:48:42,372 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:48:52,734 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.89 sec
2018-01-03 13:48:54,801 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 15.54 sec
2018-01-03 13:48:57,898 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 18.82 sec
2018-01-03 13:48:58,930 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 32.66 sec
2018-01-03 13:49:00,990 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 36.03 sec
2018-01-03 13:49:02,020 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 40.16 sec
2018-01-03 13:49:04,080 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 43.99 sec
2018-01-03 13:49:05,116 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 47.52 sec
2018-01-03 13:49:07,184 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 53.95 sec
2018-01-03 13:49:10,275 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 56.91 sec
2018-01-03 13:49:13,367 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 60.0 sec
2018-01-03 13:49:14,403 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 65.0 sec
2018-01-03 13:49:15,433 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 68.93 sec
MapReduce Total cumulative CPU time: 1 minutes 8 seconds 930 msec
Ended Job = job_1513599404024_168126
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168130, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168130/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168130
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:49:21,128 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:49:28,344 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.85 sec
2018-01-03 13:49:30,406 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.56 sec
2018-01-03 13:49:34,521 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.12 sec
MapReduce Total cumulative CPU time: 19 seconds 120 msec
Ended Job = job_1513599404024_168130
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168132, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168132/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168132
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:49:45,270 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:49:52,635 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.01 sec
2018-01-03 13:50:00,874 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.57 sec
MapReduce Total cumulative CPU time: 7 seconds 570 msec
Ended Job = job_1513599404024_168132
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 68.93 sec   HDFS Read: 226992867 HDFS Write: 1985429 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.12 sec   HDFS Read: 50803978 HDFS Write: 244296 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.57 sec   HDFS Read: 251971 HDFS Write: 2970 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 35 seconds 620 msec
OK
Time taken: 89.487 seconds, Fetched: 379 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.391 seconds
Query ID = boss_20180103135008_a6e307f9-891f-4d60-9768-f6131ed303ed
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168139, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168139/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168139
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 4
2018-01-03 13:50:17,643 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:50:26,975 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.56 sec
2018-01-03 13:50:29,040 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 24.15 sec
2018-01-03 13:50:30,073 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 27.86 sec
2018-01-03 13:50:31,108 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 31.36 sec
2018-01-03 13:50:33,170 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 34.29 sec
2018-01-03 13:50:34,200 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 37.77 sec
2018-01-03 13:50:35,232 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 50.01 sec
2018-01-03 13:50:36,263 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 52.67 sec
2018-01-03 13:50:37,293 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 56.0 sec
2018-01-03 13:50:38,325 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 60.14 sec
2018-01-03 13:50:39,356 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 62.77 sec
2018-01-03 13:50:40,391 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 65.79 sec
2018-01-03 13:50:41,422 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 68.84 sec
2018-01-03 13:50:42,452 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 72.25 sec
2018-01-03 13:50:43,482 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 75.25 sec
2018-01-03 13:50:44,511 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 80.97 sec
2018-01-03 13:50:45,540 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 83.2 sec
2018-01-03 13:50:46,570 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 85.99 sec
2018-01-03 13:50:49,660 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 89.05 sec
2018-01-03 13:50:52,746 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 91.72 sec
2018-01-03 13:50:54,809 Stage-1 map = 84%,  reduce = 22%, Cumulative CPU 94.1 sec
2018-01-03 13:50:55,840 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 97.5 sec
2018-01-03 13:50:58,929 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 100.67 sec
2018-01-03 13:50:59,958 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 102.46 sec
2018-01-03 13:51:00,986 Stage-1 map = 100%,  reduce = 94%, Cumulative CPU 117.82 sec
2018-01-03 13:51:02,015 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 119.25 sec
MapReduce Total cumulative CPU time: 1 minutes 59 seconds 250 msec
Ended Job = job_1513599404024_168139
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168143, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168143/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168143
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:51:07,745 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:51:13,942 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.67 sec
2018-01-03 13:51:16,004 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.37 sec
2018-01-03 13:51:21,156 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.74 sec
MapReduce Total cumulative CPU time: 15 seconds 740 msec
Ended Job = job_1513599404024_168143
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168146, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168146/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168146
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:51:28,934 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:51:34,111 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-03 13:51:40,287 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.7 sec
MapReduce Total cumulative CPU time: 5 seconds 700 msec
Ended Job = job_1513599404024_168146
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 4   Cumulative CPU: 119.25 sec   HDFS Read: 376229900 HDFS Write: 329044 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.74 sec   HDFS Read: 49148117 HDFS Write: 23162 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.7 sec   HDFS Read: 30838 HDFS Write: 2247 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 20 seconds 690 msec
OK
Time taken: 92.799 seconds, Fetched: 317 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103135148_c66c0b95-0cea-41af-9980-8d5d1c33d2c0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168147, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168147/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168147
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:51:57,788 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:52:08,134 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 11.69 sec
2018-01-03 13:52:11,232 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 13.94 sec
2018-01-03 13:52:13,296 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.66 sec
2018-01-03 13:52:19,488 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.84 sec
MapReduce Total cumulative CPU time: 20 seconds 840 msec
Ended Job = job_1513599404024_168147
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168151, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168151/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168151
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:52:34,202 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:52:40,399 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.72 sec
2018-01-03 13:52:42,461 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.74 sec
2018-01-03 13:53:00,993 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.36 sec
MapReduce Total cumulative CPU time: 17 seconds 360 msec
Ended Job = job_1513599404024_168151
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168153, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168153/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168153
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:53:21,832 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:53:27,006 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.51 sec
2018-01-03 13:53:32,183 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.42 sec
MapReduce Total cumulative CPU time: 6 seconds 420 msec
Ended Job = job_1513599404024_168153
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.84 sec   HDFS Read: 13706403 HDFS Write: 617307 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.36 sec   HDFS Read: 49435538 HDFS Write: 262373 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.42 sec   HDFS Read: 270010 HDFS Write: 6273 SUCCESS
Total MapReduce CPU Time Spent: 44 seconds 620 msec
OK
Time taken: 105.089 seconds, Fetched: 719 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103135339_8fc7ebb8-b08e-4378-913b-6821e2e09736
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168156, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168156/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168156
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:53:49,703 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:54:01,116 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 10.95 sec
2018-01-03 13:54:04,219 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 14.75 sec
2018-01-03 13:54:07,321 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 17.72 sec
2018-01-03 13:54:14,551 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 23.02 sec
MapReduce Total cumulative CPU time: 23 seconds 20 msec
Ended Job = job_1513599404024_168156
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168158, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168158/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168158
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:54:29,478 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:54:37,850 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.12 sec
2018-01-03 13:54:48,175 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.58 sec
2018-01-03 13:54:55,397 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.97 sec
2018-01-03 13:54:57,457 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.83 sec
MapReduce Total cumulative CPU time: 17 seconds 830 msec
Ended Job = job_1513599404024_168158
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168163, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168163/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168163
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:55:17,142 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:55:29,493 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.03 sec
2018-01-03 13:55:34,640 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.1 sec
MapReduce Total cumulative CPU time: 6 seconds 100 msec
Ended Job = job_1513599404024_168163
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 23.02 sec   HDFS Read: 13706392 HDFS Write: 983140 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.83 sec   HDFS Read: 49801367 HDFS Write: 169277 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.1 sec   HDFS Read: 176911 HDFS Write: 3234 SUCCESS
Total MapReduce CPU Time Spent: 46 seconds 950 msec
OK
Time taken: 115.726 seconds, Fetched: 430 row(s)
开始执行20171113日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103135542_47fa7b65-b7ec-4bdb-ba59-6c2a2eb90f32
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168165, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168165/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168165
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 13:55:53,622 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:56:03,992 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 13.43 sec
2018-01-03 13:56:05,027 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 23.73 sec
2018-01-03 13:56:06,061 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 27.63 sec
2018-01-03 13:56:08,129 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 32.02 sec
2018-01-03 13:56:11,227 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 35.36 sec
2018-01-03 13:56:14,323 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 38.73 sec
2018-01-03 13:56:17,420 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 41.87 sec
2018-01-03 13:56:19,488 Stage-1 map = 60%,  reduce = 8%, Cumulative CPU 42.45 sec
2018-01-03 13:56:20,519 Stage-1 map = 62%,  reduce = 8%, Cumulative CPU 45.16 sec
2018-01-03 13:56:21,557 Stage-1 map = 62%,  reduce = 17%, Cumulative CPU 45.77 sec
2018-01-03 13:56:23,619 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 48.72 sec
2018-01-03 13:56:26,715 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 51.88 sec
2018-01-03 13:56:29,808 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 54.97 sec
2018-01-03 13:56:32,897 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 58.69 sec
2018-01-03 13:56:34,960 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 58.8 sec
2018-01-03 13:56:38,049 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 64.82 sec
2018-01-03 13:56:41,137 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 67.89 sec
2018-01-03 13:56:44,227 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 70.71 sec
2018-01-03 13:56:47,313 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 73.78 sec
2018-01-03 13:56:48,341 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 75.32 sec
2018-01-03 13:56:49,370 Stage-1 map = 100%,  reduce = 35%, Cumulative CPU 75.6 sec
2018-01-03 13:56:50,398 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 78.37 sec
2018-01-03 13:56:51,426 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 86.78 sec
MapReduce Total cumulative CPU time: 1 minutes 26 seconds 780 msec
Ended Job = job_1513599404024_168165
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168169, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168169/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168169
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:56:57,354 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:57:02,510 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.87 sec
2018-01-03 13:57:05,598 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.51 sec
2018-01-03 13:57:08,684 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.66 sec
MapReduce Total cumulative CPU time: 18 seconds 660 msec
Ended Job = job_1513599404024_168169
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168171, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168171/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168171
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:57:16,345 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:57:20,477 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.87 sec
2018-01-03 13:57:26,658 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.1 sec
MapReduce Total cumulative CPU time: 6 seconds 100 msec
Ended Job = job_1513599404024_168171
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 86.78 sec   HDFS Read: 204674608 HDFS Write: 1873662 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.66 sec   HDFS Read: 46536077 HDFS Write: 185723 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.1 sec   HDFS Read: 193398 HDFS Write: 2884 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 51 seconds 540 msec
OK
Time taken: 105.11 seconds, Fetched: 375 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.388 seconds
Query ID = boss_20180103135734_a195541c-bac1-4d4d-9e04-08b43d6618b3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168173, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168173/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168173
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 13:57:43,491 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:57:51,791 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 10.8 sec
2018-01-03 13:57:53,857 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 35.87 sec
2018-01-03 13:57:56,958 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 42.71 sec
2018-01-03 13:58:00,056 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 49.52 sec
2018-01-03 13:58:02,127 Stage-1 map = 48%,  reduce = 7%, Cumulative CPU 50.91 sec
2018-01-03 13:58:03,162 Stage-1 map = 52%,  reduce = 7%, Cumulative CPU 57.25 sec
2018-01-03 13:58:06,370 Stage-1 map = 58%,  reduce = 7%, Cumulative CPU 64.1 sec
2018-01-03 13:58:09,460 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 71.54 sec
2018-01-03 13:58:12,550 Stage-1 map = 67%,  reduce = 11%, Cumulative CPU 78.5 sec
2018-01-03 13:58:15,653 Stage-1 map = 71%,  reduce = 11%, Cumulative CPU 85.58 sec
2018-01-03 13:58:16,683 Stage-1 map = 83%,  reduce = 15%, Cumulative CPU 87.31 sec
2018-01-03 13:58:17,712 Stage-1 map = 83%,  reduce = 19%, Cumulative CPU 87.38 sec
2018-01-03 13:58:18,742 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 90.5 sec
2018-01-03 13:58:21,830 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 95.22 sec
2018-01-03 13:58:22,860 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 99.35 sec
2018-01-03 13:58:23,893 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 107.44 sec
MapReduce Total cumulative CPU time: 1 minutes 47 seconds 440 msec
Ended Job = job_1513599404024_168173
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168177, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168177/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168177
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 13:58:52,690 Stage-2 map = 0%,  reduce = 0%
2018-01-03 13:58:57,867 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 7.72 sec
2018-01-03 13:59:06,123 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.53 sec
MapReduce Total cumulative CPU time: 12 seconds 530 msec
Ended Job = job_1513599404024_168177
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168180, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168180/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168180
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 13:59:11,884 Stage-3 map = 0%,  reduce = 0%
2018-01-03 13:59:16,014 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.36 sec
2018-01-03 13:59:23,220 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.84 sec
MapReduce Total cumulative CPU time: 6 seconds 840 msec
Ended Job = job_1513599404024_168180
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 107.44 sec   HDFS Read: 290166950 HDFS Write: 261040 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.53 sec   HDFS Read: 44923717 HDFS Write: 19299 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.84 sec   HDFS Read: 26975 HDFS Write: 2068 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 6 seconds 810 msec
OK
Time taken: 109.817 seconds, Fetched: 291 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103135930_744c5684-2850-46ec-ad2d-d839e1648147
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168182, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168182/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168182
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 13:59:41,756 Stage-1 map = 0%,  reduce = 0%
2018-01-03 13:59:52,111 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 11.87 sec
2018-01-03 13:59:55,210 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 14.81 sec
2018-01-03 13:59:58,305 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 17.31 sec
2018-01-03 14:00:01,396 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 20.13 sec
2018-01-03 14:00:04,489 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 23.6 sec
2018-01-03 14:00:07,578 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 26.3 sec
2018-01-03 14:00:10,666 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 28.59 sec
2018-01-03 14:00:13,757 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 32.32 sec
2018-01-03 14:00:27,136 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 37.63 sec
MapReduce Total cumulative CPU time: 37 seconds 630 msec
Ended Job = job_1513599404024_168182
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168185, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168185/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168185
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:00:34,944 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:00:41,169 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.76 sec
2018-01-03 14:00:42,203 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.73 sec
2018-01-03 14:00:54,650 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.85 sec
MapReduce Total cumulative CPU time: 17 seconds 850 msec
Ended Job = job_1513599404024_168185
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168188, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168188/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168188
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:01:08,317 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:01:13,464 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.17 sec
2018-01-03 14:01:19,635 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.9 sec
MapReduce Total cumulative CPU time: 5 seconds 900 msec
Ended Job = job_1513599404024_168188
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 37.63 sec   HDFS Read: 23239388 HDFS Write: 553406 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.85 sec   HDFS Read: 45215503 HDFS Write: 210446 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.9 sec   HDFS Read: 218083 HDFS Write: 6222 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 1 seconds 380 msec
OK
Time taken: 109.729 seconds, Fetched: 710 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.346 seconds
Query ID = boss_20180103140135_79c99aea-0ee5-40d4-86fe-efcb35be13ac
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168196, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168196/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168196
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:01:59,911 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:02:15,406 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 10.84 sec
2018-01-03 14:02:18,499 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 13.63 sec
2018-01-03 14:02:21,595 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 16.54 sec
2018-01-03 14:02:23,656 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 20.31 sec
2018-01-03 14:02:29,836 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 24.9 sec
MapReduce Total cumulative CPU time: 24 seconds 900 msec
Ended Job = job_1513599404024_168196
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168205, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168205/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168205
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:02:44,588 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:02:51,085 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.9 sec
2018-01-03 14:02:56,240 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.38 sec
MapReduce Total cumulative CPU time: 14 seconds 380 msec
Ended Job = job_1513599404024_168205
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168214, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168214/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168214
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:03:09,913 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:03:15,091 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.48 sec
2018-01-03 14:03:22,321 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.46 sec
MapReduce Total cumulative CPU time: 6 seconds 460 msec
Ended Job = job_1513599404024_168214
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 24.9 sec   HDFS Read: 23239378 HDFS Write: 822727 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.38 sec   HDFS Read: 45484824 HDFS Write: 144649 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.46 sec   HDFS Read: 152287 HDFS Write: 2982 SUCCESS
Total MapReduce CPU Time Spent: 45 seconds 740 msec
OK
Time taken: 109.045 seconds, Fetched: 441 row(s)
开始执行20171114日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.367 seconds
Query ID = boss_20180103140331_0b896f3e-503b-4ebf-8b22-1111f197779e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168220, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168220/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168220
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 14:03:46,814 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:04:01,314 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 9.55 sec
2018-01-03 14:04:03,381 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 21.8 sec
2018-01-03 14:04:06,487 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 25.87 sec
2018-01-03 14:04:09,585 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 29.33 sec
2018-01-03 14:04:11,653 Stage-1 map = 57%,  reduce = 8%, Cumulative CPU 29.8 sec
2018-01-03 14:04:12,685 Stage-1 map = 61%,  reduce = 8%, Cumulative CPU 34.51 sec
2018-01-03 14:04:14,750 Stage-1 map = 63%,  reduce = 8%, Cumulative CPU 37.51 sec
2018-01-03 14:04:16,814 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 38.27 sec
2018-01-03 14:04:17,851 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 41.08 sec
2018-01-03 14:04:20,943 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 44.04 sec
2018-01-03 14:04:24,032 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 47.34 sec
2018-01-03 14:04:27,121 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 51.45 sec
2018-01-03 14:04:30,213 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 55.49 sec
2018-01-03 14:04:33,301 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 60.02 sec
2018-01-03 14:04:36,390 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 63.0 sec
2018-01-03 14:04:39,483 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 66.46 sec
2018-01-03 14:04:41,539 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 77.45 sec
MapReduce Total cumulative CPU time: 1 minutes 17 seconds 450 msec
Ended Job = job_1513599404024_168220
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168230, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168230/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168230
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:04:55,213 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:05:00,365 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.43 sec
2018-01-03 14:05:02,430 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.73 sec
2018-01-03 14:05:10,662 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.94 sec
MapReduce Total cumulative CPU time: 19 seconds 940 msec
Ended Job = job_1513599404024_168230
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168232, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168232/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168232
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:05:17,470 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:05:21,610 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-03 14:05:27,793 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.86 sec
MapReduce Total cumulative CPU time: 6 seconds 860 msec
Ended Job = job_1513599404024_168232
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 77.45 sec   HDFS Read: 177185660 HDFS Write: 2047485 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.94 sec   HDFS Read: 45848694 HDFS Write: 161677 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.86 sec   HDFS Read: 169352 HDFS Write: 3152 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 44 seconds 250 msec
OK
Time taken: 117.585 seconds, Fetched: 404 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.397 seconds
Query ID = boss_20180103140535_345cfce9-92cb-4c46-a82d-07dec4b80e32
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168239, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168239/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168239
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 14:05:45,887 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:05:51,110 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 6.63 sec
2018-01-03 14:05:56,285 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 29.71 sec
2018-01-03 14:05:59,389 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 36.97 sec
2018-01-03 14:06:01,463 Stage-1 map = 46%,  reduce = 7%, Cumulative CPU 46.34 sec
2018-01-03 14:06:02,496 Stage-1 map = 46%,  reduce = 11%, Cumulative CPU 46.89 sec
2018-01-03 14:06:04,566 Stage-1 map = 50%,  reduce = 11%, Cumulative CPU 53.09 sec
2018-01-03 14:06:07,665 Stage-1 map = 55%,  reduce = 11%, Cumulative CPU 59.48 sec
2018-01-03 14:06:10,762 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 65.85 sec
2018-01-03 14:06:13,861 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 70.41 sec
2018-01-03 14:06:16,957 Stage-1 map = 67%,  reduce = 11%, Cumulative CPU 75.87 sec
2018-01-03 14:06:20,048 Stage-1 map = 72%,  reduce = 11%, Cumulative CPU 82.08 sec
2018-01-03 14:06:23,140 Stage-1 map = 87%,  reduce = 11%, Cumulative CPU 90.47 sec
2018-01-03 14:06:25,205 Stage-1 map = 87%,  reduce = 19%, Cumulative CPU 90.83 sec
2018-01-03 14:06:26,239 Stage-1 map = 100%,  reduce = 26%, Cumulative CPU 94.54 sec
2018-01-03 14:06:27,271 Stage-1 map = 100%,  reduce = 78%, Cumulative CPU 103.23 sec
2018-01-03 14:06:28,300 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 107.03 sec
MapReduce Total cumulative CPU time: 1 minutes 47 seconds 30 msec
Ended Job = job_1513599404024_168239
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168246, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168246/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168246
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:06:42,148 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:06:48,357 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.15 sec
2018-01-03 14:07:07,960 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.34 sec
MapReduce Total cumulative CPU time: 16 seconds 340 msec
Ended Job = job_1513599404024_168246
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168251, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168251/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168251
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:07:13,562 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:07:26,937 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.09 sec
2018-01-03 14:07:34,153 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.98 sec
MapReduce Total cumulative CPU time: 5 seconds 980 msec
Ended Job = job_1513599404024_168251
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 107.03 sec   HDFS Read: 281590664 HDFS Write: 272407 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.34 sec   HDFS Read: 44073878 HDFS Write: 18791 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.98 sec   HDFS Read: 26467 HDFS Write: 2007 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 9 seconds 350 msec
OK
Time taken: 119.335 seconds, Fetched: 290 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.35 seconds
Query ID = boss_20180103140741_6b7f90be-437b-4b96-97da-9a88734c8784
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168254, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168254/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168254
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:07:52,387 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:08:09,961 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 14.99 sec
2018-01-03 14:08:13,060 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 17.9 sec
2018-01-03 14:08:19,248 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 36.97 sec
2018-01-03 14:08:22,346 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 39.96 sec
2018-01-03 14:08:25,434 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 43.31 sec
2018-01-03 14:08:30,588 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 47.14 sec
MapReduce Total cumulative CPU time: 47 seconds 140 msec
Ended Job = job_1513599404024_168254
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168257, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168257/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168257
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:08:36,292 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:08:43,507 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.41 sec
2018-01-03 14:08:48,655 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.28 sec
2018-01-03 14:08:57,912 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.86 sec
MapReduce Total cumulative CPU time: 16 seconds 860 msec
Ended Job = job_1513599404024_168257
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168260, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168260/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168260
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:09:04,643 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:09:11,009 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.18 sec
2018-01-03 14:09:16,157 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.03 sec
MapReduce Total cumulative CPU time: 6 seconds 30 msec
Ended Job = job_1513599404024_168260
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 47.14 sec   HDFS Read: 17909517 HDFS Write: 483468 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.86 sec   HDFS Read: 44284359 HDFS Write: 188029 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.03 sec   HDFS Read: 195666 HDFS Write: 5838 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 10 seconds 30 msec
OK
Time taken: 95.314 seconds, Fetched: 658 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103140923_51a1109f-2afa-41e6-8806-e5373741111f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168262, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168262/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168262
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:09:36,438 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:09:47,828 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 11.63 sec
2018-01-03 14:09:50,929 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 16.41 sec
2018-01-03 14:09:51,962 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 18.33 sec
2018-01-03 14:09:58,156 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 23.72 sec
MapReduce Total cumulative CPU time: 23 seconds 720 msec
Ended Job = job_1513599404024_168262
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168265, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168265/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168265
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:10:03,854 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:10:11,076 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.2 sec
2018-01-03 14:10:22,406 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.77 sec
2018-01-03 14:10:27,555 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.83 sec
2018-01-03 14:10:30,641 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.67 sec
MapReduce Total cumulative CPU time: 17 seconds 670 msec
Ended Job = job_1513599404024_168265
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168268, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168268/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168268
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:10:36,277 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:10:49,643 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.61 sec
2018-01-03 14:10:54,784 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.2 sec
MapReduce Total cumulative CPU time: 6 seconds 200 msec
Ended Job = job_1513599404024_168268
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 23.72 sec   HDFS Read: 17909507 HDFS Write: 752864 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.67 sec   HDFS Read: 44553755 HDFS Write: 132189 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.2 sec   HDFS Read: 139827 HDFS Write: 2764 SUCCESS
Total MapReduce CPU Time Spent: 47 seconds 590 msec
OK
Time taken: 91.887 seconds, Fetched: 403 row(s)
开始执行20171115日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103141102_568cb479-c783-47c3-ac88-d2fb776719d7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168270, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168270/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168270
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 14:11:11,689 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:11:22,041 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 12.74 sec
2018-01-03 14:11:25,146 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 17.09 sec
2018-01-03 14:11:27,222 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 27.02 sec
2018-01-03 14:11:28,255 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 30.58 sec
2018-01-03 14:11:31,348 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 33.87 sec
2018-01-03 14:11:34,441 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 36.98 sec
2018-01-03 14:11:37,548 Stage-1 map = 66%,  reduce = 8%, Cumulative CPU 41.0 sec
2018-01-03 14:11:40,646 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 44.62 sec
2018-01-03 14:11:42,703 Stage-1 map = 71%,  reduce = 8%, Cumulative CPU 47.89 sec
2018-01-03 14:11:45,794 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 51.57 sec
2018-01-03 14:11:48,896 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 54.73 sec
2018-01-03 14:11:51,983 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 58.04 sec
2018-01-03 14:11:55,073 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 61.25 sec
2018-01-03 14:11:56,103 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 62.75 sec
2018-01-03 14:11:58,163 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 69.21 sec
2018-01-03 14:11:59,194 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 76.2 sec
MapReduce Total cumulative CPU time: 1 minutes 16 seconds 200 msec
Ended Job = job_1513599404024_168270
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168275, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168275/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168275
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:12:05,901 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:12:14,169 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.52 sec
2018-01-03 14:12:19,324 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.25 sec
2018-01-03 14:12:21,387 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.26 sec
MapReduce Total cumulative CPU time: 19 seconds 260 msec
Ended Job = job_1513599404024_168275
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168277, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168277/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168277
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:12:28,049 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:12:34,239 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.42 sec
2018-01-03 14:12:44,525 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.37 sec
MapReduce Total cumulative CPU time: 7 seconds 370 msec
Ended Job = job_1513599404024_168277
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 76.2 sec   HDFS Read: 172356248 HDFS Write: 1823353 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.26 sec   HDFS Read: 45453874 HDFS Write: 170452 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.37 sec   HDFS Read: 178127 HDFS Write: 2864 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 42 seconds 830 msec
OK
Time taken: 102.84 seconds, Fetched: 368 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.416 seconds
Query ID = boss_20180103141252_01c2d3a4-98d4-4bde-95da-31bd41581ef3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168279, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168279/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168279
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 14:13:01,514 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:13:10,897 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 23.78 sec
2018-01-03 14:13:11,930 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 37.16 sec
2018-01-03 14:13:13,994 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 45.82 sec
2018-01-03 14:13:17,090 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 51.73 sec
2018-01-03 14:13:20,179 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 58.69 sec
2018-01-03 14:13:21,214 Stage-1 map = 56%,  reduce = 7%, Cumulative CPU 59.64 sec
2018-01-03 14:13:22,246 Stage-1 map = 56%,  reduce = 11%, Cumulative CPU 60.25 sec
2018-01-03 14:13:23,276 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 67.16 sec
2018-01-03 14:13:26,370 Stage-1 map = 67%,  reduce = 11%, Cumulative CPU 73.85 sec
2018-01-03 14:13:29,458 Stage-1 map = 73%,  reduce = 11%, Cumulative CPU 80.52 sec
2018-01-03 14:13:32,547 Stage-1 map = 100%,  reduce = 30%, Cumulative CPU 89.29 sec
2018-01-03 14:13:33,580 Stage-1 map = 100%,  reduce = 70%, Cumulative CPU 97.63 sec
2018-01-03 14:13:34,610 Stage-1 map = 100%,  reduce = 89%, Cumulative CPU 100.32 sec
2018-01-03 14:13:36,667 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 103.52 sec
MapReduce Total cumulative CPU time: 1 minutes 43 seconds 520 msec
Ended Job = job_1513599404024_168279
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168282, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168282/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168282
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:13:44,629 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:13:49,819 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.49 sec
2018-01-03 14:13:51,902 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.27 sec
2018-01-03 14:14:03,255 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.34 sec
MapReduce Total cumulative CPU time: 15 seconds 340 msec
Ended Job = job_1513599404024_168282
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168285, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168285/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168285
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:14:09,013 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:14:14,168 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.32 sec
2018-01-03 14:14:20,345 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.64 sec
MapReduce Total cumulative CPU time: 4 seconds 640 msec
Ended Job = job_1513599404024_168285
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 103.52 sec   HDFS Read: 287874930 HDFS Write: 285426 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.34 sec   HDFS Read: 43916209 HDFS Write: 18417 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.64 sec   HDFS Read: 26093 HDFS Write: 2031 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 3 seconds 500 msec
OK
Time taken: 88.964 seconds, Fetched: 291 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103141428_663f077f-a9aa-4222-bc21-03eeeb6f2d89
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168286, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168286/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168286
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:14:39,048 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:14:48,389 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 12.51 sec
2018-01-03 14:14:51,498 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 14.29 sec
2018-01-03 14:14:53,565 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.66 sec
2018-01-03 14:15:00,802 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.88 sec
MapReduce Total cumulative CPU time: 21 seconds 880 msec
Ended Job = job_1513599404024_168286
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168289, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168289/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168289
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:15:06,605 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:15:11,782 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 4.93 sec
2018-01-03 14:15:17,986 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.42 sec
MapReduce Total cumulative CPU time: 14 seconds 420 msec
Ended Job = job_1513599404024_168289
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168290, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168290/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168290
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:15:25,057 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:15:33,322 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.38 sec
2018-01-03 14:15:39,509 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.26 sec
MapReduce Total cumulative CPU time: 6 seconds 260 msec
Ended Job = job_1513599404024_168290
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.88 sec   HDFS Read: 10930650 HDFS Write: 491108 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.42 sec   HDFS Read: 44121311 HDFS Write: 188210 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.26 sec   HDFS Read: 195847 HDFS Write: 5285 SUCCESS
Total MapReduce CPU Time Spent: 42 seconds 560 msec
OK
Time taken: 72.488 seconds, Fetched: 623 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103141555_a66214dc-bc43-4dde-98c1-01bfb1d772ea
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168296, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168296/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168296
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:16:04,956 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:16:15,348 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 10.32 sec
2018-01-03 14:16:18,466 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 13.6 sec
2018-01-03 14:16:21,565 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 17.37 sec
2018-01-03 14:16:35,063 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.95 sec
MapReduce Total cumulative CPU time: 21 seconds 950 msec
Ended Job = job_1513599404024_168296
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168300, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168300/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168300
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:16:45,976 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:16:52,194 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.41 sec
2018-01-03 14:16:59,423 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.39 sec
MapReduce Total cumulative CPU time: 16 seconds 390 msec
Ended Job = job_1513599404024_168300
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168301, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168301/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168301
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:17:13,157 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:17:18,319 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.07 sec
2018-01-03 14:17:31,700 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.64 sec
MapReduce Total cumulative CPU time: 5 seconds 640 msec
Ended Job = job_1513599404024_168301
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.95 sec   HDFS Read: 10930640 HDFS Write: 715703 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.39 sec   HDFS Read: 44345906 HDFS Write: 135375 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.64 sec   HDFS Read: 143013 HDFS Write: 2742 SUCCESS
Total MapReduce CPU Time Spent: 43 seconds 980 msec
OK
Time taken: 97.492 seconds, Fetched: 406 row(s)
开始执行20171116日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103141739_495e7899-afe3-4740-9051-4b2d1e395a8c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168304, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168304/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168304
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 14:17:54,685 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:18:04,012 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.02 sec
2018-01-03 14:18:07,110 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 14.82 sec
2018-01-03 14:18:10,210 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 18.43 sec
2018-01-03 14:18:13,305 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 35.72 sec
2018-01-03 14:18:16,400 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 39.76 sec
2018-01-03 14:18:19,539 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 43.17 sec
2018-01-03 14:18:22,627 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 46.27 sec
2018-01-03 14:18:23,663 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 46.97 sec
2018-01-03 14:18:25,724 Stage-1 map = 81%,  reduce = 8%, Cumulative CPU 50.42 sec
2018-01-03 14:18:27,788 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 53.29 sec
2018-01-03 14:18:28,823 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 63.6 sec
MapReduce Total cumulative CPU time: 1 minutes 3 seconds 600 msec
Ended Job = job_1513599404024_168304
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168308, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168308/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168308
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:18:35,648 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:18:40,805 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.91 sec
2018-01-03 14:18:43,905 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.55 sec
2018-01-03 14:18:49,052 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.45 sec
MapReduce Total cumulative CPU time: 18 seconds 450 msec
Ended Job = job_1513599404024_168308
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168309, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168309/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168309
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:19:09,458 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:19:14,624 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.0 sec
2018-01-03 14:19:22,871 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.8 sec
MapReduce Total cumulative CPU time: 5 seconds 800 msec
Ended Job = job_1513599404024_168309
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 63.6 sec   HDFS Read: 183391101 HDFS Write: 1747395 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.45 sec   HDFS Read: 44769452 HDFS Write: 168532 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.8 sec   HDFS Read: 176207 HDFS Write: 2932 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 27 seconds 850 msec
OK
Time taken: 104.294 seconds, Fetched: 380 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.395 seconds
Query ID = boss_20180103141930_f66b34b3-f29b-4770-a7ee-e41518a05e04
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168316, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168316/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168316
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 14:19:40,491 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:19:50,873 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 13.29 sec
2018-01-03 14:19:51,907 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 24.6 sec
2018-01-03 14:19:52,942 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 32.2 sec
2018-01-03 14:19:53,981 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 36.12 sec
2018-01-03 14:19:55,012 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 39.45 sec
2018-01-03 14:19:57,078 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 47.25 sec
2018-01-03 14:20:00,171 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 53.87 sec
2018-01-03 14:20:03,285 Stage-1 map = 50%,  reduce = 4%, Cumulative CPU 67.38 sec
2018-01-03 14:20:06,387 Stage-1 map = 55%,  reduce = 4%, Cumulative CPU 73.67 sec
2018-01-03 14:20:09,477 Stage-1 map = 60%,  reduce = 7%, Cumulative CPU 81.09 sec
2018-01-03 14:20:12,570 Stage-1 map = 63%,  reduce = 7%, Cumulative CPU 90.85 sec
2018-01-03 14:20:15,663 Stage-1 map = 67%,  reduce = 7%, Cumulative CPU 107.18 sec
2018-01-03 14:20:18,749 Stage-1 map = 70%,  reduce = 11%, Cumulative CPU 111.37 sec
2018-01-03 14:20:21,838 Stage-1 map = 74%,  reduce = 11%, Cumulative CPU 123.91 sec
2018-01-03 14:20:22,867 Stage-1 map = 87%,  reduce = 11%, Cumulative CPU 126.24 sec
2018-01-03 14:20:23,898 Stage-1 map = 87%,  reduce = 19%, Cumulative CPU 126.44 sec
2018-01-03 14:20:24,930 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 130.59 sec
2018-01-03 14:20:25,958 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 144.64 sec
MapReduce Total cumulative CPU time: 2 minutes 24 seconds 640 msec
Ended Job = job_1513599404024_168316
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168323, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168323/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168323
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:20:35,286 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:20:40,462 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.6 sec
2018-01-03 14:20:48,700 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.49 sec
2018-01-03 14:20:50,764 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.1 sec
MapReduce Total cumulative CPU time: 15 seconds 100 msec
Ended Job = job_1513599404024_168323
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168325, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168325/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168325
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:21:05,438 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:21:10,617 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.78 sec
2018-01-03 14:21:25,043 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.83 sec
MapReduce Total cumulative CPU time: 5 seconds 830 msec
Ended Job = job_1513599404024_168325
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 144.64 sec   HDFS Read: 280599970 HDFS Write: 270067 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.1 sec   HDFS Read: 43292386 HDFS Write: 19399 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.83 sec   HDFS Read: 27075 HDFS Write: 2025 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 45 seconds 570 msec
OK
Time taken: 115.433 seconds, Fetched: 290 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103142132_7ddedb7a-218e-4fe9-8dce-bd8625ad99c0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168327, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168327/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168327
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:21:42,321 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:21:52,660 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 10.43 sec
2018-01-03 14:21:55,757 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 12.27 sec
2018-01-03 14:21:57,819 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.99 sec
2018-01-03 14:22:04,006 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.21 sec
MapReduce Total cumulative CPU time: 18 seconds 210 msec
Ended Job = job_1513599404024_168327
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168330, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168330/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168330
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:22:09,715 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:22:16,954 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.35 sec
2018-01-03 14:22:20,055 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.7 sec
2018-01-03 14:22:30,374 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.68 sec
MapReduce Total cumulative CPU time: 17 seconds 680 msec
Ended Job = job_1513599404024_168330
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168333, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168333/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168333
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:22:38,102 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:22:43,263 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.45 sec
2018-01-03 14:22:55,631 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.01 sec
MapReduce Total cumulative CPU time: 7 seconds 10 msec
Ended Job = job_1513599404024_168333
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.21 sec   HDFS Read: 12721196 HDFS Write: 484981 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.68 sec   HDFS Read: 43506720 HDFS Write: 184344 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.01 sec   HDFS Read: 191981 HDFS Write: 5009 SUCCESS
Total MapReduce CPU Time Spent: 42 seconds 900 msec
OK
Time taken: 83.91 seconds, Fetched: 590 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.351 seconds
Query ID = boss_20180103142303_cd29ca02-71f7-428f-af7b-260aa993dabe
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168336, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168336/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168336
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:23:15,063 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:23:26,476 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 10.57 sec
2018-01-03 14:23:29,584 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 14.67 sec
2018-01-03 14:23:32,683 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 17.31 sec
2018-01-03 14:23:33,716 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 18.53 sec
2018-01-03 14:23:38,883 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 24.11 sec
MapReduce Total cumulative CPU time: 24 seconds 110 msec
Ended Job = job_1513599404024_168336
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168339, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168339/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168339
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:23:44,582 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:23:49,745 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.97 sec
2018-01-03 14:23:52,842 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.39 sec
2018-01-03 14:23:55,938 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.06 sec
MapReduce Total cumulative CPU time: 16 seconds 60 msec
Ended Job = job_1513599404024_168339
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168340, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168340/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168340
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:24:10,700 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:24:14,844 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.82 sec
2018-01-03 14:24:22,070 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.74 sec
MapReduce Total cumulative CPU time: 5 seconds 740 msec
Ended Job = job_1513599404024_168340
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 24.11 sec   HDFS Read: 12721186 HDFS Write: 715926 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.06 sec   HDFS Read: 43737665 HDFS Write: 141369 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.74 sec   HDFS Read: 149007 HDFS Write: 2684 SUCCESS
Total MapReduce CPU Time Spent: 45 seconds 910 msec
OK
Time taken: 79.648 seconds, Fetched: 399 row(s)
开始执行20171117日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103142430_94e8ccdb-ab1c-4c38-a827-2f076e4d97af
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168343, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168343/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168343
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 14:24:56,078 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:25:05,458 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 23.92 sec
2018-01-03 14:25:08,558 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 31.91 sec
2018-01-03 14:25:10,622 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 34.59 sec
2018-01-03 14:25:11,656 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 37.97 sec
2018-01-03 14:25:14,756 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 41.57 sec
2018-01-03 14:25:17,922 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 44.74 sec
2018-01-03 14:25:19,996 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 45.21 sec
2018-01-03 14:25:21,030 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 60.41 sec
2018-01-03 14:25:24,127 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 63.2 sec
2018-01-03 14:25:27,227 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 66.86 sec
2018-01-03 14:25:30,673 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 71.4 sec
2018-01-03 14:25:32,737 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 74.58 sec
2018-01-03 14:25:34,799 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 76.19 sec
2018-01-03 14:25:35,830 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 84.15 sec
2018-01-03 14:25:36,863 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 88.08 sec
MapReduce Total cumulative CPU time: 1 minutes 28 seconds 80 msec
Ended Job = job_1513599404024_168343
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168345, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168345/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168345
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:25:44,943 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:25:52,173 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.66 sec
2018-01-03 14:25:55,269 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.64 sec
2018-01-03 14:26:01,446 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.9 sec
MapReduce Total cumulative CPU time: 18 seconds 900 msec
Ended Job = job_1513599404024_168345
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168347, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168347/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168347
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:26:13,121 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:26:17,252 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.96 sec
2018-01-03 14:26:23,431 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.86 sec
MapReduce Total cumulative CPU time: 6 seconds 860 msec
Ended Job = job_1513599404024_168347
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 88.08 sec   HDFS Read: 211514870 HDFS Write: 1752516 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.9 sec   HDFS Read: 46332418 HDFS Write: 174683 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.86 sec   HDFS Read: 182358 HDFS Write: 2905 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 53 seconds 840 msec
OK
Time taken: 114.461 seconds, Fetched: 373 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.388 seconds
Query ID = boss_20180103142631_00467e94-4c5e-410e-881c-33c05b9c478a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168349, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168349/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168349
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 14:26:41,620 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:26:52,009 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 25.48 sec
2018-01-03 14:26:53,117 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 37.42 sec
2018-01-03 14:26:55,714 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 44.79 sec
2018-01-03 14:26:58,822 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 51.79 sec
2018-01-03 14:27:01,919 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 58.46 sec
2018-01-03 14:27:04,571 Stage-1 map = 51%,  reduce = 7%, Cumulative CPU 65.92 sec
2018-01-03 14:27:05,607 Stage-1 map = 51%,  reduce = 11%, Cumulative CPU 66.56 sec
2018-01-03 14:27:07,674 Stage-1 map = 54%,  reduce = 11%, Cumulative CPU 72.67 sec
2018-01-03 14:27:10,774 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 78.83 sec
2018-01-03 14:27:13,030 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 82.54 sec
2018-01-03 14:27:14,064 Stage-1 map = 63%,  reduce = 11%, Cumulative CPU 86.14 sec
2018-01-03 14:27:16,142 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 89.89 sec
2018-01-03 14:27:17,173 Stage-1 map = 67%,  reduce = 11%, Cumulative CPU 93.25 sec
2018-01-03 14:27:19,233 Stage-1 map = 69%,  reduce = 11%, Cumulative CPU 96.83 sec
2018-01-03 14:27:20,265 Stage-1 map = 71%,  reduce = 11%, Cumulative CPU 100.22 sec
2018-01-03 14:27:22,325 Stage-1 map = 72%,  reduce = 11%, Cumulative CPU 103.49 sec
2018-01-03 14:27:23,358 Stage-1 map = 73%,  reduce = 11%, Cumulative CPU 106.26 sec
2018-01-03 14:27:24,393 Stage-1 map = 86%,  reduce = 11%, Cumulative CPU 108.13 sec
2018-01-03 14:27:25,423 Stage-1 map = 86%,  reduce = 15%, Cumulative CPU 108.13 sec
2018-01-03 14:27:26,460 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 112.29 sec
2018-01-03 14:27:27,492 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 113.61 sec
2018-01-03 14:27:28,533 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 126.2 sec
2018-01-03 14:27:29,566 Stage-1 map = 100%,  reduce = 89%, Cumulative CPU 127.4 sec
2018-01-03 14:27:30,594 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 132.89 sec
MapReduce Total cumulative CPU time: 2 minutes 12 seconds 890 msec
Ended Job = job_1513599404024_168349
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168358, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168358/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168358
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:27:54,508 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:28:00,714 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.62 sec
2018-01-03 14:28:02,780 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.63 sec
2018-01-03 14:28:06,912 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.34 sec
MapReduce Total cumulative CPU time: 15 seconds 340 msec
Ended Job = job_1513599404024_168358
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168362, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168362/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168362
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:28:13,594 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:28:19,775 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.01 sec
2018-01-03 14:28:34,281 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.67 sec
MapReduce Total cumulative CPU time: 5 seconds 670 msec
Ended Job = job_1513599404024_168362
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 132.89 sec   HDFS Read: 302220865 HDFS Write: 269525 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.34 sec   HDFS Read: 44849689 HDFS Write: 19807 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.67 sec   HDFS Read: 27483 HDFS Write: 1972 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 33 seconds 900 msec
OK
Time taken: 124.151 seconds, Fetched: 273 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103142842_acc6082c-fa28-4d0a-b71c-fa4f614a916a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168366, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168366/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168366
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:28:52,699 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:29:10,270 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 10.25 sec
2018-01-03 14:29:13,404 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 12.95 sec
2018-01-03 14:29:14,440 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.03 sec
2018-01-03 14:29:19,597 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.62 sec
MapReduce Total cumulative CPU time: 18 seconds 620 msec
Ended Job = job_1513599404024_168366
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168374, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168374/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168374
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:29:27,402 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:29:33,586 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.83 sec
2018-01-03 14:29:35,646 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.99 sec
2018-01-03 14:29:39,774 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.8 sec
MapReduce Total cumulative CPU time: 16 seconds 800 msec
Ended Job = job_1513599404024_168374
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168375, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168375/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168375
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:29:53,350 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:30:00,587 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.68 sec
2018-01-03 14:30:15,087 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.58 sec
MapReduce Total cumulative CPU time: 7 seconds 580 msec
Ended Job = job_1513599404024_168375
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.62 sec   HDFS Read: 12297792 HDFS Write: 520198 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.8 sec   HDFS Read: 45099782 HDFS Write: 202925 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.58 sec   HDFS Read: 210562 HDFS Write: 5789 SUCCESS
Total MapReduce CPU Time Spent: 43 seconds 0 msec
OK
Time taken: 94.123 seconds, Fetched: 684 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.349 seconds
Query ID = boss_20180103143022_aef6e3fc-124c-4491-a481-22a84a519ad2
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168380, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168380/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168380
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:30:33,425 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:30:43,778 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 10.48 sec
2018-01-03 14:30:46,878 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 13.14 sec
2018-01-03 14:30:49,977 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.18 sec
2018-01-03 14:30:57,202 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.33 sec
MapReduce Total cumulative CPU time: 21 seconds 330 msec
Ended Job = job_1513599404024_168380
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168384, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168384/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168384
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:31:02,894 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:31:08,061 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.64 sec
2018-01-03 14:31:09,090 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.93 sec
2018-01-03 14:31:15,273 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.15 sec
MapReduce Total cumulative CPU time: 15 seconds 150 msec
Ended Job = job_1513599404024_168384
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168392, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168392/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168392
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:31:28,992 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:31:36,229 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.14 sec
2018-01-03 14:31:57,839 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.27 sec
MapReduce Total cumulative CPU time: 8 seconds 270 msec
Ended Job = job_1513599404024_168392
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.33 sec   HDFS Read: 12297782 HDFS Write: 774662 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.15 sec   HDFS Read: 45354246 HDFS Write: 168206 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.27 sec   HDFS Read: 175844 HDFS Write: 2679 SUCCESS
Total MapReduce CPU Time Spent: 44 seconds 750 msec
OK
Time taken: 96.059 seconds, Fetched: 389 row(s)
开始执行20171118日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.375 seconds
Query ID = boss_20180103143205_947d6267-8bd6-43d9-b963-e11f4f700ba1
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168401, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168401/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168401
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 14:32:15,813 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:32:26,173 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.54 sec
2018-01-03 14:32:27,206 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 24.31 sec
2018-01-03 14:32:29,275 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 28.42 sec
2018-01-03 14:32:32,370 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 39.03 sec
2018-01-03 14:32:35,461 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 45.3 sec
2018-01-03 14:32:38,552 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 51.53 sec
2018-01-03 14:32:41,642 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 57.47 sec
2018-01-03 14:32:43,701 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 60.56 sec
2018-01-03 14:32:44,732 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 63.59 sec
2018-01-03 14:32:47,825 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 66.61 sec
2018-01-03 14:32:50,912 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 69.71 sec
2018-01-03 14:32:53,999 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 72.84 sec
2018-01-03 14:32:55,034 Stage-1 map = 80%,  reduce = 8%, Cumulative CPU 73.41 sec
2018-01-03 14:32:57,099 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 78.14 sec
2018-01-03 14:32:59,157 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 83.36 sec
2018-01-03 14:33:00,186 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 87.96 sec
MapReduce Total cumulative CPU time: 1 minutes 27 seconds 960 msec
Ended Job = job_1513599404024_168401
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168409, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168409/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168409
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:33:05,916 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:33:13,141 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.23 sec
2018-01-03 14:33:14,172 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.74 sec
2018-01-03 14:33:18,297 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.07 sec
MapReduce Total cumulative CPU time: 20 seconds 70 msec
Ended Job = job_1513599404024_168409
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168412, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168412/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168412
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:33:24,004 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:33:30,207 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.16 sec
2018-01-03 14:33:36,407 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.62 sec
MapReduce Total cumulative CPU time: 7 seconds 620 msec
Ended Job = job_1513599404024_168412
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 87.96 sec   HDFS Read: 251639292 HDFS Write: 1819043 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.07 sec   HDFS Read: 48640747 HDFS Write: 209881 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.62 sec   HDFS Read: 217556 HDFS Write: 2859 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 55 seconds 650 msec
OK
Time taken: 91.643 seconds, Fetched: 377 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.387 seconds
Query ID = boss_20180103143344_ab139cf9-cf7f-47e1-b3de-ebe206897e1c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168416, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168416/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168416
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 4
2018-01-03 14:33:54,149 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:34:03,590 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 12.0 sec
2018-01-03 14:34:04,629 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 23.53 sec
2018-01-03 14:34:06,702 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 27.69 sec
2018-01-03 14:34:07,742 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 31.18 sec
2018-01-03 14:34:09,809 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 34.47 sec
2018-01-03 14:34:10,842 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 37.66 sec
2018-01-03 14:34:12,908 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 41.11 sec
2018-01-03 14:34:13,940 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 44.37 sec
2018-01-03 14:34:14,973 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 47.39 sec
2018-01-03 14:34:17,047 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 50.4 sec
2018-01-03 14:34:20,141 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 53.17 sec
2018-01-03 14:34:23,234 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 56.08 sec
2018-01-03 14:34:25,299 Stage-1 map = 54%,  reduce = 3%, Cumulative CPU 68.71 sec
2018-01-03 14:34:26,334 Stage-1 map = 56%,  reduce = 3%, Cumulative CPU 71.99 sec
2018-01-03 14:34:27,368 Stage-1 map = 56%,  reduce = 8%, Cumulative CPU 73.19 sec
2018-01-03 14:34:28,399 Stage-1 map = 58%,  reduce = 8%, Cumulative CPU 76.92 sec
2018-01-03 14:34:29,430 Stage-1 map = 61%,  reduce = 8%, Cumulative CPU 80.53 sec
2018-01-03 14:34:30,464 Stage-1 map = 73%,  reduce = 8%, Cumulative CPU 82.86 sec
2018-01-03 14:34:31,495 Stage-1 map = 76%,  reduce = 8%, Cumulative CPU 86.25 sec
2018-01-03 14:34:32,526 Stage-1 map = 76%,  reduce = 11%, Cumulative CPU 86.32 sec
2018-01-03 14:34:33,558 Stage-1 map = 76%,  reduce = 19%, Cumulative CPU 86.88 sec
2018-01-03 14:34:34,589 Stage-1 map = 80%,  reduce = 22%, Cumulative CPU 90.4 sec
2018-01-03 14:34:37,683 Stage-1 map = 83%,  reduce = 22%, Cumulative CPU 93.95 sec
2018-01-03 14:34:40,775 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 97.75 sec
2018-01-03 14:34:43,866 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 101.79 sec
2018-01-03 14:34:44,898 Stage-1 map = 100%,  reduce = 72%, Cumulative CPU 110.66 sec
2018-01-03 14:34:45,927 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 118.04 sec
MapReduce Total cumulative CPU time: 1 minutes 58 seconds 40 msec
Ended Job = job_1513599404024_168416
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168424, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168424/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168424
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:34:52,667 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:34:57,821 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.52 sec
2018-01-03 14:34:58,849 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.77 sec
2018-01-03 14:35:02,966 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.35 sec
MapReduce Total cumulative CPU time: 14 seconds 350 msec
Ended Job = job_1513599404024_168424
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168429, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168429/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168429
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:35:38,640 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:35:43,884 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.14 sec
2018-01-03 14:35:51,090 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.17 sec
MapReduce Total cumulative CPU time: 6 seconds 170 msec
Ended Job = job_1513599404024_168429
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 4   Cumulative CPU: 118.04 sec   HDFS Read: 377627680 HDFS Write: 325565 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.35 sec   HDFS Read: 47147793 HDFS Write: 23611 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.17 sec   HDFS Read: 31287 HDFS Write: 2145 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 18 seconds 560 msec
OK
Time taken: 127.965 seconds, Fetched: 295 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103143558_77ad39b0-0ddc-4df9-8b70-9d6ede8d9227
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168432, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168432/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168432
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:36:10,523 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:36:20,905 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 10.0 sec
2018-01-03 14:36:24,006 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.84 sec
2018-01-03 14:36:32,259 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.82 sec
MapReduce Total cumulative CPU time: 17 seconds 820 msec
Ended Job = job_1513599404024_168432
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168439, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168439/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168439
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:36:38,959 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:36:44,125 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.1 sec
2018-01-03 14:36:45,156 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.81 sec
2018-01-03 14:36:52,371 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.0 sec
MapReduce Total cumulative CPU time: 18 seconds 0 msec
Ended Job = job_1513599404024_168439
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168442, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168442/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168442
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:37:06,114 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:37:12,302 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.37 sec
2018-01-03 14:37:17,451 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.18 sec
MapReduce Total cumulative CPU time: 6 seconds 180 msec
Ended Job = job_1513599404024_168442
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.82 sec   HDFS Read: 13554384 HDFS Write: 527765 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.0 sec   HDFS Read: 47349151 HDFS Write: 227444 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.18 sec   HDFS Read: 235081 HDFS Write: 5973 SUCCESS
Total MapReduce CPU Time Spent: 42 seconds 0 msec
OK
Time taken: 79.66 seconds, Fetched: 703 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.351 seconds
Query ID = boss_20180103143725_4148768b-a13d-44e3-bc48-09390ffeca7f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168444, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168444/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168444
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:37:36,778 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:37:47,132 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 13.48 sec
2018-01-03 14:37:50,230 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 18.24 sec
2018-01-03 14:37:51,262 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 20.12 sec
2018-01-03 14:38:08,780 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 26.22 sec
MapReduce Total cumulative CPU time: 26 seconds 220 msec
Ended Job = job_1513599404024_168444
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168451, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168451/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168451
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:38:20,569 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:38:25,758 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.99 sec
2018-01-03 14:38:26,793 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.48 sec
2018-01-03 14:38:34,035 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.85 sec
MapReduce Total cumulative CPU time: 15 seconds 850 msec
Ended Job = job_1513599404024_168451
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168456, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168456/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168456
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:38:41,887 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:38:47,050 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.27 sec
2018-01-03 14:38:54,253 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.4 sec
MapReduce Total cumulative CPU time: 6 seconds 400 msec
Ended Job = job_1513599404024_168456
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 26.22 sec   HDFS Read: 13554374 HDFS Write: 898813 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.85 sec   HDFS Read: 47720199 HDFS Write: 186252 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.4 sec   HDFS Read: 193890 HDFS Write: 3122 SUCCESS
Total MapReduce CPU Time Spent: 48 seconds 470 msec
OK
Time taken: 90.128 seconds, Fetched: 392 row(s)
开始执行20171119日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.371 seconds
Query ID = boss_20180103143902_4a38c2d6-6931-46b9-a146-3f31cd019448
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168459, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168459/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168459
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 14:39:19,433 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:39:28,834 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 13.36 sec
2018-01-03 14:39:29,867 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 25.65 sec
2018-01-03 14:39:31,932 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 29.37 sec
2018-01-03 14:39:32,963 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 33.01 sec
2018-01-03 14:39:35,023 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 36.79 sec
2018-01-03 14:39:36,052 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 40.36 sec
2018-01-03 14:39:38,113 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 43.66 sec
2018-01-03 14:39:39,142 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 47.82 sec
2018-01-03 14:39:41,201 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 51.41 sec
2018-01-03 14:39:42,235 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 54.37 sec
2018-01-03 14:39:45,323 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 57.37 sec
2018-01-03 14:39:48,409 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 60.43 sec
2018-01-03 14:39:50,466 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 63.53 sec
2018-01-03 14:39:51,503 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 64.23 sec
2018-01-03 14:39:53,565 Stage-1 map = 76%,  reduce = 8%, Cumulative CPU 66.74 sec
2018-01-03 14:39:56,653 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 70.19 sec
2018-01-03 14:39:59,745 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 73.96 sec
2018-01-03 14:40:01,804 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 76.2 sec
2018-01-03 14:40:02,833 Stage-1 map = 100%,  reduce = 30%, Cumulative CPU 76.4 sec
2018-01-03 14:40:03,862 Stage-1 map = 100%,  reduce = 72%, Cumulative CPU 81.24 sec
2018-01-03 14:40:04,895 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 85.33 sec
MapReduce Total cumulative CPU time: 1 minutes 25 seconds 330 msec
Ended Job = job_1513599404024_168459
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168473, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168473/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168473
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:40:13,014 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:40:19,228 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.57 sec
2018-01-03 14:40:21,290 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.73 sec
2018-01-03 14:40:29,543 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.18 sec
MapReduce Total cumulative CPU time: 20 seconds 180 msec
Ended Job = job_1513599404024_168473
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168474, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168474/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168474
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:40:57,603 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:41:42,094 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 7.65 sec
2018-01-03 14:42:20,488 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 11.53 sec
2018-01-03 14:42:28,689 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 21.46 sec
MapReduce Total cumulative CPU time: 21 seconds 460 msec
Ended Job = job_1513599404024_168474
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 85.33 sec   HDFS Read: 236801711 HDFS Write: 1710002 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.18 sec   HDFS Read: 47038724 HDFS Write: 185386 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 21.46 sec   HDFS Read: 193061 HDFS Write: 2824 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 6 seconds 970 msec
OK
Time taken: 207.505 seconds, Fetched: 377 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.407 seconds
Query ID = boss_20180103144236_017340b7-b7da-4a6f-8815-cc7af2c50a9b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168480, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168480/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168480
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 14:42:45,365 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:42:55,744 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 39.85 sec
2018-01-03 14:42:58,844 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 52.94 sec
2018-01-03 14:43:00,906 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 56.19 sec
2018-01-03 14:43:01,941 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 64.36 sec
2018-01-03 14:43:04,012 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 67.5 sec
2018-01-03 14:43:05,044 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 76.59 sec
2018-01-03 14:43:07,104 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 83.04 sec
2018-01-03 14:43:08,137 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 88.04 sec
2018-01-03 14:43:10,196 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 91.46 sec
2018-01-03 14:43:11,234 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 94.78 sec
2018-01-03 14:43:13,306 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 99.27 sec
2018-01-03 14:43:14,339 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 103.77 sec
2018-01-03 14:43:17,430 Stage-1 map = 88%,  reduce = 0%, Cumulative CPU 110.55 sec
2018-01-03 14:43:18,463 Stage-1 map = 88%,  reduce = 15%, Cumulative CPU 111.76 sec
2018-01-03 14:43:19,493 Stage-1 map = 100%,  reduce = 15%, Cumulative CPU 115.52 sec
2018-01-03 14:43:21,552 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 121.96 sec
2018-01-03 14:43:22,581 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 122.94 sec
2018-01-03 14:43:26,697 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 127.83 sec
MapReduce Total cumulative CPU time: 2 minutes 7 seconds 830 msec
Ended Job = job_1513599404024_168480
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168482, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168482/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168482
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:43:34,422 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:43:39,587 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.64 sec
2018-01-03 14:43:42,678 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.74 sec
2018-01-03 14:43:45,770 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.46 sec
MapReduce Total cumulative CPU time: 16 seconds 460 msec
Ended Job = job_1513599404024_168482
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168484, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168484/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168484
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:43:59,429 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:44:09,747 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.33 sec
2018-01-03 14:44:24,180 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.07 sec
MapReduce Total cumulative CPU time: 5 seconds 70 msec
Ended Job = job_1513599404024_168484
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 127.83 sec   HDFS Read: 363199935 HDFS Write: 311179 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.46 sec   HDFS Read: 45640163 HDFS Write: 22501 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.07 sec   HDFS Read: 30177 HDFS Write: 2040 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 29 seconds 360 msec
OK
Time taken: 108.776 seconds, Fetched: 295 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103144431_212cd9d1-2f26-465d-9e59-8fe2120660b7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168488, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168488/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168488
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:44:43,009 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:44:56,468 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 11.59 sec
2018-01-03 14:44:59,563 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 14.15 sec
2018-01-03 14:45:01,625 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.27 sec
2018-01-03 14:45:06,790 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.26 sec
MapReduce Total cumulative CPU time: 20 seconds 260 msec
Ended Job = job_1513599404024_168488
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168490, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168490/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168490
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:45:12,684 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:45:17,839 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.42 sec
2018-01-03 14:45:20,934 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.13 sec
2018-01-03 14:45:24,022 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.28 sec
MapReduce Total cumulative CPU time: 18 seconds 280 msec
Ended Job = job_1513599404024_168490
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168492, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168492/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168492
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:45:29,663 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:45:34,821 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.41 sec
2018-01-03 14:45:40,999 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.24 sec
MapReduce Total cumulative CPU time: 7 seconds 240 msec
Ended Job = job_1513599404024_168492
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.26 sec   HDFS Read: 12280803 HDFS Write: 503301 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.28 sec   HDFS Read: 45831705 HDFS Write: 214334 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.24 sec   HDFS Read: 221971 HDFS Write: 5441 SUCCESS
Total MapReduce CPU Time Spent: 45 seconds 780 msec
OK
Time taken: 70.151 seconds, Fetched: 636 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103144548_f758ff6a-99d4-4789-ad62-840a116134e5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168494, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168494/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168494
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:45:58,370 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:46:07,762 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 11.81 sec
2018-01-03 14:46:09,826 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.63 sec
2018-01-03 14:46:16,021 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.15 sec
MapReduce Total cumulative CPU time: 20 seconds 150 msec
Ended Job = job_1513599404024_168494
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168497, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168497/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168497
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:46:21,894 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:46:28,111 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.25 sec
2018-01-03 14:46:30,189 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.67 sec
2018-01-03 14:46:35,351 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.94 sec
MapReduce Total cumulative CPU time: 17 seconds 940 msec
Ended Job = job_1513599404024_168497
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168500, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168500/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168500
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:46:50,050 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:46:55,328 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.47 sec
2018-01-03 14:47:02,554 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.6 sec
MapReduce Total cumulative CPU time: 6 seconds 600 msec
Ended Job = job_1513599404024_168500
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.15 sec   HDFS Read: 12280793 HDFS Write: 858238 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.94 sec   HDFS Read: 46186642 HDFS Write: 178840 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.6 sec   HDFS Read: 186478 HDFS Write: 2983 SUCCESS
Total MapReduce CPU Time Spent: 44 seconds 690 msec
OK
Time taken: 74.867 seconds, Fetched: 406 row(s)
开始执行20171120日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.373 seconds
Query ID = boss_20180103144710_2a027b09-2b91-469c-991e-08c2034295ca
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168504, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168504/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168504
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 14:47:20,713 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:47:31,070 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 24.21 sec
2018-01-03 14:47:33,136 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 26.99 sec
2018-01-03 14:47:34,172 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 30.19 sec
2018-01-03 14:47:37,280 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 33.41 sec
2018-01-03 14:47:40,372 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 37.04 sec
2018-01-03 14:47:43,469 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 40.01 sec
2018-01-03 14:47:44,506 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 41.24 sec
2018-01-03 14:47:46,569 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 44.28 sec
2018-01-03 14:47:49,663 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 47.61 sec
2018-01-03 14:47:52,760 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 50.71 sec
2018-01-03 14:47:55,847 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 53.81 sec
2018-01-03 14:47:58,935 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 57.63 sec
2018-01-03 14:48:00,997 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 48.72 sec
2018-01-03 14:48:02,027 Stage-1 map = 100%,  reduce = 51%, Cumulative CPU 51.32 sec
2018-01-03 14:48:03,056 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 56.13 sec
MapReduce Total cumulative CPU time: 56 seconds 130 msec
Ended Job = job_1513599404024_168504
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168509, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168509/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168509
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:48:08,735 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:48:14,912 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.49 sec
2018-01-03 14:48:15,957 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.48 sec
2018-01-03 14:48:22,126 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.35 sec
MapReduce Total cumulative CPU time: 18 seconds 350 msec
Ended Job = job_1513599404024_168509
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168510, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168510/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168510
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:48:30,813 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:48:43,323 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.83 sec
2018-01-03 14:48:57,743 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.8 sec
MapReduce Total cumulative CPU time: 5 seconds 800 msec
Ended Job = job_1513599404024_168510
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 56.13 sec   HDFS Read: 177070107 HDFS Write: 1542685 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.35 sec   HDFS Read: 43780368 HDFS Write: 134245 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.8 sec   HDFS Read: 141920 HDFS Write: 2592 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 20 seconds 280 msec
OK
Time taken: 108.134 seconds, Fetched: 347 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.488 seconds
Query ID = boss_20180103144905_7a8f8c5b-5143-4c94-8a0d-9afad2811624
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168514, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168514/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168514
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 14:49:14,796 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:49:24,117 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.93 sec
2018-01-03 14:49:25,151 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 26.24 sec
2018-01-03 14:49:27,220 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 29.58 sec
2018-01-03 14:49:28,254 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 34.36 sec
2018-01-03 14:49:30,316 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 37.71 sec
2018-01-03 14:49:31,346 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 41.15 sec
2018-01-03 14:49:33,411 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 44.5 sec
2018-01-03 14:49:34,441 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 48.08 sec
2018-01-03 14:49:36,497 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 51.4 sec
2018-01-03 14:49:37,530 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 54.64 sec
2018-01-03 14:49:39,589 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 57.91 sec
2018-01-03 14:49:40,618 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 62.49 sec
2018-01-03 14:49:43,704 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 65.92 sec
2018-01-03 14:49:45,761 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 69.74 sec
2018-01-03 14:49:47,827 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 80.68 sec
MapReduce Total cumulative CPU time: 1 minutes 20 seconds 680 msec
Ended Job = job_1513599404024_168514
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168517, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168517/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168517
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:49:53,492 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:49:58,649 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 7.8 sec
2018-01-03 14:50:03,798 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.39 sec
MapReduce Total cumulative CPU time: 12 seconds 390 msec
Ended Job = job_1513599404024_168517
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168518, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168518/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168518
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:50:10,463 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:50:15,633 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.73 sec
2018-01-03 14:50:22,842 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.11 sec
MapReduce Total cumulative CPU time: 5 seconds 110 msec
Ended Job = job_1513599404024_168518
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 80.68 sec   HDFS Read: 264790166 HDFS Write: 236007 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.39 sec   HDFS Read: 42473952 HDFS Write: 19441 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.11 sec   HDFS Read: 27117 HDFS Write: 1906 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 38 seconds 180 msec
OK
Time taken: 78.294 seconds, Fetched: 268 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103145030_7ace024b-993d-4e94-a07a-aa7c6f6ecb98
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168521, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168521/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168521
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:50:42,275 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:50:51,608 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 9.18 sec
2018-01-03 14:50:54,710 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 11.39 sec
2018-01-03 14:51:00,901 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 14.85 sec
MapReduce Total cumulative CPU time: 14 seconds 850 msec
Ended Job = job_1513599404024_168521
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168524, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168524/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168524
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:51:06,688 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:51:11,850 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.18 sec
2018-01-03 14:51:12,880 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.11 sec
2018-01-03 14:51:18,026 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.93 sec
MapReduce Total cumulative CPU time: 16 seconds 930 msec
Ended Job = job_1513599404024_168524
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168526, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168526/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168526
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:51:24,658 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:51:29,825 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.37 sec
2018-01-03 14:51:34,974 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.19 sec
MapReduce Total cumulative CPU time: 6 seconds 190 msec
Ended Job = job_1513599404024_168526
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 14.85 sec   HDFS Read: 10495549 HDFS Write: 454732 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.93 sec   HDFS Read: 42692093 HDFS Write: 174826 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.19 sec   HDFS Read: 182459 HDFS Write: 5266 SUCCESS
Total MapReduce CPU Time Spent: 37 seconds 970 msec
OK
Time taken: 65.276 seconds, Fetched: 608 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.344 seconds
Query ID = boss_20180103145142_ce3c5c0d-1d65-4519-a6a8-4b5b1b2ef59f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168529, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168529/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168529
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:51:52,237 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:52:01,624 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 11.55 sec
2018-01-03 14:52:02,657 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.26 sec
2018-01-03 14:52:07,824 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.44 sec
MapReduce Total cumulative CPU time: 18 seconds 440 msec
Ended Job = job_1513599404024_168529
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168531, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168531/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168531
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:52:14,757 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:52:20,952 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.64 sec
2018-01-03 14:52:28,165 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.69 sec
2018-01-03 14:52:29,195 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.93 sec
MapReduce Total cumulative CPU time: 14 seconds 930 msec
Ended Job = job_1513599404024_168531
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168533, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168533/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168533
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:52:35,866 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:52:41,032 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.99 sec
2018-01-03 14:52:47,210 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.64 sec
MapReduce Total cumulative CPU time: 6 seconds 640 msec
Ended Job = job_1513599404024_168533
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.44 sec   HDFS Read: 10495540 HDFS Write: 686138 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.93 sec   HDFS Read: 42923503 HDFS Write: 153971 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.64 sec   HDFS Read: 161609 HDFS Write: 2826 SUCCESS
Total MapReduce CPU Time Spent: 40 seconds 10 msec
OK
Time taken: 65.53 seconds, Fetched: 361 row(s)
开始执行20171121日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103145255_7b6be986-b770-4377-9121-7c520e4d3cce
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168534, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168534/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168534
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 14:53:04,181 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:53:14,529 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 25.49 sec
2018-01-03 14:53:15,562 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 27.95 sec
2018-01-03 14:53:17,630 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 32.39 sec
2018-01-03 14:53:20,724 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 35.98 sec
2018-01-03 14:53:23,813 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 39.39 sec
2018-01-03 14:53:26,912 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 43.44 sec
2018-01-03 14:53:28,974 Stage-1 map = 71%,  reduce = 8%, Cumulative CPU 46.83 sec
2018-01-03 14:53:32,059 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 50.56 sec
2018-01-03 14:53:34,118 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 51.21 sec
2018-01-03 14:53:35,151 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 55.2 sec
2018-01-03 14:53:38,239 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 59.64 sec
2018-01-03 14:53:40,298 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 62.59 sec
2018-01-03 14:53:42,355 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 72.09 sec
MapReduce Total cumulative CPU time: 1 minutes 12 seconds 90 msec
Ended Job = job_1513599404024_168534
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168537, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168537/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168537
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:53:48,022 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:53:54,210 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.05 sec
2018-01-03 14:54:08,611 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.55 sec
2018-01-03 14:54:14,780 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.25 sec
MapReduce Total cumulative CPU time: 16 seconds 250 msec
Ended Job = job_1513599404024_168537
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168540, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168540/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168540
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:54:20,384 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:54:24,503 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.89 sec
2018-01-03 14:54:29,649 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.54 sec
MapReduce Total cumulative CPU time: 5 seconds 540 msec
Ended Job = job_1513599404024_168540
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 72.09 sec   HDFS Read: 180282383 HDFS Write: 1599946 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.25 sec   HDFS Read: 45265837 HDFS Write: 171094 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.54 sec   HDFS Read: 178769 HDFS Write: 2780 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 33 seconds 880 msec
OK
Time taken: 95.574 seconds, Fetched: 361 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.395 seconds
Query ID = boss_20180103145437_0c97ccd7-ac47-4ae3-bbb1-5a1c23cd7fce
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168542, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168542/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168542
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 14:55:00,377 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:55:10,725 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 11.98 sec
2018-01-03 14:55:13,820 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 15.3 sec
2018-01-03 14:55:16,910 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 18.64 sec
2018-01-03 14:55:17,939 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 31.71 sec
2018-01-03 14:55:19,997 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 34.83 sec
2018-01-03 14:55:21,027 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 39.14 sec
2018-01-03 14:55:22,057 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 42.5 sec
2018-01-03 14:55:24,118 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 45.81 sec
2018-01-03 14:55:25,147 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 48.78 sec
2018-01-03 14:55:27,205 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 51.93 sec
2018-01-03 14:55:28,234 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 54.84 sec
2018-01-03 14:55:30,290 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 58.28 sec
2018-01-03 14:55:31,319 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 61.12 sec
2018-01-03 14:55:33,378 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 64.34 sec
2018-01-03 14:55:34,407 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 67.48 sec
2018-01-03 14:55:35,436 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 68.98 sec
2018-01-03 14:55:36,468 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 72.23 sec
2018-01-03 14:55:39,585 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 75.51 sec
2018-01-03 14:55:42,672 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 79.76 sec
2018-01-03 14:55:43,703 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 90.81 sec
MapReduce Total cumulative CPU time: 1 minutes 30 seconds 810 msec
Ended Job = job_1513599404024_168542
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168545, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168545/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168545
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:55:49,379 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:55:54,527 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.44 sec
2018-01-03 14:55:55,557 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.04 sec
2018-01-03 14:56:00,700 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.36 sec
MapReduce Total cumulative CPU time: 13 seconds 360 msec
Ended Job = job_1513599404024_168545
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168546, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168546/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168546
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:56:06,394 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:56:11,544 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.57 sec
2018-01-03 14:56:17,715 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.9 sec
MapReduce Total cumulative CPU time: 4 seconds 900 msec
Ended Job = job_1513599404024_168546
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 90.81 sec   HDFS Read: 266442402 HDFS Write: 222306 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.36 sec   HDFS Read: 43888459 HDFS Write: 17573 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.9 sec   HDFS Read: 25249 HDFS Write: 1854 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 49 seconds 70 msec
OK
Time taken: 101.352 seconds, Fetched: 271 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.474 seconds
Query ID = boss_20180103145625_31750733-2b41-4957-8167-0c85d80c4003
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168550, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168550/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168550
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:56:35,098 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:56:45,434 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 11.76 sec
2018-01-03 14:56:47,500 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 13.87 sec
2018-01-03 14:56:48,531 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.33 sec
2018-01-03 14:56:55,744 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.82 sec
MapReduce Total cumulative CPU time: 18 seconds 820 msec
Ended Job = job_1513599404024_168550
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168552, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168552/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168552
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:57:14,464 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:57:20,670 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.66 sec
2018-01-03 14:57:21,707 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.66 sec
2018-01-03 14:57:26,873 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.87 sec
MapReduce Total cumulative CPU time: 14 seconds 870 msec
Ended Job = job_1513599404024_168552
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168555, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168555/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168555
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:57:48,509 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:57:53,662 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.34 sec
2018-01-03 14:57:59,839 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.7 sec
MapReduce Total cumulative CPU time: 6 seconds 700 msec
Ended Job = job_1513599404024_168555
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.82 sec   HDFS Read: 10141044 HDFS Write: 409829 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.87 sec   HDFS Read: 44075402 HDFS Write: 156713 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.7 sec   HDFS Read: 164350 HDFS Write: 5002 SUCCESS
Total MapReduce CPU Time Spent: 40 seconds 390 msec
OK
Time taken: 95.323 seconds, Fetched: 598 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.377 seconds
Query ID = boss_20180103145821_aec6f78b-b7c4-44e0-92ca-c75f438e10b5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168559, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168559/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168559
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 14:58:39,491 Stage-1 map = 0%,  reduce = 0%
2018-01-03 14:58:48,865 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.32 sec
2018-01-03 14:58:55,059 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.26 sec
MapReduce Total cumulative CPU time: 17 seconds 260 msec
Ended Job = job_1513599404024_168559
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168562, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168562/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168562
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 14:59:08,784 Stage-2 map = 0%,  reduce = 0%
2018-01-03 14:59:13,964 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.43 sec
2018-01-03 14:59:16,034 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.99 sec
2018-01-03 14:59:28,430 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.94 sec
MapReduce Total cumulative CPU time: 15 seconds 940 msec
Ended Job = job_1513599404024_168562
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168567, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168567/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168567
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 14:59:34,118 Stage-3 map = 0%,  reduce = 0%
2018-01-03 14:59:39,271 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.33 sec
2018-01-03 14:59:45,445 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.1 sec
MapReduce Total cumulative CPU time: 6 seconds 100 msec
Ended Job = job_1513599404024_168567
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.26 sec   HDFS Read: 10141034 HDFS Write: 677945 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.94 sec   HDFS Read: 44343518 HDFS Write: 147706 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.1 sec   HDFS Read: 155344 HDFS Write: 2777 SUCCESS
Total MapReduce CPU Time Spent: 39 seconds 300 msec
OK
Time taken: 84.6 seconds, Fetched: 389 row(s)
开始执行20171122日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.367 seconds
Query ID = boss_20180103145953_f6d61a06-158f-4adf-b4a4-2cf6aed8c9aa
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168572, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168572/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168572
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:00:02,373 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:00:12,777 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 12.77 sec
2018-01-03 15:00:14,842 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 17.19 sec
2018-01-03 15:00:17,937 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 20.74 sec
2018-01-03 15:00:21,026 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 24.06 sec
2018-01-03 15:00:24,116 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 27.44 sec
2018-01-03 15:00:27,207 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 30.82 sec
2018-01-03 15:00:28,237 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 45.85 sec
2018-01-03 15:00:30,302 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 48.68 sec
2018-01-03 15:00:33,407 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 51.61 sec
2018-01-03 15:00:36,499 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 54.89 sec
2018-01-03 15:00:39,591 Stage-1 map = 83%,  reduce = 17%, Cumulative CPU 60.1 sec
2018-01-03 15:00:40,620 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 61.28 sec
2018-01-03 15:00:41,650 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 70.91 sec
MapReduce Total cumulative CPU time: 1 minutes 10 seconds 910 msec
Ended Job = job_1513599404024_168572
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168574, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168574/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168574
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:00:56,405 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:01:01,579 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.99 sec
2018-01-03 15:01:03,645 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.51 sec
2018-01-03 15:01:07,771 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.47 sec
MapReduce Total cumulative CPU time: 17 seconds 470 msec
Ended Job = job_1513599404024_168574
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168577, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168577/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168577
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:01:15,438 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:01:28,820 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.47 sec
2018-01-03 15:01:34,996 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.1 sec
MapReduce Total cumulative CPU time: 6 seconds 100 msec
Ended Job = job_1513599404024_168577
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 71.33 sec   HDFS Read: 175856515 HDFS Write: 1600359 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.47 sec   HDFS Read: 44748138 HDFS Write: 209983 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.1 sec   HDFS Read: 217658 HDFS Write: 2714 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 34 seconds 900 msec
OK
Time taken: 102.598 seconds, Fetched: 363 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.381 seconds
Query ID = boss_20180103150142_914e1441-3baa-4173-a616-658c42195b96
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168581, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168581/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168581
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 15:02:14,128 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:02:20,361 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 6.83 sec
2018-01-03 15:02:24,494 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 31.26 sec
2018-01-03 15:02:27,593 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 38.81 sec
2018-01-03 15:02:30,692 Stage-1 map = 49%,  reduce = 4%, Cumulative CPU 45.74 sec
2018-01-03 15:02:31,725 Stage-1 map = 49%,  reduce = 7%, Cumulative CPU 46.32 sec
2018-01-03 15:02:33,786 Stage-1 map = 56%,  reduce = 7%, Cumulative CPU 53.12 sec
2018-01-03 15:02:35,858 Stage-1 map = 59%,  reduce = 7%, Cumulative CPU 56.48 sec
2018-01-03 15:02:36,890 Stage-1 map = 61%,  reduce = 7%, Cumulative CPU 59.87 sec
2018-01-03 15:02:37,921 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 60.6 sec
2018-01-03 15:02:38,950 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 63.92 sec
2018-01-03 15:02:39,980 Stage-1 map = 66%,  reduce = 11%, Cumulative CPU 67.57 sec
2018-01-03 15:02:41,011 Stage-1 map = 79%,  reduce = 11%, Cumulative CPU 70.71 sec
2018-01-03 15:02:43,072 Stage-1 map = 82%,  reduce = 15%, Cumulative CPU 73.71 sec
2018-01-03 15:02:44,101 Stage-1 map = 82%,  reduce = 19%, Cumulative CPU 73.83 sec
2018-01-03 15:02:45,131 Stage-1 map = 82%,  reduce = 22%, Cumulative CPU 74.64 sec
2018-01-03 15:02:46,164 Stage-1 map = 84%,  reduce = 22%, Cumulative CPU 77.96 sec
2018-01-03 15:02:49,248 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 81.67 sec
2018-01-03 15:02:51,304 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 85.67 sec
2018-01-03 15:02:52,332 Stage-1 map = 100%,  reduce = 63%, Cumulative CPU 90.55 sec
2018-01-03 15:02:53,360 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 96.77 sec
MapReduce Total cumulative CPU time: 1 minutes 36 seconds 770 msec
Ended Job = job_1513599404024_168581
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168587, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168587/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168587
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:02:59,214 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:03:05,422 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.53 sec
2018-01-03 15:03:06,456 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.19 sec
2018-01-03 15:03:25,010 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.59 sec
MapReduce Total cumulative CPU time: 13 seconds 590 msec
Ended Job = job_1513599404024_168587
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168592, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168592/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168592
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:03:38,685 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:03:52,070 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.64 sec
2018-01-03 15:03:59,284 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.77 sec
MapReduce Total cumulative CPU time: 5 seconds 770 msec
Ended Job = job_1513599404024_168592
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 96.77 sec   HDFS Read: 262740426 HDFS Write: 233270 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.59 sec   HDFS Read: 43381311 HDFS Write: 18734 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.77 sec   HDFS Read: 26410 HDFS Write: 1962 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 56 seconds 130 msec
OK
Time taken: 137.508 seconds, Fetched: 275 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.432 seconds
Query ID = boss_20180103150407_55f210dc-7126-4e6e-80ae-f2f09d78b5eb
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168597, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168597/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168597
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:04:17,091 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:04:27,465 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 9.04 sec
2018-01-03 15:04:30,570 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 10.06 sec
2018-01-03 15:04:31,604 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 11.49 sec
2018-01-03 15:04:37,815 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 14.86 sec
MapReduce Total cumulative CPU time: 14 seconds 860 msec
Ended Job = job_1513599404024_168597
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168598, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168598/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168598
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:04:43,684 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:04:48,841 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.55 sec
2018-01-03 15:04:49,871 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.56 sec
2018-01-03 15:04:55,024 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.4 sec
MapReduce Total cumulative CPU time: 14 seconds 400 msec
Ended Job = job_1513599404024_168598
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168603, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168603/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168603
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:05:00,674 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:05:05,852 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.36 sec
2018-01-03 15:05:12,050 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.79 sec
MapReduce Total cumulative CPU time: 5 seconds 790 msec
Ended Job = job_1513599404024_168603
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 14.86 sec   HDFS Read: 10109066 HDFS Write: 362800 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.4 sec   HDFS Read: 43510261 HDFS Write: 135398 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.79 sec   HDFS Read: 143035 HDFS Write: 4723 SUCCESS
Total MapReduce CPU Time Spent: 35 seconds 50 msec
OK
Time taken: 65.795 seconds, Fetched: 551 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103150519_a114f264-67b7-437f-b106-10e4da20bd3c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168606, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168606/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168606
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:05:30,415 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:05:39,751 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 12.67 sec
2018-01-03 15:05:40,784 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.77 sec
2018-01-03 15:05:46,982 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.17 sec
MapReduce Total cumulative CPU time: 20 seconds 170 msec
Ended Job = job_1513599404024_168606
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168611, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168611/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168611
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:05:54,153 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:05:59,325 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.34 sec
2018-01-03 15:06:00,357 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.58 sec
2018-01-03 15:06:05,509 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.94 sec
MapReduce Total cumulative CPU time: 13 seconds 940 msec
Ended Job = job_1513599404024_168611
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168616, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168616/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168616
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:06:11,132 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:06:15,259 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.07 sec
2018-01-03 15:06:21,438 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.98 sec
MapReduce Total cumulative CPU time: 6 seconds 980 msec
Ended Job = job_1513599404024_168616
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.17 sec   HDFS Read: 10109056 HDFS Write: 701196 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.94 sec   HDFS Read: 43848657 HDFS Write: 163305 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.98 sec   HDFS Read: 170943 HDFS Write: 3086 SUCCESS
Total MapReduce CPU Time Spent: 41 seconds 90 msec
OK
Time taken: 62.675 seconds, Fetched: 410 row(s)
开始执行20171123日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103150629_0479d440-9e1a-4bd9-b2e2-104f7b4857f3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168620, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168620/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168620
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:06:39,270 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:06:49,624 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 13.08 sec
2018-01-03 15:06:52,722 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 16.78 sec
2018-01-03 15:06:55,822 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 19.43 sec
2018-01-03 15:06:57,883 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 36.51 sec
2018-01-03 15:06:58,913 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 39.89 sec
2018-01-03 15:07:02,007 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 43.19 sec
2018-01-03 15:07:05,100 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 46.14 sec
2018-01-03 15:07:08,188 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 49.68 sec
2018-01-03 15:07:10,255 Stage-1 map = 76%,  reduce = 8%, Cumulative CPU 50.26 sec
2018-01-03 15:07:11,287 Stage-1 map = 78%,  reduce = 8%, Cumulative CPU 53.34 sec
2018-01-03 15:07:14,376 Stage-1 map = 82%,  reduce = 8%, Cumulative CPU 57.12 sec
2018-01-03 15:07:15,405 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 59.69 sec
2018-01-03 15:07:16,436 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 65.0 sec
2018-01-03 15:07:18,494 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 69.22 sec
MapReduce Total cumulative CPU time: 1 minutes 9 seconds 220 msec
Ended Job = job_1513599404024_168620
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168626, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168626/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168626
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:07:24,166 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:07:30,349 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.21 sec
2018-01-03 15:07:32,407 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.6 sec
2018-01-03 15:08:08,363 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 26.25 sec
2018-01-03 15:08:14,525 Stage-2 map = 100%,  reduce = 87%, Cumulative CPU 46.59 sec
2018-01-03 15:08:17,603 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 56.31 sec
MapReduce Total cumulative CPU time: 56 seconds 310 msec
Ended Job = job_1513599404024_168626
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168632, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168632/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168632
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:08:24,236 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:08:30,435 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.46 sec
2018-01-03 15:08:36,610 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.75 sec
MapReduce Total cumulative CPU time: 7 seconds 750 msec
Ended Job = job_1513599404024_168632
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 69.22 sec   HDFS Read: 175890598 HDFS Write: 1510615 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 56.31 sec   HDFS Read: 45601184 HDFS Write: 183350 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.75 sec   HDFS Read: 191025 HDFS Write: 2652 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 13 seconds 280 msec
OK
Time taken: 129.329 seconds, Fetched: 361 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.434 seconds
Query ID = boss_20180103150845_462b68a9-9417-4802-af09-0e56ac8083e5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168636, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168636/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168636
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 15:08:54,687 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:09:05,081 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 23.86 sec
2018-01-03 15:09:08,178 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 32.97 sec
2018-01-03 15:09:11,269 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 39.87 sec
2018-01-03 15:09:13,328 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 42.95 sec
2018-01-03 15:09:14,359 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 45.93 sec
2018-01-03 15:09:16,417 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 48.89 sec
2018-01-03 15:09:17,450 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 51.83 sec
2018-01-03 15:09:19,509 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 54.74 sec
2018-01-03 15:09:20,537 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 57.85 sec
2018-01-03 15:09:22,596 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 63.58 sec
2018-01-03 15:09:25,682 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 68.97 sec
2018-01-03 15:09:28,770 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 75.05 sec
2018-01-03 15:09:30,827 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 80.83 sec
2018-01-03 15:09:35,982 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 88.74 sec
2018-01-03 15:09:42,153 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 92.25 sec
MapReduce Total cumulative CPU time: 1 minutes 32 seconds 250 msec
Ended Job = job_1513599404024_168636
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168640, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168640/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168640
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:09:57,385 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:10:04,065 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.53 sec
2018-01-03 15:10:05,096 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.07 sec
2018-01-03 15:10:13,400 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.15 sec
MapReduce Total cumulative CPU time: 15 seconds 150 msec
Ended Job = job_1513599404024_168640
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168643, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168643/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168643
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:10:19,002 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:10:25,190 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.29 sec
2018-01-03 15:10:39,594 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.33 sec
MapReduce Total cumulative CPU time: 6 seconds 330 msec
Ended Job = job_1513599404024_168643
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 92.25 sec   HDFS Read: 254207545 HDFS Write: 229024 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.15 sec   HDFS Read: 44319855 HDFS Write: 18212 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.33 sec   HDFS Read: 25888 HDFS Write: 1987 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 53 seconds 730 msec
OK
Time taken: 114.853 seconds, Fetched: 281 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103151047_93184d47-1b6f-4ace-bc96-6ab327c648a5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168645, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168645/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168645
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:10:58,155 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:11:08,514 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 10.83 sec
2018-01-03 15:11:11,613 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 12.94 sec
2018-01-03 15:11:13,677 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.46 sec
2018-01-03 15:11:19,870 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.3 sec
MapReduce Total cumulative CPU time: 19 seconds 300 msec
Ended Job = job_1513599404024_168645
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168648, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168648/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168648
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:11:25,548 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:11:30,727 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.11 sec
2018-01-03 15:11:42,081 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.84 sec
MapReduce Total cumulative CPU time: 14 seconds 840 msec
Ended Job = job_1513599404024_168648
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168650, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168650/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168650
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:12:05,839 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:12:19,256 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.1 sec
2018-01-03 15:12:26,475 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.13 sec
MapReduce Total cumulative CPU time: 6 seconds 130 msec
Ended Job = job_1513599404024_168650
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.3 sec   HDFS Read: 10497376 HDFS Write: 360513 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.84 sec   HDFS Read: 44450764 HDFS Write: 139337 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.13 sec   HDFS Read: 146974 HDFS Write: 4916 SUCCESS
Total MapReduce CPU Time Spent: 40 seconds 270 msec
OK
Time taken: 99.891 seconds, Fetched: 599 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.412 seconds
Query ID = boss_20180103151234_8d18d096-287b-496e-b244-929158ddf903
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168655, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168655/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168655
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:12:43,802 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:12:53,150 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 11.15 sec
2018-01-03 15:12:54,183 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.6 sec
2018-01-03 15:12:59,346 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.77 sec
MapReduce Total cumulative CPU time: 17 seconds 770 msec
Ended Job = job_1513599404024_168655
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168657, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168657/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168657
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:13:21,186 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:13:27,367 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.28 sec
2018-01-03 15:13:34,578 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.48 sec
MapReduce Total cumulative CPU time: 14 seconds 480 msec
Ended Job = job_1513599404024_168657
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168659, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168659/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168659
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:13:40,235 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:13:44,394 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.78 sec
2018-01-03 15:13:51,625 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.35 sec
MapReduce Total cumulative CPU time: 5 seconds 350 msec
Ended Job = job_1513599404024_168659
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.77 sec   HDFS Read: 10497366 HDFS Write: 659484 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.48 sec   HDFS Read: 44749735 HDFS Write: 151213 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.35 sec   HDFS Read: 158851 HDFS Write: 2461 SUCCESS
Total MapReduce CPU Time Spent: 37 seconds 600 msec
OK
Time taken: 78.314 seconds, Fetched: 376 row(s)
开始执行20171124日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.366 seconds
Query ID = boss_20180103151359_2f0dc537-f893-4a46-8a22-25d8e7b7b948
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168661, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168661/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168661
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:14:08,732 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:14:19,115 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 24.29 sec
2018-01-03 15:14:22,223 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 31.52 sec
2018-01-03 15:14:24,292 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 35.29 sec
2018-01-03 15:14:25,326 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 38.53 sec
2018-01-03 15:14:28,428 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 41.3 sec
2018-01-03 15:14:31,526 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 43.87 sec
2018-01-03 15:14:34,620 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 47.4 sec
2018-01-03 15:14:35,658 Stage-1 map = 67%,  reduce = 8%, Cumulative CPU 48.02 sec
2018-01-03 15:14:36,690 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 48.61 sec
2018-01-03 15:14:37,722 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 51.5 sec
2018-01-03 15:14:40,837 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 54.59 sec
2018-01-03 15:14:43,961 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 58.38 sec
2018-01-03 15:14:47,057 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 61.77 sec
2018-01-03 15:14:50,153 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 64.67 sec
2018-01-03 15:14:52,214 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 67.82 sec
2018-01-03 15:14:53,244 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 68.76 sec
2018-01-03 15:14:54,275 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 73.28 sec
2018-01-03 15:14:55,305 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 77.46 sec
MapReduce Total cumulative CPU time: 1 minutes 17 seconds 460 msec
Ended Job = job_1513599404024_168661
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168664, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168664/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168664
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:15:02,111 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:15:07,299 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.64 sec
2018-01-03 15:15:13,522 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.6 sec
2018-01-03 15:15:15,589 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.69 sec
MapReduce Total cumulative CPU time: 16 seconds 690 msec
Ended Job = job_1513599404024_168664
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168666, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168666/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168666
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:15:23,298 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:15:28,461 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.5 sec
2018-01-03 15:15:35,669 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.19 sec
MapReduce Total cumulative CPU time: 6 seconds 190 msec
Ended Job = job_1513599404024_168666
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 77.46 sec   HDFS Read: 227957853 HDFS Write: 1505717 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.69 sec   HDFS Read: 45605220 HDFS Write: 203868 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.19 sec   HDFS Read: 211543 HDFS Write: 2661 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 40 seconds 340 msec
OK
Time taken: 97.129 seconds, Fetched: 351 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.396 seconds
Query ID = boss_20180103151543_a49f2e3e-78cf-45db-b793-3a6ce617d821
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168667, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168667/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168667
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 15:15:53,344 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:16:03,706 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 25.01 sec
2018-01-03 15:16:06,806 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 34.57 sec
2018-01-03 15:16:09,900 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 41.38 sec
2018-01-03 15:16:12,992 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 47.86 sec
2018-01-03 15:16:16,084 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 54.03 sec
2018-01-03 15:16:19,174 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 60.55 sec
2018-01-03 15:16:22,263 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 68.83 sec
2018-01-03 15:16:25,356 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 71.72 sec
2018-01-03 15:16:27,415 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 74.69 sec
2018-01-03 15:16:29,475 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 76.63 sec
2018-01-03 15:16:30,508 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 80.92 sec
2018-01-03 15:16:31,539 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 84.47 sec
2018-01-03 15:16:35,659 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 88.02 sec
MapReduce Total cumulative CPU time: 1 minutes 28 seconds 20 msec
Ended Job = job_1513599404024_168667
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168673, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168673/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168673
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:16:42,361 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:16:47,553 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.37 sec
2018-01-03 15:16:49,612 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.03 sec
2018-01-03 15:16:53,742 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.46 sec
MapReduce Total cumulative CPU time: 14 seconds 460 msec
Ended Job = job_1513599404024_168673
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168678, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168678/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168678
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:17:01,715 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:17:07,937 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.16 sec
2018-01-03 15:17:15,245 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.45 sec
MapReduce Total cumulative CPU time: 7 seconds 450 msec
Ended Job = job_1513599404024_168678
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 88.02 sec   HDFS Read: 259757574 HDFS Write: 255206 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.46 sec   HDFS Read: 44354971 HDFS Write: 19691 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.45 sec   HDFS Read: 27367 HDFS Write: 2011 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 49 seconds 930 msec
OK
Time taken: 92.908 seconds, Fetched: 296 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103151723_378646e0-cabb-46f0-97d6-7ffaac81bbaa
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168679, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168679/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168679
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:17:32,583 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:17:49,103 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 11.31 sec
2018-01-03 15:17:52,192 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 13.54 sec
2018-01-03 15:17:54,257 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.56 sec
2018-01-03 15:17:59,416 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.65 sec
MapReduce Total cumulative CPU time: 20 seconds 650 msec
Ended Job = job_1513599404024_168679
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168683, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168683/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168683
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:18:07,154 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:18:14,391 Stage-2 map = 50%,  reduce = 0%
2018-01-03 15:18:16,454 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.57 sec
2018-01-03 15:18:26,759 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.9 sec
MapReduce Total cumulative CPU time: 18 seconds 900 msec
Ended Job = job_1513599404024_168683
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168686, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168686/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168686
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:18:40,494 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:18:45,668 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.3 sec
2018-01-03 15:18:52,887 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.95 sec
MapReduce Total cumulative CPU time: 5 seconds 950 msec
Ended Job = job_1513599404024_168686
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.65 sec   HDFS Read: 11541602 HDFS Write: 376958 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.9 sec   HDFS Read: 44476143 HDFS Write: 135031 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.95 sec   HDFS Read: 142668 HDFS Write: 4780 SUCCESS
Total MapReduce CPU Time Spent: 45 seconds 500 msec
OK
Time taken: 90.926 seconds, Fetched: 543 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103151900_ddaa0572-c15f-4d58-a5c1-34d97a55c227
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168689, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168689/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168689
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:19:10,322 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:19:19,635 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 11.8 sec
2018-01-03 15:19:20,667 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.57 sec
2018-01-03 15:19:25,829 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.68 sec
MapReduce Total cumulative CPU time: 17 seconds 680 msec
Ended Job = job_1513599404024_168689
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168691, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168691/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168691
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:19:39,683 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:19:44,837 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.13 sec
2018-01-03 15:19:56,161 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 4.62 sec
2018-01-03 15:20:01,304 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 9.77 sec
2018-01-03 15:20:02,334 Stage-2 map = 100%,  reduce = 46%, Cumulative CPU 9.97 sec
2018-01-03 15:20:03,362 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.68 sec
MapReduce Total cumulative CPU time: 14 seconds 680 msec
Ended Job = job_1513599404024_168691
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168696, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168696/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168696
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:20:10,108 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:20:15,274 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.82 sec
2018-01-03 15:20:21,485 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.24 sec
MapReduce Total cumulative CPU time: 7 seconds 240 msec
Ended Job = job_1513599404024_168696
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.68 sec   HDFS Read: 11541592 HDFS Write: 676887 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.68 sec   HDFS Read: 44776072 HDFS Write: 133466 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.24 sec   HDFS Read: 141104 HDFS Write: 2833 SUCCESS
Total MapReduce CPU Time Spent: 39 seconds 600 msec
OK
Time taken: 82.938 seconds, Fetched: 396 row(s)
开始执行20171125日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.526 seconds
Query ID = boss_20180103152030_ecce9edd-c027-45af-ae6b-4d7bdd9dd49a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168699, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168699/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168699
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:20:41,632 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:20:51,992 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 25.02 sec
2018-01-03 15:20:55,094 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 33.11 sec
2018-01-03 15:20:58,190 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 40.48 sec
2018-01-03 15:21:01,285 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 48.29 sec
2018-01-03 15:21:03,348 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 51.3 sec
2018-01-03 15:21:04,384 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 54.64 sec
2018-01-03 15:21:07,480 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 57.91 sec
2018-01-03 15:21:10,584 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 61.59 sec
2018-01-03 15:21:13,682 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 66.22 sec
2018-01-03 15:21:16,772 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 69.91 sec
2018-01-03 15:21:19,863 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 73.88 sec
2018-01-03 15:21:22,958 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 77.32 sec
2018-01-03 15:21:25,017 Stage-1 map = 100%,  reduce = 39%, Cumulative CPU 81.17 sec
2018-01-03 15:21:26,046 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 88.8 sec
MapReduce Total cumulative CPU time: 1 minutes 28 seconds 800 msec
Ended Job = job_1513599404024_168699
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168704, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168704/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168704
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:21:32,802 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:21:37,997 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.86 sec
2018-01-03 15:21:47,293 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.48 sec
MapReduce Total cumulative CPU time: 17 seconds 480 msec
Ended Job = job_1513599404024_168704
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168705, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168705/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168705
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:21:53,966 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:21:59,131 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.46 sec
2018-01-03 15:22:12,508 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.18 sec
MapReduce Total cumulative CPU time: 6 seconds 180 msec
Ended Job = job_1513599404024_168705
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 88.8 sec   HDFS Read: 239655913 HDFS Write: 1669528 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.48 sec   HDFS Read: 48951369 HDFS Write: 243897 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.18 sec   HDFS Read: 251572 HDFS Write: 2865 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 52 seconds 460 msec
OK
Time taken: 102.87 seconds, Fetched: 367 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.384 seconds
Query ID = boss_20180103152220_ee1c3017-ecf6-4777-bf5e-1949d04f1eb4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168708, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168708/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168708
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 15:22:30,202 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:22:40,559 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 23.55 sec
2018-01-03 15:22:43,661 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 31.04 sec
2018-01-03 15:22:46,757 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 36.97 sec
2018-01-03 15:22:49,852 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 43.28 sec
2018-01-03 15:22:52,952 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 49.55 sec
2018-01-03 15:22:54,000 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 61.38 sec
2018-01-03 15:22:56,062 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 70.53 sec
2018-01-03 15:22:59,156 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 76.26 sec
2018-01-03 15:23:02,246 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 81.66 sec
2018-01-03 15:23:05,334 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 87.5 sec
2018-01-03 15:23:07,399 Stage-1 map = 86%,  reduce = 7%, Cumulative CPU 92.01 sec
2018-01-03 15:23:08,429 Stage-1 map = 87%,  reduce = 7%, Cumulative CPU 95.56 sec
2018-01-03 15:23:09,460 Stage-1 map = 87%,  reduce = 15%, Cumulative CPU 96.41 sec
2018-01-03 15:23:10,490 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 99.45 sec
2018-01-03 15:23:11,524 Stage-1 map = 100%,  reduce = 48%, Cumulative CPU 103.54 sec
2018-01-03 15:23:12,553 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 112.11 sec
MapReduce Total cumulative CPU time: 1 minutes 52 seconds 110 msec
Ended Job = job_1513599404024_168708
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168713, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168713/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168713
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:23:18,550 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:23:25,794 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.17 sec
2018-01-03 15:23:30,962 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.69 sec
2018-01-03 15:23:39,216 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.32 sec
MapReduce Total cumulative CPU time: 15 seconds 320 msec
Ended Job = job_1513599404024_168713
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168714, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168714/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168714
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:24:00,937 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:24:06,110 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.55 sec
2018-01-03 15:24:17,462 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.01 sec
MapReduce Total cumulative CPU time: 7 seconds 10 msec
Ended Job = job_1513599404024_168714
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 112.11 sec   HDFS Read: 304962059 HDFS Write: 308321 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.32 sec   HDFS Read: 47590424 HDFS Write: 23281 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.01 sec   HDFS Read: 30957 HDFS Write: 2142 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 14 seconds 440 msec
OK
Time taken: 118.226 seconds, Fetched: 303 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103152425_4a2ddac0-7685-472c-9ae6-1bfffc26c2ed
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168717, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168717/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168717
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:24:34,717 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:24:47,281 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 10.33 sec
2018-01-03 15:24:50,374 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 11.76 sec
2018-01-03 15:24:53,464 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 13.09 sec
2018-01-03 15:24:55,527 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.74 sec
2018-01-03 15:25:06,853 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.18 sec
MapReduce Total cumulative CPU time: 18 seconds 180 msec
Ended Job = job_1513599404024_168717
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168719, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168719/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168719
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:25:13,658 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:25:18,829 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.62 sec
2018-01-03 15:25:21,927 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.01 sec
2018-01-03 15:25:26,045 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.44 sec
MapReduce Total cumulative CPU time: 15 seconds 440 msec
Ended Job = job_1513599404024_168719
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168720, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168720/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168720
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:25:39,764 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:25:53,176 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec
2018-01-03 15:25:58,337 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.52 sec
MapReduce Total cumulative CPU time: 5 seconds 520 msec
Ended Job = job_1513599404024_168720
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.18 sec   HDFS Read: 11548423 HDFS Write: 366642 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.44 sec   HDFS Read: 47648165 HDFS Write: 152427 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.52 sec   HDFS Read: 160064 HDFS Write: 5181 SUCCESS
Total MapReduce CPU Time Spent: 39 seconds 140 msec
OK
Time taken: 94.417 seconds, Fetched: 591 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103152614_c5bd06f8-bf6d-4a27-866c-a50ee4798df4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168724, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168724/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168724
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:26:29,158 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:26:40,656 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 12.53 sec
2018-01-03 15:26:43,757 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 16.9 sec
2018-01-03 15:26:45,821 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 19.88 sec
2018-01-03 15:27:01,420 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 25.83 sec
MapReduce Total cumulative CPU time: 25 seconds 830 msec
Ended Job = job_1513599404024_168724
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168730, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168730/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168730
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:27:29,330 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:27:34,778 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.44 sec
2018-01-03 15:27:35,812 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.41 sec
2018-01-03 15:27:40,972 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.86 sec
MapReduce Total cumulative CPU time: 14 seconds 860 msec
Ended Job = job_1513599404024_168730
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168733, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168733/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168733
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:27:54,667 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:27:58,792 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.76 sec
2018-01-03 15:28:05,999 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.27 sec
MapReduce Total cumulative CPU time: 6 seconds 270 msec
Ended Job = job_1513599404024_168733
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 25.83 sec   HDFS Read: 11548413 HDFS Write: 778779 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.86 sec   HDFS Read: 48060302 HDFS Write: 140735 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.27 sec   HDFS Read: 148373 HDFS Write: 2828 SUCCESS
Total MapReduce CPU Time Spent: 46 seconds 960 msec
OK
Time taken: 112.864 seconds, Fetched: 412 row(s)
开始执行20171126日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.374 seconds
Query ID = boss_20180103152813_0a92a1ea-9580-4e0a-a83e-356dbcbe37a4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168738, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168738/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168738
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:28:23,042 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:28:33,408 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 26.65 sec
2018-01-03 15:28:36,526 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 34.73 sec
2018-01-03 15:28:39,620 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 44.73 sec
2018-01-03 15:28:42,713 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 60.21 sec
2018-01-03 15:28:45,807 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 68.96 sec
2018-01-03 15:28:48,898 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 72.24 sec
2018-01-03 15:28:51,988 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 75.37 sec
2018-01-03 15:28:55,081 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 78.87 sec
2018-01-03 15:28:57,142 Stage-1 map = 71%,  reduce = 8%, Cumulative CPU 79.54 sec
2018-01-03 15:28:58,171 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 83.17 sec
2018-01-03 15:29:01,259 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 86.43 sec
2018-01-03 15:29:04,350 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 89.85 sec
2018-01-03 15:29:07,441 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 94.94 sec
2018-01-03 15:29:08,470 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 100.52 sec
2018-01-03 15:29:09,498 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 106.62 sec
MapReduce Total cumulative CPU time: 1 minutes 46 seconds 620 msec
Ended Job = job_1513599404024_168738
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168743, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168743/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168743
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:29:23,225 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:29:28,374 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.9 sec
2018-01-03 15:29:29,407 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.39 sec
2018-01-03 15:29:34,547 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.32 sec
MapReduce Total cumulative CPU time: 16 seconds 320 msec
Ended Job = job_1513599404024_168743
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168746, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168746/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168746
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:29:40,211 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:29:44,334 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.07 sec
2018-01-03 15:30:11,043 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.84 sec
MapReduce Total cumulative CPU time: 5 seconds 840 msec
Ended Job = job_1513599404024_168746
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 106.62 sec   HDFS Read: 227974214 HDFS Write: 1605993 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.32 sec   HDFS Read: 47997583 HDFS Write: 233952 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.84 sec   HDFS Read: 241627 HDFS Write: 3044 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 8 seconds 780 msec
OK
Time taken: 118.127 seconds, Fetched: 365 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.39 seconds
Query ID = boss_20180103153018_4cffa1db-4a34-4d61-acf6-6618a93ca928
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168752, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168752/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168752
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 15:30:28,692 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:30:39,057 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 24.87 sec
2018-01-03 15:30:40,091 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 35.99 sec
2018-01-03 15:30:41,135 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 40.81 sec
2018-01-03 15:30:42,174 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 48.74 sec
2018-01-03 15:30:45,315 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 55.27 sec
2018-01-03 15:30:47,378 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 58.37 sec
2018-01-03 15:30:48,409 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 61.33 sec
2018-01-03 15:30:50,473 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 64.46 sec
2018-01-03 15:30:51,513 Stage-1 map = 61%,  reduce = 4%, Cumulative CPU 68.09 sec
2018-01-03 15:30:52,547 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 69.5 sec
2018-01-03 15:30:53,582 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 72.56 sec
2018-01-03 15:30:54,615 Stage-1 map = 66%,  reduce = 11%, Cumulative CPU 75.5 sec
2018-01-03 15:30:55,651 Stage-1 map = 79%,  reduce = 11%, Cumulative CPU 78.27 sec
2018-01-03 15:30:57,712 Stage-1 map = 81%,  reduce = 15%, Cumulative CPU 81.38 sec
2018-01-03 15:30:58,743 Stage-1 map = 81%,  reduce = 22%, Cumulative CPU 81.68 sec
2018-01-03 15:31:00,814 Stage-1 map = 83%,  reduce = 22%, Cumulative CPU 84.9 sec
2018-01-03 15:31:03,911 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 88.24 sec
2018-01-03 15:31:07,011 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 91.65 sec
2018-01-03 15:31:08,047 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 93.55 sec
2018-01-03 15:31:09,082 Stage-1 map = 100%,  reduce = 48%, Cumulative CPU 98.55 sec
2018-01-03 15:31:10,114 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 106.77 sec
MapReduce Total cumulative CPU time: 1 minutes 46 seconds 770 msec
Ended Job = job_1513599404024_168752
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168761, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168761/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168761
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:31:18,187 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:31:23,355 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.58 sec
2018-01-03 15:31:36,741 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.32 sec
MapReduce Total cumulative CPU time: 13 seconds 320 msec
Ended Job = job_1513599404024_168761
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168764, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168764/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168764
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:31:56,491 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:32:01,664 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.29 sec
2018-01-03 15:32:06,820 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.81 sec
MapReduce Total cumulative CPU time: 4 seconds 810 msec
Ended Job = job_1513599404024_168764
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 106.77 sec   HDFS Read: 302022417 HDFS Write: 293704 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.32 sec   HDFS Read: 46685556 HDFS Write: 20062 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.81 sec   HDFS Read: 27738 HDFS Write: 2112 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 4 seconds 900 msec
OK
Time taken: 109.115 seconds, Fetched: 303 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103153214_7790d002-133e-4bf3-afc2-800a2947509f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168769, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168769/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168769
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:32:26,672 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:32:41,263 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 10.17 sec
2018-01-03 15:32:44,357 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 12.22 sec
2018-01-03 15:32:47,457 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.56 sec
2018-01-03 15:33:00,860 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.5 sec
MapReduce Total cumulative CPU time: 18 seconds 500 msec
Ended Job = job_1513599404024_168769
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168774, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168774/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168774
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:33:07,567 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:33:12,729 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.78 sec
2018-01-03 15:33:18,910 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.06 sec
MapReduce Total cumulative CPU time: 15 seconds 60 msec
Ended Job = job_1513599404024_168774
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168776, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168776/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168776
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:33:24,526 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:33:29,670 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.97 sec
2018-01-03 15:33:35,842 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.51 sec
MapReduce Total cumulative CPU time: 5 seconds 510 msec
Ended Job = job_1513599404024_168776
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.5 sec   HDFS Read: 11436439 HDFS Write: 350981 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.06 sec   HDFS Read: 46742253 HDFS Write: 145378 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.51 sec   HDFS Read: 153015 HDFS Write: 4836 SUCCESS
Total MapReduce CPU Time Spent: 39 seconds 70 msec
OK
Time taken: 82.337 seconds, Fetched: 550 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103153343_d2549508-3310-4950-9585-330ca745d1da
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168780, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168780/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168780
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:33:53,192 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:34:11,818 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 13.6 sec
2018-01-03 15:34:14,916 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 19.03 sec
2018-01-03 15:34:21,114 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 24.9 sec
MapReduce Total cumulative CPU time: 24 seconds 900 msec
Ended Job = job_1513599404024_168780
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168784, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168784/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168784
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:34:34,980 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:34:40,144 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.0 sec
2018-01-03 15:34:41,175 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.91 sec
2018-01-03 15:34:53,541 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.85 sec
MapReduce Total cumulative CPU time: 16 seconds 850 msec
Ended Job = job_1513599404024_168784
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168789, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168789/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168789
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:35:07,293 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:35:14,531 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.72 sec
2018-01-03 15:35:20,706 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.47 sec
MapReduce Total cumulative CPU time: 9 seconds 470 msec
Ended Job = job_1513599404024_168789
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 24.9 sec   HDFS Read: 11436429 HDFS Write: 763851 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.85 sec   HDFS Read: 47155123 HDFS Write: 132943 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.47 sec   HDFS Read: 140581 HDFS Write: 2750 SUCCESS
Total MapReduce CPU Time Spent: 51 seconds 220 msec
OK
Time taken: 98.175 seconds, Fetched: 396 row(s)
开始执行20171127日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.367 seconds
Query ID = boss_20180103153528_9593e364-1426-4e1c-be58-5d6a278ca740
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168791, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168791/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168791
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:35:43,865 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:35:52,181 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 12.31 sec
2018-01-03 15:36:02,512 Stage-1 map = 50%,  reduce = 8%, Cumulative CPU 12.78 sec
2018-01-03 15:36:03,546 Stage-1 map = 50%,  reduce = 17%, Cumulative CPU 13.33 sec
2018-01-03 15:36:09,734 Stage-1 map = 57%,  reduce = 17%, Cumulative CPU 27.27 sec
2018-01-03 15:36:12,825 Stage-1 map = 61%,  reduce = 17%, Cumulative CPU 31.14 sec
2018-01-03 15:36:15,918 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 34.66 sec
2018-01-03 15:36:19,005 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 38.28 sec
2018-01-03 15:36:22,092 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 42.04 sec
2018-01-03 15:36:25,182 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 45.55 sec
2018-01-03 15:36:28,268 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 50.18 sec
2018-01-03 15:36:29,299 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 51.51 sec
2018-01-03 15:36:30,328 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 59.44 sec
MapReduce Total cumulative CPU time: 59 seconds 440 msec
Ended Job = job_1513599404024_168791
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168797, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168797/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168797
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:37:29,090 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:37:39,574 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.48 sec
2018-01-03 15:37:48,113 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.38 sec
MapReduce Total cumulative CPU time: 16 seconds 380 msec
Ended Job = job_1513599404024_168797
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168803, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168803/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168803
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:37:53,902 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:37:59,051 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.55 sec
2018-01-03 15:38:05,221 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.57 sec
MapReduce Total cumulative CPU time: 6 seconds 570 msec
Ended Job = job_1513599404024_168803
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 59.44 sec   HDFS Read: 172828476 HDFS Write: 1549507 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.38 sec   HDFS Read: 43867853 HDFS Write: 172661 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.57 sec   HDFS Read: 180336 HDFS Write: 2820 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 22 seconds 390 msec
OK
Time taken: 157.632 seconds, Fetched: 363 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.389 seconds
Query ID = boss_20180103153813_8a462a51-cded-4fe7-a5b1-8b16070a5b00
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168804, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168804/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168804
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 15:38:22,974 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:38:32,307 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 12.03 sec
2018-01-03 15:38:35,404 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 15.39 sec
2018-01-03 15:38:38,500 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 18.76 sec
2018-01-03 15:38:41,592 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 22.17 sec
2018-01-03 15:38:43,653 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 24.21 sec
2018-01-03 15:38:46,747 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 37.03 sec
2018-01-03 15:38:49,837 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 41.05 sec
2018-01-03 15:38:52,925 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 44.69 sec
2018-01-03 15:38:53,959 Stage-1 map = 63%,  reduce = 17%, Cumulative CPU 46.34 sec
2018-01-03 15:38:56,023 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 49.95 sec
2018-01-03 15:38:59,112 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 53.33 sec
2018-01-03 15:39:02,201 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 56.73 sec
2018-01-03 15:39:05,294 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 60.35 sec
2018-01-03 15:39:08,384 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 65.51 sec
2018-01-03 15:39:09,415 Stage-1 map = 100%,  reduce = 28%, Cumulative CPU 65.62 sec
2018-01-03 15:39:10,447 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 74.79 sec
MapReduce Total cumulative CPU time: 1 minutes 14 seconds 790 msec
Ended Job = job_1513599404024_168804
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168810, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168810/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168810
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:39:16,131 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:39:21,287 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.37 sec
2018-01-03 15:39:27,457 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.59 sec
MapReduce Total cumulative CPU time: 13 seconds 590 msec
Ended Job = job_1513599404024_168810
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168814, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168814/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168814
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:39:34,105 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:39:38,235 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.26 sec
2018-01-03 15:39:44,414 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.6 sec
MapReduce Total cumulative CPU time: 4 seconds 600 msec
Ended Job = job_1513599404024_168814
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 74.79 sec   HDFS Read: 228573905 HDFS Write: 231397 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.59 sec   HDFS Read: 42550005 HDFS Write: 18117 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.6 sec   HDFS Read: 25793 HDFS Write: 2064 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 32 seconds 980 msec
OK
Time taken: 92.431 seconds, Fetched: 295 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103153952_62c5d7e3-25a2-4c3e-9ff7-4d9ef2e19a98
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168815, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168815/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168815
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:40:02,714 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:40:13,075 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 11.37 sec
2018-01-03 15:40:15,144 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.21 sec
2018-01-03 15:40:22,368 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.85 sec
MapReduce Total cumulative CPU time: 17 seconds 850 msec
Ended Job = job_1513599404024_168815
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168818, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168818/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168818
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:40:28,061 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:40:33,223 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.55 sec
2018-01-03 15:40:35,285 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.49 sec
2018-01-03 15:40:39,407 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.25 sec
MapReduce Total cumulative CPU time: 14 seconds 250 msec
Ended Job = job_1513599404024_168818
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168821, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168821/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168821
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:40:45,024 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:40:50,184 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.56 sec
2018-01-03 15:40:55,339 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.06 sec
MapReduce Total cumulative CPU time: 6 seconds 60 msec
Ended Job = job_1513599404024_168821
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.85 sec   HDFS Read: 9760612 HDFS Write: 358922 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.25 sec   HDFS Read: 42676946 HDFS Write: 132745 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.06 sec   HDFS Read: 140378 HDFS Write: 4881 SUCCESS
Total MapReduce CPU Time Spent: 38 seconds 160 msec
OK
Time taken: 64.225 seconds, Fetched: 592 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103154103_4318771f-3f2b-4d6f-9f90-6974a1d628dc
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168830, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168830/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168830
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:41:12,567 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:41:22,973 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 12.0 sec
2018-01-03 15:41:25,041 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.32 sec
2018-01-03 15:41:45,648 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.8 sec
MapReduce Total cumulative CPU time: 19 seconds 800 msec
Ended Job = job_1513599404024_168830
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168839, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168839/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168839
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:41:52,551 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:41:59,774 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.76 sec
2018-01-03 15:42:03,896 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.08 sec
2018-01-03 15:42:05,953 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.67 sec
MapReduce Total cumulative CPU time: 16 seconds 670 msec
Ended Job = job_1513599404024_168839
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168845, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168845/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168845
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:42:30,781 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:43:00,197 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 9.49 sec
2018-01-03 15:43:31,297 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 15.43 sec
2018-01-03 15:43:38,491 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 20.7 sec
MapReduce Total cumulative CPU time: 20 seconds 700 msec
Ended Job = job_1513599404024_168845
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.8 sec   HDFS Read: 9760603 HDFS Write: 611555 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.67 sec   HDFS Read: 42929583 HDFS Write: 112473 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 21.28 sec   HDFS Read: 120111 HDFS Write: 2565 SUCCESS
Total MapReduce CPU Time Spent: 57 seconds 750 msec
OK
Time taken: 157.493 seconds, Fetched: 380 row(s)
开始执行20171128日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103154347_fd2fc5fc-09f1-4d97-b91e-bf2fe935eb88
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168851, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168851/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168851
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:44:04,843 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:44:16,227 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 11.57 sec
2018-01-03 15:44:19,325 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 14.9 sec
2018-01-03 15:44:21,391 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 29.25 sec
2018-01-03 15:44:24,481 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 32.5 sec
2018-01-03 15:44:27,576 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 35.58 sec
2018-01-03 15:44:30,666 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 38.55 sec
2018-01-03 15:44:31,700 Stage-1 map = 68%,  reduce = 8%, Cumulative CPU 38.99 sec
2018-01-03 15:44:32,729 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 39.56 sec
2018-01-03 15:44:33,759 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 42.54 sec
2018-01-03 15:44:36,851 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 45.7 sec
2018-01-03 15:44:39,939 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 49.02 sec
2018-01-03 15:44:43,026 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 53.95 sec
2018-01-03 15:44:46,117 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 57.64 sec
2018-01-03 15:44:47,146 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 65.61 sec
MapReduce Total cumulative CPU time: 1 minutes 5 seconds 610 msec
Ended Job = job_1513599404024_168851
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168855, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168855/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168855
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:45:03,874 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:45:09,100 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.29 sec
2018-01-03 15:45:10,130 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.64 sec
2018-01-03 15:45:14,255 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.39 sec
MapReduce Total cumulative CPU time: 16 seconds 390 msec
Ended Job = job_1513599404024_168855
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168857, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168857/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168857
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:45:20,058 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:45:28,297 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 5.11 sec
2018-01-03 15:45:34,472 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.76 sec
MapReduce Total cumulative CPU time: 8 seconds 760 msec
Ended Job = job_1513599404024_168857
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 65.61 sec   HDFS Read: 171719499 HDFS Write: 1577053 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.39 sec   HDFS Read: 44153111 HDFS Write: 174548 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.76 sec   HDFS Read: 182223 HDFS Write: 2709 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 30 seconds 760 msec
OK
Time taken: 109.071 seconds, Fetched: 353 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.384 seconds
Query ID = boss_20180103154543_d4c9cc8f-83de-4c47-b598-43de2a740068
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168861, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168861/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168861
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:46:00,228 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:46:10,614 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 23.56 sec
2018-01-03 15:46:13,723 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 30.25 sec
2018-01-03 15:46:16,823 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 37.51 sec
2018-01-03 15:46:19,919 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 43.68 sec
2018-01-03 15:46:23,019 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 50.07 sec
2018-01-03 15:46:26,113 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 56.12 sec
2018-01-03 15:46:28,175 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 59.52 sec
2018-01-03 15:46:29,207 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 62.46 sec
2018-01-03 15:46:32,305 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 65.57 sec
2018-01-03 15:46:35,396 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 69.84 sec
2018-01-03 15:46:36,430 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 75.26 sec
2018-01-03 15:46:37,463 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 79.94 sec
MapReduce Total cumulative CPU time: 1 minutes 19 seconds 940 msec
Ended Job = job_1513599404024_168861
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168869, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168869/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168869
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:46:45,183 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:46:50,359 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.23 sec
2018-01-03 15:47:00,894 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.07 sec
MapReduce Total cumulative CPU time: 14 seconds 70 msec
Ended Job = job_1513599404024_168869
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168872, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168872/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168872
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:47:11,724 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:47:15,876 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.67 sec
2018-01-03 15:47:22,083 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.34 sec
MapReduce Total cumulative CPU time: 5 seconds 340 msec
Ended Job = job_1513599404024_168872
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 79.94 sec   HDFS Read: 229616525 HDFS Write: 232971 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.07 sec   HDFS Read: 42809029 HDFS Write: 18031 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.34 sec   HDFS Read: 25707 HDFS Write: 2076 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 39 seconds 350 msec
OK
Time taken: 99.883 seconds, Fetched: 294 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103154729_b1dd87f3-ddca-4f07-95fc-41db8b660ad2
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168873, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168873/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168873
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:47:41,340 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:47:51,765 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 10.22 sec
2018-01-03 15:47:54,865 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.21 sec
2018-01-03 15:48:00,027 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.35 sec
MapReduce Total cumulative CPU time: 18 seconds 350 msec
Ended Job = job_1513599404024_168873
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168875, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168875/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168875
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:48:05,818 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:48:13,066 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.38 sec
2018-01-03 15:48:17,201 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.85 sec
2018-01-03 15:48:27,517 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.84 sec
MapReduce Total cumulative CPU time: 15 seconds 840 msec
Ended Job = job_1513599404024_168875
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168877, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168877/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168877
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:48:34,166 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:48:39,343 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.99 sec
2018-01-03 15:48:46,569 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.71 sec
MapReduce Total cumulative CPU time: 5 seconds 710 msec
Ended Job = job_1513599404024_168877
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.35 sec   HDFS Read: 9613263 HDFS Write: 354609 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.84 sec   HDFS Read: 42930349 HDFS Write: 132556 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.71 sec   HDFS Read: 140193 HDFS Write: 5013 SUCCESS
Total MapReduce CPU Time Spent: 39 seconds 900 msec
OK
Time taken: 77.796 seconds, Fetched: 560 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.374 seconds
Query ID = boss_20180103154854_0352048a-ebfe-4245-8fb6-b8aadc612770
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168883, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168883/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168883
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:49:04,418 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:49:23,006 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 13.56 sec
2018-01-03 15:49:24,037 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.74 sec
2018-01-03 15:49:29,195 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.09 sec
MapReduce Total cumulative CPU time: 21 seconds 90 msec
Ended Job = job_1513599404024_168883
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168885, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168885/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168885
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:49:34,883 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:49:41,081 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.8 sec
2018-01-03 15:49:42,113 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.93 sec
2018-01-03 15:49:46,233 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.0 sec
MapReduce Total cumulative CPU time: 16 seconds 0 msec
Ended Job = job_1513599404024_168885
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168887, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168887/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168887
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:49:52,897 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:49:59,098 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec
2018-01-03 15:50:05,277 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.52 sec
MapReduce Total cumulative CPU time: 5 seconds 520 msec
Ended Job = job_1513599404024_168887
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.09 sec   HDFS Read: 9613253 HDFS Write: 598543 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.0 sec   HDFS Read: 43174283 HDFS Write: 112700 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.52 sec   HDFS Read: 120338 HDFS Write: 2746 SUCCESS
Total MapReduce CPU Time Spent: 42 seconds 610 msec
OK
Time taken: 71.708 seconds, Fetched: 406 row(s)
开始执行20171129日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103155013_4aa09f67-8ec2-477e-af6c-a666c6251527
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168889, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168889/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168889
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:50:24,684 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:50:34,015 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.69 sec
2018-01-03 15:50:37,113 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 17.05 sec
2018-01-03 15:50:40,218 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 20.37 sec
2018-01-03 15:50:43,311 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 23.75 sec
2018-01-03 15:50:46,402 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 27.28 sec
2018-01-03 15:50:49,496 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 43.27 sec
2018-01-03 15:50:51,555 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 46.39 sec
2018-01-03 15:50:52,586 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 50.33 sec
2018-01-03 15:50:53,617 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 52.12 sec
2018-01-03 15:50:56,714 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 56.35 sec
2018-01-03 15:50:59,805 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 61.38 sec
MapReduce Total cumulative CPU time: 1 minutes 1 seconds 380 msec
Ended Job = job_1513599404024_168889
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168891, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168891/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168891
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:51:13,494 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:51:18,649 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.85 sec
2018-01-03 15:51:26,884 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.57 sec
2018-01-03 15:51:29,967 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.89 sec
MapReduce Total cumulative CPU time: 16 seconds 890 msec
Ended Job = job_1513599404024_168891
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168894, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168894/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168894
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:51:43,593 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:51:47,718 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec
2018-01-03 15:51:52,861 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.73 sec
MapReduce Total cumulative CPU time: 5 seconds 730 msec
Ended Job = job_1513599404024_168894
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 61.38 sec   HDFS Read: 176119999 HDFS Write: 1573432 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.89 sec   HDFS Read: 44601798 HDFS Write: 180939 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.73 sec   HDFS Read: 188614 HDFS Write: 2813 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 24 seconds 0 msec
OK
Time taken: 100.187 seconds, Fetched: 363 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.396 seconds
Query ID = boss_20180103155208_002157f2-a6dd-460d-bdfe-422eb3560491
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168898, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168898/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168898
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 15:52:17,718 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:52:27,041 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.84 sec
2018-01-03 15:52:28,074 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 22.31 sec
2018-01-03 15:52:30,145 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 26.22 sec
2018-01-03 15:52:31,178 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 29.92 sec
2018-01-03 15:52:33,241 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 33.33 sec
2018-01-03 15:52:34,271 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 36.76 sec
2018-01-03 15:52:36,331 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 39.88 sec
2018-01-03 15:52:37,363 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 42.97 sec
2018-01-03 15:52:39,423 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 45.98 sec
2018-01-03 15:52:40,458 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 48.98 sec
2018-01-03 15:52:42,518 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 53.11 sec
2018-01-03 15:52:43,548 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 56.07 sec
2018-01-03 15:52:46,637 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 59.02 sec
2018-01-03 15:52:48,697 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 62.17 sec
2018-01-03 15:52:51,787 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 65.15 sec
2018-01-03 15:52:53,850 Stage-1 map = 100%,  reduce = 11%, Cumulative CPU 68.89 sec
2018-01-03 15:52:55,912 Stage-1 map = 100%,  reduce = 39%, Cumulative CPU 73.4 sec
2018-01-03 15:52:56,944 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 77.15 sec
2018-01-03 15:53:02,096 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 80.85 sec
MapReduce Total cumulative CPU time: 1 minutes 20 seconds 850 msec
Ended Job = job_1513599404024_168898
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168901, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168901/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168901
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:53:10,821 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:53:16,001 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.75 sec
2018-01-03 15:53:24,334 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.36 sec
2018-01-03 15:53:26,396 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.02 sec
MapReduce Total cumulative CPU time: 13 seconds 20 msec
Ended Job = job_1513599404024_168901
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168902, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168902/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168902
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:53:34,034 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:53:39,190 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.78 sec
2018-01-03 15:53:53,614 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.85 sec
MapReduce Total cumulative CPU time: 5 seconds 850 msec
Ended Job = job_1513599404024_168902
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 80.85 sec   HDFS Read: 239300572 HDFS Write: 230649 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.02 sec   HDFS Read: 43259277 HDFS Write: 17083 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.85 sec   HDFS Read: 24759 HDFS Write: 1925 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 39 seconds 720 msec
OK
Time taken: 105.972 seconds, Fetched: 274 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103155401_c0ef2978-f2a3-4f2b-a052-30f1ebbcb644
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168906, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168906/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168906
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:54:22,224 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:54:32,655 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 10.13 sec
2018-01-03 15:54:35,755 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 11.7 sec
2018-01-03 15:54:36,786 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.71 sec
2018-01-03 15:54:41,944 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.66 sec
MapReduce Total cumulative CPU time: 17 seconds 660 msec
Ended Job = job_1513599404024_168906
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168910, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168910/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168910
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:55:29,727 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:55:34,884 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.95 sec
2018-01-03 15:55:36,944 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.44 sec
2018-01-03 15:55:45,182 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.92 sec
MapReduce Total cumulative CPU time: 17 seconds 920 msec
Ended Job = job_1513599404024_168910
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168926, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168926/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168926
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:55:59,017 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:56:04,187 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.95 sec
2018-01-03 15:56:18,649 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.96 sec
MapReduce Total cumulative CPU time: 5 seconds 960 msec
Ended Job = job_1513599404024_168926
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.66 sec   HDFS Read: 9594172 HDFS Write: 342926 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.92 sec   HDFS Read: 43370974 HDFS Write: 131777 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.96 sec   HDFS Read: 139414 HDFS Write: 4866 SUCCESS
Total MapReduce CPU Time Spent: 41 seconds 540 msec
OK
Time taken: 138.325 seconds, Fetched: 570 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.348 seconds
Query ID = boss_20180103155626_902cf156-e941-4fcb-9e26-d637f1cb4f64
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168931, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168931/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168931
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 15:56:36,212 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:56:47,622 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 11.67 sec
2018-01-03 15:56:50,728 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 17.99 sec
2018-01-03 15:56:56,932 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 23.36 sec
MapReduce Total cumulative CPU time: 23 seconds 360 msec
Ended Job = job_1513599404024_168931
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168933, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168933/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168933
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:57:03,709 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:57:08,959 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.23 sec
2018-01-03 15:57:11,026 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.78 sec
2018-01-03 15:57:17,227 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.96 sec
MapReduce Total cumulative CPU time: 14 seconds 960 msec
Ended Job = job_1513599404024_168933
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168934, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168934/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168934
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:57:26,984 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:57:53,720 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.87 sec
2018-01-03 15:58:06,063 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.15 sec
MapReduce Total cumulative CPU time: 6 seconds 150 msec
Ended Job = job_1513599404024_168934
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 23.36 sec   HDFS Read: 9594162 HDFS Write: 578236 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.96 sec   HDFS Read: 43606284 HDFS Write: 105900 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.15 sec   HDFS Read: 113538 HDFS Write: 2662 SUCCESS
Total MapReduce CPU Time Spent: 44 seconds 470 msec
OK
Time taken: 100.715 seconds, Fetched: 382 row(s)
开始执行20171130日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103155814_423b4eff-dbf1-4923-9a2c-6aa2fc60bbb8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168937, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168937/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168937
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 15:58:23,608 Stage-1 map = 0%,  reduce = 0%
2018-01-03 15:58:32,974 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 12.99 sec
2018-01-03 15:58:39,186 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 24.92 sec
2018-01-03 15:58:42,285 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 29.39 sec
2018-01-03 15:58:44,356 Stage-1 map = 56%,  reduce = 8%, Cumulative CPU 30.07 sec
2018-01-03 15:58:45,391 Stage-1 map = 59%,  reduce = 8%, Cumulative CPU 33.23 sec
2018-01-03 15:58:48,497 Stage-1 map = 62%,  reduce = 8%, Cumulative CPU 36.63 sec
2018-01-03 15:58:51,593 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 40.29 sec
2018-01-03 15:58:54,690 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 43.33 sec
2018-01-03 15:58:57,788 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 46.52 sec
2018-01-03 15:59:00,884 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 49.78 sec
2018-01-03 15:59:03,979 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 53.06 sec
2018-01-03 15:59:07,073 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 57.8 sec
2018-01-03 15:59:08,104 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 51.32 sec
2018-01-03 15:59:09,135 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 64.4 sec
2018-01-03 15:59:10,165 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 69.61 sec
MapReduce Total cumulative CPU time: 1 minutes 9 seconds 610 msec
Ended Job = job_1513599404024_168937
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168942, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168942/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168942
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 15:59:18,012 Stage-2 map = 0%,  reduce = 0%
2018-01-03 15:59:23,191 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.07 sec
2018-01-03 15:59:29,392 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.76 sec
MapReduce Total cumulative CPU time: 15 seconds 760 msec
Ended Job = job_1513599404024_168942
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168944, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168944/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168944
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 15:59:37,339 Stage-3 map = 0%,  reduce = 0%
2018-01-03 15:59:43,527 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.56 sec
2018-01-03 15:59:57,946 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 11.69 sec
MapReduce Total cumulative CPU time: 11 seconds 690 msec
Ended Job = job_1513599404024_168944
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 69.61 sec   HDFS Read: 178483569 HDFS Write: 1571170 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.76 sec   HDFS Read: 44979173 HDFS Write: 164559 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 11.69 sec   HDFS Read: 172230 HDFS Write: 2708 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 37 seconds 60 msec
OK
Time taken: 105.977 seconds, Fetched: 346 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.388 seconds
Query ID = boss_20180103160006_a6e648b6-a4dc-488f-a93c-e1340a6048f8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168947, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168947/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168947
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 16:00:17,039 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:00:27,395 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 11.67 sec
2018-01-03 16:00:28,429 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 23.67 sec
2018-01-03 16:00:30,497 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 31.5 sec
2018-01-03 16:00:33,591 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 38.56 sec
2018-01-03 16:00:35,652 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 41.78 sec
2018-01-03 16:00:36,683 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 44.92 sec
2018-01-03 16:00:38,744 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 48.91 sec
2018-01-03 16:00:39,779 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 52.58 sec
2018-01-03 16:00:42,869 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 55.53 sec
2018-01-03 16:00:45,959 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 58.56 sec
2018-01-03 16:00:49,061 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 62.07 sec
2018-01-03 16:00:52,153 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 65.05 sec
2018-01-03 16:00:55,242 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 68.54 sec
2018-01-03 16:00:56,291 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 70.03 sec
2018-01-03 16:00:57,321 Stage-1 map = 100%,  reduce = 72%, Cumulative CPU 78.35 sec
2018-01-03 16:00:58,351 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 81.69 sec
MapReduce Total cumulative CPU time: 1 minutes 21 seconds 690 msec
Ended Job = job_1513599404024_168947
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168955, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168955/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168955
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:01:05,146 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:01:10,390 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.19 sec
2018-01-03 16:01:22,738 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.19 sec
2018-01-03 16:01:24,797 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.64 sec
MapReduce Total cumulative CPU time: 15 seconds 640 msec
Ended Job = job_1513599404024_168955
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168961, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168961/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168961
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:01:34,131 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:01:39,297 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.39 sec
2018-01-03 16:01:47,554 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.7 sec
MapReduce Total cumulative CPU time: 5 seconds 700 msec
Ended Job = job_1513599404024_168961
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 81.69 sec   HDFS Read: 238744862 HDFS Write: 236429 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.64 sec   HDFS Read: 43644699 HDFS Write: 16976 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.7 sec   HDFS Read: 24652 HDFS Write: 1950 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 43 seconds 30 msec
OK
Time taken: 101.736 seconds, Fetched: 283 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103160155_fe732a3a-d68a-48c9-945b-0cf10baa74ac
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168972, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168972/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168972
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:02:05,992 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:02:16,350 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 10.91 sec
2018-01-03 16:02:17,384 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.15 sec
2018-01-03 16:02:26,683 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.79 sec
MapReduce Total cumulative CPU time: 16 seconds 790 msec
Ended Job = job_1513599404024_168972
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168980, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168980/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168980
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:02:33,502 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:02:38,679 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.68 sec
2018-01-03 16:02:45,907 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.44 sec
MapReduce Total cumulative CPU time: 14 seconds 440 msec
Ended Job = job_1513599404024_168980
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168985, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168985/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168985
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:02:52,592 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:02:57,771 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.88 sec
2018-01-03 16:03:05,052 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.87 sec
MapReduce Total cumulative CPU time: 6 seconds 870 msec
Ended Job = job_1513599404024_168985
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.79 sec   HDFS Read: 9819062 HDFS Write: 350533 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.44 sec   HDFS Read: 43758223 HDFS Write: 128673 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.87 sec   HDFS Read: 136310 HDFS Write: 4929 SUCCESS
Total MapReduce CPU Time Spent: 38 seconds 100 msec
OK
Time taken: 70.863 seconds, Fetched: 594 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103160313_1866b24a-ef83-4683-a824-0df2c5baa5c9
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168988, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168988/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168988
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:03:22,913 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:03:33,266 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 13.76 sec
2018-01-03 16:03:34,302 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.31 sec
2018-01-03 16:03:40,491 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.15 sec
MapReduce Total cumulative CPU time: 21 seconds 150 msec
Ended Job = job_1513599404024_168988
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_168995, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_168995/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_168995
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:03:54,580 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:03:59,740 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.02 sec
2018-01-03 16:04:07,981 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.92 sec
2018-01-03 16:04:27,527 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.04 sec
MapReduce Total cumulative CPU time: 16 seconds 40 msec
Ended Job = job_1513599404024_168995
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169003, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169003/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169003
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:04:36,189 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:04:43,512 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.38 sec
2018-01-03 16:04:51,746 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.0 sec
MapReduce Total cumulative CPU time: 8 seconds 0 msec
Ended Job = job_1513599404024_169003
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.15 sec   HDFS Read: 9819051 HDFS Write: 593020 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.04 sec   HDFS Read: 44000706 HDFS Write: 105423 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.0 sec   HDFS Read: 113057 HDFS Write: 2682 SUCCESS
Total MapReduce CPU Time Spent: 45 seconds 190 msec
OK
Time taken: 99.469 seconds, Fetched: 394 row(s)
开始执行20171201日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.372 seconds
Query ID = boss_20180103160459_5730f1fa-8333-49c6-9dec-3a5228a97a63
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169019, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169019/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169019
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:05:19,965 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:05:30,305 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 12.34 sec
2018-01-03 16:05:31,339 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 12.34 sec
2018-01-03 16:05:32,372 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 26.02 sec
2018-01-03 16:05:35,468 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 29.56 sec
2018-01-03 16:05:38,557 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 32.98 sec
2018-01-03 16:05:41,643 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 37.14 sec
2018-01-03 16:05:42,685 Stage-1 map = 60%,  reduce = 17%, Cumulative CPU 38.59 sec
2018-01-03 16:05:44,750 Stage-1 map = 62%,  reduce = 17%, Cumulative CPU 41.27 sec
2018-01-03 16:05:47,840 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 44.35 sec
2018-01-03 16:05:50,927 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 47.38 sec
2018-01-03 16:05:54,023 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 50.62 sec
2018-01-03 16:05:57,110 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 53.64 sec
2018-01-03 16:05:59,167 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 56.81 sec
2018-01-03 16:06:02,255 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 60.72 sec
2018-01-03 16:06:05,340 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 64.13 sec
2018-01-03 16:06:06,368 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 66.89 sec
2018-01-03 16:06:07,396 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 77.75 sec
MapReduce Total cumulative CPU time: 1 minutes 17 seconds 750 msec
Ended Job = job_1513599404024_169019
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169035, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169035/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169035
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:06:43,262 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:06:48,441 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.28 sec
2018-01-03 16:06:49,539 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.66 sec
2018-01-03 16:06:56,744 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.58 sec
MapReduce Total cumulative CPU time: 18 seconds 580 msec
Ended Job = job_1513599404024_169035
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169040, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169040/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169040
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:07:03,458 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:07:08,617 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.42 sec
2018-01-03 16:07:14,788 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.87 sec
MapReduce Total cumulative CPU time: 6 seconds 870 msec
Ended Job = job_1513599404024_169040
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 77.75 sec   HDFS Read: 190344920 HDFS Write: 1791565 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.58 sec   HDFS Read: 47598049 HDFS Write: 199305 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.87 sec   HDFS Read: 206980 HDFS Write: 2827 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 43 seconds 200 msec
OK
Time taken: 136.082 seconds, Fetched: 365 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.382 seconds
Query ID = boss_20180103160722_bf1b66b6-e210-4efe-8913-97e4d846344e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169044, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169044/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169044
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 16:07:45,558 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:07:56,980 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 11.37 sec
2018-01-03 16:08:00,088 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 14.99 sec
2018-01-03 16:08:01,125 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 26.92 sec
2018-01-03 16:08:03,192 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 30.18 sec
2018-01-03 16:08:04,225 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 34.26 sec
2018-01-03 16:08:06,289 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 37.42 sec
2018-01-03 16:08:07,322 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 40.68 sec
2018-01-03 16:08:09,389 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 43.66 sec
2018-01-03 16:08:10,421 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 46.93 sec
2018-01-03 16:08:12,483 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 49.81 sec
2018-01-03 16:08:13,514 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 52.73 sec
2018-01-03 16:08:15,576 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 55.72 sec
2018-01-03 16:08:16,608 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 58.76 sec
2018-01-03 16:08:17,644 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 61.66 sec
2018-01-03 16:08:19,706 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 64.58 sec
2018-01-03 16:08:20,736 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 66.84 sec
2018-01-03 16:08:22,795 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 69.84 sec
2018-01-03 16:08:23,826 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 73.27 sec
2018-01-03 16:08:24,856 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 77.62 sec
2018-01-03 16:08:28,981 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 81.57 sec
2018-01-03 16:08:37,224 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 85.52 sec
2018-01-03 16:08:50,598 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 88.92 sec
MapReduce Total cumulative CPU time: 1 minutes 28 seconds 920 msec
Ended Job = job_1513599404024_169044
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169054, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169054/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169054
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:08:59,297 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:09:04,456 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.39 sec
2018-01-03 16:09:06,514 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.61 sec
2018-01-03 16:09:10,629 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.79 sec
MapReduce Total cumulative CPU time: 13 seconds 790 msec
Ended Job = job_1513599404024_169054
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169059, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169059/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169059
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:09:18,337 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:09:24,538 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec
2018-01-03 16:09:35,850 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.85 sec
MapReduce Total cumulative CPU time: 6 seconds 850 msec
Ended Job = job_1513599404024_169059
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 88.92 sec   HDFS Read: 243991428 HDFS Write: 263586 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.79 sec   HDFS Read: 46070332 HDFS Write: 20218 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.85 sec   HDFS Read: 27894 HDFS Write: 2057 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 49 seconds 560 msec
OK
Time taken: 134.476 seconds, Fetched: 292 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103160943_af260db7-d4fe-4dcb-afe4-bd925093139f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169062, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169062/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169062
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:09:53,604 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:10:11,167 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 9.98 sec
2018-01-03 16:10:13,231 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.09 sec
2018-01-03 16:10:19,424 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.15 sec
MapReduce Total cumulative CPU time: 17 seconds 150 msec
Ended Job = job_1513599404024_169062
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169064, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169064/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169064
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:10:28,312 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:10:35,624 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.73 sec
2018-01-03 16:10:36,656 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.93 sec
2018-01-03 16:10:41,911 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.44 sec
MapReduce Total cumulative CPU time: 17 seconds 440 msec
Ended Job = job_1513599404024_169064
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169065, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169065/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169065
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:10:49,602 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:10:54,768 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.36 sec
2018-01-03 16:11:08,169 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.71 sec
MapReduce Total cumulative CPU time: 6 seconds 710 msec
Ended Job = job_1513599404024_169065
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.15 sec   HDFS Read: 10226794 HDFS Write: 401238 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.44 sec   HDFS Read: 46207400 HDFS Write: 139748 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.71 sec   HDFS Read: 147381 HDFS Write: 5178 SUCCESS
Total MapReduce CPU Time Spent: 41 seconds 300 msec
OK
Time taken: 85.505 seconds, Fetched: 620 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103161115_8acf25e2-cdc0-4275-82a1-39ffde468968
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169069, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169069/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169069
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:11:25,877 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:11:36,255 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 13.79 sec
2018-01-03 16:11:37,299 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.3 sec
2018-01-03 16:11:50,738 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.32 sec
MapReduce Total cumulative CPU time: 20 seconds 320 msec
Ended Job = job_1513599404024_169069
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169070, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169070/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169070
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:11:59,556 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:12:04,721 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.07 sec
2018-01-03 16:12:06,789 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.07 sec
2018-01-03 16:12:44,875 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.03 sec
MapReduce Total cumulative CPU time: 19 seconds 30 msec
Ended Job = job_1513599404024_169070
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169075, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169075/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169075
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:12:52,712 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:13:05,084 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.83 sec
2018-01-03 16:13:11,282 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.4 sec
MapReduce Total cumulative CPU time: 6 seconds 400 msec
Ended Job = job_1513599404024_169075
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.32 sec   HDFS Read: 10226785 HDFS Write: 685956 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.03 sec   HDFS Read: 46492122 HDFS Write: 121824 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.4 sec   HDFS Read: 129462 HDFS Write: 3135 SUCCESS
Total MapReduce CPU Time Spent: 45 seconds 750 msec
OK
Time taken: 116.4 seconds, Fetched: 486 row(s)
开始执行20171202日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.371 seconds
Query ID = boss_20180103161319_9e8051f5-b79e-43dd-8a09-3bda4d521564
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169077, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169077/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169077
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:13:30,625 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:13:41,027 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 26.65 sec
2018-01-03 16:13:44,130 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 34.85 sec
2018-01-03 16:13:47,226 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 42.38 sec
2018-01-03 16:13:50,319 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 49.41 sec
2018-01-03 16:13:51,350 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 51.1 sec
2018-01-03 16:13:53,419 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 54.21 sec
2018-01-03 16:13:56,524 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 57.85 sec
2018-01-03 16:13:59,614 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 61.56 sec
2018-01-03 16:14:02,707 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 65.15 sec
2018-01-03 16:14:03,741 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 65.73 sec
2018-01-03 16:14:05,803 Stage-1 map = 80%,  reduce = 8%, Cumulative CPU 69.75 sec
2018-01-03 16:14:07,863 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 73.42 sec
2018-01-03 16:14:09,924 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 74.9 sec
2018-01-03 16:14:10,953 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 77.71 sec
2018-01-03 16:14:24,343 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 83.38 sec
MapReduce Total cumulative CPU time: 1 minutes 23 seconds 380 msec
Ended Job = job_1513599404024_169077
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169079, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169079/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169079
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:14:33,105 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:14:38,471 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.84 sec
2018-01-03 16:14:48,788 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.66 sec
2018-01-03 16:14:49,819 Stage-2 map = 100%,  reduce = 33%, Cumulative CPU 10.44 sec
2018-01-03 16:14:54,967 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 14.04 sec
2018-01-03 16:15:03,198 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.71 sec
MapReduce Total cumulative CPU time: 20 seconds 710 msec
Ended Job = job_1513599404024_169079
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169082, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169082/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169082
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:15:26,931 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:15:31,052 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.7 sec
2018-01-03 16:15:37,233 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.34 sec
MapReduce Total cumulative CPU time: 5 seconds 340 msec
Ended Job = job_1513599404024_169082
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 83.38 sec   HDFS Read: 228888791 HDFS Write: 2271317 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.71 sec   HDFS Read: 61782346 HDFS Write: 89619 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.34 sec   HDFS Read: 97294 HDFS Write: 2930 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 49 seconds 430 msec
OK
Time taken: 138.94 seconds, Fetched: 378 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.394 seconds
Query ID = boss_20180103161545_ff6f325b-feb2-4815-8b20-f7c00db61a81
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169084, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169084/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169084
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 16:16:00,112 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:16:10,491 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 24.08 sec
2018-01-03 16:16:12,563 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 28.49 sec
2018-01-03 16:16:13,603 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 33.58 sec
2018-01-03 16:16:15,670 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 37.27 sec
2018-01-03 16:16:16,704 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 41.25 sec
2018-01-03 16:16:17,743 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 54.03 sec
2018-01-03 16:16:19,806 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 57.04 sec
2018-01-03 16:16:20,839 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 61.01 sec
2018-01-03 16:16:22,906 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 64.0 sec
2018-01-03 16:16:23,937 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 67.29 sec
2018-01-03 16:16:26,005 Stage-1 map = 66%,  reduce = 7%, Cumulative CPU 71.39 sec
2018-01-03 16:16:27,038 Stage-1 map = 82%,  reduce = 11%, Cumulative CPU 77.76 sec
2018-01-03 16:16:29,103 Stage-1 map = 82%,  reduce = 19%, Cumulative CPU 77.9 sec
2018-01-03 16:16:30,135 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 81.07 sec
2018-01-03 16:16:33,234 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 84.81 sec
2018-01-03 16:16:34,268 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 95.74 sec
MapReduce Total cumulative CPU time: 1 minutes 35 seconds 740 msec
Ended Job = job_1513599404024_169084
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169086, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169086/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169086
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:16:40,094 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:16:45,245 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.24 sec
2018-01-03 16:16:51,422 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.45 sec
MapReduce Total cumulative CPU time: 13 seconds 450 msec
Ended Job = job_1513599404024_169086
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169088, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169088/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169088
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:16:58,085 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:17:03,245 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.9 sec
2018-01-03 16:17:09,430 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.2 sec
MapReduce Total cumulative CPU time: 5 seconds 200 msec
Ended Job = job_1513599404024_169088
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 95.74 sec   HDFS Read: 296931702 HDFS Write: 338602 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.45 sec   HDFS Read: 59849893 HDFS Write: 20710 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.2 sec   HDFS Read: 28386 HDFS Write: 2220 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 54 seconds 390 msec
OK
Time taken: 85.486 seconds, Fetched: 321 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.35 seconds
Query ID = boss_20180103161717_cca87d75-6758-4bb0-8f0a-cd5cf13a733b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169092, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169092/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169092
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:17:26,633 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:17:36,991 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 9.41 sec
2018-01-03 16:17:40,097 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 11.18 sec
2018-01-03 16:17:41,129 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.6 sec
2018-01-03 16:17:47,321 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.42 sec
MapReduce Total cumulative CPU time: 16 seconds 420 msec
Ended Job = job_1513599404024_169092
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169095, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169095/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169095
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:18:07,007 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:18:13,191 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.81 sec
2018-01-03 16:18:20,400 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.74 sec
2018-01-03 16:18:22,459 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.06 sec
MapReduce Total cumulative CPU time: 15 seconds 60 msec
Ended Job = job_1513599404024_169095
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169097, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169097/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169097
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:18:28,072 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:18:32,196 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.74 sec
2018-01-03 16:18:38,376 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.54 sec
MapReduce Total cumulative CPU time: 6 seconds 540 msec
Ended Job = job_1513599404024_169097
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.42 sec   HDFS Read: 11735516 HDFS Write: 683622 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.06 sec   HDFS Read: 60194333 HDFS Write: 197827 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.54 sec   HDFS Read: 205464 HDFS Write: 7324 SUCCESS
Total MapReduce CPU Time Spent: 38 seconds 20 msec
OK
Time taken: 82.285 seconds, Fetched: 900 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.362 seconds
Query ID = boss_20180103161846_5b395650-d6dc-4d4c-aae2-42ff541cc822
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169099, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169099/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169099
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:18:56,935 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:19:07,302 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 10.27 sec
2018-01-03 16:19:10,404 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 11.04 sec
2018-01-03 16:19:13,499 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.19 sec
2018-01-03 16:19:19,694 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.08 sec
MapReduce Total cumulative CPU time: 20 seconds 80 msec
Ended Job = job_1513599404024_169099
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169101, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169101/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169101
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:19:34,427 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:19:57,081 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 8.78 sec
2018-01-03 16:20:00,170 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 22.2 sec
2018-01-03 16:20:15,605 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 28.85 sec
MapReduce Total cumulative CPU time: 28 seconds 850 msec
Ended Job = job_1513599404024_169101
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169103, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169103/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169103
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:21:03,957 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:21:09,333 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.26 sec
2018-01-03 16:21:17,748 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.15 sec
MapReduce Total cumulative CPU time: 6 seconds 150 msec
Ended Job = job_1513599404024_169103
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.08 sec   HDFS Read: 11735506 HDFS Write: 853810 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 28.85 sec   HDFS Read: 60364521 HDFS Write: 136865 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.15 sec   HDFS Read: 144503 HDFS Write: 4149 SUCCESS
Total MapReduce CPU Time Spent: 55 seconds 80 msec
OK
Time taken: 152.763 seconds, Fetched: 608 row(s)
开始执行20171203日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.368 seconds
Query ID = boss_20180103162125_a743c9e6-f94b-47be-8ed5-4853d8fd4617
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169106, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169106/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169106
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:21:42,867 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:21:53,247 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.28 sec
2018-01-03 16:21:56,353 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 16.84 sec
2018-01-03 16:21:58,420 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 28.55 sec
2018-01-03 16:21:59,453 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 31.76 sec
2018-01-03 16:22:01,518 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 35.34 sec
2018-01-03 16:22:02,550 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 38.71 sec
2018-01-03 16:22:04,614 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 45.79 sec
2018-01-03 16:22:07,721 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 53.82 sec
2018-01-03 16:22:10,815 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 57.01 sec
2018-01-03 16:22:14,945 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 61.61 sec
2018-01-03 16:22:23,188 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 67.37 sec
MapReduce Total cumulative CPU time: 1 minutes 7 seconds 370 msec
Ended Job = job_1513599404024_169106
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169112, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169112/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169112
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:22:36,904 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:22:43,095 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 7.45 sec
2018-01-03 16:22:49,268 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.82 sec
2018-01-03 16:22:52,363 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.72 sec
MapReduce Total cumulative CPU time: 21 seconds 720 msec
Ended Job = job_1513599404024_169112
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169118, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169118/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169118
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:22:59,068 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:23:05,249 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.41 sec
2018-01-03 16:23:12,575 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.3 sec
MapReduce Total cumulative CPU time: 9 seconds 300 msec
Ended Job = job_1513599404024_169118
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 67.37 sec   HDFS Read: 217230235 HDFS Write: 2029861 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 21.72 sec   HDFS Read: 45602990 HDFS Write: 158271 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.3 sec   HDFS Read: 165942 HDFS Write: 2946 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 38 seconds 390 msec
OK
Time taken: 107.727 seconds, Fetched: 362 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.392 seconds
Query ID = boss_20180103162320_b4d2fe21-c309-4a82-83f3-3334166d3c9d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169120, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169120/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169120
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 16:23:35,376 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:23:44,720 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 13.13 sec
2018-01-03 16:23:45,755 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 25.57 sec
2018-01-03 16:23:47,825 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 29.67 sec
2018-01-03 16:23:48,863 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 34.56 sec
2018-01-03 16:23:49,896 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 36.38 sec
2018-01-03 16:23:50,929 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 53.79 sec
2018-01-03 16:23:54,032 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 61.15 sec
2018-01-03 16:23:57,137 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 71.37 sec
2018-01-03 16:24:00,240 Stage-1 map = 74%,  reduce = 4%, Cumulative CPU 79.51 sec
2018-01-03 16:24:01,274 Stage-1 map = 74%,  reduce = 7%, Cumulative CPU 80.09 sec
2018-01-03 16:24:03,341 Stage-1 map = 76%,  reduce = 11%, Cumulative CPU 88.4 sec
2018-01-03 16:24:04,377 Stage-1 map = 76%,  reduce = 15%, Cumulative CPU 88.49 sec
2018-01-03 16:24:06,439 Stage-1 map = 79%,  reduce = 15%, Cumulative CPU 91.7 sec
2018-01-03 16:24:09,539 Stage-1 map = 80%,  reduce = 15%, Cumulative CPU 108.22 sec
2018-01-03 16:24:12,635 Stage-1 map = 82%,  reduce = 15%, Cumulative CPU 118.49 sec
2018-01-03 16:24:16,762 Stage-1 map = 85%,  reduce = 15%, Cumulative CPU 129.77 sec
2018-01-03 16:24:19,853 Stage-1 map = 87%,  reduce = 15%, Cumulative CPU 132.71 sec
2018-01-03 16:24:20,883 Stage-1 map = 87%,  reduce = 22%, Cumulative CPU 133.33 sec
2018-01-03 16:24:22,945 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 136.66 sec
2018-01-03 16:24:23,978 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 143.77 sec
2018-01-03 16:24:26,041 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 151.35 sec
MapReduce Total cumulative CPU time: 2 minutes 31 seconds 350 msec
Ended Job = job_1513599404024_169120
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169123, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169123/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169123
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:24:32,990 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:24:39,185 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.68 sec
2018-01-03 16:24:45,371 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.22 sec
2018-01-03 16:24:53,600 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.32 sec
MapReduce Total cumulative CPU time: 17 seconds 320 msec
Ended Job = job_1513599404024_169123
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169124, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169124/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169124
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:25:01,246 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:25:10,522 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.26 sec
2018-01-03 16:25:20,810 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.81 sec
MapReduce Total cumulative CPU time: 7 seconds 810 msec
Ended Job = job_1513599404024_169124
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 151.35 sec   HDFS Read: 285839563 HDFS Write: 306445 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.32 sec   HDFS Read: 43879841 HDFS Write: 20554 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.81 sec   HDFS Read: 28230 HDFS Write: 2133 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 56 seconds 480 msec
OK
Time taken: 121.513 seconds, Fetched: 300 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103162528_e2134015-8e31-458b-a373-0d6a3b0ab92a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169126, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169126/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169126
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:25:41,096 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:25:50,422 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 9.23 sec
2018-01-03 16:25:51,455 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 10.73 sec
2018-01-03 16:25:57,655 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.05 sec
MapReduce Total cumulative CPU time: 16 seconds 50 msec
Ended Job = job_1513599404024_169126
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169128, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169128/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169128
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:26:10,342 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:26:15,515 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.74 sec
2018-01-03 16:26:20,709 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.47 sec
2018-01-03 16:26:28,951 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.75 sec
MapReduce Total cumulative CPU time: 19 seconds 750 msec
Ended Job = job_1513599404024_169128
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169129, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169129/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169129
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:26:36,664 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:26:40,794 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.75 sec
2018-01-03 16:26:46,975 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.68 sec
MapReduce Total cumulative CPU time: 6 seconds 680 msec
Ended Job = job_1513599404024_169129
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.05 sec   HDFS Read: 11031255 HDFS Write: 462081 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.75 sec   HDFS Read: 44034897 HDFS Write: 165961 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.68 sec   HDFS Read: 173598 HDFS Write: 5741 SUCCESS
Total MapReduce CPU Time Spent: 42 seconds 480 msec
OK
Time taken: 79.464 seconds, Fetched: 683 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.376 seconds
Query ID = boss_20180103162702_a352b59e-32b2-4269-9235-6753e1864a54
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169136, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169136/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169136
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:27:16,200 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:27:26,784 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 10.71 sec
2018-01-03 16:27:29,994 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 14.19 sec
2018-01-03 16:27:31,030 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.88 sec
2018-01-03 16:27:50,646 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.69 sec
MapReduce Total cumulative CPU time: 21 seconds 690 msec
Ended Job = job_1513599404024_169136
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169140, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169140/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169140
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:27:58,492 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:28:03,653 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.8 sec
2018-01-03 16:28:16,008 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.07 sec
MapReduce Total cumulative CPU time: 16 seconds 70 msec
Ended Job = job_1513599404024_169140
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169147, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169147/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169147
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:28:23,699 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:28:29,877 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.35 sec
2018-01-03 16:28:37,078 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.03 sec
MapReduce Total cumulative CPU time: 7 seconds 30 msec
Ended Job = job_1513599404024_169147
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.69 sec   HDFS Read: 11031245 HDFS Write: 765520 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.07 sec   HDFS Read: 44338336 HDFS Write: 132286 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.03 sec   HDFS Read: 139924 HDFS Write: 3491 SUCCESS
Total MapReduce CPU Time Spent: 44 seconds 790 msec
OK
Time taken: 95.357 seconds, Fetched: 564 row(s)
开始执行20171204日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.385 seconds
Query ID = boss_20180103162845_9ac56003-d7e6-4748-8861-4cf75e517e44
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169150, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169150/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169150
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:29:09,148 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:29:19,756 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 13.62 sec
2018-01-03 16:29:22,009 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 27.52 sec
2018-01-03 16:29:23,058 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 32.06 sec
2018-01-03 16:29:25,127 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 34.88 sec
2018-01-03 16:29:27,197 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 41.48 sec
2018-01-03 16:29:28,232 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 45.83 sec
2018-01-03 16:29:31,337 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 48.46 sec
2018-01-03 16:29:34,438 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 52.09 sec
2018-01-03 16:29:37,533 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 55.58 sec
2018-01-03 16:29:40,635 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 59.98 sec
2018-01-03 16:29:43,739 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 64.11 sec
2018-01-03 16:29:46,840 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 68.4 sec
2018-01-03 16:29:49,932 Stage-1 map = 100%,  reduce = 35%, Cumulative CPU 71.97 sec
2018-01-03 16:29:50,967 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 77.25 sec
2018-01-03 16:29:53,026 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 81.52 sec
MapReduce Total cumulative CPU time: 1 minutes 21 seconds 520 msec
Ended Job = job_1513599404024_169150
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169157, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169157/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169157
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:30:00,539 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:30:08,781 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.46 sec
2018-01-03 16:30:12,915 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 25.52 sec
2018-01-03 16:30:16,002 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 32.26 sec
MapReduce Total cumulative CPU time: 32 seconds 260 msec
Ended Job = job_1513599404024_169157
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169159, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169159/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169159
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:30:29,709 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:30:42,074 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.98 sec
2018-01-03 16:30:51,495 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 9.21 sec
MapReduce Total cumulative CPU time: 9 seconds 210 msec
Ended Job = job_1513599404024_169159
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 81.52 sec   HDFS Read: 176076294 HDFS Write: 1636834 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 32.26 sec   HDFS Read: 44632186 HDFS Write: 152816 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 9.21 sec   HDFS Read: 160487 HDFS Write: 2606 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 2 seconds 990 msec
OK
Time taken: 127.377 seconds, Fetched: 339 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.432 seconds
Query ID = boss_20180103163059_47a839ab-952f-4265-aa0a-658e6279d088
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169164, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169164/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169164
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:31:13,280 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:31:24,686 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 11.27 sec
2018-01-03 16:31:26,753 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.27 sec
2018-01-03 16:31:27,785 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 55.67 sec
2018-01-03 16:31:29,851 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 59.3 sec
2018-01-03 16:31:30,886 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 62.66 sec
2018-01-03 16:31:33,983 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 68.25 sec
2018-01-03 16:31:36,050 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 71.24 sec
2018-01-03 16:31:38,115 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 78.35 sec
2018-01-03 16:31:39,147 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 81.41 sec
2018-01-03 16:31:41,206 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 92.14 sec
2018-01-03 16:31:42,236 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 95.22 sec
2018-01-03 16:31:44,342 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 103.32 sec
2018-01-03 16:31:45,379 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 106.2 sec
2018-01-03 16:31:46,408 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 107.5 sec
2018-01-03 16:31:47,438 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 125.24 sec
2018-01-03 16:31:49,495 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 128.23 sec
2018-01-03 16:31:53,608 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 144.28 sec
2018-01-03 16:31:57,724 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 153.99 sec
2018-01-03 16:31:58,758 Stage-1 map = 77%,  reduce = 8%, Cumulative CPU 154.56 sec
2018-01-03 16:32:00,814 Stage-1 map = 79%,  reduce = 8%, Cumulative CPU 164.57 sec
2018-01-03 16:32:03,917 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 173.33 sec
2018-01-03 16:32:04,952 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 175.26 sec
2018-01-03 16:32:05,986 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 177.42 sec
2018-01-03 16:32:07,016 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 183.71 sec
MapReduce Total cumulative CPU time: 3 minutes 3 seconds 710 msec
Ended Job = job_1513599404024_169164
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169173, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169173/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169173
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:32:22,081 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:32:30,372 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.74 sec
2018-01-03 16:32:35,514 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.19 sec
2018-01-03 16:32:37,575 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.07 sec
MapReduce Total cumulative CPU time: 16 seconds 70 msec
Ended Job = job_1513599404024_169173
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169178, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169178/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169178
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:32:43,301 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:32:50,501 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.67 sec
2018-01-03 16:32:58,725 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.38 sec
MapReduce Total cumulative CPU time: 7 seconds 380 msec
Ended Job = job_1513599404024_169178
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 185.46 sec   HDFS Read: 225734642 HDFS Write: 237252 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.07 sec   HDFS Read: 43232609 HDFS Write: 18451 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.38 sec   HDFS Read: 26127 HDFS Write: 2077 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 28 seconds 910 msec
OK
Time taken: 120.182 seconds, Fetched: 301 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103163306_a08a6e50-e22c-4933-8f9e-fe3bfe4691d7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169181, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169181/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169181
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:33:16,657 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:33:32,234 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 13.95 sec
2018-01-03 16:33:35,327 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 16.39 sec
2018-01-03 16:33:39,450 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 23.21 sec
2018-01-03 16:33:41,511 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 24.57 sec
2018-01-03 16:33:49,176 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 30.35 sec
MapReduce Total cumulative CPU time: 30 seconds 350 msec
Ended Job = job_1513599404024_169181
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169186, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169186/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169186
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:34:17,780 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:34:46,193 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 8.56 sec
2018-01-03 16:34:48,361 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 18.89 sec
2018-01-03 16:35:18,848 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 32.85 sec
MapReduce Total cumulative CPU time: 32 seconds 850 msec
Ended Job = job_1513599404024_169186
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169192, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169192/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169192
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:35:48,492 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:36:04,991 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.54 sec
2018-01-03 16:36:29,076 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 11.4 sec
MapReduce Total cumulative CPU time: 11 seconds 400 msec
Ended Job = job_1513599404024_169192
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 30.35 sec   HDFS Read: 11339265 HDFS Write: 421221 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 34.3 sec   HDFS Read: 43416260 HDFS Write: 138868 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 11.4 sec   HDFS Read: 146505 HDFS Write: 5061 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 16 seconds 50 msec
OK
Time taken: 204.663 seconds, Fetched: 628 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103163637_8e92a7e2-c65c-4d8d-825b-9d6e8159a359
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169199, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169199/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169199
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:36:49,771 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:37:06,326 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 8.71 sec
2018-01-03 16:37:09,460 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 11.88 sec
2018-01-03 16:37:12,552 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 13.53 sec
2018-01-03 16:37:15,656 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.31 sec
2018-01-03 16:37:22,874 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.11 sec
MapReduce Total cumulative CPU time: 19 seconds 110 msec
Ended Job = job_1513599404024_169199
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169202, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169202/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169202
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:37:30,903 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:37:38,151 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.54 sec
2018-01-03 16:37:48,470 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 16.34 sec
2018-01-03 16:37:49,502 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 17.09 sec
2018-01-03 16:37:50,533 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 23.13 sec
MapReduce Total cumulative CPU time: 23 seconds 130 msec
Ended Job = job_1513599404024_169202
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169205, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169205/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169205
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:38:01,288 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:38:07,466 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.02 sec
2018-01-03 16:38:15,696 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.46 sec
MapReduce Total cumulative CPU time: 7 seconds 460 msec
Ended Job = job_1513599404024_169205
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.11 sec   HDFS Read: 11339254 HDFS Write: 645511 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 23.13 sec   HDFS Read: 43640546 HDFS Write: 120756 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.46 sec   HDFS Read: 128390 HDFS Write: 3939 SUCCESS
Total MapReduce CPU Time Spent: 49 seconds 700 msec
OK
Time taken: 98.817 seconds, Fetched: 641 row(s)
开始执行20171205日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103163823_ff96378e-8ffc-46cf-93a0-eaac8b8cd8ef
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169209, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169209/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169209
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:38:39,854 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:38:50,333 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 11.71 sec
2018-01-03 16:38:53,458 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 16.83 sec
2018-01-03 16:38:56,564 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 20.13 sec
2018-01-03 16:38:58,639 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 39.22 sec
2018-01-03 16:38:59,676 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 44.1 sec
2018-01-03 16:39:02,785 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 46.42 sec
2018-01-03 16:39:05,879 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 49.92 sec
2018-01-03 16:39:08,974 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 53.56 sec
2018-01-03 16:39:12,067 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 56.32 sec
2018-01-03 16:39:15,157 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 59.03 sec
2018-01-03 16:39:18,253 Stage-1 map = 79%,  reduce = 8%, Cumulative CPU 62.32 sec
2018-01-03 16:39:19,286 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 63.46 sec
2018-01-03 16:39:21,352 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 66.2 sec
2018-01-03 16:39:23,417 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 69.3 sec
2018-01-03 16:39:25,478 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 70.48 sec
2018-01-03 16:39:26,509 Stage-1 map = 100%,  reduce = 70%, Cumulative CPU 74.43 sec
2018-01-03 16:39:28,570 Stage-1 map = 100%,  reduce = 88%, Cumulative CPU 83.41 sec
2018-01-03 16:39:30,632 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 87.76 sec
MapReduce Total cumulative CPU time: 1 minutes 27 seconds 760 msec
Ended Job = job_1513599404024_169209
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169217, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169217/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169217
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:39:52,375 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:39:58,601 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.36 sec
2018-01-03 16:40:04,789 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.67 sec
2018-01-03 16:40:07,882 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 11.67 sec
MapReduce Total cumulative CPU time: 11 seconds 670 msec
Ended Job = job_1513599404024_169217
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169222, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169222/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169222
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:40:28,642 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:40:32,765 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.98 sec
2018-01-03 16:40:47,203 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.48 sec
MapReduce Total cumulative CPU time: 6 seconds 480 msec
Ended Job = job_1513599404024_169222
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 87.76 sec   HDFS Read: 170128851 HDFS Write: 1525799 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.18 sec   HDFS Read: 42989104 HDFS Write: 150936 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.48 sec   HDFS Read: 158611 HDFS Write: 2793 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 52 seconds 420 msec
OK
Time taken: 144.455 seconds, Fetched: 356 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.387 seconds
Query ID = boss_20180103164108_a1081ee4-9e19-482b-b062-0933f989240d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169227, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169227/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169227
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:41:18,299 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:41:28,652 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.24 sec
2018-01-03 16:41:31,753 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 15.65 sec
2018-01-03 16:41:33,816 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 27.18 sec
2018-01-03 16:41:34,848 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 31.09 sec
2018-01-03 16:41:36,909 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 34.47 sec
2018-01-03 16:41:37,940 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 37.77 sec
2018-01-03 16:41:40,002 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 40.84 sec
2018-01-03 16:41:41,036 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 44.47 sec
2018-01-03 16:41:42,067 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 48.72 sec
2018-01-03 16:41:44,127 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 51.77 sec
2018-01-03 16:41:45,157 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 55.61 sec
2018-01-03 16:41:47,216 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 58.58 sec
2018-01-03 16:41:48,248 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 61.4 sec
2018-01-03 16:41:49,280 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 65.0 sec
2018-01-03 16:41:51,344 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 67.83 sec
2018-01-03 16:41:54,432 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 70.52 sec
2018-01-03 16:41:57,518 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 73.55 sec
2018-01-03 16:41:59,584 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 74.52 sec
2018-01-03 16:42:00,613 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 76.9 sec
2018-01-03 16:42:02,671 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 79.89 sec
2018-01-03 16:42:03,701 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 83.53 sec
2018-01-03 16:42:04,730 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 88.21 sec
MapReduce Total cumulative CPU time: 1 minutes 28 seconds 210 msec
Ended Job = job_1513599404024_169227
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169236, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169236/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169236
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:42:19,740 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:42:26,954 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.14 sec
2018-01-03 16:42:33,139 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.2 sec
2018-01-03 16:42:48,597 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.15 sec
MapReduce Total cumulative CPU time: 15 seconds 150 msec
Ended Job = job_1513599404024_169236
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169240, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169240/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169240
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:42:55,280 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:43:00,451 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.38 sec
2018-01-03 16:43:12,831 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.88 sec
MapReduce Total cumulative CPU time: 7 seconds 880 msec
Ended Job = job_1513599404024_169240
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 88.21 sec   HDFS Read: 220712518 HDFS Write: 225226 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.15 sec   HDFS Read: 41688531 HDFS Write: 16850 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.88 sec   HDFS Read: 24526 HDFS Write: 2083 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 51 seconds 240 msec
OK
Time taken: 125.933 seconds, Fetched: 289 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.38 seconds
Query ID = boss_20180103164321_017d6477-6f93-4b90-a13c-67eb4689e21e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169244, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169244/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169244
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:43:47,004 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:43:57,390 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 10.78 sec
2018-01-03 16:44:00,497 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 14.39 sec
2018-01-03 16:44:01,530 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.81 sec
2018-01-03 16:44:15,982 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.92 sec
MapReduce Total cumulative CPU time: 20 seconds 920 msec
Ended Job = job_1513599404024_169244
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169252, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169252/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169252
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:44:21,732 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:44:26,892 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.61 sec
2018-01-03 16:44:27,923 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.85 sec
2018-01-03 16:44:33,073 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.96 sec
MapReduce Total cumulative CPU time: 18 seconds 960 msec
Ended Job = job_1513599404024_169252
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169254, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169254/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169254
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:44:45,857 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:44:51,045 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.84 sec
2018-01-03 16:44:57,223 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.88 sec
MapReduce Total cumulative CPU time: 5 seconds 880 msec
Ended Job = job_1513599404024_169254
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.92 sec   HDFS Read: 10752833 HDFS Write: 432089 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.96 sec   HDFS Read: 41895076 HDFS Write: 133658 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.88 sec   HDFS Read: 141295 HDFS Write: 4901 SUCCESS
Total MapReduce CPU Time Spent: 45 seconds 760 msec
OK
Time taken: 96.652 seconds, Fetched: 592 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.366 seconds
Query ID = boss_20180103164505_b23b7ddf-7c35-445d-9c67-7d234ef6e5e3
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169260, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169260/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169260
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:45:15,715 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:45:26,072 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 13.26 sec
2018-01-03 16:45:28,139 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 17.27 sec
2018-01-03 16:45:33,307 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.4 sec
MapReduce Total cumulative CPU time: 21 seconds 400 msec
Ended Job = job_1513599404024_169260
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169264, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169264/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169264
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:45:42,043 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:45:48,249 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.68 sec
2018-01-03 16:45:55,470 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.38 sec
2018-01-03 16:46:02,685 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.68 sec
MapReduce Total cumulative CPU time: 16 seconds 680 msec
Ended Job = job_1513599404024_169264
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169271, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169271/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169271
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:46:16,348 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:46:21,504 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.13 sec
2018-01-03 16:46:27,681 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.78 sec
MapReduce Total cumulative CPU time: 6 seconds 780 msec
Ended Job = job_1513599404024_169271
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.4 sec   HDFS Read: 10752823 HDFS Write: 607220 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.68 sec   HDFS Read: 42070207 HDFS Write: 113873 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.78 sec   HDFS Read: 121511 HDFS Write: 4011 SUCCESS
Total MapReduce CPU Time Spent: 44 seconds 860 msec
OK
Time taken: 84.762 seconds, Fetched: 691 row(s)
开始执行20171206日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.414 seconds
Query ID = boss_20180103164658_1b5ccbf0-1aae-4f1b-bb04-18682bd51faf
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169277, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169277/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169277
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:47:10,466 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:47:20,841 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 25.02 sec
2018-01-03 16:47:24,038 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 29.89 sec
2018-01-03 16:47:27,134 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 33.01 sec
2018-01-03 16:47:30,226 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 36.52 sec
2018-01-03 16:47:32,295 Stage-1 map = 67%,  reduce = 8%, Cumulative CPU 37.16 sec
2018-01-03 16:47:33,332 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 41.39 sec
2018-01-03 16:47:36,427 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 45.07 sec
2018-01-03 16:47:39,517 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 48.95 sec
2018-01-03 16:47:41,578 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 53.76 sec
2018-01-03 16:47:43,642 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 56.74 sec
2018-01-03 16:47:44,671 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 56.77 sec
2018-01-03 16:47:45,700 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 65.04 sec
MapReduce Total cumulative CPU time: 1 minutes 5 seconds 40 msec
Ended Job = job_1513599404024_169277
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169282, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169282/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169282
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:47:51,387 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:48:01,702 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 7.26 sec
2018-01-03 16:48:14,055 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 7.93 sec
2018-01-03 16:48:17,139 Stage-2 map = 100%,  reduce = 33%, Cumulative CPU 13.48 sec
2018-01-03 16:48:19,200 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.42 sec
MapReduce Total cumulative CPU time: 19 seconds 420 msec
Ended Job = job_1513599404024_169282
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169286, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169286/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169286
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:48:26,891 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:48:34,137 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.04 sec
2018-01-03 16:48:44,425 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 12.12 sec
MapReduce Total cumulative CPU time: 12 seconds 120 msec
Ended Job = job_1513599404024_169286
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 65.04 sec   HDFS Read: 167170348 HDFS Write: 1428207 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.42 sec   HDFS Read: 43102022 HDFS Write: 141520 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 12.12 sec   HDFS Read: 149195 HDFS Write: 2743 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 36 seconds 580 msec
OK
Time taken: 106.647 seconds, Fetched: 356 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.392 seconds
Query ID = boss_20180103164852_dae0c68a-33b8-4c8a-bb92-eafb603e7db5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169289, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169289/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169289
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:49:10,222 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:49:20,605 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 14.29 sec
2018-01-03 16:49:21,642 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 26.54 sec
2018-01-03 16:49:23,716 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 30.32 sec
2018-01-03 16:49:24,750 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 34.1 sec
2018-01-03 16:49:26,816 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 37.62 sec
2018-01-03 16:49:27,850 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 42.08 sec
2018-01-03 16:49:29,916 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 45.56 sec
2018-01-03 16:49:30,949 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 49.77 sec
2018-01-03 16:49:33,018 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 52.9 sec
2018-01-03 16:49:34,050 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 56.73 sec
2018-01-03 16:49:36,112 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 64.66 sec
2018-01-03 16:49:39,206 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 68.76 sec
2018-01-03 16:49:42,301 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 72.36 sec
2018-01-03 16:49:45,390 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 76.15 sec
2018-01-03 16:49:48,488 Stage-1 map = 80%,  reduce = 8%, Cumulative CPU 79.89 sec
2018-01-03 16:49:51,588 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 83.72 sec
2018-01-03 16:49:53,650 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 93.2 sec
MapReduce Total cumulative CPU time: 1 minutes 33 seconds 200 msec
Ended Job = job_1513599404024_169289
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169292, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169292/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169292
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:50:07,385 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:50:12,544 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.0 sec
2018-01-03 16:50:20,777 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.41 sec
2018-01-03 16:50:22,835 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.17 sec
MapReduce Total cumulative CPU time: 15 seconds 170 msec
Ended Job = job_1513599404024_169292
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169294, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169294/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169294
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:50:44,590 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:50:48,710 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.32 sec
2018-01-03 16:51:02,083 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.5 sec
MapReduce Total cumulative CPU time: 4 seconds 500 msec
Ended Job = job_1513599404024_169294
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 93.2 sec   HDFS Read: 219344653 HDFS Write: 228763 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.17 sec   HDFS Read: 41902578 HDFS Write: 17617 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.5 sec   HDFS Read: 25293 HDFS Write: 1884 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 52 seconds 870 msec
OK
Time taken: 130.915 seconds, Fetched: 270 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103165109_903c7b53-4e62-410a-abd6-2a20edb3e344
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169299, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169299/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169299
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:51:19,438 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:51:28,761 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 13.71 sec
2018-01-03 16:51:30,826 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.43 sec
2018-01-03 16:51:40,104 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.82 sec
MapReduce Total cumulative CPU time: 21 seconds 820 msec
Ended Job = job_1513599404024_169299
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169302, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169302/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169302
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:51:54,889 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:52:03,169 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.17 sec
2018-01-03 16:52:08,338 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.53 sec
2018-01-03 16:52:10,402 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.66 sec
MapReduce Total cumulative CPU time: 15 seconds 660 msec
Ended Job = job_1513599404024_169302
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169304, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169304/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169304
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:52:18,184 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:52:26,531 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.49 sec
2018-01-03 16:52:41,112 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.41 sec
MapReduce Total cumulative CPU time: 6 seconds 410 msec
Ended Job = job_1513599404024_169304
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.82 sec   HDFS Read: 10037461 HDFS Write: 434969 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.66 sec   HDFS Read: 42108466 HDFS Write: 130632 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.41 sec   HDFS Read: 138269 HDFS Write: 4908 SUCCESS
Total MapReduce CPU Time Spent: 43 seconds 890 msec
OK
Time taken: 92.385 seconds, Fetched: 618 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103165249_b3151ee8-5c21-4d38-8e7e-d9a801cdbbe0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169308, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169308/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169308
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:53:02,851 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:53:21,500 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 13.43 sec
2018-01-03 16:53:23,565 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 17.12 sec
2018-01-03 16:53:28,731 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.12 sec
MapReduce Total cumulative CPU time: 21 seconds 120 msec
Ended Job = job_1513599404024_169308
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169314, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169314/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169314
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:54:03,528 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:54:09,725 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.12 sec
2018-01-03 16:54:20,049 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.81 sec
2018-01-03 16:54:27,268 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.81 sec
2018-01-03 16:54:29,325 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.68 sec
MapReduce Total cumulative CPU time: 17 seconds 680 msec
Ended Job = job_1513599404024_169314
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169316, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169316/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169316
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:54:35,077 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:54:41,252 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.82 sec
2018-01-03 16:54:52,561 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.8 sec
MapReduce Total cumulative CPU time: 8 seconds 800 msec
Ended Job = job_1513599404024_169316
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.12 sec   HDFS Read: 10037451 HDFS Write: 591759 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.68 sec   HDFS Read: 42265256 HDFS Write: 126720 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.8 sec   HDFS Read: 134358 HDFS Write: 4503 SUCCESS
Total MapReduce CPU Time Spent: 47 seconds 600 msec
OK
Time taken: 124.585 seconds, Fetched: 825 row(s)
开始执行20171207日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.367 seconds
Query ID = boss_20180103165500_ad57422d-7f35-47a4-ba45-b3e31a7b5f84
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169317, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169317/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169317
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:55:23,630 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:55:34,016 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 11.37 sec
2018-01-03 16:55:37,124 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 14.65 sec
2018-01-03 16:55:40,226 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 29.6 sec
2018-01-03 16:55:43,331 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 36.93 sec
2018-01-03 16:55:46,434 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 39.88 sec
2018-01-03 16:55:49,530 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 43.46 sec
2018-01-03 16:55:51,593 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 47.51 sec
2018-01-03 16:55:53,661 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 51.74 sec
2018-01-03 16:55:58,823 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 57.33 sec
MapReduce Total cumulative CPU time: 57 seconds 330 msec
Ended Job = job_1513599404024_169317
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169325, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169325/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169325
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:56:05,888 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:56:14,175 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.73 sec
2018-01-03 16:56:21,410 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 19.5 sec
MapReduce Total cumulative CPU time: 19 seconds 500 msec
Ended Job = job_1513599404024_169325
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169329, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169329/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169329
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:56:37,077 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:56:42,257 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec
2018-01-03 16:56:48,438 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.6 sec
MapReduce Total cumulative CPU time: 5 seconds 600 msec
Ended Job = job_1513599404024_169329
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 57.33 sec   HDFS Read: 173898641 HDFS Write: 1233700 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 19.5 sec   HDFS Read: 42385025 HDFS Write: 127573 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.6 sec   HDFS Read: 135248 HDFS Write: 2652 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 22 seconds 430 msec
OK
Time taken: 108.994 seconds, Fetched: 352 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.403 seconds
Query ID = boss_20180103165710_f1905402-d3b4-4c05-ac39-b04d4d3ac249
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169333, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169333/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169333
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 16:57:21,237 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:57:30,573 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 12.98 sec
2018-01-03 16:57:31,607 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 26.92 sec
2018-01-03 16:57:33,675 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 30.6 sec
2018-01-03 16:57:34,712 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 34.89 sec
2018-01-03 16:57:36,775 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 38.33 sec
2018-01-03 16:57:37,807 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 41.67 sec
2018-01-03 16:57:39,876 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 45.05 sec
2018-01-03 16:57:40,909 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 48.56 sec
2018-01-03 16:57:41,940 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 51.18 sec
2018-01-03 16:57:44,005 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 54.31 sec
2018-01-03 16:57:47,106 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 57.89 sec
2018-01-03 16:57:50,197 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 61.26 sec
2018-01-03 16:57:52,256 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 65.22 sec
2018-01-03 16:57:53,297 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 66.4 sec
2018-01-03 16:57:54,337 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 74.22 sec
MapReduce Total cumulative CPU time: 1 minutes 14 seconds 220 msec
Ended Job = job_1513599404024_169333
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169340, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169340/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169340
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:58:01,299 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:58:07,489 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.27 sec
2018-01-03 16:58:13,670 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.97 sec
2018-01-03 16:58:15,729 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.57 sec
MapReduce Total cumulative CPU time: 15 seconds 570 msec
Ended Job = job_1513599404024_169340
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169346, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169346/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169346
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:58:30,647 Stage-3 map = 0%,  reduce = 0%
2018-01-03 16:58:35,916 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.33 sec
2018-01-03 16:58:49,293 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 10.2 sec
MapReduce Total cumulative CPU time: 10 seconds 200 msec
Ended Job = job_1513599404024_169346
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 74.22 sec   HDFS Read: 220599289 HDFS Write: 229830 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.57 sec   HDFS Read: 41381155 HDFS Write: 16950 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 10.2 sec   HDFS Read: 24626 HDFS Write: 1950 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 39 seconds 990 msec
OK
Time taken: 100.093 seconds, Fetched: 272 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103165857_eb8d642b-8c64-4dee-9d54-5f0e2844bce5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169350, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169350/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169350
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 16:59:15,596 Stage-1 map = 0%,  reduce = 0%
2018-01-03 16:59:24,990 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 11.38 sec
2018-01-03 16:59:26,027 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.75 sec
2018-01-03 16:59:31,207 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.18 sec
MapReduce Total cumulative CPU time: 18 seconds 180 msec
Ended Job = job_1513599404024_169350
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169352, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169352/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169352
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 16:59:38,995 Stage-2 map = 0%,  reduce = 0%
2018-01-03 16:59:44,165 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.04 sec
2018-01-03 16:59:45,198 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.04 sec
2018-01-03 16:59:50,352 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.01 sec
MapReduce Total cumulative CPU time: 15 seconds 10 msec
Ended Job = job_1513599404024_169352
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169354, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169354/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169354
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 16:59:55,988 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:00:04,229 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.26 sec
2018-01-03 17:00:12,463 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.5 sec
MapReduce Total cumulative CPU time: 7 seconds 500 msec
Ended Job = job_1513599404024_169354
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.18 sec   HDFS Read: 11168917 HDFS Write: 432360 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.01 sec   HDFS Read: 41583367 HDFS Write: 135268 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.5 sec   HDFS Read: 142905 HDFS Write: 4919 SUCCESS
Total MapReduce CPU Time Spent: 40 seconds 690 msec
OK
Time taken: 76.514 seconds, Fetched: 629 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.351 seconds
Query ID = boss_20180103170020_1e86c900-ff4b-486d-87b6-3be47e91de77
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169359, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169359/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169359
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:00:41,034 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:00:51,423 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 12.72 sec
2018-01-03 17:00:52,460 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.56 sec
2018-01-03 17:00:59,699 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.45 sec
MapReduce Total cumulative CPU time: 20 seconds 450 msec
Ended Job = job_1513599404024_169359
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169364, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169364/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169364
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:01:19,424 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:01:23,564 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.29 sec
2018-01-03 17:01:31,845 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.8 sec
2018-01-03 17:01:35,029 Stage-2 map = 100%,  reduce = 68%, Cumulative CPU 13.04 sec
2018-01-03 17:01:36,060 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.95 sec
MapReduce Total cumulative CPU time: 14 seconds 950 msec
Ended Job = job_1513599404024_169364
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169369, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169369/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169369
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:01:49,686 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:01:55,873 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.83 sec
2018-01-03 17:02:10,280 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.14 sec
MapReduce Total cumulative CPU time: 7 seconds 140 msec
Ended Job = job_1513599404024_169369
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.45 sec   HDFS Read: 11168907 HDFS Write: 622900 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.95 sec   HDFS Read: 41773907 HDFS Write: 113694 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.14 sec   HDFS Read: 121332 HDFS Write: 3915 SUCCESS
Total MapReduce CPU Time Spent: 42 seconds 540 msec
OK
Time taken: 111.1 seconds, Fetched: 681 row(s)
开始执行20171208日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103170218_8d560e79-2fcb-4391-bafc-358b8a421146
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169378, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169378/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169378
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 17:02:29,275 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:02:38,628 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 12.3 sec
2018-01-03 17:02:39,660 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 24.08 sec
2018-01-03 17:02:41,726 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 27.86 sec
2018-01-03 17:02:42,762 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 31.26 sec
2018-01-03 17:02:44,829 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 37.08 sec
2018-01-03 17:02:47,940 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 40.4 sec
2018-01-03 17:02:51,036 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 43.55 sec
2018-01-03 17:02:54,169 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 46.49 sec
2018-01-03 17:02:55,205 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 49.54 sec
2018-01-03 17:02:56,236 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 55.01 sec
2018-01-03 17:02:57,269 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 59.8 sec
MapReduce Total cumulative CPU time: 59 seconds 800 msec
Ended Job = job_1513599404024_169378
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169383, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169383/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169383
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:03:04,142 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:03:10,338 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.13 sec
2018-01-03 17:03:21,681 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 12.97 sec
2018-01-03 17:03:23,741 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 20.25 sec
MapReduce Total cumulative CPU time: 20 seconds 250 msec
Ended Job = job_1513599404024_169383
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169386, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169386/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169386
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:03:31,506 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:03:36,674 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.22 sec
2018-01-03 17:03:41,829 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.55 sec
MapReduce Total cumulative CPU time: 5 seconds 550 msec
Ended Job = job_1513599404024_169386
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 59.8 sec   HDFS Read: 195397635 HDFS Write: 903665 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 20.66 sec   HDFS Read: 41723792 HDFS Write: 104190 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.55 sec   HDFS Read: 111865 HDFS Write: 2689 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 26 seconds 10 msec
OK
Time taken: 84.678 seconds, Fetched: 344 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.404 seconds
Query ID = boss_20180103170349_102c92f1-6479-4609-ac2c-ddbc94a90a3c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169394, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169394/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169394
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 17:03:58,881 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:04:09,235 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 24.12 sec
2018-01-03 17:04:12,336 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 31.88 sec
2018-01-03 17:04:15,429 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 39.81 sec
2018-01-03 17:04:18,526 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 46.4 sec
2018-01-03 17:04:21,623 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 52.17 sec
2018-01-03 17:04:24,712 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 58.37 sec
2018-01-03 17:04:26,770 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 61.87 sec
2018-01-03 17:04:27,800 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 64.75 sec
2018-01-03 17:04:30,890 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 67.93 sec
2018-01-03 17:04:33,981 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 70.76 sec
2018-01-03 17:04:37,070 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 73.29 sec
2018-01-03 17:04:38,105 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 75.3 sec
2018-01-03 17:04:39,134 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 77.61 sec
2018-01-03 17:04:40,169 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 82.43 sec
2018-01-03 17:04:41,199 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 87.42 sec
MapReduce Total cumulative CPU time: 1 minutes 27 seconds 420 msec
Ended Job = job_1513599404024_169394
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169402, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169402/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169402
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:04:51,085 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:04:57,335 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.45 sec
2018-01-03 17:05:02,489 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.76 sec
2018-01-03 17:05:03,668 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.08 sec
MapReduce Total cumulative CPU time: 13 seconds 80 msec
Ended Job = job_1513599404024_169402
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169409, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169409/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169409
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:05:18,494 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:05:25,698 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.51 sec
2018-01-03 17:05:32,893 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.75 sec
MapReduce Total cumulative CPU time: 7 seconds 750 msec
Ended Job = job_1513599404024_169409
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 90.15 sec   HDFS Read: 234322566 HDFS Write: 237752 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.08 sec   HDFS Read: 41057879 HDFS Write: 17958 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.75 sec   HDFS Read: 25634 HDFS Write: 1885 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 50 seconds 980 msec
OK
Time taken: 104.338 seconds, Fetched: 275 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.364 seconds
Query ID = boss_20180103170540_267218c4-8e33-4a11-9efb-d6619ceed3bd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169415, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169415/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169415
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:05:50,517 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:06:00,880 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 12.76 sec
2018-01-03 17:06:02,950 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.96 sec
2018-01-03 17:06:08,119 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.03 sec
MapReduce Total cumulative CPU time: 20 seconds 30 msec
Ended Job = job_1513599404024_169415
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169421, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169421/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169421
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:06:14,276 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:06:19,438 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.11 sec
2018-01-03 17:06:25,617 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.0 sec
MapReduce Total cumulative CPU time: 16 seconds 0 msec
Ended Job = job_1513599404024_169421
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169422, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169422/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169422
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:07:02,438 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:07:06,682 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec
2018-01-03 17:07:20,098 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.81 sec
MapReduce Total cumulative CPU time: 5 seconds 810 msec
Ended Job = job_1513599404024_169422
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.03 sec   HDFS Read: 10706148 HDFS Write: 474004 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.0 sec   HDFS Read: 41293813 HDFS Write: 128771 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.81 sec   HDFS Read: 136408 HDFS Write: 5255 SUCCESS
Total MapReduce CPU Time Spent: 41 seconds 840 msec
OK
Time taken: 100.558 seconds, Fetched: 660 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.369 seconds
Query ID = boss_20180103170727_a3c353cb-07b3-4343-bb22-0d621f250c82
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169432, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169432/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169432
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:07:55,074 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:08:05,455 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 13.8 sec
2018-01-03 17:08:07,531 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 18.27 sec
2018-01-03 17:08:13,738 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 23.66 sec
MapReduce Total cumulative CPU time: 23 seconds 660 msec
Ended Job = job_1513599404024_169432
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169435, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169435/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169435
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:08:19,468 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:08:23,605 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.73 sec
2018-01-03 17:08:24,638 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.79 sec
2018-01-03 17:08:29,796 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.59 sec
MapReduce Total cumulative CPU time: 15 seconds 590 msec
Ended Job = job_1513599404024_169435
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169439, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169439/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169439
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:08:52,605 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:08:58,903 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.08 sec
2018-01-03 17:09:11,292 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.68 sec
MapReduce Total cumulative CPU time: 7 seconds 680 msec
Ended Job = job_1513599404024_169439
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 23.66 sec   HDFS Read: 10706138 HDFS Write: 889080 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.59 sec   HDFS Read: 41708889 HDFS Write: 119790 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.68 sec   HDFS Read: 127428 HDFS Write: 3746 SUCCESS
Total MapReduce CPU Time Spent: 46 seconds 930 msec
OK
Time taken: 104.389 seconds, Fetched: 606 row(s)
开始执行20171209日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.376 seconds
Query ID = boss_20180103170919_9c8a8732-51eb-4437-95dc-e045fd60838d
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169442, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169442/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169442
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 17:09:29,527 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:09:39,900 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 13.64 sec
2018-01-03 17:09:43,002 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 17.67 sec
2018-01-03 17:09:46,098 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 21.29 sec
2018-01-03 17:09:48,164 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 33.21 sec
2018-01-03 17:09:49,196 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 36.55 sec
2018-01-03 17:09:50,228 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 38.06 sec
2018-01-03 17:09:51,259 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 41.67 sec
2018-01-03 17:09:53,324 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 44.87 sec
2018-01-03 17:09:56,415 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 48.32 sec
2018-01-03 17:09:59,506 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 51.83 sec
2018-01-03 17:10:01,576 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 53.21 sec
2018-01-03 17:10:02,607 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 56.55 sec
2018-01-03 17:10:05,698 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 59.93 sec
2018-01-03 17:10:07,759 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 62.81 sec
2018-01-03 17:10:08,794 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 67.55 sec
2018-01-03 17:10:09,823 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 73.29 sec
MapReduce Total cumulative CPU time: 1 minutes 13 seconds 290 msec
Ended Job = job_1513599404024_169442
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169446, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169446/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169446
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:10:15,516 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:10:20,676 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.1 sec
2018-01-03 17:10:22,737 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.0 sec
2018-01-03 17:10:28,924 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.5 sec
MapReduce Total cumulative CPU time: 17 seconds 500 msec
Ended Job = job_1513599404024_169446
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169451, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169451/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169451
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:10:35,578 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:10:39,768 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.24 sec
2018-01-03 17:10:46,992 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.45 sec
MapReduce Total cumulative CPU time: 7 seconds 450 msec
Ended Job = job_1513599404024_169451
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 73.29 sec   HDFS Read: 226396158 HDFS Write: 988905 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.5 sec   HDFS Read: 43585361 HDFS Write: 117492 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.45 sec   HDFS Read: 125167 HDFS Write: 2698 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 38 seconds 240 msec
OK
Time taken: 88.507 seconds, Fetched: 364 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.39 seconds
Query ID = boss_20180103171054_2c29543f-8ca1-4bd8-b8ac-9d473f99a4d6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169455, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169455/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169455
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 17:11:03,838 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:11:14,222 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 26.28 sec
2018-01-03 17:11:16,291 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 29.67 sec
2018-01-03 17:11:17,329 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 48.71 sec
2018-01-03 17:11:20,430 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 56.18 sec
2018-01-03 17:11:23,527 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 63.09 sec
2018-01-03 17:11:26,631 Stage-1 map = 58%,  reduce = 7%, Cumulative CPU 71.02 sec
2018-01-03 17:11:27,664 Stage-1 map = 58%,  reduce = 11%, Cumulative CPU 71.68 sec
2018-01-03 17:11:29,728 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 78.03 sec
2018-01-03 17:11:32,824 Stage-1 map = 68%,  reduce = 11%, Cumulative CPU 85.14 sec
2018-01-03 17:11:35,923 Stage-1 map = 74%,  reduce = 11%, Cumulative CPU 92.62 sec
2018-01-03 17:11:36,955 Stage-1 map = 86%,  reduce = 11%, Cumulative CPU 94.51 sec
2018-01-03 17:11:39,017 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 97.92 sec
2018-01-03 17:11:40,049 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 99.87 sec
2018-01-03 17:11:41,080 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 112.67 sec
MapReduce Total cumulative CPU time: 1 minutes 52 seconds 670 msec
Ended Job = job_1513599404024_169455
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169459, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169459/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169459
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:11:55,816 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:12:03,123 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.99 sec
2018-01-03 17:12:04,157 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.15 sec
2018-01-03 17:12:08,283 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.61 sec
MapReduce Total cumulative CPU time: 15 seconds 610 msec
Ended Job = job_1513599404024_169459
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169462, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169462/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169462
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:12:17,004 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:12:22,205 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.74 sec
2018-01-03 17:12:29,429 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.4 sec
MapReduce Total cumulative CPU time: 5 seconds 400 msec
Ended Job = job_1513599404024_169462
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 112.67 sec   HDFS Read: 288988740 HDFS Write: 288248 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.61 sec   HDFS Read: 42884966 HDFS Write: 20673 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.4 sec   HDFS Read: 28349 HDFS Write: 2063 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 13 seconds 680 msec
OK
Time taken: 95.702 seconds, Fetched: 299 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103171237_88e05122-d887-4906-bb02-17dce8604eda
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169465, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169465/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169465
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:12:48,091 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:12:59,503 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 12.54 sec
2018-01-03 17:13:01,580 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.88 sec
2018-01-03 17:13:15,016 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.92 sec
MapReduce Total cumulative CPU time: 18 seconds 920 msec
Ended Job = job_1513599404024_169465
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169469, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169469/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169469
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:13:45,767 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:13:50,947 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.03 sec
2018-01-03 17:13:57,139 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.23 sec
MapReduce Total cumulative CPU time: 15 seconds 230 msec
Ended Job = job_1513599404024_169469
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169472, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169472/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169472
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:14:03,793 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:14:07,936 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.75 sec
2018-01-03 17:14:20,296 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.21 sec
MapReduce Total cumulative CPU time: 6 seconds 210 msec
Ended Job = job_1513599404024_169472
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.92 sec   HDFS Read: 11325388 HDFS Write: 409685 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.23 sec   HDFS Read: 43005823 HDFS Write: 147037 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.21 sec   HDFS Read: 154674 HDFS Write: 5353 SUCCESS
Total MapReduce CPU Time Spent: 40 seconds 360 msec
OK
Time taken: 104.04 seconds, Fetched: 661 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103171428_eb2f7249-2488-43e7-b5d2-992f1a7501ca
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169474, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169474/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169474
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:14:37,805 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:14:48,178 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 14.14 sec
2018-01-03 17:14:50,258 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 18.51 sec
2018-01-03 17:14:59,557 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 23.11 sec
MapReduce Total cumulative CPU time: 23 seconds 110 msec
Ended Job = job_1513599404024_169474
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169476, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169476/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169476
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:15:05,694 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:15:11,905 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.37 sec
2018-01-03 17:15:15,006 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.72 sec
2018-01-03 17:15:18,106 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.41 sec
MapReduce Total cumulative CPU time: 16 seconds 410 msec
Ended Job = job_1513599404024_169476
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169477, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169477/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169477
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:15:35,851 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:15:47,185 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec
2018-01-03 17:15:53,374 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.4 sec
MapReduce Total cumulative CPU time: 6 seconds 400 msec
Ended Job = job_1513599404024_169477
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 23.11 sec   HDFS Read: 11325378 HDFS Write: 773887 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.41 sec   HDFS Read: 43370025 HDFS Write: 132846 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.4 sec   HDFS Read: 140484 HDFS Write: 3850 SUCCESS
Total MapReduce CPU Time Spent: 45 seconds 920 msec
OK
Time taken: 87.383 seconds, Fetched: 627 row(s)
开始执行20171210日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.368 seconds
Query ID = boss_20180103171602_e9b7e945-665a-4aa6-92f0-507e64875907
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169479, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169479/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169479
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 17:16:11,545 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:16:20,871 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 12.56 sec
2018-01-03 17:16:23,969 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 16.44 sec
2018-01-03 17:16:26,036 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 18.8 sec
2018-01-03 17:16:29,129 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 32.75 sec
2018-01-03 17:16:32,221 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 37.18 sec
2018-01-03 17:16:35,327 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 40.33 sec
2018-01-03 17:16:36,364 Stage-1 map = 59%,  reduce = 8%, Cumulative CPU 41.0 sec
2018-01-03 17:16:38,428 Stage-1 map = 62%,  reduce = 17%, Cumulative CPU 44.17 sec
2018-01-03 17:16:41,522 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 47.18 sec
2018-01-03 17:16:44,612 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 50.33 sec
2018-01-03 17:16:47,699 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 53.87 sec
2018-01-03 17:16:50,823 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 57.33 sec
2018-01-03 17:16:53,922 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 60.52 sec
2018-01-03 17:16:57,013 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 64.21 sec
2018-01-03 17:16:59,072 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 67.63 sec
2018-01-03 17:17:01,134 Stage-1 map = 100%,  reduce = 37%, Cumulative CPU 68.8 sec
2018-01-03 17:17:02,167 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 78.0 sec
MapReduce Total cumulative CPU time: 1 minutes 18 seconds 0 msec
Ended Job = job_1513599404024_169479
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169488, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169488/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169488
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:17:07,860 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:17:13,027 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.54 sec
2018-01-03 17:17:16,117 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.83 sec
2018-01-03 17:17:19,207 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.14 sec
MapReduce Total cumulative CPU time: 16 seconds 140 msec
Ended Job = job_1513599404024_169488
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169490, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169490/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169490
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:17:31,195 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:17:36,380 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.54 sec
2018-01-03 17:17:42,609 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.25 sec
MapReduce Total cumulative CPU time: 7 seconds 250 msec
Ended Job = job_1513599404024_169490
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 78.0 sec   HDFS Read: 214246651 HDFS Write: 946762 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.14 sec   HDFS Read: 43077946 HDFS Write: 115094 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.25 sec   HDFS Read: 122769 HDFS Write: 2659 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 41 seconds 390 msec
OK
Time taken: 102.318 seconds, Fetched: 357 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.395 seconds
Query ID = boss_20180103171751_13e50f41-09b8-4c58-9f4e-cbbe344778cd
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169493, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169493/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169493
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 17:18:00,979 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:18:09,286 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 11.97 sec
2018-01-03 17:18:10,320 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 24.18 sec
2018-01-03 17:18:13,417 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 67.3 sec
2018-01-03 17:18:15,484 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 77.84 sec
2018-01-03 17:18:16,517 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 81.11 sec
2018-01-03 17:18:18,578 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 84.19 sec
2018-01-03 17:18:19,617 Stage-1 map = 50%,  reduce = 7%, Cumulative CPU 88.35 sec
2018-01-03 17:18:21,679 Stage-1 map = 51%,  reduce = 7%, Cumulative CPU 91.04 sec
2018-01-03 17:18:22,713 Stage-1 map = 54%,  reduce = 7%, Cumulative CPU 94.26 sec
2018-01-03 17:18:24,773 Stage-1 map = 56%,  reduce = 7%, Cumulative CPU 98.48 sec
2018-01-03 17:18:25,804 Stage-1 map = 59%,  reduce = 7%, Cumulative CPU 101.78 sec
2018-01-03 17:18:27,868 Stage-1 map = 75%,  reduce = 7%, Cumulative CPU 108.42 sec
2018-01-03 17:18:28,901 Stage-1 map = 75%,  reduce = 15%, Cumulative CPU 108.74 sec
2018-01-03 17:18:34,052 Stage-1 map = 77%,  reduce = 15%, Cumulative CPU 149.99 sec
2018-01-03 17:18:37,138 Stage-1 map = 79%,  reduce = 15%, Cumulative CPU 152.97 sec
2018-01-03 17:18:40,239 Stage-1 map = 81%,  reduce = 15%, Cumulative CPU 156.72 sec
2018-01-03 17:18:43,329 Stage-1 map = 84%,  reduce = 15%, Cumulative CPU 160.29 sec
2018-01-03 17:18:46,447 Stage-1 map = 85%,  reduce = 15%, Cumulative CPU 167.16 sec
2018-01-03 17:18:47,477 Stage-1 map = 85%,  reduce = 22%, Cumulative CPU 167.93 sec
2018-01-03 17:18:49,534 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 181.68 sec
2018-01-03 17:18:52,625 Stage-1 map = 88%,  reduce = 22%, Cumulative CPU 184.92 sec
2018-01-03 17:18:53,653 Stage-1 map = 100%,  reduce = 27%, Cumulative CPU 186.71 sec
2018-01-03 17:18:54,680 Stage-1 map = 100%,  reduce = 48%, Cumulative CPU 190.19 sec
2018-01-03 17:18:55,708 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 197.76 sec
MapReduce Total cumulative CPU time: 3 minutes 17 seconds 760 msec
Ended Job = job_1513599404024_169493
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169497, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169497/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169497
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:19:09,873 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:19:15,048 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.84 sec
2018-01-03 17:19:17,119 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.78 sec
2018-01-03 17:19:20,214 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.4 sec
MapReduce Total cumulative CPU time: 14 seconds 400 msec
Ended Job = job_1513599404024_169497
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169500, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169500/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169500
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:19:25,835 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:19:32,016 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.5 sec
2018-01-03 17:19:52,682 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.69 sec
MapReduce Total cumulative CPU time: 6 seconds 690 msec
Ended Job = job_1513599404024_169500
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 197.76 sec   HDFS Read: 279483189 HDFS Write: 275661 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.4 sec   HDFS Read: 42407107 HDFS Write: 21173 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.69 sec   HDFS Read: 28849 HDFS Write: 2258 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 38 seconds 850 msec
OK
Time taken: 123.344 seconds, Fetched: 315 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103172001_af442ded-56f7-4360-b081-bd8bc9e6dbfb
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169503, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169503/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169503
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:20:11,257 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:20:32,941 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 14.71 sec
2018-01-03 17:20:36,033 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 17.63 sec
2018-01-03 17:20:39,120 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 22.84 sec
2018-01-03 17:20:48,386 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 26.6 sec
MapReduce Total cumulative CPU time: 26 seconds 600 msec
Ended Job = job_1513599404024_169503
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169508, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169508/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169508
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:21:01,299 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:21:08,553 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.87 sec
2018-01-03 17:21:15,266 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.92 sec
2018-01-03 17:21:21,438 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.66 sec
MapReduce Total cumulative CPU time: 14 seconds 660 msec
Ended Job = job_1513599404024_169508
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169512, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169512/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169512
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:21:37,509 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:21:46,802 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.14 sec
2018-01-03 17:21:55,035 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.41 sec
MapReduce Total cumulative CPU time: 6 seconds 410 msec
Ended Job = job_1513599404024_169512
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 26.6 sec   HDFS Read: 10985495 HDFS Write: 367195 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.66 sec   HDFS Read: 42498061 HDFS Write: 151263 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.41 sec   HDFS Read: 158900 HDFS Write: 5239 SUCCESS
Total MapReduce CPU Time Spent: 47 seconds 670 msec
OK
Time taken: 114.595 seconds, Fetched: 636 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103172202_6495d148-6e0e-4ab5-9a75-e6e31a5e8be8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169516, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169516/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169516
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:22:14,516 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:22:24,878 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 12.34 sec
2018-01-03 17:22:29,012 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 16.03 sec
2018-01-03 17:22:30,045 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 17.8 sec
2018-01-03 17:22:38,312 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 22.69 sec
MapReduce Total cumulative CPU time: 22 seconds 690 msec
Ended Job = job_1513599404024_169516
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169520, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169520/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169520
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:23:00,210 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:23:08,481 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.78 sec
2018-01-03 17:23:13,639 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.55 sec
2018-01-03 17:23:15,705 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.34 sec
MapReduce Total cumulative CPU time: 17 seconds 340 msec
Ended Job = job_1513599404024_169520
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169526, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169526/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169526
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:23:21,408 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:23:26,573 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.18 sec
2018-01-03 17:23:31,757 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.48 sec
MapReduce Total cumulative CPU time: 5 seconds 480 msec
Ended Job = job_1513599404024_169526
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 22.69 sec   HDFS Read: 10985485 HDFS Write: 733287 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.34 sec   HDFS Read: 42864153 HDFS Write: 135459 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.48 sec   HDFS Read: 143097 HDFS Write: 3492 SUCCESS
Total MapReduce CPU Time Spent: 45 seconds 510 msec
OK
Time taken: 91.089 seconds, Fetched: 481 row(s)
开始执行20171211日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103172340_5f8c103e-bb46-41f1-abea-09c96c755aca
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169530, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169530/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169530
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 17:23:49,722 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:23:57,171 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 9.76 sec
2018-01-03 17:24:06,465 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 22.13 sec
2018-01-03 17:24:07,502 Stage-1 map = 52%,  reduce = 17%, Cumulative CPU 23.15 sec
2018-01-03 17:24:09,563 Stage-1 map = 54%,  reduce = 17%, Cumulative CPU 27.32 sec
2018-01-03 17:24:11,639 Stage-1 map = 56%,  reduce = 17%, Cumulative CPU 30.6 sec
2018-01-03 17:24:14,729 Stage-1 map = 59%,  reduce = 17%, Cumulative CPU 34.87 sec
2018-01-03 17:24:17,818 Stage-1 map = 61%,  reduce = 17%, Cumulative CPU 38.65 sec
2018-01-03 17:24:20,912 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 42.0 sec
2018-01-03 17:24:24,000 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 45.2 sec
2018-01-03 17:24:27,088 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 48.7 sec
2018-01-03 17:24:30,177 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 53.24 sec
2018-01-03 17:24:33,265 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 57.36 sec
2018-01-03 17:24:36,351 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 60.41 sec
2018-01-03 17:24:39,438 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 63.71 sec
2018-01-03 17:24:41,497 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 66.87 sec
2018-01-03 17:24:43,553 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 74.78 sec
MapReduce Total cumulative CPU time: 1 minutes 14 seconds 780 msec
Ended Job = job_1513599404024_169530
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169535, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169535/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169535
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:24:51,663 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:24:58,128 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.71 sec
2018-01-03 17:25:01,232 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 13.36 sec
2018-01-03 17:25:14,624 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.61 sec
MapReduce Total cumulative CPU time: 21 seconds 610 msec
Ended Job = job_1513599404024_169535
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169540, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169540/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169540
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:25:21,427 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:25:28,640 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.39 sec
2018-01-03 17:25:35,837 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.35 sec
MapReduce Total cumulative CPU time: 6 seconds 350 msec
Ended Job = job_1513599404024_169540
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 74.78 sec   HDFS Read: 161092986 HDFS Write: 795773 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 21.61 sec   HDFS Read: 40172498 HDFS Write: 92216 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.35 sec   HDFS Read: 99891 HDFS Write: 2558 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 42 seconds 740 msec
OK
Time taken: 116.096 seconds, Fetched: 349 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.391 seconds
Query ID = boss_20180103172543_e979f684-3e9a-4de0-a8c7-aa054af1637c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169543, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169543/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169543
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 17:25:55,776 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:26:06,155 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 24.88 sec
2018-01-03 17:26:07,192 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 36.63 sec
2018-01-03 17:26:09,268 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 48.43 sec
2018-01-03 17:26:12,369 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 55.55 sec
2018-01-03 17:26:15,468 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 61.58 sec
2018-01-03 17:26:18,566 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 67.78 sec
2018-01-03 17:26:20,634 Stage-1 map = 58%,  reduce = 7%, Cumulative CPU 68.91 sec
2018-01-03 17:26:21,666 Stage-1 map = 64%,  reduce = 7%, Cumulative CPU 75.09 sec
2018-01-03 17:26:24,763 Stage-1 map = 70%,  reduce = 7%, Cumulative CPU 81.1 sec
2018-01-03 17:26:27,860 Stage-1 map = 87%,  reduce = 7%, Cumulative CPU 87.89 sec
2018-01-03 17:26:29,925 Stage-1 map = 100%,  reduce = 15%, Cumulative CPU 90.87 sec
2018-01-03 17:26:30,956 Stage-1 map = 100%,  reduce = 48%, Cumulative CPU 95.5 sec
2018-01-03 17:26:31,986 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 101.54 sec
MapReduce Total cumulative CPU time: 1 minutes 41 seconds 540 msec
Ended Job = job_1513599404024_169543
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169549, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169549/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169549
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:26:37,731 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:26:42,890 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.4 sec
2018-01-03 17:26:44,956 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.03 sec
2018-01-03 17:26:50,105 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.37 sec
MapReduce Total cumulative CPU time: 13 seconds 370 msec
Ended Job = job_1513599404024_169549
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169555, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169555/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169555
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:27:10,795 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:27:14,928 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.31 sec
2018-01-03 17:27:22,140 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.16 sec
MapReduce Total cumulative CPU time: 5 seconds 160 msec
Ended Job = job_1513599404024_169555
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 101.54 sec   HDFS Read: 288877321 HDFS Write: 210121 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.37 sec   HDFS Read: 39587102 HDFS Write: 18445 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.16 sec   HDFS Read: 26117 HDFS Write: 2022 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 0 seconds 70 msec
OK
Time taken: 99.59 seconds, Fetched: 291 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103172737_693efa09-26ef-45ea-9ffd-4993fafbf7ad
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169559, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169559/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169559
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:27:48,407 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:27:58,849 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 13.62 sec
2018-01-03 17:28:01,972 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 19.13 sec
2018-01-03 17:28:07,149 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 23.52 sec
MapReduce Total cumulative CPU time: 23 seconds 520 msec
Ended Job = job_1513599404024_169559
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169563, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169563/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169563
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:28:13,000 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:28:19,217 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.71 sec
2018-01-03 17:28:25,412 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.58 sec
2018-01-03 17:28:28,510 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.11 sec
MapReduce Total cumulative CPU time: 18 seconds 110 msec
Ended Job = job_1513599404024_169563
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169565, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169565/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169565
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:28:43,484 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:28:47,632 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.87 sec
2018-01-03 17:29:02,081 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.03 sec
MapReduce Total cumulative CPU time: 7 seconds 30 msec
Ended Job = job_1513599404024_169565
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 23.52 sec   HDFS Read: 11021541 HDFS Write: 431700 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.11 sec   HDFS Read: 39808103 HDFS Write: 128733 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.03 sec   HDFS Read: 136366 HDFS Write: 5203 SUCCESS
Total MapReduce CPU Time Spent: 48 seconds 660 msec
OK
Time taken: 85.247 seconds, Fetched: 653 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103172910_143a738d-a509-444f-b654-38beddf03728
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169569, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169569/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169569
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:29:27,113 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:29:39,520 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 13.71 sec
2018-01-03 17:29:42,614 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 17.05 sec
2018-01-03 17:29:44,674 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 20.63 sec
2018-01-03 17:30:13,494 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 25.93 sec
MapReduce Total cumulative CPU time: 25 seconds 930 msec
Ended Job = job_1513599404024_169569
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169574, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169574/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169574
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:30:41,289 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:30:47,488 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.43 sec
2018-01-03 17:30:57,808 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.14 sec
2018-01-03 17:31:02,954 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.24 sec
2018-01-03 17:31:04,071 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 14.02 sec
2018-01-03 17:31:05,178 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.94 sec
MapReduce Total cumulative CPU time: 16 seconds 940 msec
Ended Job = job_1513599404024_169574
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169576, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169576/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169576
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:31:13,908 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:31:19,063 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.16 sec
2018-01-03 17:31:25,240 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.86 sec
MapReduce Total cumulative CPU time: 5 seconds 860 msec
Ended Job = job_1513599404024_169576
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 25.93 sec   HDFS Read: 11021532 HDFS Write: 650557 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.94 sec   HDFS Read: 40026964 HDFS Write: 118243 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.86 sec   HDFS Read: 125881 HDFS Write: 3387 SUCCESS
Total MapReduce CPU Time Spent: 48 seconds 730 msec
OK
Time taken: 136.272 seconds, Fetched: 524 row(s)
开始执行20171212日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103173133_b7a28064-806e-493b-8b99-4fa9ce53a098
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169582, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169582/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169582
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 17:31:53,220 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:32:10,274 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 11.36 sec
2018-01-03 17:32:16,609 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 26.39 sec
2018-01-03 17:32:19,724 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 29.04 sec
2018-01-03 17:32:22,826 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 42.28 sec
2018-01-03 17:32:25,925 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 45.4 sec
2018-01-03 17:32:28,242 Stage-1 map = 55%,  reduce = 8%, Cumulative CPU 46.02 sec
2018-01-03 17:32:29,276 Stage-1 map = 56%,  reduce = 8%, Cumulative CPU 58.08 sec
2018-01-03 17:32:32,400 Stage-1 map = 60%,  reduce = 8%, Cumulative CPU 61.76 sec
2018-01-03 17:32:35,501 Stage-1 map = 63%,  reduce = 8%, Cumulative CPU 65.43 sec
2018-01-03 17:32:38,601 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 69.33 sec
2018-01-03 17:32:41,707 Stage-1 map = 68%,  reduce = 17%, Cumulative CPU 72.68 sec
2018-01-03 17:32:43,789 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 73.6 sec
2018-01-03 17:32:46,898 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 75.87 sec
2018-01-03 17:32:50,007 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 85.61 sec
2018-01-03 17:32:53,117 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 87.77 sec
2018-01-03 17:32:57,265 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 93.39 sec
2018-01-03 17:33:00,417 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 95.42 sec
2018-01-03 17:33:02,611 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 98.46 sec
2018-01-03 17:33:05,710 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 104.46 sec
2018-01-03 17:33:08,807 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 107.72 sec
2018-01-03 17:33:10,876 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 110.83 sec
2018-01-03 17:33:11,995 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 112.79 sec
2018-01-03 17:33:16,130 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 115.97 sec
2018-01-03 17:33:26,113 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 123.67 sec
MapReduce Total cumulative CPU time: 2 minutes 3 seconds 670 msec
Ended Job = job_1513599404024_169582
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169593, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169593/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169593
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:33:44,546 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:33:50,756 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.93 sec
2018-01-03 17:33:51,803 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 12.0 sec
2018-01-03 17:33:58,009 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.25 sec
MapReduce Total cumulative CPU time: 21 seconds 250 msec
Ended Job = job_1513599404024_169593
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169594, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169594/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169594
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:34:07,697 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:34:22,267 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.09 sec
2018-01-03 17:34:28,439 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 8.3 sec
MapReduce Total cumulative CPU time: 8 seconds 300 msec
Ended Job = job_1513599404024_169594
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 123.67 sec   HDFS Read: 161659627 HDFS Write: 797496 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 21.25 sec   HDFS Read: 40775186 HDFS Write: 96812 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 8.3 sec   HDFS Read: 104487 HDFS Write: 2585 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 33 seconds 220 msec
OK
Time taken: 176.443 seconds, Fetched: 339 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.391 seconds
Query ID = boss_20180103173436_12b427f6-aacb-4053-aa6e-7aa433c2adfb
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169598, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169598/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169598
Hadoop job information for Stage-1: number of mappers: 4; number of reducers: 3
2018-01-03 17:34:48,495 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:34:54,761 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 8.83 sec
2018-01-03 17:34:57,859 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 22.59 sec
2018-01-03 17:34:58,895 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 36.37 sec
2018-01-03 17:35:00,965 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 44.17 sec
2018-01-03 17:35:03,029 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 47.19 sec
2018-01-03 17:35:04,061 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 50.57 sec
2018-01-03 17:35:05,097 Stage-1 map = 58%,  reduce = 11%, Cumulative CPU 51.86 sec
2018-01-03 17:35:06,129 Stage-1 map = 62%,  reduce = 17%, Cumulative CPU 64.57 sec
2018-01-03 17:35:07,160 Stage-1 map = 65%,  reduce = 17%, Cumulative CPU 67.8 sec
2018-01-03 17:35:09,220 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 71.44 sec
2018-01-03 17:35:10,253 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 74.69 sec
2018-01-03 17:35:12,326 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 77.92 sec
2018-01-03 17:35:13,360 Stage-1 map = 87%,  reduce = 17%, Cumulative CPU 82.29 sec
2018-01-03 17:35:14,391 Stage-1 map = 87%,  reduce = 19%, Cumulative CPU 82.55 sec
2018-01-03 17:35:15,420 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 86.94 sec
2018-01-03 17:35:17,481 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 97.23 sec
MapReduce Total cumulative CPU time: 1 minutes 37 seconds 230 msec
Ended Job = job_1513599404024_169598
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169604, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169604/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169604
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:35:23,518 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:35:29,705 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.73 sec
2018-01-03 17:35:35,885 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.55 sec
2018-01-03 17:35:36,918 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.88 sec
MapReduce Total cumulative CPU time: 13 seconds 880 msec
Ended Job = job_1513599404024_169604
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169612, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169612/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169612
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:35:42,546 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:35:52,837 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.25 sec
2018-01-03 17:36:01,069 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.39 sec
MapReduce Total cumulative CPU time: 6 seconds 390 msec
Ended Job = job_1513599404024_169612
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 4  Reduce: 3   Cumulative CPU: 97.23 sec   HDFS Read: 311361051 HDFS Write: 200356 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.88 sec   HDFS Read: 40178302 HDFS Write: 17049 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.39 sec   HDFS Read: 24721 HDFS Write: 1825 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 57 seconds 500 msec
OK
Time taken: 85.791 seconds, Fetched: 270 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103173608_7c265005-72eb-491a-9131-627bbe447640
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169617, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169617/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169617
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:36:18,538 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:36:29,920 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 11.13 sec
2018-01-03 17:36:33,018 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 15.03 sec
2018-01-03 17:36:34,049 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 17.09 sec
2018-01-03 17:36:39,218 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.5 sec
MapReduce Total cumulative CPU time: 21 seconds 500 msec
Ended Job = job_1513599404024_169617
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169621, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169621/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169621
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:36:45,081 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:36:50,242 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.32 sec
2018-01-03 17:37:00,547 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.73 sec
MapReduce Total cumulative CPU time: 16 seconds 730 msec
Ended Job = job_1513599404024_169621
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169622, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169622/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169622
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:37:15,211 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:37:22,449 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.75 sec
2018-01-03 17:37:27,607 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.49 sec
MapReduce Total cumulative CPU time: 6 seconds 490 msec
Ended Job = job_1513599404024_169622
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.5 sec   HDFS Read: 12292888 HDFS Write: 502170 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.73 sec   HDFS Read: 40479542 HDFS Write: 137043 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.49 sec   HDFS Read: 144680 HDFS Write: 5181 SUCCESS
Total MapReduce CPU Time Spent: 44 seconds 720 msec
OK
Time taken: 79.807 seconds, Fetched: 647 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103173735_cd67ceb8-1e4a-48c8-83e5-ee6e015c9085
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169628, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169628/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169628
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:37:44,956 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:37:56,387 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 10.79 sec
2018-01-03 17:37:58,455 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 10.79 sec
2018-01-03 17:37:59,487 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.72 sec
2018-01-03 17:38:04,647 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.96 sec
MapReduce Total cumulative CPU time: 18 seconds 960 msec
Ended Job = job_1513599404024_169628
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169629, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169629/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169629
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:38:10,472 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:38:16,676 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.27 sec
2018-01-03 17:38:23,892 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.26 sec
MapReduce Total cumulative CPU time: 16 seconds 260 msec
Ended Job = job_1513599404024_169629
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169632, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169632/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169632
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:38:29,564 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:38:34,744 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.07 sec
2018-01-03 17:38:41,975 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.39 sec
MapReduce Total cumulative CPU time: 6 seconds 390 msec
Ended Job = job_1513599404024_169632
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.96 sec   HDFS Read: 12292878 HDFS Write: 685253 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.26 sec   HDFS Read: 40662625 HDFS Write: 144618 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.39 sec   HDFS Read: 152256 HDFS Write: 3568 SUCCESS
Total MapReduce CPU Time Spent: 41 seconds 610 msec
OK
Time taken: 67.651 seconds, Fetched: 549 row(s)
开始执行20171213日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.372 seconds
Query ID = boss_20180103173850_6a920e90-186a-4d50-93b6-147a30038ad6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169636, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169636/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169636
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 17:39:00,440 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:39:09,805 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 14.53 sec
2018-01-03 17:39:11,885 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 27.77 sec
2018-01-03 17:39:12,930 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 31.83 sec
2018-01-03 17:39:16,061 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 34.92 sec
2018-01-03 17:39:19,164 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 38.2 sec
2018-01-03 17:39:22,264 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 40.99 sec
2018-01-03 17:39:24,340 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 42.23 sec
2018-01-03 17:39:25,376 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 45.19 sec
2018-01-03 17:39:28,477 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 48.5 sec
2018-01-03 17:39:31,576 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 51.81 sec
2018-01-03 17:39:33,641 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 54.46 sec
2018-01-03 17:39:35,702 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 57.72 sec
2018-01-03 17:39:36,744 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 62.59 sec
MapReduce Total cumulative CPU time: 1 minutes 2 seconds 590 msec
Ended Job = job_1513599404024_169636
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169639, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169639/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169639
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:39:43,502 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:39:48,705 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.39 sec
2018-01-03 17:39:55,920 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.48 sec
2018-01-03 17:40:03,130 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.47 sec
MapReduce Total cumulative CPU time: 17 seconds 470 msec
Ended Job = job_1513599404024_169639
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169647, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169647/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169647
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:40:31,235 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:40:55,488 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 5.93 sec
2018-01-03 17:41:24,053 Stage-3 map = 100%,  reduce = 67%, Cumulative CPU 12.54 sec
2018-01-03 17:41:29,243 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 16.96 sec
MapReduce Total cumulative CPU time: 16 seconds 960 msec
Ended Job = job_1513599404024_169647
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 62.59 sec   HDFS Read: 167948581 HDFS Write: 823538 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.47 sec   HDFS Read: 40742934 HDFS Write: 97413 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 16.96 sec   HDFS Read: 105076 HDFS Write: 2496 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 37 seconds 20 msec
OK
Time taken: 161.365 seconds, Fetched: 341 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.392 seconds
Query ID = boss_20180103174138_f7a34ec7-8e10-45ff-be01-02493e0d985a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169655, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169655/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169655
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 3
2018-01-03 17:41:59,388 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:42:09,909 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 9.82 sec
2018-01-03 17:42:18,170 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.08 sec
2018-01-03 17:42:19,351 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 13.78 sec
2018-01-03 17:42:22,589 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 15.01 sec
2018-01-03 17:42:27,160 Stage-1 map = 7%,  reduce = 0%, Cumulative CPU 16.42 sec
2018-01-03 17:42:31,793 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 19.26 sec
2018-01-03 17:42:34,958 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 22.51 sec
2018-01-03 17:42:39,147 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 32.73 sec
2018-01-03 17:42:41,303 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 38.9 sec
2018-01-03 17:42:47,551 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 44.75 sec
2018-01-03 17:42:50,815 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 49.07 sec
2018-01-03 17:42:53,954 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 54.63 sec
2018-01-03 17:42:57,050 Stage-1 map = 31%,  reduce = 0%, Cumulative CPU 60.12 sec
2018-01-03 17:43:00,163 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 64.62 sec
2018-01-03 17:43:01,195 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 66.52 sec
2018-01-03 17:43:05,377 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 69.49 sec
2018-01-03 17:43:08,476 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 71.94 sec
2018-01-03 17:43:12,612 Stage-1 map = 55%,  reduce = 11%, Cumulative CPU 73.4 sec
2018-01-03 17:43:13,641 Stage-1 map = 56%,  reduce = 11%, Cumulative CPU 90.59 sec
2018-01-03 17:43:16,733 Stage-1 map = 57%,  reduce = 11%, Cumulative CPU 92.75 sec
2018-01-03 17:43:19,816 Stage-1 map = 61%,  reduce = 11%, Cumulative CPU 95.8 sec
2018-01-03 17:43:33,174 Stage-1 map = 64%,  reduce = 11%, Cumulative CPU 120.49 sec
2018-01-03 17:43:36,257 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 121.35 sec
2018-01-03 17:43:39,335 Stage-1 map = 70%,  reduce = 11%, Cumulative CPU 124.61 sec
2018-01-03 17:43:40,363 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 125.77 sec
2018-01-03 17:43:42,418 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 128.12 sec
2018-01-03 17:43:45,496 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 128.82 sec
2018-01-03 17:43:48,573 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 132.22 sec
2018-01-03 17:43:51,654 Stage-1 map = 100%,  reduce = 33%, Cumulative CPU 134.42 sec
2018-01-03 17:43:52,681 Stage-1 map = 100%,  reduce = 61%, Cumulative CPU 138.1 sec
2018-01-03 17:43:53,707 Stage-1 map = 100%,  reduce = 80%, Cumulative CPU 141.53 sec
2018-01-03 17:43:54,733 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 146.57 sec
MapReduce Total cumulative CPU time: 2 minutes 26 seconds 570 msec
Ended Job = job_1513599404024_169655
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169663, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169663/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169663
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:44:20,511 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:44:26,709 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.2 sec
2018-01-03 17:44:38,027 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 5.58 sec
2018-01-03 17:44:39,060 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 14.1 sec
2018-01-03 17:44:41,113 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 17.05 sec
2018-01-03 17:44:43,166 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 21.01 sec
MapReduce Total cumulative CPU time: 21 seconds 10 msec
Ended Job = job_1513599404024_169663
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169665, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169665/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169665
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:44:50,896 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:44:56,045 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.74 sec
2018-01-03 17:45:02,244 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.74 sec
MapReduce Total cumulative CPU time: 5 seconds 740 msec
Ended Job = job_1513599404024_169665
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 3   Cumulative CPU: 146.57 sec   HDFS Read: 248830700 HDFS Write: 211980 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 21.01 sec   HDFS Read: 40131653 HDFS Write: 20894 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.74 sec   HDFS Read: 28570 HDFS Write: 1965 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 53 seconds 320 msec
OK
Time taken: 206.285 seconds, Fetched: 292 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.356 seconds
Query ID = boss_20180103174511_887c480b-38c8-469f-a548-ebda407eb791
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169667, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169667/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169667
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:45:28,593 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:45:38,936 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 9.68 sec
2018-01-03 17:45:41,002 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 11.89 sec
2018-01-03 17:45:49,253 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.55 sec
MapReduce Total cumulative CPU time: 17 seconds 550 msec
Ended Job = job_1513599404024_169667
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169670, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169670/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169670
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:45:56,280 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:46:01,457 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.09 sec
2018-01-03 17:46:02,489 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.33 sec
2018-01-03 17:46:07,666 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.22 sec
MapReduce Total cumulative CPU time: 14 seconds 220 msec
Ended Job = job_1513599404024_169670
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169673, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169673/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169673
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:46:28,399 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:46:32,544 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.75 sec
2018-01-03 17:46:38,736 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.33 sec
MapReduce Total cumulative CPU time: 5 seconds 330 msec
Ended Job = job_1513599404024_169673
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.55 sec   HDFS Read: 9590898 HDFS Write: 374148 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.22 sec   HDFS Read: 40293241 HDFS Write: 139676 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.33 sec   HDFS Read: 147313 HDFS Write: 4862 SUCCESS
Total MapReduce CPU Time Spent: 37 seconds 100 msec
OK
Time taken: 88.757 seconds, Fetched: 589 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103174646_d5d8037d-1fe1-4251-af82-3608b48df059
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169676, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169676/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169676
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:47:00,978 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:47:12,373 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 11.17 sec
2018-01-03 17:47:15,473 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 15.08 sec
2018-01-03 17:47:18,566 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 17.67 sec
2018-01-03 17:47:19,597 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 19.6 sec
2018-01-03 17:47:51,513 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 33.39 sec
2018-01-03 17:47:56,655 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 49.83 sec
MapReduce Total cumulative CPU time: 49 seconds 830 msec
Ended Job = job_1513599404024_169676
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169679, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169679/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169679
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:48:03,347 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:48:09,538 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.02 sec
2018-01-03 17:48:16,745 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.27 sec
2018-01-03 17:48:23,945 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.97 sec
MapReduce Total cumulative CPU time: 15 seconds 970 msec
Ended Job = job_1513599404024_169679
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169681, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169681/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169681
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:48:43,597 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:48:55,012 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.31 sec
2018-01-03 17:49:01,196 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.64 sec
MapReduce Total cumulative CPU time: 6 seconds 640 msec
Ended Job = job_1513599404024_169681
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 49.83 sec   HDFS Read: 9590888 HDFS Write: 630183 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.97 sec   HDFS Read: 40549276 HDFS Write: 189754 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.64 sec   HDFS Read: 197392 HDFS Write: 2750 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 12 seconds 440 msec
OK
Time taken: 135.789 seconds, Fetched: 408 row(s)
开始执行20171214日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103174909_fafc29dc-7eb4-41e5-bccc-9a0618fd4bc7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169685, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169685/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169685
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 17:49:22,577 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:49:32,934 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 14.07 sec
2018-01-03 17:49:36,035 Stage-1 map = 10%,  reduce = 0%, Cumulative CPU 18.18 sec
2018-01-03 17:49:39,130 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 21.4 sec
2018-01-03 17:49:42,220 Stage-1 map = 17%,  reduce = 0%, Cumulative CPU 24.97 sec
2018-01-03 17:49:45,314 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 28.46 sec
2018-01-03 17:49:47,376 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 40.01 sec
2018-01-03 17:49:48,406 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 43.35 sec
2018-01-03 17:49:51,496 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 46.82 sec
2018-01-03 17:49:54,588 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 50.31 sec
2018-01-03 17:49:57,678 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 54.35 sec
2018-01-03 17:49:58,710 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 58.14 sec
2018-01-03 17:50:00,770 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 62.5 sec
MapReduce Total cumulative CPU time: 1 minutes 2 seconds 500 msec
Ended Job = job_1513599404024_169685
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169689, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169689/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169689
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:50:06,459 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:50:11,628 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.0 sec
2018-01-03 17:50:17,824 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.67 sec
MapReduce Total cumulative CPU time: 14 seconds 670 msec
Ended Job = job_1513599404024_169689
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169691, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169691/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169691
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:50:34,516 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:50:40,792 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.89 sec
2018-01-03 17:51:02,391 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.29 sec
MapReduce Total cumulative CPU time: 6 seconds 290 msec
Ended Job = job_1513599404024_169691
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 62.5 sec   HDFS Read: 174688067 HDFS Write: 872095 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.67 sec   HDFS Read: 40202673 HDFS Write: 102763 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.29 sec   HDFS Read: 110438 HDFS Write: 2650 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 23 seconds 460 msec
OK
Time taken: 114.267 seconds, Fetched: 349 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.401 seconds
Query ID = boss_20180103175110_3c9ad080-5873-4990-be52-e00546e8283f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169696, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169696/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169696
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 17:51:20,259 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:51:29,584 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 11.58 sec
2018-01-03 17:51:30,618 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 35.66 sec
2018-01-03 17:51:32,684 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 40.08 sec
2018-01-03 17:51:33,720 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 47.46 sec
2018-01-03 17:51:36,815 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 54.56 sec
2018-01-03 17:51:39,907 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 60.84 sec
2018-01-03 17:51:43,001 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 67.03 sec
2018-01-03 17:51:45,066 Stage-1 map = 61%,  reduce = 7%, Cumulative CPU 68.2 sec
2018-01-03 17:51:46,097 Stage-1 map = 68%,  reduce = 7%, Cumulative CPU 74.2 sec
2018-01-03 17:51:49,190 Stage-1 map = 72%,  reduce = 11%, Cumulative CPU 81.0 sec
2018-01-03 17:51:50,221 Stage-1 map = 85%,  reduce = 11%, Cumulative CPU 83.21 sec
2018-01-03 17:51:52,290 Stage-1 map = 100%,  reduce = 15%, Cumulative CPU 87.22 sec
2018-01-03 17:51:53,320 Stage-1 map = 100%,  reduce = 95%, Cumulative CPU 95.21 sec
2018-01-03 17:51:54,350 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 96.28 sec
MapReduce Total cumulative CPU time: 1 minutes 36 seconds 280 msec
Ended Job = job_1513599404024_169696
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169700, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169700/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169700
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:52:01,424 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:52:06,589 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.07 sec
2018-01-03 17:52:12,771 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.58 sec
MapReduce Total cumulative CPU time: 13 seconds 580 msec
Ended Job = job_1513599404024_169700
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169701, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169701/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169701
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:52:18,382 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:52:22,570 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.63 sec
2018-01-03 17:52:28,741 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.61 sec
MapReduce Total cumulative CPU time: 4 seconds 610 msec
Ended Job = job_1513599404024_169701
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 96.28 sec   HDFS Read: 303097888 HDFS Write: 236863 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.58 sec   HDFS Read: 39567703 HDFS Write: 19263 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.61 sec   HDFS Read: 26939 HDFS Write: 1975 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 54 seconds 470 msec
OK
Time taken: 79.566 seconds, Fetched: 286 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103175244_fa909e2a-42e8-46bf-880f-e19e85e831e5
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169705, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169705/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169705
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:52:55,005 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:53:12,578 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 11.14 sec
2018-01-03 17:53:27,066 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.02 sec
MapReduce Total cumulative CPU time: 16 seconds 20 msec
Ended Job = job_1513599404024_169705
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169709, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169709/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169709
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:53:32,756 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:53:37,959 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.93 sec
2018-01-03 17:53:38,991 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.86 sec
2018-01-03 17:53:44,137 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.36 sec
MapReduce Total cumulative CPU time: 14 seconds 360 msec
Ended Job = job_1513599404024_169709
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169710, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169710/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169710
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:53:48,756 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:54:02,125 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.8 sec
2018-01-03 17:54:07,273 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.05 sec
MapReduce Total cumulative CPU time: 5 seconds 50 msec
Ended Job = job_1513599404024_169710
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.02 sec   HDFS Read: 9521242 HDFS Write: 356549 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.36 sec   HDFS Read: 39686809 HDFS Write: 138578 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.05 sec   HDFS Read: 146215 HDFS Write: 4802 SUCCESS
Total MapReduce CPU Time Spent: 35 seconds 430 msec
OK
Time taken: 83.831 seconds, Fetched: 544 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103175415_1f2b6f5d-9ca0-4c65-a46d-8853be90046f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169712, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169712/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169712
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:54:24,559 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:54:34,899 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.74 sec
2018-01-03 17:54:42,122 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.64 sec
MapReduce Total cumulative CPU time: 21 seconds 640 msec
Ended Job = job_1513599404024_169712
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169714, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169714/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169714
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:54:48,845 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:54:54,013 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.83 sec
2018-01-03 17:54:55,043 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.74 sec
2018-01-03 17:55:00,194 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.64 sec
MapReduce Total cumulative CPU time: 13 seconds 640 msec
Ended Job = job_1513599404024_169714
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169715, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169715/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169715
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:55:06,857 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:55:12,041 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.88 sec
2018-01-03 17:55:18,217 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.46 sec
MapReduce Total cumulative CPU time: 5 seconds 460 msec
Ended Job = job_1513599404024_169715
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.64 sec   HDFS Read: 9521232 HDFS Write: 567029 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.64 sec   HDFS Read: 39897289 HDFS Write: 178900 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.46 sec   HDFS Read: 186538 HDFS Write: 1920 SUCCESS
Total MapReduce CPU Time Spent: 40 seconds 740 msec
OK
Time taken: 64.196 seconds, Fetched: 247 row(s)
开始执行20171215日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103175526_e0edb886-f3ee-498c-a59f-054c4546f4a8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169717, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169717/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169717
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 17:55:35,066 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:55:44,447 Stage-1 map = 25%,  reduce = 0%, Cumulative CPU 11.9 sec
2018-01-03 17:55:46,511 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 15.16 sec
2018-01-03 17:55:50,642 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 27.35 sec
2018-01-03 17:55:52,703 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 31.51 sec
2018-01-03 17:55:55,791 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 35.03 sec
2018-01-03 17:55:56,829 Stage-1 map = 60%,  reduce = 17%, Cumulative CPU 36.11 sec
2018-01-03 17:55:58,891 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 39.25 sec
2018-01-03 17:56:01,980 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 42.41 sec
2018-01-03 17:56:05,067 Stage-1 map = 70%,  reduce = 17%, Cumulative CPU 45.84 sec
2018-01-03 17:56:08,156 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 48.87 sec
2018-01-03 17:56:11,239 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 51.98 sec
2018-01-03 17:56:14,324 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 47.4 sec
2018-01-03 17:56:15,354 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 49.44 sec
2018-01-03 17:56:17,411 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 56.22 sec
MapReduce Total cumulative CPU time: 56 seconds 220 msec
Ended Job = job_1513599404024_169717
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169721, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169721/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169721
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:56:23,243 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:56:28,411 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.76 sec
2018-01-03 17:56:29,444 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.63 sec
2018-01-03 17:56:34,606 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.19 sec
MapReduce Total cumulative CPU time: 17 seconds 190 msec
Ended Job = job_1513599404024_169721
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169722, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169722/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169722
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:56:42,358 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:56:47,517 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.83 sec
2018-01-03 17:56:52,666 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.02 sec
MapReduce Total cumulative CPU time: 5 seconds 20 msec
Ended Job = job_1513599404024_169722
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 56.22 sec   HDFS Read: 189273954 HDFS Write: 1001277 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.19 sec   HDFS Read: 41051697 HDFS Write: 111112 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.02 sec   HDFS Read: 118787 HDFS Write: 2547 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 18 seconds 430 msec
OK
Time taken: 87.586 seconds, Fetched: 348 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.381 seconds
Query ID = boss_20180103175700_7d0482eb-ebdf-44f1-8d12-3573e678d8b6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169725, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169725/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169725
Hadoop job information for Stage-1: number of mappers: 4; number of reducers: 4
2018-01-03 17:57:09,882 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:57:19,236 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 24.01 sec
2018-01-03 17:57:20,271 Stage-1 map = 27%,  reduce = 0%, Cumulative CPU 52.16 sec
2018-01-03 17:57:22,340 Stage-1 map = 35%,  reduce = 0%, Cumulative CPU 59.92 sec
2018-01-03 17:57:23,377 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 67.93 sec
2018-01-03 17:57:24,410 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 72.77 sec
2018-01-03 17:57:25,444 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 75.67 sec
2018-01-03 17:57:26,490 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 79.3 sec
2018-01-03 17:57:28,554 Stage-1 map = 76%,  reduce = 0%, Cumulative CPU 82.05 sec
2018-01-03 17:57:29,586 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 86.43 sec
2018-01-03 17:57:32,685 Stage-1 map = 90%,  reduce = 0%, Cumulative CPU 89.65 sec
2018-01-03 17:57:33,719 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 92.43 sec
2018-01-03 17:57:34,753 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 100.55 sec
2018-01-03 17:57:35,786 Stage-1 map = 100%,  reduce = 75%, Cumulative CPU 105.22 sec
2018-01-03 17:57:55,400 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 110.53 sec
MapReduce Total cumulative CPU time: 1 minutes 50 seconds 530 msec
Ended Job = job_1513599404024_169725
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169729, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169729/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169729
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:58:02,112 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:58:08,303 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.5 sec
2018-01-03 17:58:14,482 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.81 sec
MapReduce Total cumulative CPU time: 12 seconds 810 msec
Ended Job = job_1513599404024_169729
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169732, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169732/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169732
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 17:58:28,173 Stage-3 map = 0%,  reduce = 0%
2018-01-03 17:58:40,534 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.28 sec
2018-01-03 17:58:53,917 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.26 sec
MapReduce Total cumulative CPU time: 4 seconds 260 msec
Ended Job = job_1513599404024_169732
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 4  Reduce: 4   Cumulative CPU: 110.53 sec   HDFS Read: 368077735 HDFS Write: 267855 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.81 sec   HDFS Read: 40318799 HDFS Write: 21526 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.26 sec   HDFS Read: 29202 HDFS Write: 1912 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 7 seconds 600 msec
OK
Time taken: 114.58 seconds, Fetched: 279 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.378 seconds
Query ID = boss_20180103175909_9b047ec1-2a61-4f54-9679-665b3d2e698a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169736, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169736/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169736
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 17:59:19,584 Stage-1 map = 0%,  reduce = 0%
2018-01-03 17:59:28,938 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 11.63 sec
2018-01-03 17:59:35,151 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 14.94 sec
MapReduce Total cumulative CPU time: 14 seconds 940 msec
Ended Job = job_1513599404024_169736
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169739, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169739/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169739
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 17:59:48,855 Stage-2 map = 0%,  reduce = 0%
2018-01-03 17:59:54,011 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.49 sec
2018-01-03 17:59:55,043 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.45 sec
2018-01-03 18:00:00,197 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.19 sec
MapReduce Total cumulative CPU time: 15 seconds 190 msec
Ended Job = job_1513599404024_169739
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169741, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169741/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169741
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:00:05,803 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:00:09,929 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.78 sec
2018-01-03 18:00:16,107 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.23 sec
MapReduce Total cumulative CPU time: 6 seconds 230 msec
Ended Job = job_1513599404024_169741
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 14.94 sec   HDFS Read: 9960819 HDFS Write: 338893 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.19 sec   HDFS Read: 40388995 HDFS Write: 136829 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.23 sec   HDFS Read: 144466 HDFS Write: 4787 SUCCESS
Total MapReduce CPU Time Spent: 36 seconds 360 msec
OK
Time taken: 67.441 seconds, Fetched: 523 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103180031_2588ebac-eeea-4299-a2e5-ec9daaf6c36b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169744, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169744/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169744
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:00:42,575 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:00:52,935 Stage-1 map = 44%,  reduce = 0%, Cumulative CPU 10.54 sec
2018-01-03 18:00:55,006 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.05 sec
2018-01-03 18:01:01,198 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.05 sec
MapReduce Total cumulative CPU time: 17 seconds 50 msec
Ended Job = job_1513599404024_169744
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169747, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169747/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169747
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:01:07,086 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:01:12,242 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.75 sec
2018-01-03 18:01:18,417 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.73 sec
MapReduce Total cumulative CPU time: 15 seconds 730 msec
Ended Job = job_1513599404024_169747
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169749, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169749/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169749
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:01:24,026 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:01:28,150 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.73 sec
2018-01-03 18:01:33,300 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.26 sec
MapReduce Total cumulative CPU time: 5 seconds 260 msec
Ended Job = job_1513599404024_169749
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.05 sec   HDFS Read: 9960809 HDFS Write: 557339 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.73 sec   HDFS Read: 40607441 HDFS Write: 174362 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.26 sec   HDFS Read: 182000 HDFS Write: 2730 SUCCESS
Total MapReduce CPU Time Spent: 38 seconds 40 msec
OK
Time taken: 62.492 seconds, Fetched: 395 row(s)
开始执行20171216日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.374 seconds
Query ID = boss_20180103180141_ae3cd0d7-8240-4da5-9846-e50cdc902dcc
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169754, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169754/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169754
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 18:02:05,320 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:02:15,721 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 27.6 sec
2018-01-03 18:02:18,828 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 35.55 sec
2018-01-03 18:02:21,927 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 42.54 sec
2018-01-03 18:02:22,962 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 45.01 sec
2018-01-03 18:02:25,029 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 48.36 sec
2018-01-03 18:02:28,130 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 52.17 sec
2018-01-03 18:02:31,225 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 55.44 sec
2018-01-03 18:02:34,322 Stage-1 map = 76%,  reduce = 8%, Cumulative CPU 59.18 sec
2018-01-03 18:02:37,420 Stage-1 map = 80%,  reduce = 8%, Cumulative CPU 63.05 sec
2018-01-03 18:02:40,512 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 67.73 sec
2018-01-03 18:02:41,544 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 73.01 sec
2018-01-03 18:02:42,574 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 76.75 sec
MapReduce Total cumulative CPU time: 1 minutes 16 seconds 750 msec
Ended Job = job_1513599404024_169754
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169765, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169765/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169765
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:03:04,582 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:03:10,791 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.69 sec
2018-01-03 18:03:21,112 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 6.24 sec
2018-01-03 18:03:26,266 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 11.79 sec
2018-01-03 18:03:30,392 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.77 sec
MapReduce Total cumulative CPU time: 18 seconds 770 msec
Ended Job = job_1513599404024_169765
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169777, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169777/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169777
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:03:36,063 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:03:41,212 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.35 sec
2018-01-03 18:03:48,419 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.77 sec
MapReduce Total cumulative CPU time: 6 seconds 770 msec
Ended Job = job_1513599404024_169777
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 76.75 sec   HDFS Read: 224463969 HDFS Write: 1127304 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.77 sec   HDFS Read: 42498429 HDFS Write: 133775 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.77 sec   HDFS Read: 141450 HDFS Write: 2783 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 42 seconds 290 msec
OK
Time taken: 128.188 seconds, Fetched: 355 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.407 seconds
Query ID = boss_20180103180356_06c1296c-b46f-4dae-8e8e-0985f3fceeea
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 5
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169784, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169784/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169784
Hadoop job information for Stage-1: number of mappers: 5; number of reducers: 5
2018-01-03 18:04:05,059 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:04:15,411 Stage-1 map = 8%,  reduce = 0%, Cumulative CPU 12.21 sec
2018-01-03 18:04:17,474 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 16.66 sec
2018-01-03 18:04:18,509 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 17.98 sec
2018-01-03 18:04:20,574 Stage-1 map = 22%,  reduce = 0%, Cumulative CPU 29.48 sec
2018-01-03 18:04:22,636 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 54.28 sec
2018-01-03 18:04:23,668 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 71.23 sec
2018-01-03 18:04:25,730 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 83.03 sec
2018-01-03 18:04:26,761 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 86.1 sec
2018-01-03 18:04:27,794 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 92.59 sec
2018-01-03 18:04:28,839 Stage-1 map = 72%,  reduce = 4%, Cumulative CPU 97.59 sec
2018-01-03 18:04:29,877 Stage-1 map = 74%,  reduce = 4%, Cumulative CPU 100.59 sec
2018-01-03 18:04:31,939 Stage-1 map = 75%,  reduce = 16%, Cumulative CPU 104.64 sec
2018-01-03 18:04:32,969 Stage-1 map = 77%,  reduce = 16%, Cumulative CPU 107.63 sec
2018-01-03 18:04:35,030 Stage-1 map = 81%,  reduce = 16%, Cumulative CPU 111.22 sec
2018-01-03 18:04:38,119 Stage-1 map = 91%,  reduce = 17%, Cumulative CPU 121.35 sec
2018-01-03 18:04:40,176 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 124.3 sec
2018-01-03 18:04:41,206 Stage-1 map = 100%,  reduce = 45%, Cumulative CPU 125.49 sec
2018-01-03 18:04:42,235 Stage-1 map = 100%,  reduce = 85%, Cumulative CPU 138.32 sec
2018-01-03 18:04:43,263 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 143.24 sec
MapReduce Total cumulative CPU time: 2 minutes 23 seconds 240 msec
Ended Job = job_1513599404024_169784
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169792, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169792/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169792
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:04:50,976 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:04:56,265 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.33 sec
2018-01-03 18:05:09,651 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.13 sec
MapReduce Total cumulative CPU time: 14 seconds 130 msec
Ended Job = job_1513599404024_169792
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169797, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169797/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169797
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:05:31,382 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:05:38,617 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.6 sec
2018-01-03 18:05:44,807 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.13 sec
MapReduce Total cumulative CPU time: 5 seconds 130 msec
Ended Job = job_1513599404024_169797
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 5  Reduce: 5   Cumulative CPU: 143.24 sec   HDFS Read: 441191268 HDFS Write: 316393 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.13 sec   HDFS Read: 41688288 HDFS Write: 21758 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.13 sec   HDFS Read: 29426 HDFS Write: 2033 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 42 seconds 500 msec
OK
Time taken: 109.699 seconds, Fetched: 297 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103180552_3644c833-3313-487e-b038-f01f0c4557bf
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169802, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169802/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169802
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:06:02,004 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:06:12,346 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 12.02 sec
2018-01-03 18:06:13,381 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.48 sec
2018-01-03 18:06:18,545 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 18.58 sec
MapReduce Total cumulative CPU time: 18 seconds 580 msec
Ended Job = job_1513599404024_169802
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169804, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169804/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169804
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:06:25,362 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:06:33,610 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 6.21 sec
2018-01-03 18:06:38,760 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.34 sec
2018-01-03 18:06:40,818 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.14 sec
MapReduce Total cumulative CPU time: 16 seconds 140 msec
Ended Job = job_1513599404024_169804
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169808, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169808/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169808
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:06:46,422 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:06:51,586 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.01 sec
2018-01-03 18:06:57,762 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.92 sec
MapReduce Total cumulative CPU time: 5 seconds 920 msec
Ended Job = job_1513599404024_169808
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 18.58 sec   HDFS Read: 10573497 HDFS Write: 322149 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.14 sec   HDFS Read: 41692956 HDFS Write: 143214 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.92 sec   HDFS Read: 150851 HDFS Write: 4791 SUCCESS
Total MapReduce CPU Time Spent: 40 seconds 640 msec
OK
Time taken: 66.295 seconds, Fetched: 540 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.482 seconds
Query ID = boss_20180103180705_987b4c4d-7491-453a-a4ce-d8489c1e4dc8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169811, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169811/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169811
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:07:16,421 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:07:26,777 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.52 sec
2018-01-03 18:07:31,945 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.13 sec
MapReduce Total cumulative CPU time: 16 seconds 130 msec
Ended Job = job_1513599404024_169811
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169814, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169814/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169814
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:07:37,666 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:07:41,794 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.0 sec
2018-01-03 18:07:42,825 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.19 sec
2018-01-03 18:07:49,005 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.97 sec
MapReduce Total cumulative CPU time: 12 seconds 970 msec
Ended Job = job_1513599404024_169814
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169818, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169818/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169818
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:07:54,635 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:08:07,026 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.73 sec
2018-01-03 18:08:14,252 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.64 sec
MapReduce Total cumulative CPU time: 5 seconds 640 msec
Ended Job = job_1513599404024_169818
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.13 sec   HDFS Read: 10573487 HDFS Write: 553213 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.97 sec   HDFS Read: 41924020 HDFS Write: 140338 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.64 sec   HDFS Read: 147976 HDFS Write: 2682 SUCCESS
Total MapReduce CPU Time Spent: 34 seconds 740 msec
OK
Time taken: 69.656 seconds, Fetched: 326 row(s)
开始执行20171217日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.362 seconds
Query ID = boss_20180103180830_ff6c156c-80e9-4860-8631-adcc87efd88c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169822, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169822/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169822
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 18:08:47,513 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:08:56,835 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 13.61 sec
2018-01-03 18:08:57,869 Stage-1 map = 15%,  reduce = 0%, Cumulative CPU 25.04 sec
2018-01-03 18:08:59,932 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 32.58 sec
2018-01-03 18:09:03,027 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 39.83 sec
2018-01-03 18:09:04,059 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 41.84 sec
2018-01-03 18:09:06,119 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 44.87 sec
2018-01-03 18:09:09,211 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 48.02 sec
2018-01-03 18:09:12,301 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 51.25 sec
2018-01-03 18:09:14,364 Stage-1 map = 69%,  reduce = 8%, Cumulative CPU 51.76 sec
2018-01-03 18:09:15,394 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 55.4 sec
2018-01-03 18:09:18,481 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 58.25 sec
2018-01-03 18:09:21,571 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 61.43 sec
2018-01-03 18:09:24,659 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 64.94 sec
2018-01-03 18:09:26,717 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 67.94 sec
2018-01-03 18:09:27,746 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 67.98 sec
2018-01-03 18:09:28,775 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 76.11 sec
MapReduce Total cumulative CPU time: 1 minutes 16 seconds 110 msec
Ended Job = job_1513599404024_169822
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169824, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169824/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169824
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:09:49,587 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:09:54,822 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.75 sec
2018-01-03 18:10:01,012 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 18.87 sec
MapReduce Total cumulative CPU time: 18 seconds 870 msec
Ended Job = job_1513599404024_169824
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169828, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169828/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169828
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:10:10,692 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:10:15,985 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.95 sec
2018-01-03 18:10:29,359 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.33 sec
MapReduce Total cumulative CPU time: 6 seconds 330 msec
Ended Job = job_1513599404024_169828
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 76.11 sec   HDFS Read: 209697749 HDFS Write: 1049386 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 18.87 sec   HDFS Read: 40922770 HDFS Write: 117936 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.33 sec   HDFS Read: 125611 HDFS Write: 2539 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 41 seconds 310 msec
OK
Time taken: 119.832 seconds, Fetched: 340 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.388 seconds
Query ID = boss_20180103181037_00e70b2a-f293-47fa-9aef-387971072b3c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169832, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169832/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169832
Hadoop job information for Stage-1: number of mappers: 4; number of reducers: 4
2018-01-03 18:10:46,002 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:10:55,325 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 37.58 sec
2018-01-03 18:10:56,357 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 48.88 sec
2018-01-03 18:10:58,421 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 60.33 sec
2018-01-03 18:10:59,455 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 64.13 sec
2018-01-03 18:11:00,486 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 67.48 sec
2018-01-03 18:11:01,517 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 74.02 sec
2018-01-03 18:11:04,608 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 86.57 sec
2018-01-03 18:11:05,638 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 88.66 sec
2018-01-03 18:11:07,697 Stage-1 map = 80%,  reduce = 0%, Cumulative CPU 93.69 sec
2018-01-03 18:11:08,730 Stage-1 map = 90%,  reduce = 0%, Cumulative CPU 95.74 sec
2018-01-03 18:11:09,759 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 97.96 sec
2018-01-03 18:11:11,822 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 115.26 sec
MapReduce Total cumulative CPU time: 1 minutes 55 seconds 260 msec
Ended Job = job_1513599404024_169832
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169835, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169835/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169835
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:11:20,292 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:11:25,456 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.33 sec
2018-01-03 18:11:36,799 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 4.95 sec
2018-01-03 18:11:40,918 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 9.7 sec
2018-01-03 18:11:42,977 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.69 sec
MapReduce Total cumulative CPU time: 13 seconds 690 msec
Ended Job = job_1513599404024_169835
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169843, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169843/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169843
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:12:01,688 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:12:07,882 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.95 sec
2018-01-03 18:12:15,086 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.64 sec
MapReduce Total cumulative CPU time: 5 seconds 640 msec
Ended Job = job_1513599404024_169843
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 4  Reduce: 4   Cumulative CPU: 115.26 sec   HDFS Read: 404897642 HDFS Write: 297808 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.69 sec   HDFS Read: 40171716 HDFS Write: 22060 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.64 sec   HDFS Read: 29736 HDFS Write: 2059 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 14 seconds 590 msec
OK
Time taken: 99.027 seconds, Fetched: 295 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103181223_6ceb1c95-0ccf-45e4-a304-fc8e85e26489
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169847, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169847/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169847
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:12:33,105 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:12:44,470 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 11.06 sec
2018-01-03 18:12:46,536 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.33 sec
2018-01-03 18:12:53,751 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.67 sec
MapReduce Total cumulative CPU time: 16 seconds 670 msec
Ended Job = job_1513599404024_169847
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169849, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169849/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169849
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:13:00,462 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:13:05,630 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.06 sec
2018-01-03 18:13:12,844 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.4 sec
2018-01-03 18:13:19,019 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.18 sec
MapReduce Total cumulative CPU time: 14 seconds 180 msec
Ended Job = job_1513599404024_169849
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169852, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169852/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169852
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:13:24,654 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:13:28,803 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.67 sec
2018-01-03 18:13:41,182 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.59 sec
MapReduce Total cumulative CPU time: 5 seconds 590 msec
Ended Job = job_1513599404024_169852
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.67 sec   HDFS Read: 10191546 HDFS Write: 293837 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.18 sec   HDFS Read: 40166903 HDFS Write: 130368 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.59 sec   HDFS Read: 138005 HDFS Write: 4479 SUCCESS
Total MapReduce CPU Time Spent: 36 seconds 440 msec
OK
Time taken: 78.884 seconds, Fetched: 520 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.363 seconds
Query ID = boss_20180103181349_097363fb-8350-4ff4-b578-e57c3218e9d0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169856, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169856/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169856
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:14:00,212 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:14:18,807 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.52 sec
2018-01-03 18:14:26,028 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.6 sec
MapReduce Total cumulative CPU time: 17 seconds 600 msec
Ended Job = job_1513599404024_169856
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169860, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169860/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169860
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:14:48,770 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:14:54,039 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.4 sec
2018-01-03 18:15:04,366 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 4.86 sec
2018-01-03 18:15:22,906 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 10.42 sec
2018-01-03 18:15:23,938 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.6 sec
MapReduce Total cumulative CPU time: 15 seconds 600 msec
Ended Job = job_1513599404024_169860
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169864, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169864/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169864
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:15:29,570 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:15:34,796 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.95 sec
2018-01-03 18:15:40,962 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.59 sec
MapReduce Total cumulative CPU time: 5 seconds 590 msec
Ended Job = job_1513599404024_169864
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.6 sec   HDFS Read: 10191536 HDFS Write: 530541 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.6 sec   HDFS Read: 40403607 HDFS Write: 136189 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.59 sec   HDFS Read: 143827 HDFS Write: 2484 SUCCESS
Total MapReduce CPU Time Spent: 38 seconds 790 msec
OK
Time taken: 113.002 seconds, Fetched: 301 row(s)
开始执行20171218日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.37 seconds
Query ID = boss_20180103181548_d242d765-441c-4534-a2af-45b702e1aff4
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169873, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169873/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169873
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 18:15:58,838 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:16:07,138 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 11.95 sec
2018-01-03 18:16:09,208 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 22.08 sec
2018-01-03 18:16:12,310 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 26.27 sec
2018-01-03 18:16:15,408 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 28.6 sec
2018-01-03 18:16:18,565 Stage-1 map = 65%,  reduce = 8%, Cumulative CPU 31.59 sec
2018-01-03 18:16:20,637 Stage-1 map = 69%,  reduce = 8%, Cumulative CPU 34.8 sec
2018-01-03 18:16:22,701 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 35.32 sec
2018-01-03 18:16:23,735 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 37.2 sec
2018-01-03 18:16:26,840 Stage-1 map = 76%,  reduce = 17%, Cumulative CPU 40.37 sec
2018-01-03 18:16:29,933 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 43.54 sec
2018-01-03 18:16:33,023 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 47.27 sec
2018-01-03 18:16:34,052 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 54.32 sec
MapReduce Total cumulative CPU time: 54 seconds 320 msec
Ended Job = job_1513599404024_169873
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169879, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169879/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169879
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:16:47,751 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:16:52,905 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.65 sec
2018-01-03 18:17:01,143 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.13 sec
MapReduce Total cumulative CPU time: 17 seconds 130 msec
Ended Job = job_1513599404024_169879
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169882, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169882/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169882
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:17:14,932 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:17:20,105 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.11 sec
2018-01-03 18:17:28,365 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.11 sec
MapReduce Total cumulative CPU time: 6 seconds 110 msec
Ended Job = job_1513599404024_169882
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 54.32 sec   HDFS Read: 163029744 HDFS Write: 921712 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.13 sec   HDFS Read: 38553234 HDFS Write: 100313 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.11 sec   HDFS Read: 107988 HDFS Write: 2491 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 17 seconds 560 msec
OK
Time taken: 100.55 seconds, Fetched: 336 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.396 seconds
Query ID = boss_20180103181736_dcbe3224-af97-410a-ac5b-d760e29d7930
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169885, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169885/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169885
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 18:17:45,081 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:17:55,481 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 36.93 sec
2018-01-03 18:17:58,579 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 50.07 sec
2018-01-03 18:18:01,671 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 60.38 sec
2018-01-03 18:18:04,761 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 69.69 sec
2018-01-03 18:18:05,790 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 71.81 sec
2018-01-03 18:18:07,853 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 77.73 sec
2018-01-03 18:18:09,911 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 83.68 sec
2018-01-03 18:18:12,997 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 86.67 sec
2018-01-03 18:18:15,056 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 88.82 sec
2018-01-03 18:18:16,089 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 95.89 sec
2018-01-03 18:18:19,180 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 100.42 sec
MapReduce Total cumulative CPU time: 1 minutes 40 seconds 420 msec
Ended Job = job_1513599404024_169885
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169890, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169890/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169890
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:18:40,935 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:18:46,112 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.73 sec
2018-01-03 18:18:54,370 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.02 sec
2018-01-03 18:18:55,401 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.42 sec
MapReduce Total cumulative CPU time: 12 seconds 420 msec
Ended Job = job_1513599404024_169890
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169896, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169896/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169896
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:19:10,187 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:19:15,371 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.83 sec
2018-01-03 18:19:23,623 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.11 sec
MapReduce Total cumulative CPU time: 6 seconds 110 msec
Ended Job = job_1513599404024_169896
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 100.42 sec   HDFS Read: 283141312 HDFS Write: 253682 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.42 sec   HDFS Read: 37885460 HDFS Write: 19954 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.11 sec   HDFS Read: 27626 HDFS Write: 1992 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 58 seconds 950 msec
OK
Time taken: 108.507 seconds, Fetched: 286 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.358 seconds
Query ID = boss_20180103181931_d21c652a-4ab5-49f1-9d66-39263d299e5c
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169901, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169901/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169901
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:19:43,958 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:19:54,401 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 13.13 sec
2018-01-03 18:19:55,435 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.09 sec
2018-01-03 18:20:01,731 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 20.32 sec
MapReduce Total cumulative CPU time: 20 seconds 320 msec
Ended Job = job_1513599404024_169901
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169904, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169904/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169904
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:20:09,646 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:20:14,817 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.04 sec
2018-01-03 18:20:20,997 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.76 sec
MapReduce Total cumulative CPU time: 14 seconds 760 msec
Ended Job = job_1513599404024_169904
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169906, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169906/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169906
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:20:27,661 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:20:32,880 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.27 sec
2018-01-03 18:20:41,137 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.53 sec
MapReduce Total cumulative CPU time: 6 seconds 530 msec
Ended Job = job_1513599404024_169906
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 20.32 sec   HDFS Read: 8879760 HDFS Write: 306136 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.76 sec   HDFS Read: 37937340 HDFS Write: 123035 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.53 sec   HDFS Read: 130672 HDFS Write: 4348 SUCCESS
Total MapReduce CPU Time Spent: 41 seconds 610 msec
OK
Time taken: 70.775 seconds, Fetched: 512 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.36 seconds
Query ID = boss_20180103182057_358fdce5-18fc-4a2f-bc2c-72391034aeea
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169916, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169916/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169916
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:21:16,674 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:21:28,135 Stage-1 map = 36%,  reduce = 0%, Cumulative CPU 11.45 sec
2018-01-03 18:21:31,242 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 14.02 sec
2018-01-03 18:21:32,277 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.47 sec
2018-01-03 18:21:40,542 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 22.71 sec
MapReduce Total cumulative CPU time: 22 seconds 710 msec
Ended Job = job_1513599404024_169916
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169920, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169920/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169920
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:21:47,410 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:22:00,793 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.37 sec
2018-01-03 18:22:08,005 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.23 sec
2018-01-03 18:22:16,239 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.83 sec
MapReduce Total cumulative CPU time: 13 seconds 830 msec
Ended Job = job_1513599404024_169920
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169924, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169924/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169924
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:22:30,890 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:22:35,024 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.72 sec
2018-01-03 18:22:40,180 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.33 sec
MapReduce Total cumulative CPU time: 5 seconds 330 msec
Ended Job = job_1513599404024_169924
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 22.71 sec   HDFS Read: 8879750 HDFS Write: 437876 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.83 sec   HDFS Read: 38069080 HDFS Write: 119496 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.33 sec   HDFS Read: 127134 HDFS Write: 2182 SUCCESS
Total MapReduce CPU Time Spent: 41 seconds 870 msec
OK
Time taken: 105.156 seconds, Fetched: 309 row(s)
开始执行20171219日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.493 seconds
Query ID = boss_20180103182249_a6f0f8d7-229f-451d-a56b-12d5ebd46db0
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169929, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169929/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169929
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 18:22:59,625 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:23:07,980 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 11.02 sec
2018-01-03 18:23:10,053 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 22.69 sec
2018-01-03 18:23:13,159 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 27.01 sec
2018-01-03 18:23:15,228 Stage-1 map = 60%,  reduce = 0%, Cumulative CPU 30.31 sec
2018-01-03 18:23:18,332 Stage-1 map = 63%,  reduce = 8%, Cumulative CPU 34.05 sec
2018-01-03 18:23:21,435 Stage-1 map = 66%,  reduce = 17%, Cumulative CPU 37.66 sec
2018-01-03 18:23:24,532 Stage-1 map = 69%,  reduce = 17%, Cumulative CPU 40.93 sec
2018-01-03 18:23:27,626 Stage-1 map = 72%,  reduce = 17%, Cumulative CPU 44.61 sec
2018-01-03 18:23:30,721 Stage-1 map = 75%,  reduce = 17%, Cumulative CPU 47.82 sec
2018-01-03 18:23:33,819 Stage-1 map = 79%,  reduce = 17%, Cumulative CPU 50.83 sec
2018-01-03 18:23:35,881 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 42.0 sec
2018-01-03 18:23:36,911 Stage-1 map = 82%,  reduce = 17%, Cumulative CPU 53.94 sec
2018-01-03 18:23:37,943 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 56.13 sec
2018-01-03 18:23:38,975 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 60.19 sec
2018-01-03 18:23:40,006 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 63.3 sec
MapReduce Total cumulative CPU time: 1 minutes 3 seconds 300 msec
Ended Job = job_1513599404024_169929
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169935, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169935/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169935
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:23:45,676 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:23:50,834 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.63 sec
2018-01-03 18:23:51,864 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.44 sec
2018-01-03 18:23:58,041 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.24 sec
MapReduce Total cumulative CPU time: 16 seconds 240 msec
Ended Job = job_1513599404024_169935
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169937, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169937/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169937
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:24:03,658 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:24:08,817 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.93 sec
2018-01-03 18:24:13,958 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.33 sec
MapReduce Total cumulative CPU time: 5 seconds 330 msec
Ended Job = job_1513599404024_169937
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 63.3 sec   HDFS Read: 161685047 HDFS Write: 869487 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.24 sec   HDFS Read: 38377150 HDFS Write: 101024 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.33 sec   HDFS Read: 108699 HDFS Write: 2674 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 24 seconds 870 msec
OK
Time taken: 85.727 seconds, Fetched: 343 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.406 seconds
Query ID = boss_20180103182421_44da086b-62b5-43b7-988a-54eff9add4c6
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169940, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169940/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169940
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 18:24:32,190 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:24:42,670 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 34.43 sec
2018-01-03 18:24:43,706 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 35.74 sec
2018-01-03 18:24:45,780 Stage-1 map = 42%,  reduce = 0%, Cumulative CPU 42.85 sec
2018-01-03 18:24:48,880 Stage-1 map = 48%,  reduce = 0%, Cumulative CPU 51.15 sec
2018-01-03 18:24:50,945 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 54.5 sec
2018-01-03 18:24:51,978 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 57.82 sec
2018-01-03 18:24:54,046 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 60.88 sec
2018-01-03 18:24:55,085 Stage-1 map = 59%,  reduce = 11%, Cumulative CPU 65.75 sec
2018-01-03 18:24:57,147 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 71.55 sec
2018-01-03 18:25:00,240 Stage-1 map = 70%,  reduce = 11%, Cumulative CPU 77.75 sec
2018-01-03 18:25:03,333 Stage-1 map = 76%,  reduce = 11%, Cumulative CPU 84.2 sec
2018-01-03 18:25:04,369 Stage-1 map = 100%,  reduce = 11%, Cumulative CPU 87.56 sec
2018-01-03 18:25:05,399 Stage-1 map = 100%,  reduce = 41%, Cumulative CPU 90.96 sec
2018-01-03 18:25:06,430 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 96.69 sec
MapReduce Total cumulative CPU time: 1 minutes 36 seconds 690 msec
Ended Job = job_1513599404024_169940
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169944, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169944/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169944
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:25:13,131 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:25:19,323 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.85 sec
2018-01-03 18:25:30,648 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.08 sec
MapReduce Total cumulative CPU time: 14 seconds 80 msec
Ended Job = job_1513599404024_169944
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169947, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169947/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169947
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:25:37,321 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:25:41,464 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.31 sec
2018-01-03 18:25:48,670 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.05 sec
MapReduce Total cumulative CPU time: 5 seconds 50 msec
Ended Job = job_1513599404024_169947
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 96.69 sec   HDFS Read: 268926331 HDFS Write: 243708 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.08 sec   HDFS Read: 37751633 HDFS Write: 17810 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.05 sec   HDFS Read: 25486 HDFS Write: 1874 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 55 seconds 820 msec
OK
Time taken: 87.93 seconds, Fetched: 265 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.344 seconds
Query ID = boss_20180103182556_529f25a4-4799-4483-9878-42a55e0b046b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169949, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169949/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169949
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:26:08,058 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:26:17,390 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 10.03 sec
2018-01-03 18:26:18,423 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 11.07 sec
2018-01-03 18:26:24,637 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.12 sec
MapReduce Total cumulative CPU time: 16 seconds 120 msec
Ended Job = job_1513599404024_169949
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169956, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169956/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169956
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:26:38,324 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:26:44,513 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.92 sec
2018-01-03 18:26:50,692 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.47 sec
2018-01-03 18:26:53,784 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.72 sec
MapReduce Total cumulative CPU time: 14 seconds 720 msec
Ended Job = job_1513599404024_169956
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169958, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169958/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169958
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:27:00,403 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:27:18,992 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.38 sec
2018-01-03 18:27:26,204 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.02 sec
MapReduce Total cumulative CPU time: 6 seconds 20 msec
Ended Job = job_1513599404024_169958
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.12 sec   HDFS Read: 8756774 HDFS Write: 307172 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.72 sec   HDFS Read: 37814517 HDFS Write: 122090 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.02 sec   HDFS Read: 129727 HDFS Write: 4276 SUCCESS
Total MapReduce CPU Time Spent: 36 seconds 860 msec
OK
Time taken: 90.848 seconds, Fetched: 506 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.353 seconds
Query ID = boss_20180103182741_20655673-a896-4d99-ad35-93b4eb3fe1ee
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169966, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169966/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169966
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:27:52,946 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:28:11,531 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 14.31 sec
2018-01-03 18:28:12,562 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 16.04 sec
2018-01-03 18:28:18,768 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.89 sec
MapReduce Total cumulative CPU time: 21 seconds 890 msec
Ended Job = job_1513599404024_169966
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169972, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169972/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169972
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:28:32,449 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:28:36,576 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.83 sec
2018-01-03 18:28:37,607 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.36 sec
2018-01-03 18:28:44,815 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.98 sec
MapReduce Total cumulative CPU time: 13 seconds 980 msec
Ended Job = job_1513599404024_169972
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169974, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169974/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169974
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:28:52,554 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:29:04,982 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.7 sec
2018-01-03 18:29:10,133 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.95 sec
MapReduce Total cumulative CPU time: 4 seconds 950 msec
Ended Job = job_1513599404024_169974
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 21.89 sec   HDFS Read: 8756763 HDFS Write: 418919 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.98 sec   HDFS Read: 37926260 HDFS Write: 115831 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.95 sec   HDFS Read: 123465 HDFS Write: 2105 SUCCESS
Total MapReduce CPU Time Spent: 40 seconds 820 msec
OK
Time taken: 89.228 seconds, Fetched: 300 row(s)
开始执行20171220日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103182918_ff316578-cf4c-46ba-af06-ed307affa569
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169978, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169978/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169978
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 18:29:27,022 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:29:37,376 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 22.53 sec
2018-01-03 18:29:40,478 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 26.58 sec
2018-01-03 18:29:43,572 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 29.92 sec
2018-01-03 18:29:46,662 Stage-1 map = 64%,  reduce = 0%, Cumulative CPU 33.21 sec
2018-01-03 18:29:47,701 Stage-1 map = 64%,  reduce = 8%, Cumulative CPU 33.95 sec
2018-01-03 18:29:49,777 Stage-1 map = 67%,  reduce = 8%, Cumulative CPU 37.21 sec
2018-01-03 18:29:52,867 Stage-1 map = 71%,  reduce = 8%, Cumulative CPU 40.5 sec
2018-01-03 18:29:54,924 Stage-1 map = 74%,  reduce = 8%, Cumulative CPU 43.64 sec
2018-01-03 18:29:55,953 Stage-1 map = 74%,  reduce = 17%, Cumulative CPU 44.3 sec
2018-01-03 18:29:58,012 Stage-1 map = 77%,  reduce = 17%, Cumulative CPU 47.47 sec
2018-01-03 18:30:01,102 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 51.45 sec
2018-01-03 18:30:04,190 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 55.19 sec
2018-01-03 18:30:05,220 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 59.87 sec
2018-01-03 18:30:06,249 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 64.6 sec
MapReduce Total cumulative CPU time: 1 minutes 4 seconds 600 msec
Ended Job = job_1513599404024_169978
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169983, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169983/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169983
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:30:13,118 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:30:18,280 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.14 sec
2018-01-03 18:30:30,639 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.53 sec
MapReduce Total cumulative CPU time: 14 seconds 530 msec
Ended Job = job_1513599404024_169983
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169985, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169985/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169985
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:30:37,288 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:30:42,445 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.86 sec
2018-01-03 18:30:49,672 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.46 sec
MapReduce Total cumulative CPU time: 5 seconds 460 msec
Ended Job = job_1513599404024_169985
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 64.6 sec   HDFS Read: 160989036 HDFS Write: 857222 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.53 sec   HDFS Read: 37562889 HDFS Write: 97969 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.46 sec   HDFS Read: 105644 HDFS Write: 2524 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 24 seconds 590 msec
OK
Time taken: 92.621 seconds, Fetched: 342 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.395 seconds
Query ID = boss_20180103183105_daa006dd-cebf-487d-b5e4-a012fb42e529
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169990, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169990/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169990
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 18:31:15,431 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:31:25,789 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 37.71 sec
2018-01-03 18:31:28,890 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 50.18 sec
2018-01-03 18:31:30,953 Stage-1 map = 33%,  reduce = 0%, Cumulative CPU 53.37 sec
2018-01-03 18:31:31,985 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 60.08 sec
2018-01-03 18:31:34,047 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 66.59 sec
2018-01-03 18:31:35,079 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 70.58 sec
2018-01-03 18:31:36,110 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 75.79 sec
2018-01-03 18:31:37,141 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 79.62 sec
2018-01-03 18:31:41,281 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 91.26 sec
MapReduce Total cumulative CPU time: 1 minutes 31 seconds 260 msec
Ended Job = job_1513599404024_169990
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169997, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169997/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169997
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:31:55,037 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:32:01,248 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.31 sec
2018-01-03 18:32:08,487 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.38 sec
MapReduce Total cumulative CPU time: 14 seconds 380 msec
Ended Job = job_1513599404024_169997
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_169999, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_169999/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_169999
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:32:14,148 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:32:27,520 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec
2018-01-03 18:32:34,719 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.24 sec
MapReduce Total cumulative CPU time: 6 seconds 240 msec
Ended Job = job_1513599404024_169999
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 91.26 sec   HDFS Read: 331034355 HDFS Write: 247326 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.38 sec   HDFS Read: 36953255 HDFS Write: 21911 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.24 sec   HDFS Read: 29587 HDFS Write: 2017 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 51 seconds 880 msec
OK
Time taken: 90.281 seconds, Fetched: 294 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.361 seconds
Query ID = boss_20180103183242_29e1ca2b-5158-4e3c-a0ec-ed4bb7568b8e
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170003, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170003/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170003
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:32:52,042 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:33:02,454 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 9.84 sec
2018-01-03 18:33:04,523 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.56 sec
2018-01-03 18:33:10,711 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.99 sec
MapReduce Total cumulative CPU time: 17 seconds 990 msec
Ended Job = job_1513599404024_170003
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170005, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170005/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170005
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:33:24,377 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:33:29,542 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.74 sec
2018-01-03 18:33:34,693 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.62 sec
MapReduce Total cumulative CPU time: 14 seconds 620 msec
Ended Job = job_1513599404024_170005
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170007, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170007/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170007
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:33:41,331 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:33:46,492 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec
2018-01-03 18:33:51,645 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.5 sec
MapReduce Total cumulative CPU time: 5 seconds 500 msec
Ended Job = job_1513599404024_170007
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.99 sec   HDFS Read: 8268737 HDFS Write: 314771 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.62 sec   HDFS Read: 37020120 HDFS Write: 117610 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.5 sec   HDFS Read: 125247 HDFS Write: 4450 SUCCESS
Total MapReduce CPU Time Spent: 38 seconds 110 msec
OK
Time taken: 71.208 seconds, Fetched: 525 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103183400_5bfa3459-edae-4a49-b235-fd306c62a189
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170009, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170009/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170009
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:34:10,240 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:34:19,602 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.15 sec
2018-01-03 18:34:24,782 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.02 sec
MapReduce Total cumulative CPU time: 17 seconds 20 msec
Ended Job = job_1513599404024_170009
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170011, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170011/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170011
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:34:38,572 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:34:43,751 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.08 sec
2018-01-03 18:34:45,824 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.22 sec
2018-01-03 18:35:32,169 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.92 sec
MapReduce Total cumulative CPU time: 12 seconds 920 msec
Ended Job = job_1513599404024_170011
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170017, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170017/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170017
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:35:37,796 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:35:42,945 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.49 sec
2018-01-03 18:35:50,142 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.37 sec
MapReduce Total cumulative CPU time: 6 seconds 370 msec
Ended Job = job_1513599404024_170017
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.02 sec   HDFS Read: 8268727 HDFS Write: 375787 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.92 sec   HDFS Read: 37081136 HDFS Write: 96548 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.37 sec   HDFS Read: 104186 HDFS Write: 2520 SUCCESS
Total MapReduce CPU Time Spent: 36 seconds 310 msec
OK
Time taken: 110.721 seconds, Fetched: 310 row(s)
开始执行20171221日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.371 seconds
Query ID = boss_20180103183558_39133e1d-d42b-4964-9f4f-530b94252ac8
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170020, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170020/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170020
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 18:36:07,031 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:36:14,292 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 10.85 sec
2018-01-03 18:36:17,394 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 23.75 sec
2018-01-03 18:36:20,495 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 27.0 sec
2018-01-03 18:36:23,589 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 30.31 sec
2018-01-03 18:36:24,628 Stage-1 map = 57%,  reduce = 8%, Cumulative CPU 30.76 sec
2018-01-03 18:36:26,690 Stage-1 map = 62%,  reduce = 8%, Cumulative CPU 33.86 sec
2018-01-03 18:36:28,751 Stage-1 map = 64%,  reduce = 8%, Cumulative CPU 37.28 sec
2018-01-03 18:36:30,814 Stage-1 map = 64%,  reduce = 17%, Cumulative CPU 37.99 sec
2018-01-03 18:36:31,843 Stage-1 map = 67%,  reduce = 17%, Cumulative CPU 41.08 sec
2018-01-03 18:36:34,932 Stage-1 map = 71%,  reduce = 17%, Cumulative CPU 44.41 sec
2018-01-03 18:36:38,020 Stage-1 map = 73%,  reduce = 17%, Cumulative CPU 47.52 sec
2018-01-03 18:36:41,111 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 50.7 sec
2018-01-03 18:36:44,196 Stage-1 map = 80%,  reduce = 17%, Cumulative CPU 54.85 sec
2018-01-03 18:36:47,282 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 58.06 sec
2018-01-03 18:36:48,315 Stage-1 map = 100%,  reduce = 95%, Cumulative CPU 64.92 sec
2018-01-03 18:36:49,344 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 65.5 sec
MapReduce Total cumulative CPU time: 1 minutes 5 seconds 500 msec
Ended Job = job_1513599404024_170020
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170025, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170025/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170025
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:37:03,071 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:37:08,243 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.69 sec
2018-01-03 18:37:17,531 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.98 sec
MapReduce Total cumulative CPU time: 16 seconds 980 msec
Ended Job = job_1513599404024_170025
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170027, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170027/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170027
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:37:29,205 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:37:42,609 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.0 sec
2018-01-03 18:37:48,789 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.58 sec
MapReduce Total cumulative CPU time: 5 seconds 580 msec
Ended Job = job_1513599404024_170027
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 65.5 sec   HDFS Read: 161220395 HDFS Write: 1043487 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.98 sec   HDFS Read: 37455072 HDFS Write: 105053 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.58 sec   HDFS Read: 112728 HDFS Write: 2692 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 28 seconds 60 msec
OK
Time taken: 111.754 seconds, Fetched: 354 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.399 seconds
Query ID = boss_20180103183756_7f178560-de80-4c12-9741-c2d46b15d690
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170032, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170032/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170032
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 18:38:06,656 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:38:16,013 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 12.95 sec
2018-01-03 18:38:17,050 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 24.13 sec
2018-01-03 18:38:19,123 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 31.45 sec
2018-01-03 18:38:22,228 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 38.42 sec
2018-01-03 18:38:24,295 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 40.73 sec
2018-01-03 18:38:25,328 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 54.13 sec
2018-01-03 18:38:28,425 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 58.36 sec
2018-01-03 18:38:31,545 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 61.89 sec
2018-01-03 18:38:32,585 Stage-1 map = 79%,  reduce = 15%, Cumulative CPU 62.96 sec
2018-01-03 18:38:34,654 Stage-1 map = 83%,  reduce = 15%, Cumulative CPU 66.17 sec
2018-01-03 18:38:37,761 Stage-1 map = 87%,  reduce = 15%, Cumulative CPU 69.32 sec
2018-01-03 18:38:38,797 Stage-1 map = 100%,  reduce = 15%, Cumulative CPU 71.91 sec
2018-01-03 18:38:39,830 Stage-1 map = 100%,  reduce = 41%, Cumulative CPU 74.59 sec
2018-01-03 18:38:40,862 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 85.53 sec
MapReduce Total cumulative CPU time: 1 minutes 25 seconds 530 msec
Ended Job = job_1513599404024_170032
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170034, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170034/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170034
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:38:48,624 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:38:54,819 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.56 sec
2018-01-03 18:38:55,850 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.52 sec
2018-01-03 18:38:59,973 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.77 sec
MapReduce Total cumulative CPU time: 14 seconds 770 msec
Ended Job = job_1513599404024_170034
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170035, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170035/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170035
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:39:50,704 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:39:54,834 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.3 sec
2018-01-03 18:39:59,984 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.31 sec
MapReduce Total cumulative CPU time: 4 seconds 310 msec
Ended Job = job_1513599404024_170035
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 85.53 sec   HDFS Read: 264547799 HDFS Write: 213108 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.77 sec   HDFS Read: 36624955 HDFS Write: 17036 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.31 sec   HDFS Read: 24712 HDFS Write: 1874 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 44 seconds 610 msec
OK
Time taken: 124.352 seconds, Fetched: 278 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.373 seconds
Query ID = boss_20180103184007_db6697cb-faff-499f-b5bb-67e85ebc40af
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170049, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170049/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170049
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:40:18,249 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:40:28,623 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 11.47 sec
2018-01-03 18:40:30,699 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.86 sec
2018-01-03 18:40:51,548 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 20.13 sec
2018-01-03 18:40:54,646 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 26.12 sec
MapReduce Total cumulative CPU time: 26 seconds 120 msec
Ended Job = job_1513599404024_170049
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170052, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170052/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170052
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:41:15,909 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:41:23,138 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.94 sec
2018-01-03 18:41:27,260 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 14.96 sec
2018-01-03 18:41:42,695 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 22.16 sec
MapReduce Total cumulative CPU time: 22 seconds 160 msec
Ended Job = job_1513599404024_170052
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170057, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170057/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170057
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:41:50,369 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:41:55,526 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.93 sec
2018-01-03 18:42:01,705 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.41 sec
MapReduce Total cumulative CPU time: 5 seconds 410 msec
Ended Job = job_1513599404024_170057
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 26.12 sec   HDFS Read: 9299136 HDFS Write: 341588 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 22.16 sec   HDFS Read: 36752855 HDFS Write: 118342 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.41 sec   HDFS Read: 125979 HDFS Write: 4703 SUCCESS
Total MapReduce CPU Time Spent: 53 seconds 690 msec
OK
Time taken: 114.998 seconds, Fetched: 587 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.355 seconds
Query ID = boss_20180103184209_73cbf84b-3ec9-47a3-87d8-722ff79f9d23
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170060, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170060/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170060
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:42:19,330 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:42:27,666 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 11.81 sec
2018-01-03 18:42:33,860 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.66 sec
MapReduce Total cumulative CPU time: 16 seconds 660 msec
Ended Job = job_1513599404024_170060
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170063, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170063/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170063
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:42:40,564 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:42:45,729 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.28 sec
2018-01-03 18:42:52,945 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.67 sec
2018-01-03 18:42:55,005 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 15.85 sec
MapReduce Total cumulative CPU time: 15 seconds 850 msec
Ended Job = job_1513599404024_170063
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170065, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170065/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170065
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:43:01,661 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:43:06,823 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec
2018-01-03 18:43:14,040 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.47 sec
MapReduce Total cumulative CPU time: 5 seconds 470 msec
Ended Job = job_1513599404024_170065
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.66 sec   HDFS Read: 9299126 HDFS Write: 433390 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 15.85 sec   HDFS Read: 36844657 HDFS Write: 95711 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.47 sec   HDFS Read: 103349 HDFS Write: 2275 SUCCESS
Total MapReduce CPU Time Spent: 37 seconds 980 msec
OK
Time taken: 65.226 seconds, Fetched: 323 row(s)
开始执行20171222日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.359 seconds
Query ID = boss_20180103184321_da094276-3c88-4671-8235-2a2fb64cd05f
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170068, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170068/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170068
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 18:43:32,004 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:43:42,373 Stage-1 map = 4%,  reduce = 0%, Cumulative CPU 12.06 sec
2018-01-03 18:43:45,476 Stage-1 map = 6%,  reduce = 0%, Cumulative CPU 16.37 sec
2018-01-03 18:43:48,571 Stage-1 map = 9%,  reduce = 0%, Cumulative CPU 19.66 sec
2018-01-03 18:43:51,662 Stage-1 map = 12%,  reduce = 0%, Cumulative CPU 23.21 sec
2018-01-03 18:43:52,693 Stage-1 map = 62%,  reduce = 0%, Cumulative CPU 36.68 sec
2018-01-03 18:43:54,758 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 39.7 sec
2018-01-03 18:43:57,850 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 42.81 sec
2018-01-03 18:44:00,940 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 45.94 sec
2018-01-03 18:44:03,005 Stage-1 map = 72%,  reduce = 8%, Cumulative CPU 46.43 sec
2018-01-03 18:44:04,042 Stage-1 map = 75%,  reduce = 8%, Cumulative CPU 49.53 sec
2018-01-03 18:44:07,132 Stage-1 map = 78%,  reduce = 8%, Cumulative CPU 53.23 sec
2018-01-03 18:44:09,191 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 57.44 sec
2018-01-03 18:44:11,251 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 59.79 sec
2018-01-03 18:44:12,280 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 64.05 sec
2018-01-03 18:44:13,313 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 69.61 sec
MapReduce Total cumulative CPU time: 1 minutes 9 seconds 610 msec
Ended Job = job_1513599404024_170068
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170073, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170073/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170073
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:44:18,972 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:44:25,155 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 10.96 sec
2018-01-03 18:44:32,359 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.2 sec
MapReduce Total cumulative CPU time: 17 seconds 200 msec
Ended Job = job_1513599404024_170073
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170078, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170078/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170078
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:44:52,065 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:44:57,232 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.75 sec
2018-01-03 18:45:03,425 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.36 sec
MapReduce Total cumulative CPU time: 5 seconds 360 msec
Ended Job = job_1513599404024_170078
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 69.61 sec   HDFS Read: 174491096 HDFS Write: 1104777 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.2 sec   HDFS Read: 37606055 HDFS Write: 111148 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.36 sec   HDFS Read: 118823 HDFS Write: 2672 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 32 seconds 170 msec
OK
Time taken: 102.501 seconds, Fetched: 354 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.395 seconds
Query ID = boss_20180103184511_beccf216-7537-4989-b6d8-f6aafc22fb7a
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170082, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170082/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170082
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 18:45:28,981 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:45:34,176 Stage-1 map = 33%,  reduce = 0%
2018-01-03 18:45:39,347 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 33.44 sec
2018-01-03 18:45:42,450 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 37.34 sec
2018-01-03 18:45:43,481 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 41.6 sec
2018-01-03 18:45:44,520 Stage-1 map = 45%,  reduce = 7%, Cumulative CPU 42.59 sec
2018-01-03 18:45:45,551 Stage-1 map = 49%,  reduce = 7%, Cumulative CPU 49.83 sec
2018-01-03 18:45:48,643 Stage-1 map = 55%,  reduce = 7%, Cumulative CPU 56.68 sec
2018-01-03 18:45:51,741 Stage-1 map = 60%,  reduce = 7%, Cumulative CPU 63.01 sec
2018-01-03 18:45:52,771 Stage-1 map = 60%,  reduce = 11%, Cumulative CPU 63.5 sec
2018-01-03 18:45:54,831 Stage-1 map = 66%,  reduce = 11%, Cumulative CPU 70.09 sec
2018-01-03 18:45:57,920 Stage-1 map = 72%,  reduce = 11%, Cumulative CPU 76.49 sec
2018-01-03 18:45:59,979 Stage-1 map = 85%,  reduce = 19%, Cumulative CPU 79.84 sec
2018-01-03 18:46:01,011 Stage-1 map = 88%,  reduce = 19%, Cumulative CPU 82.69 sec
2018-01-03 18:46:02,040 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 84.5 sec
2018-01-03 18:46:03,069 Stage-1 map = 100%,  reduce = 52%, Cumulative CPU 85.48 sec
2018-01-03 18:46:04,097 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 94.43 sec
MapReduce Total cumulative CPU time: 1 minutes 34 seconds 430 msec
Ended Job = job_1513599404024_170082
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170088, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170088/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170088
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:46:09,785 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:46:13,910 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 3.65 sec
2018-01-03 18:46:25,227 Stage-2 map = 50%,  reduce = 17%, Cumulative CPU 4.2 sec
2018-01-03 18:46:30,369 Stage-2 map = 100%,  reduce = 17%, Cumulative CPU 9.82 sec
2018-01-03 18:46:31,397 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 13.55 sec
MapReduce Total cumulative CPU time: 13 seconds 550 msec
Ended Job = job_1513599404024_170088
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170091, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170091/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170091
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:46:38,032 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:46:50,393 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.35 sec
2018-01-03 18:46:55,562 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.64 sec
MapReduce Total cumulative CPU time: 4 seconds 640 msec
Ended Job = job_1513599404024_170091
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 94.43 sec   HDFS Read: 260688516 HDFS Write: 204696 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 13.55 sec   HDFS Read: 36706236 HDFS Write: 17483 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.64 sec   HDFS Read: 25159 HDFS Write: 1839 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 52 seconds 620 msec
OK
Time taken: 105.186 seconds, Fetched: 269 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.352 seconds
Query ID = boss_20180103184703_fec65ad4-466d-40de-adc0-7012c4601c7b
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170093, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170093/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170093
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:47:12,866 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:47:23,276 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 10.82 sec
2018-01-03 18:47:24,311 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.73 sec
2018-01-03 18:47:30,506 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.11 sec
MapReduce Total cumulative CPU time: 16 seconds 110 msec
Ended Job = job_1513599404024_170093
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170095, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170095/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170095
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:47:36,248 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:47:41,429 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.59 sec
2018-01-03 18:47:42,463 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.04 sec
2018-01-03 18:47:47,627 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.99 sec
MapReduce Total cumulative CPU time: 12 seconds 990 msec
Ended Job = job_1513599404024_170095
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170096, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170096/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170096
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:48:01,369 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:48:05,496 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.75 sec
2018-01-03 18:48:11,669 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.61 sec
MapReduce Total cumulative CPU time: 5 seconds 610 msec
Ended Job = job_1513599404024_170096
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.11 sec   HDFS Read: 9984378 HDFS Write: 330657 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.99 sec   HDFS Read: 36831617 HDFS Write: 125994 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.61 sec   HDFS Read: 133631 HDFS Write: 4860 SUCCESS
Total MapReduce CPU Time Spent: 34 seconds 710 msec
OK
Time taken: 69.397 seconds, Fetched: 612 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.432 seconds
Query ID = boss_20180103184819_d2dae3f1-bcfc-4e1b-a3b1-1c974bb89340
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170098, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170098/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170098
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:48:29,523 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:48:39,868 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 10.48 sec
2018-01-03 18:48:40,901 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.81 sec
2018-01-03 18:48:47,091 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.64 sec
MapReduce Total cumulative CPU time: 17 seconds 640 msec
Ended Job = job_1513599404024_170098
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170100, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170100/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170100
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:49:06,864 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:49:12,045 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.17 sec
2018-01-03 18:49:13,080 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 7.85 sec
2018-01-03 18:49:18,243 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.9 sec
MapReduce Total cumulative CPU time: 12 seconds 900 msec
Ended Job = job_1513599404024_170100
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170103, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170103/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170103
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:49:23,863 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:49:27,988 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.72 sec
2018-01-03 18:49:39,327 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.58 sec
MapReduce Total cumulative CPU time: 5 seconds 580 msec
Ended Job = job_1513599404024_170103
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.64 sec   HDFS Read: 9984368 HDFS Write: 456762 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 12.9 sec   HDFS Read: 36957722 HDFS Write: 110498 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.58 sec   HDFS Read: 118136 HDFS Write: 2111 SUCCESS
Total MapReduce CPU Time Spent: 36 seconds 120 msec
OK
Time taken: 80.884 seconds, Fetched: 306 row(s)
开始执行20171223日的脚本

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.362 seconds
Query ID = boss_20180103184947_1b507b01-5c1c-4294-b69c-aaf673a6b3f7
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170106, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170106/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170106
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2018-01-03 18:49:57,435 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:50:07,793 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 12.52 sec
2018-01-03 18:50:10,894 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 17.14 sec
2018-01-03 18:50:13,988 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 33.9 sec
2018-01-03 18:50:17,081 Stage-1 map = 30%,  reduce = 0%, Cumulative CPU 40.8 sec
2018-01-03 18:50:20,175 Stage-1 map = 41%,  reduce = 0%, Cumulative CPU 47.53 sec
2018-01-03 18:50:22,260 Stage-1 map = 65%,  reduce = 0%, Cumulative CPU 51.4 sec
2018-01-03 18:50:23,291 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 54.36 sec
2018-01-03 18:50:26,392 Stage-1 map = 72%,  reduce = 0%, Cumulative CPU 57.53 sec
2018-01-03 18:50:29,483 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 60.54 sec
2018-01-03 18:50:32,570 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 64.05 sec
2018-01-03 18:50:33,604 Stage-1 map = 78%,  reduce = 17%, Cumulative CPU 65.02 sec
2018-01-03 18:50:34,635 Stage-1 map = 81%,  reduce = 17%, Cumulative CPU 68.42 sec
2018-01-03 18:50:36,697 Stage-1 map = 100%,  reduce = 17%, Cumulative CPU 68.51 sec
2018-01-03 18:50:37,727 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 75.11 sec
2018-01-03 18:50:38,759 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 79.43 sec
MapReduce Total cumulative CPU time: 1 minutes 19 seconds 430 msec
Ended Job = job_1513599404024_170106
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170110, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170110/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170110
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:50:44,440 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:50:50,630 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.3 sec
2018-01-03 18:50:58,864 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 17.97 sec
MapReduce Total cumulative CPU time: 17 seconds 970 msec
Ended Job = job_1513599404024_170110
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170111, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170111/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170111
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:51:04,483 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:51:08,602 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.89 sec
2018-01-03 18:51:14,779 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.24 sec
MapReduce Total cumulative CPU time: 6 seconds 240 msec
Ended Job = job_1513599404024_170111
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 79.43 sec   HDFS Read: 212976129 HDFS Write: 1298234 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 17.97 sec   HDFS Read: 39839510 HDFS Write: 129195 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.24 sec   HDFS Read: 136870 HDFS Write: 2680 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 43 seconds 640 msec
OK
Time taken: 88.545 seconds, Fetched: 350 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.374 seconds
Query ID = boss_20180103185122_5d2bb7ca-2b53-4069-869e-76b43bf57c86
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 3
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170114, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170114/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170114
Hadoop job information for Stage-1: number of mappers: 3; number of reducers: 3
2018-01-03 18:51:32,755 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:51:43,115 Stage-1 map = 14%,  reduce = 0%, Cumulative CPU 26.09 sec
2018-01-03 18:51:46,214 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 33.4 sec
2018-01-03 18:51:48,278 Stage-1 map = 40%,  reduce = 0%, Cumulative CPU 36.89 sec
2018-01-03 18:51:49,310 Stage-1 map = 43%,  reduce = 0%, Cumulative CPU 40.69 sec
2018-01-03 18:51:51,373 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 53.57 sec
2018-01-03 18:51:52,404 Stage-1 map = 49%,  reduce = 0%, Cumulative CPU 57.25 sec
2018-01-03 18:51:54,466 Stage-1 map = 52%,  reduce = 0%, Cumulative CPU 61.07 sec
2018-01-03 18:51:55,502 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 64.2 sec
2018-01-03 18:51:57,562 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 67.64 sec
2018-01-03 18:51:58,598 Stage-1 map = 60%,  reduce = 11%, Cumulative CPU 72.53 sec
2018-01-03 18:52:00,661 Stage-1 map = 62%,  reduce = 11%, Cumulative CPU 76.1 sec
2018-01-03 18:52:01,693 Stage-1 map = 65%,  reduce = 11%, Cumulative CPU 79.4 sec
2018-01-03 18:52:02,724 Stage-1 map = 68%,  reduce = 11%, Cumulative CPU 79.4 sec
2018-01-03 18:52:03,754 Stage-1 map = 81%,  reduce = 11%, Cumulative CPU 86.76 sec
2018-01-03 18:52:04,788 Stage-1 map = 81%,  reduce = 22%, Cumulative CPU 87.03 sec
2018-01-03 18:52:05,818 Stage-1 map = 84%,  reduce = 22%, Cumulative CPU 90.28 sec
2018-01-03 18:52:08,905 Stage-1 map = 86%,  reduce = 22%, Cumulative CPU 94.16 sec
2018-01-03 18:52:11,993 Stage-1 map = 100%,  reduce = 22%, Cumulative CPU 98.44 sec
2018-01-03 18:52:13,022 Stage-1 map = 100%,  reduce = 74%, Cumulative CPU 105.46 sec
2018-01-03 18:52:14,055 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 110.03 sec
MapReduce Total cumulative CPU time: 1 minutes 50 seconds 30 msec
Ended Job = job_1513599404024_170114
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170119, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170119/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170119
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:52:19,785 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:52:30,135 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.74 sec
2018-01-03 18:52:31,167 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 11.26 sec
2018-01-03 18:52:35,299 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 16.22 sec
MapReduce Total cumulative CPU time: 16 seconds 220 msec
Ended Job = job_1513599404024_170119
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170120, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170120/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170120
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:52:43,212 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:52:49,412 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.15 sec
2018-01-03 18:52:55,604 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.23 sec
MapReduce Total cumulative CPU time: 6 seconds 230 msec
Ended Job = job_1513599404024_170120
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 3  Reduce: 3   Cumulative CPU: 110.03 sec   HDFS Read: 328750140 HDFS Write: 252912 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 16.22 sec   HDFS Read: 38794450 HDFS Write: 18644 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.23 sec   HDFS Read: 26320 HDFS Write: 1874 SUCCESS
Total MapReduce CPU Time Spent: 2 minutes 12 seconds 480 msec
OK
Time taken: 94.083 seconds, Fetched: 266 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.357 seconds
Query ID = boss_20180103185303_556177b0-5990-4386-b3ff-18699f89ec93
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170123, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170123/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170123
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:53:14,936 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:53:26,320 Stage-1 map = 23%,  reduce = 0%, Cumulative CPU 10.08 sec
2018-01-03 18:53:29,421 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 14.11 sec
2018-01-03 18:53:31,484 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.93 sec
2018-01-03 18:53:38,867 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.88 sec
MapReduce Total cumulative CPU time: 19 seconds 880 msec
Ended Job = job_1513599404024_170123
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170128, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170128/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170128
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:54:15,687 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:54:20,851 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 5.24 sec
2018-01-03 18:54:29,116 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 9.66 sec
2018-01-03 18:54:42,493 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.83 sec
MapReduce Total cumulative CPU time: 14 seconds 830 msec
Ended Job = job_1513599404024_170128
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170134, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170134/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170134
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:54:50,155 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:54:56,458 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.78 sec
2018-01-03 18:55:01,608 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.68 sec
MapReduce Total cumulative CPU time: 7 seconds 680 msec
Ended Job = job_1513599404024_170134
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.88 sec   HDFS Read: 11179962 HDFS Write: 346736 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.83 sec   HDFS Read: 38887690 HDFS Write: 141415 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.68 sec   HDFS Read: 149048 HDFS Write: 5187 SUCCESS
Total MapReduce CPU Time Spent: 42 seconds 390 msec
OK
Time taken: 119.313 seconds, Fetched: 625 row(s)

Logging initialized using configuration in file:/letv/usr/local/apache-hive-1.2.1-bin/conf/hive-log4j.properties
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/letv/usr/local/tez-0.8.4-minimal/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/letv/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Added [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar] to class path
Added resources: [/home/boss/shell/hive/common_stat/inner_channel_stat/channel/boss-hive-1.0-SNAPSHOT.jar]
OK
Time taken: 1.354 seconds
Query ID = boss_20180103185509_9df297b6-8b37-48c3-acfd-b61af04527da
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170137, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170137/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170137
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2018-01-03 18:55:19,144 Stage-1 map = 0%,  reduce = 0%
2018-01-03 18:55:30,517 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 11.81 sec
2018-01-03 18:55:33,611 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.21 sec
2018-01-03 18:55:38,765 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 19.35 sec
MapReduce Total cumulative CPU time: 19 seconds 350 msec
Ended Job = job_1513599404024_170137
Stage-7 is filtered out by condition resolver.
Stage-2 is selected by condition resolver.
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170142, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170142/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170142
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
2018-01-03 18:55:54,487 Stage-2 map = 0%,  reduce = 0%
2018-01-03 18:55:58,844 Stage-2 map = 50%,  reduce = 0%, Cumulative CPU 4.08 sec
2018-01-03 18:55:59,878 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.29 sec
2018-01-03 18:56:05,028 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 14.32 sec
MapReduce Total cumulative CPU time: 14 seconds 320 msec
Ended Job = job_1513599404024_170142
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513599404024_170145, Tracking URL = http://letv-rm1:50030/proxy/application_1513599404024_170145/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1513599404024_170145
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2018-01-03 18:56:19,742 Stage-3 map = 0%,  reduce = 0%
2018-01-03 18:56:25,926 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.98 sec
2018-01-03 18:56:31,067 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.29 sec
MapReduce Total cumulative CPU time: 7 seconds 290 msec
Ended Job = job_1513599404024_170145
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 19.35 sec   HDFS Read: 11179953 HDFS Write: 530626 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 14.32 sec   HDFS Read: 39071584 HDFS Write: 118447 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.29 sec   HDFS Read: 126085 HDFS Write: 2271 SUCCESS
Total MapReduce CPU Time Spent: 40 seconds 960 msec
OK
Time taken: 82.744 seconds, Fetched: 328 row(s)
